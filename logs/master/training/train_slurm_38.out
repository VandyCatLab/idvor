2021-07-02 02:17:36.600086: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 02:19:11.053425: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-07-02 02:19:11.081040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-02 02:19:11.081145: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 02:19:11.124461: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-02 02:19:11.146538: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-02 02:19:11.155394: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-02 02:19:11.201530: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-02 02:19:11.210537: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-02 02:19:11.308342: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 02:19:11.310930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-02 02:19:11.315159: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-02 02:19:11.332969: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599865000 Hz
2021-07-02 02:19:11.333169: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5bd99c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-07-02 02:19:11.333192: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-07-02 02:19:11.491867: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5bbbab0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-07-02 02:19:11.491948: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN X (Pascal), Compute Capability 6.1
2021-07-02 02:19:11.496076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-02 02:19:11.496211: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 02:19:11.496265: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-02 02:19:11.496288: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-02 02:19:11.496307: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-02 02:19:11.496327: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-02 02:19:11.496346: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-02 02:19:11.497193: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 02:19:11.503638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-02 02:19:11.505578: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 02:19:13.467190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-02 02:19:13.467276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-07-02 02:19:13.467289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-07-02 02:19:13.475322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11228 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)
2021-07-02 02:19:19.894161: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 02:19:34.023592: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
Using model index: 38
Making train data...
GCN...
ZCA...
Done!
Making test data...
Done!
Epoch 1/350


Snapshot weight 8 shuffle 3 at epoch 1
Layer 11
Getting activations...


391/391 - 25s - loss: 2.3115 - accuracy: 0.1205 - val_loss: 2.2935 - val_accuracy: 0.1312
Epoch 2/350


Snapshot weight 8 shuffle 3 at epoch 2
Layer 11
Getting activations...


391/391 - 25s - loss: 2.1152 - accuracy: 0.2371 - val_loss: 1.8975 - val_accuracy: 0.3189
Epoch 3/350


Snapshot weight 8 shuffle 3 at epoch 3
Layer 11
Getting activations...


391/391 - 25s - loss: 1.7810 - accuracy: 0.3509 - val_loss: 1.7467 - val_accuracy: 0.3701
Epoch 4/350


Snapshot weight 8 shuffle 3 at epoch 4
Layer 11
Getting activations...


391/391 - 25s - loss: 1.5343 - accuracy: 0.4521 - val_loss: 1.5049 - val_accuracy: 0.4766
Epoch 5/350


Snapshot weight 8 shuffle 3 at epoch 5
Layer 11
Getting activations...


391/391 - 25s - loss: 1.3691 - accuracy: 0.5151 - val_loss: 1.1998 - val_accuracy: 0.5781
Epoch 6/350


Snapshot weight 8 shuffle 3 at epoch 6
Layer 11
Getting activations...


391/391 - 25s - loss: 1.2874 - accuracy: 0.5465 - val_loss: 1.1725 - val_accuracy: 0.5969
Epoch 7/350


Snapshot weight 8 shuffle 3 at epoch 7
Layer 11
Getting activations...


391/391 - 25s - loss: 1.1831 - accuracy: 0.5830 - val_loss: 1.2158 - val_accuracy: 0.5779
Epoch 8/350


Snapshot weight 8 shuffle 3 at epoch 8
Layer 11
Getting activations...


391/391 - 25s - loss: 1.1200 - accuracy: 0.6103 - val_loss: 1.0444 - val_accuracy: 0.6448
Epoch 9/350


Snapshot weight 8 shuffle 3 at epoch 9
Layer 11
Getting activations...


391/391 - 25s - loss: 1.0712 - accuracy: 0.6276 - val_loss: 0.9571 - val_accuracy: 0.6676
Epoch 10/350


Snapshot weight 8 shuffle 3 at epoch 10
Layer 11
Getting activations...


391/391 - 25s - loss: 1.0166 - accuracy: 0.6454 - val_loss: 0.8934 - val_accuracy: 0.6871
Epoch 11/350
391/391 - 25s - loss: 0.9866 - accuracy: 0.6579 - val_loss: 0.9637 - val_accuracy: 0.6709
Epoch 12/350
391/391 - 25s - loss: 0.9514 - accuracy: 0.6717 - val_loss: 0.9158 - val_accuracy: 0.6893
Epoch 13/350
391/391 - 25s - loss: 0.9083 - accuracy: 0.6881 - val_loss: 0.9306 - val_accuracy: 0.6893
Epoch 14/350
391/391 - 25s - loss: 0.8836 - accuracy: 0.6965 - val_loss: 0.8387 - val_accuracy: 0.7131
Epoch 15/350
391/391 - 25s - loss: 0.8508 - accuracy: 0.7102 - val_loss: 0.8162 - val_accuracy: 0.7277
Epoch 16/350
391/391 - 25s - loss: 0.8273 - accuracy: 0.7196 - val_loss: 0.7496 - val_accuracy: 0.7505
Epoch 17/350
391/391 - 25s - loss: 0.7975 - accuracy: 0.7309 - val_loss: 0.7611 - val_accuracy: 0.7462
Epoch 18/350
391/391 - 25s - loss: 0.7607 - accuracy: 0.7442 - val_loss: 0.7750 - val_accuracy: 0.7465
Epoch 19/350
391/391 - 25s - loss: 0.7386 - accuracy: 0.7510 - val_loss: 0.6989 - val_accuracy: 0.7690
Epoch 20/350
391/391 - 25s - loss: 0.7259 - accuracy: 0.7561 - val_loss: 0.6898 - val_accuracy: 0.7771
Epoch 21/350
391/391 - 25s - loss: 0.6913 - accuracy: 0.7683 - val_loss: 0.6954 - val_accuracy: 0.7733
Epoch 22/350
391/391 - 25s - loss: 0.6745 - accuracy: 0.7740 - val_loss: 0.6561 - val_accuracy: 0.7829
Epoch 23/350
391/391 - 25s - loss: 0.6590 - accuracy: 0.7802 - val_loss: 0.6746 - val_accuracy: 0.7847
Epoch 24/350
391/391 - 25s - loss: 0.6431 - accuracy: 0.7846 - val_loss: 0.6253 - val_accuracy: 0.7972
Epoch 25/350
391/391 - 25s - loss: 0.6321 - accuracy: 0.7879 - val_loss: 0.6334 - val_accuracy: 0.7972
Epoch 26/350
391/391 - 25s - loss: 0.6058 - accuracy: 0.7973 - val_loss: 0.6876 - val_accuracy: 0.7848
Epoch 27/350
391/391 - 25s - loss: 0.5947 - accuracy: 0.8039 - val_loss: 0.6093 - val_accuracy: 0.8082
Epoch 28/350
391/391 - 25s - loss: 0.5797 - accuracy: 0.8085 - val_loss: 0.5497 - val_accuracy: 0.8240
Epoch 29/350
391/391 - 25s - loss: 0.5710 - accuracy: 0.8118 - val_loss: 0.6319 - val_accuracy: 0.8008
Epoch 30/350
391/391 - 25s - loss: 0.5660 - accuracy: 0.8133 - val_loss: 0.5815 - val_accuracy: 0.8218
Epoch 31/350
391/391 - 25s - loss: 0.5492 - accuracy: 0.8181 - val_loss: 0.5508 - val_accuracy: 0.8242
Epoch 32/350
391/391 - 25s - loss: 0.5375 - accuracy: 0.8230 - val_loss: 0.5964 - val_accuracy: 0.8094
Epoch 33/350
391/391 - 25s - loss: 0.5204 - accuracy: 0.8300 - val_loss: 0.5304 - val_accuracy: 0.8290
Epoch 34/350
391/391 - 25s - loss: 0.5169 - accuracy: 0.8302 - val_loss: 0.5257 - val_accuracy: 0.8328
Epoch 35/350
391/391 - 25s - loss: 0.5130 - accuracy: 0.8322 - val_loss: 0.4942 - val_accuracy: 0.8449
Epoch 36/350
391/391 - 25s - loss: 0.5006 - accuracy: 0.8367 - val_loss: 0.5256 - val_accuracy: 0.8369
Epoch 37/350
391/391 - 25s - loss: 0.4941 - accuracy: 0.8370 - val_loss: 0.4914 - val_accuracy: 0.8440
Epoch 38/350
391/391 - 25s - loss: 0.4842 - accuracy: 0.8412 - val_loss: 0.5014 - val_accuracy: 0.8436
Epoch 39/350
391/391 - 25s - loss: 0.4731 - accuracy: 0.8468 - val_loss: 0.5395 - val_accuracy: 0.8366
Epoch 40/350
391/391 - 25s - loss: 0.4753 - accuracy: 0.8456 - val_loss: 0.4875 - val_accuracy: 0.8428
Epoch 41/350
391/391 - 25s - loss: 0.4642 - accuracy: 0.8504 - val_loss: 0.4878 - val_accuracy: 0.8498
Epoch 42/350
391/391 - 25s - loss: 0.4547 - accuracy: 0.8517 - val_loss: 0.5154 - val_accuracy: 0.8446
Epoch 43/350
391/391 - 25s - loss: 0.4482 - accuracy: 0.8545 - val_loss: 0.5094 - val_accuracy: 0.8440
Epoch 44/350
391/391 - 25s - loss: 0.4431 - accuracy: 0.8566 - val_loss: 0.4650 - val_accuracy: 0.8527
Epoch 45/350
391/391 - 25s - loss: 0.4309 - accuracy: 0.8588 - val_loss: 0.4868 - val_accuracy: 0.8525
Epoch 46/350
391/391 - 25s - loss: 0.4352 - accuracy: 0.8601 - val_loss: 0.4827 - val_accuracy: 0.8513
Epoch 47/350
391/391 - 25s - loss: 0.4274 - accuracy: 0.8599 - val_loss: 0.4811 - val_accuracy: 0.8563
Epoch 48/350
391/391 - 25s - loss: 0.4193 - accuracy: 0.8653 - val_loss: 0.4785 - val_accuracy: 0.8590
Epoch 49/350
391/391 - 25s - loss: 0.4174 - accuracy: 0.8654 - val_loss: 0.5115 - val_accuracy: 0.8450
Epoch 50/350


Snapshot weight 8 shuffle 3 at epoch 50
Layer 11
Getting activations...


391/391 - 25s - loss: 0.4139 - accuracy: 0.8667 - val_loss: 0.4709 - val_accuracy: 0.8570
Epoch 51/350
391/391 - 25s - loss: 0.4066 - accuracy: 0.8699 - val_loss: 0.4552 - val_accuracy: 0.8535
Epoch 52/350
391/391 - 25s - loss: 0.4000 - accuracy: 0.8715 - val_loss: 0.4423 - val_accuracy: 0.8626
Epoch 53/350
391/391 - 25s - loss: 0.3966 - accuracy: 0.8739 - val_loss: 0.4890 - val_accuracy: 0.8545
Epoch 54/350
391/391 - 25s - loss: 0.3909 - accuracy: 0.8748 - val_loss: 0.4563 - val_accuracy: 0.8600
Epoch 55/350
391/391 - 25s - loss: 0.3893 - accuracy: 0.8744 - val_loss: 0.4589 - val_accuracy: 0.8632
Epoch 56/350
391/391 - 25s - loss: 0.3788 - accuracy: 0.8795 - val_loss: 0.4776 - val_accuracy: 0.8624
Epoch 57/350
391/391 - 25s - loss: 0.3793 - accuracy: 0.8773 - val_loss: 0.4512 - val_accuracy: 0.8636
Epoch 58/350
391/391 - 25s - loss: 0.3736 - accuracy: 0.8816 - val_loss: 0.4585 - val_accuracy: 0.8651
Epoch 59/350
391/391 - 25s - loss: 0.3676 - accuracy: 0.8843 - val_loss: 0.4279 - val_accuracy: 0.8756
Epoch 60/350
391/391 - 25s - loss: 0.3666 - accuracy: 0.8828 - val_loss: 0.4390 - val_accuracy: 0.8698
Epoch 61/350
391/391 - 25s - loss: 0.3673 - accuracy: 0.8839 - val_loss: 0.4652 - val_accuracy: 0.8607
Epoch 62/350
391/391 - 25s - loss: 0.3586 - accuracy: 0.8866 - val_loss: 0.4433 - val_accuracy: 0.8702
Epoch 63/350
391/391 - 25s - loss: 0.3532 - accuracy: 0.8890 - val_loss: 0.4686 - val_accuracy: 0.8656
Epoch 64/350
391/391 - 25s - loss: 0.3525 - accuracy: 0.8868 - val_loss: 0.4465 - val_accuracy: 0.8695
Epoch 65/350
391/391 - 25s - loss: 0.3441 - accuracy: 0.8903 - val_loss: 0.4423 - val_accuracy: 0.8714
Epoch 66/350
391/391 - 25s - loss: 0.3478 - accuracy: 0.8902 - val_loss: 0.4279 - val_accuracy: 0.8732
Epoch 67/350
391/391 - 25s - loss: 0.3435 - accuracy: 0.8901 - val_loss: 0.4444 - val_accuracy: 0.8692
Epoch 68/350
391/391 - 25s - loss: 0.3378 - accuracy: 0.8934 - val_loss: 0.4230 - val_accuracy: 0.8801
Epoch 69/350
391/391 - 25s - loss: 0.3359 - accuracy: 0.8932 - val_loss: 0.4944 - val_accuracy: 0.8615
Epoch 70/350
391/391 - 25s - loss: 0.3320 - accuracy: 0.8945 - val_loss: 0.4392 - val_accuracy: 0.8725
Epoch 71/350
391/391 - 25s - loss: 0.3265 - accuracy: 0.8971 - val_loss: 0.4464 - val_accuracy: 0.8690
Epoch 72/350
391/391 - 25s - loss: 0.3223 - accuracy: 0.8982 - val_loss: 0.4230 - val_accuracy: 0.8789
Epoch 73/350
391/391 - 25s - loss: 0.3225 - accuracy: 0.8977 - val_loss: 0.4518 - val_accuracy: 0.8715
Epoch 74/350
391/391 - 25s - loss: 0.3191 - accuracy: 0.9004 - val_loss: 0.4219 - val_accuracy: 0.8779
Epoch 75/350
391/391 - 25s - loss: 0.3184 - accuracy: 0.9015 - val_loss: 0.4374 - val_accuracy: 0.8765
Epoch 76/350
391/391 - 25s - loss: 0.3173 - accuracy: 0.9012 - val_loss: 0.4283 - val_accuracy: 0.8794
Epoch 77/350
391/391 - 25s - loss: 0.3123 - accuracy: 0.9025 - val_loss: 0.4503 - val_accuracy: 0.8765
Epoch 78/350
391/391 - 25s - loss: 0.3085 - accuracy: 0.9038 - val_loss: 0.4506 - val_accuracy: 0.8689
Epoch 79/350
391/391 - 25s - loss: 0.3042 - accuracy: 0.9047 - val_loss: 0.4207 - val_accuracy: 0.8811
Epoch 80/350
391/391 - 25s - loss: 0.2998 - accuracy: 0.9079 - val_loss: 0.4218 - val_accuracy: 0.8824
Epoch 81/350
391/391 - 25s - loss: 0.3034 - accuracy: 0.9047 - val_loss: 0.4627 - val_accuracy: 0.8720
Epoch 82/350
391/391 - 25s - loss: 0.2946 - accuracy: 0.9085 - val_loss: 0.4674 - val_accuracy: 0.8730
Epoch 83/350
391/391 - 25s - loss: 0.2974 - accuracy: 0.9068 - val_loss: 0.4623 - val_accuracy: 0.8707
Epoch 84/350
391/391 - 25s - loss: 0.2959 - accuracy: 0.9094 - val_loss: 0.3985 - val_accuracy: 0.8860
Epoch 85/350
391/391 - 25s - loss: 0.2894 - accuracy: 0.9109 - val_loss: 0.4463 - val_accuracy: 0.8777
Epoch 86/350
391/391 - 25s - loss: 0.2940 - accuracy: 0.9085 - val_loss: 0.4281 - val_accuracy: 0.8799
Epoch 87/350
391/391 - 25s - loss: 0.2846 - accuracy: 0.9118 - val_loss: 0.4156 - val_accuracy: 0.8827
Epoch 88/350
391/391 - 25s - loss: 0.2840 - accuracy: 0.9123 - val_loss: 0.4148 - val_accuracy: 0.8849
Epoch 89/350
391/391 - 25s - loss: 0.2819 - accuracy: 0.9108 - val_loss: 0.4621 - val_accuracy: 0.8759
Epoch 90/350
391/391 - 25s - loss: 0.2807 - accuracy: 0.9136 - val_loss: 0.4364 - val_accuracy: 0.8837
Epoch 91/350
391/391 - 25s - loss: 0.2753 - accuracy: 0.9153 - val_loss: 0.4651 - val_accuracy: 0.8708
Epoch 92/350
391/391 - 25s - loss: 0.2740 - accuracy: 0.9160 - val_loss: 0.4360 - val_accuracy: 0.8755
Epoch 93/350
391/391 - 25s - loss: 0.2743 - accuracy: 0.9157 - val_loss: 0.4555 - val_accuracy: 0.8790
Epoch 94/350
391/391 - 25s - loss: 0.2737 - accuracy: 0.9164 - val_loss: 0.4059 - val_accuracy: 0.8883
Epoch 95/350
391/391 - 25s - loss: 0.2721 - accuracy: 0.9183 - val_loss: 0.4507 - val_accuracy: 0.8820
Epoch 96/350
391/391 - 25s - loss: 0.2719 - accuracy: 0.9170 - val_loss: 0.4288 - val_accuracy: 0.8811
Epoch 97/350
391/391 - 25s - loss: 0.2685 - accuracy: 0.9179 - val_loss: 0.4344 - val_accuracy: 0.8802
Epoch 98/350
391/391 - 25s - loss: 0.2595 - accuracy: 0.9212 - val_loss: 0.4364 - val_accuracy: 0.8821
Epoch 99/350
391/391 - 25s - loss: 0.2615 - accuracy: 0.9212 - val_loss: 0.4430 - val_accuracy: 0.8814
Epoch 100/350


Snapshot weight 8 shuffle 3 at epoch 100
Layer 11
Getting activations...


391/391 - 25s - loss: 0.2593 - accuracy: 0.9207 - val_loss: 0.4525 - val_accuracy: 0.8798
Epoch 101/350
391/391 - 25s - loss: 0.2618 - accuracy: 0.9208 - val_loss: 0.4432 - val_accuracy: 0.8812
Epoch 102/350
391/391 - 25s - loss: 0.2586 - accuracy: 0.9208 - val_loss: 0.4532 - val_accuracy: 0.8812
Epoch 103/350
391/391 - 25s - loss: 0.2559 - accuracy: 0.9237 - val_loss: 0.4221 - val_accuracy: 0.8853
Epoch 104/350
391/391 - 25s - loss: 0.2565 - accuracy: 0.9222 - val_loss: 0.4147 - val_accuracy: 0.8888
Epoch 105/350
391/391 - 25s - loss: 0.2565 - accuracy: 0.9221 - val_loss: 0.4323 - val_accuracy: 0.8845
Epoch 106/350
391/391 - 25s - loss: 0.2534 - accuracy: 0.9233 - val_loss: 0.4292 - val_accuracy: 0.8862
Epoch 107/350
391/391 - 25s - loss: 0.2494 - accuracy: 0.9259 - val_loss: 0.4202 - val_accuracy: 0.8840
Epoch 108/350
391/391 - 25s - loss: 0.2491 - accuracy: 0.9247 - val_loss: 0.4298 - val_accuracy: 0.8828
Epoch 109/350
391/391 - 25s - loss: 0.2479 - accuracy: 0.9258 - val_loss: 0.4226 - val_accuracy: 0.8899
Epoch 110/350
391/391 - 25s - loss: 0.2430 - accuracy: 0.9272 - val_loss: 0.4099 - val_accuracy: 0.8952
Epoch 111/350
391/391 - 25s - loss: 0.2398 - accuracy: 0.9269 - val_loss: 0.4480 - val_accuracy: 0.8873
Epoch 112/350
391/391 - 25s - loss: 0.2388 - accuracy: 0.9291 - val_loss: 0.4628 - val_accuracy: 0.8807
Epoch 113/350
391/391 - 25s - loss: 0.2389 - accuracy: 0.9296 - val_loss: 0.4170 - val_accuracy: 0.8919
Epoch 114/350
391/391 - 25s - loss: 0.2402 - accuracy: 0.9278 - val_loss: 0.4605 - val_accuracy: 0.8834
Epoch 115/350
391/391 - 25s - loss: 0.2431 - accuracy: 0.9288 - val_loss: 0.4131 - val_accuracy: 0.8893
Epoch 116/350
391/391 - 25s - loss: 0.2334 - accuracy: 0.9309 - val_loss: 0.4402 - val_accuracy: 0.8913
Epoch 117/350
391/391 - 25s - loss: 0.2393 - accuracy: 0.9287 - val_loss: 0.4455 - val_accuracy: 0.8840
Epoch 118/350
391/391 - 25s - loss: 0.2309 - accuracy: 0.9320 - val_loss: 0.4260 - val_accuracy: 0.8944
Epoch 119/350
391/391 - 25s - loss: 0.2358 - accuracy: 0.9304 - val_loss: 0.4419 - val_accuracy: 0.8805
Epoch 120/350
391/391 - 25s - loss: 0.2307 - accuracy: 0.9323 - val_loss: 0.4258 - val_accuracy: 0.8889
Epoch 121/350
391/391 - 25s - loss: 0.2320 - accuracy: 0.9315 - val_loss: 0.4502 - val_accuracy: 0.8915
Epoch 122/350
391/391 - 25s - loss: 0.2248 - accuracy: 0.9339 - val_loss: 0.4370 - val_accuracy: 0.8895
Epoch 123/350
391/391 - 25s - loss: 0.2266 - accuracy: 0.9340 - val_loss: 0.4538 - val_accuracy: 0.8842
Epoch 124/350
391/391 - 25s - loss: 0.2251 - accuracy: 0.9340 - val_loss: 0.4440 - val_accuracy: 0.8871
Epoch 125/350
391/391 - 25s - loss: 0.2241 - accuracy: 0.9337 - val_loss: 0.4824 - val_accuracy: 0.8867
Epoch 126/350
391/391 - 25s - loss: 0.2278 - accuracy: 0.9336 - val_loss: 0.4191 - val_accuracy: 0.8904
Epoch 127/350
391/391 - 25s - loss: 0.2233 - accuracy: 0.9344 - val_loss: 0.4087 - val_accuracy: 0.8944
Epoch 128/350
391/391 - 25s - loss: 0.2223 - accuracy: 0.9355 - val_loss: 0.4390 - val_accuracy: 0.8910
Epoch 129/350
391/391 - 25s - loss: 0.2199 - accuracy: 0.9363 - val_loss: 0.4746 - val_accuracy: 0.8805
Epoch 130/350
391/391 - 25s - loss: 0.2228 - accuracy: 0.9362 - val_loss: 0.4295 - val_accuracy: 0.8921
Epoch 131/350
391/391 - 25s - loss: 0.2157 - accuracy: 0.9372 - val_loss: 0.4628 - val_accuracy: 0.8874
Epoch 132/350
391/391 - 25s - loss: 0.2223 - accuracy: 0.9357 - val_loss: 0.4841 - val_accuracy: 0.8827
Epoch 133/350
391/391 - 25s - loss: 0.2157 - accuracy: 0.9374 - val_loss: 0.4378 - val_accuracy: 0.8911
Epoch 134/350
391/391 - 25s - loss: 0.2160 - accuracy: 0.9382 - val_loss: 0.4384 - val_accuracy: 0.8902
Epoch 135/350
391/391 - 25s - loss: 0.2148 - accuracy: 0.9388 - val_loss: 0.4658 - val_accuracy: 0.8905
Epoch 136/350
391/391 - 25s - loss: 0.2116 - accuracy: 0.9394 - val_loss: 0.4276 - val_accuracy: 0.8923
Epoch 137/350
391/391 - 25s - loss: 0.2097 - accuracy: 0.9402 - val_loss: 0.4621 - val_accuracy: 0.8850
Epoch 138/350
391/391 - 25s - loss: 0.2101 - accuracy: 0.9393 - val_loss: 0.4392 - val_accuracy: 0.8903
Epoch 139/350
391/391 - 25s - loss: 0.2038 - accuracy: 0.9421 - val_loss: 0.4536 - val_accuracy: 0.8839
Epoch 140/350
391/391 - 25s - loss: 0.2108 - accuracy: 0.9397 - val_loss: 0.4778 - val_accuracy: 0.8891
Epoch 141/350
391/391 - 25s - loss: 0.2097 - accuracy: 0.9408 - val_loss: 0.4166 - val_accuracy: 0.8938
Epoch 142/350
391/391 - 25s - loss: 0.2090 - accuracy: 0.9407 - val_loss: 0.4566 - val_accuracy: 0.8910
Epoch 143/350
391/391 - 25s - loss: 0.2007 - accuracy: 0.9447 - val_loss: 0.4756 - val_accuracy: 0.8829
Epoch 144/350
391/391 - 25s - loss: 0.2060 - accuracy: 0.9411 - val_loss: 0.4671 - val_accuracy: 0.8873
Epoch 145/350
391/391 - 25s - loss: 0.2018 - accuracy: 0.9436 - val_loss: 0.4866 - val_accuracy: 0.8882
Epoch 146/350
391/391 - 25s - loss: 0.2018 - accuracy: 0.9430 - val_loss: 0.4499 - val_accuracy: 0.8932
Epoch 147/350
391/391 - 25s - loss: 0.2025 - accuracy: 0.9432 - val_loss: 0.4505 - val_accuracy: 0.8908
Epoch 148/350
391/391 - 25s - loss: 0.1994 - accuracy: 0.9448 - val_loss: 0.4394 - val_accuracy: 0.8959
Epoch 149/350
391/391 - 25s - loss: 0.2024 - accuracy: 0.9430 - val_loss: 0.4395 - val_accuracy: 0.8908
Epoch 150/350


Snapshot weight 8 shuffle 3 at epoch 150
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1984 - accuracy: 0.9438 - val_loss: 0.4301 - val_accuracy: 0.8946
Epoch 151/350
391/391 - 25s - loss: 0.1985 - accuracy: 0.9447 - val_loss: 0.4815 - val_accuracy: 0.8891
Epoch 152/350
391/391 - 25s - loss: 0.1965 - accuracy: 0.9458 - val_loss: 0.4653 - val_accuracy: 0.8932
Epoch 153/350
391/391 - 25s - loss: 0.1985 - accuracy: 0.9442 - val_loss: 0.4863 - val_accuracy: 0.8851
Epoch 154/350
391/391 - 25s - loss: 0.1916 - accuracy: 0.9469 - val_loss: 0.4537 - val_accuracy: 0.8960
Epoch 155/350
391/391 - 25s - loss: 0.1961 - accuracy: 0.9457 - val_loss: 0.4277 - val_accuracy: 0.8928
Epoch 156/350
391/391 - 25s - loss: 0.1906 - accuracy: 0.9476 - val_loss: 0.4427 - val_accuracy: 0.8949
Epoch 157/350
391/391 - 25s - loss: 0.1924 - accuracy: 0.9468 - val_loss: 0.4375 - val_accuracy: 0.8975
Epoch 158/350
391/391 - 25s - loss: 0.1945 - accuracy: 0.9459 - val_loss: 0.4391 - val_accuracy: 0.8957
Epoch 159/350
391/391 - 25s - loss: 0.1865 - accuracy: 0.9490 - val_loss: 0.4370 - val_accuracy: 0.8969
Epoch 160/350
391/391 - 25s - loss: 0.1850 - accuracy: 0.9493 - val_loss: 0.4498 - val_accuracy: 0.8969
Epoch 161/350
391/391 - 25s - loss: 0.1902 - accuracy: 0.9481 - val_loss: 0.4389 - val_accuracy: 0.8923
Epoch 162/350
391/391 - 25s - loss: 0.1847 - accuracy: 0.9495 - val_loss: 0.4600 - val_accuracy: 0.8932
Epoch 163/350
391/391 - 25s - loss: 0.1892 - accuracy: 0.9472 - val_loss: 0.4548 - val_accuracy: 0.8931
Epoch 164/350
391/391 - 25s - loss: 0.1887 - accuracy: 0.9478 - val_loss: 0.4392 - val_accuracy: 0.8934
Epoch 165/350
391/391 - 25s - loss: 0.1923 - accuracy: 0.9468 - val_loss: 0.4443 - val_accuracy: 0.8970
Epoch 166/350
391/391 - 25s - loss: 0.1879 - accuracy: 0.9491 - val_loss: 0.4195 - val_accuracy: 0.8947
Epoch 167/350
391/391 - 25s - loss: 0.1832 - accuracy: 0.9506 - val_loss: 0.4604 - val_accuracy: 0.8967
Epoch 168/350
391/391 - 25s - loss: 0.1837 - accuracy: 0.9497 - val_loss: 0.4805 - val_accuracy: 0.8873
Epoch 169/350
391/391 - 25s - loss: 0.1837 - accuracy: 0.9506 - val_loss: 0.4493 - val_accuracy: 0.8952
Epoch 170/350
391/391 - 25s - loss: 0.1848 - accuracy: 0.9494 - val_loss: 0.4291 - val_accuracy: 0.8967
Epoch 171/350
391/391 - 25s - loss: 0.1870 - accuracy: 0.9485 - val_loss: 0.4668 - val_accuracy: 0.8891
Epoch 172/350
391/391 - 25s - loss: 0.1791 - accuracy: 0.9509 - val_loss: 0.4583 - val_accuracy: 0.8931
Epoch 173/350
391/391 - 25s - loss: 0.1822 - accuracy: 0.9511 - val_loss: 0.4679 - val_accuracy: 0.8851
Epoch 174/350
391/391 - 25s - loss: 0.1816 - accuracy: 0.9524 - val_loss: 0.4711 - val_accuracy: 0.8957
Epoch 175/350
391/391 - 25s - loss: 0.1808 - accuracy: 0.9518 - val_loss: 0.5015 - val_accuracy: 0.8865
Epoch 176/350
391/391 - 25s - loss: 0.1826 - accuracy: 0.9509 - val_loss: 0.4431 - val_accuracy: 0.8958
Epoch 177/350
391/391 - 25s - loss: 0.1746 - accuracy: 0.9535 - val_loss: 0.4863 - val_accuracy: 0.8923
Epoch 178/350
391/391 - 25s - loss: 0.1821 - accuracy: 0.9513 - val_loss: 0.4553 - val_accuracy: 0.8954
Epoch 179/350
391/391 - 25s - loss: 0.1752 - accuracy: 0.9534 - val_loss: 0.4809 - val_accuracy: 0.8965
Epoch 180/350
391/391 - 25s - loss: 0.1789 - accuracy: 0.9527 - val_loss: 0.4528 - val_accuracy: 0.8969
Epoch 181/350
391/391 - 25s - loss: 0.1765 - accuracy: 0.9527 - val_loss: 0.4561 - val_accuracy: 0.8969
Epoch 182/350
391/391 - 25s - loss: 0.1751 - accuracy: 0.9528 - val_loss: 0.4713 - val_accuracy: 0.8945
Epoch 183/350
391/391 - 25s - loss: 0.1758 - accuracy: 0.9539 - val_loss: 0.4852 - val_accuracy: 0.8910
Epoch 184/350
391/391 - 25s - loss: 0.1731 - accuracy: 0.9550 - val_loss: 0.4401 - val_accuracy: 0.8950
Epoch 185/350
391/391 - 25s - loss: 0.1723 - accuracy: 0.9544 - val_loss: 0.4956 - val_accuracy: 0.8942
Epoch 186/350
391/391 - 25s - loss: 0.1728 - accuracy: 0.9551 - val_loss: 0.4904 - val_accuracy: 0.8945
Epoch 187/350
391/391 - 25s - loss: 0.1745 - accuracy: 0.9546 - val_loss: 0.4654 - val_accuracy: 0.8980
Epoch 188/350
391/391 - 25s - loss: 0.1682 - accuracy: 0.9556 - val_loss: 0.4733 - val_accuracy: 0.9000
Epoch 189/350
391/391 - 25s - loss: 0.1756 - accuracy: 0.9547 - val_loss: 0.4289 - val_accuracy: 0.9025
Epoch 190/350
391/391 - 25s - loss: 0.1673 - accuracy: 0.9562 - val_loss: 0.4552 - val_accuracy: 0.9027
Epoch 191/350
391/391 - 25s - loss: 0.1705 - accuracy: 0.9560 - val_loss: 0.4461 - val_accuracy: 0.8985
Epoch 192/350
391/391 - 25s - loss: 0.1672 - accuracy: 0.9571 - val_loss: 0.4635 - val_accuracy: 0.8987
Epoch 193/350
391/391 - 25s - loss: 0.1693 - accuracy: 0.9569 - val_loss: 0.4573 - val_accuracy: 0.8985
Epoch 194/350
391/391 - 25s - loss: 0.1705 - accuracy: 0.9563 - val_loss: 0.4894 - val_accuracy: 0.8919
Epoch 195/350
391/391 - 25s - loss: 0.1713 - accuracy: 0.9551 - val_loss: 0.4588 - val_accuracy: 0.8977
Epoch 196/350
391/391 - 25s - loss: 0.1630 - accuracy: 0.9574 - val_loss: 0.4953 - val_accuracy: 0.8901
Epoch 197/350
391/391 - 25s - loss: 0.1671 - accuracy: 0.9577 - val_loss: 0.4909 - val_accuracy: 0.8952
Epoch 198/350
391/391 - 25s - loss: 0.1660 - accuracy: 0.9567 - val_loss: 0.4620 - val_accuracy: 0.9011
Epoch 199/350
391/391 - 25s - loss: 0.1685 - accuracy: 0.9572 - val_loss: 0.4775 - val_accuracy: 0.8936
Epoch 200/350


Snapshot weight 8 shuffle 3 at epoch 200
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1638 - accuracy: 0.9589 - val_loss: 0.4509 - val_accuracy: 0.9015
Epoch 201/350
391/391 - 25s - loss: 0.1411 - accuracy: 0.9671 - val_loss: 0.4373 - val_accuracy: 0.9060
Epoch 202/350
391/391 - 25s - loss: 0.1293 - accuracy: 0.9702 - val_loss: 0.4369 - val_accuracy: 0.9056
Epoch 203/350
391/391 - 25s - loss: 0.1264 - accuracy: 0.9723 - val_loss: 0.4417 - val_accuracy: 0.9072
Epoch 204/350
391/391 - 25s - loss: 0.1238 - accuracy: 0.9733 - val_loss: 0.4457 - val_accuracy: 0.9083
Epoch 205/350
391/391 - 25s - loss: 0.1215 - accuracy: 0.9736 - val_loss: 0.4544 - val_accuracy: 0.9063
Epoch 206/350
391/391 - 25s - loss: 0.1185 - accuracy: 0.9751 - val_loss: 0.4577 - val_accuracy: 0.9054
Epoch 207/350
391/391 - 25s - loss: 0.1172 - accuracy: 0.9748 - val_loss: 0.4583 - val_accuracy: 0.9054
Epoch 208/350
391/391 - 25s - loss: 0.1190 - accuracy: 0.9741 - val_loss: 0.4722 - val_accuracy: 0.9049
Epoch 209/350
391/391 - 25s - loss: 0.1167 - accuracy: 0.9751 - val_loss: 0.4617 - val_accuracy: 0.9062
Epoch 210/350
391/391 - 25s - loss: 0.1153 - accuracy: 0.9752 - val_loss: 0.4676 - val_accuracy: 0.9062
Epoch 211/350
391/391 - 25s - loss: 0.1153 - accuracy: 0.9755 - val_loss: 0.4707 - val_accuracy: 0.9063
Epoch 212/350
391/391 - 25s - loss: 0.1169 - accuracy: 0.9753 - val_loss: 0.4746 - val_accuracy: 0.9055
Epoch 213/350
391/391 - 25s - loss: 0.1154 - accuracy: 0.9750 - val_loss: 0.4646 - val_accuracy: 0.9082
Epoch 214/350
391/391 - 25s - loss: 0.1153 - accuracy: 0.9761 - val_loss: 0.4648 - val_accuracy: 0.9063
Epoch 215/350
391/391 - 25s - loss: 0.1129 - accuracy: 0.9759 - val_loss: 0.4745 - val_accuracy: 0.9078
Epoch 216/350
391/391 - 25s - loss: 0.1106 - accuracy: 0.9772 - val_loss: 0.4789 - val_accuracy: 0.9063
Epoch 217/350
391/391 - 25s - loss: 0.1129 - accuracy: 0.9762 - val_loss: 0.4786 - val_accuracy: 0.9063
Epoch 218/350
391/391 - 25s - loss: 0.1126 - accuracy: 0.9763 - val_loss: 0.4739 - val_accuracy: 0.9067
Epoch 219/350
391/391 - 25s - loss: 0.1117 - accuracy: 0.9770 - val_loss: 0.4690 - val_accuracy: 0.9067
Epoch 220/350
391/391 - 25s - loss: 0.1099 - accuracy: 0.9774 - val_loss: 0.4737 - val_accuracy: 0.9071
Epoch 221/350
391/391 - 25s - loss: 0.1125 - accuracy: 0.9762 - val_loss: 0.4736 - val_accuracy: 0.9083
Epoch 222/350
391/391 - 25s - loss: 0.1132 - accuracy: 0.9771 - val_loss: 0.4778 - val_accuracy: 0.9050
Epoch 223/350
391/391 - 25s - loss: 0.1112 - accuracy: 0.9777 - val_loss: 0.4754 - val_accuracy: 0.9088
Epoch 224/350
391/391 - 25s - loss: 0.1124 - accuracy: 0.9770 - val_loss: 0.4788 - val_accuracy: 0.9058
Epoch 225/350
391/391 - 25s - loss: 0.1085 - accuracy: 0.9775 - val_loss: 0.4835 - val_accuracy: 0.9065
Epoch 226/350
391/391 - 25s - loss: 0.1069 - accuracy: 0.9783 - val_loss: 0.4876 - val_accuracy: 0.9076
Epoch 227/350
391/391 - 25s - loss: 0.1098 - accuracy: 0.9779 - val_loss: 0.4872 - val_accuracy: 0.9069
Epoch 228/350
391/391 - 25s - loss: 0.1082 - accuracy: 0.9778 - val_loss: 0.4905 - val_accuracy: 0.9063
Epoch 229/350
391/391 - 25s - loss: 0.1094 - accuracy: 0.9774 - val_loss: 0.4851 - val_accuracy: 0.9082
Epoch 230/350
391/391 - 25s - loss: 0.1101 - accuracy: 0.9770 - val_loss: 0.4829 - val_accuracy: 0.9096
Epoch 231/350
391/391 - 25s - loss: 0.1071 - accuracy: 0.9784 - val_loss: 0.4904 - val_accuracy: 0.9072
Epoch 232/350
391/391 - 25s - loss: 0.1087 - accuracy: 0.9777 - val_loss: 0.4793 - val_accuracy: 0.9078
Epoch 233/350
391/391 - 25s - loss: 0.1087 - accuracy: 0.9778 - val_loss: 0.4933 - val_accuracy: 0.9083
Epoch 234/350
391/391 - 25s - loss: 0.1076 - accuracy: 0.9788 - val_loss: 0.4789 - val_accuracy: 0.9087
Epoch 235/350
391/391 - 25s - loss: 0.1070 - accuracy: 0.9785 - val_loss: 0.4860 - val_accuracy: 0.9083
Epoch 236/350
391/391 - 25s - loss: 0.1104 - accuracy: 0.9776 - val_loss: 0.4782 - val_accuracy: 0.9109
Epoch 237/350
391/391 - 25s - loss: 0.1050 - accuracy: 0.9790 - val_loss: 0.4911 - val_accuracy: 0.9079
Epoch 238/350
391/391 - 25s - loss: 0.1067 - accuracy: 0.9782 - val_loss: 0.4891 - val_accuracy: 0.9090
Epoch 239/350
391/391 - 25s - loss: 0.1069 - accuracy: 0.9787 - val_loss: 0.4950 - val_accuracy: 0.9062
Epoch 240/350
391/391 - 25s - loss: 0.1070 - accuracy: 0.9781 - val_loss: 0.4912 - val_accuracy: 0.9076
Epoch 241/350
391/391 - 25s - loss: 0.1078 - accuracy: 0.9777 - val_loss: 0.4888 - val_accuracy: 0.9074
Epoch 242/350
391/391 - 25s - loss: 0.1053 - accuracy: 0.9785 - val_loss: 0.5061 - val_accuracy: 0.9068
Epoch 243/350
391/391 - 25s - loss: 0.1057 - accuracy: 0.9790 - val_loss: 0.4998 - val_accuracy: 0.9074
Epoch 244/350
391/391 - 25s - loss: 0.1043 - accuracy: 0.9793 - val_loss: 0.4921 - val_accuracy: 0.9087
Epoch 245/350
391/391 - 25s - loss: 0.1040 - accuracy: 0.9797 - val_loss: 0.4975 - val_accuracy: 0.9067
Epoch 246/350
391/391 - 25s - loss: 0.1086 - accuracy: 0.9779 - val_loss: 0.4897 - val_accuracy: 0.9084
Epoch 247/350
391/391 - 25s - loss: 0.1075 - accuracy: 0.9782 - val_loss: 0.4832 - val_accuracy: 0.9074
Epoch 248/350
391/391 - 25s - loss: 0.1065 - accuracy: 0.9789 - val_loss: 0.4860 - val_accuracy: 0.9073
Epoch 249/350
391/391 - 25s - loss: 0.1052 - accuracy: 0.9789 - val_loss: 0.5045 - val_accuracy: 0.9067
Epoch 250/350


Snapshot weight 8 shuffle 3 at epoch 250
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1022 - accuracy: 0.9796 - val_loss: 0.4947 - val_accuracy: 0.9091
Epoch 251/350
391/391 - 25s - loss: 0.1029 - accuracy: 0.9803 - val_loss: 0.4937 - val_accuracy: 0.9091
Epoch 252/350
391/391 - 25s - loss: 0.1055 - accuracy: 0.9788 - val_loss: 0.4931 - val_accuracy: 0.9085
Epoch 253/350
391/391 - 25s - loss: 0.1027 - accuracy: 0.9799 - val_loss: 0.4930 - val_accuracy: 0.9076
Epoch 254/350
391/391 - 25s - loss: 0.1050 - accuracy: 0.9797 - val_loss: 0.4925 - val_accuracy: 0.9087
Epoch 255/350
391/391 - 25s - loss: 0.1030 - accuracy: 0.9802 - val_loss: 0.4883 - val_accuracy: 0.9085
Epoch 256/350
391/391 - 25s - loss: 0.1032 - accuracy: 0.9800 - val_loss: 0.4887 - val_accuracy: 0.9085
Epoch 257/350
391/391 - 25s - loss: 0.1029 - accuracy: 0.9802 - val_loss: 0.4897 - val_accuracy: 0.9083
Epoch 258/350
391/391 - 25s - loss: 0.1023 - accuracy: 0.9802 - val_loss: 0.4905 - val_accuracy: 0.9079
Epoch 259/350
391/391 - 25s - loss: 0.1022 - accuracy: 0.9800 - val_loss: 0.4897 - val_accuracy: 0.9079
Epoch 260/350
391/391 - 25s - loss: 0.1022 - accuracy: 0.9800 - val_loss: 0.4910 - val_accuracy: 0.9076
Epoch 261/350
391/391 - 25s - loss: 0.1027 - accuracy: 0.9802 - val_loss: 0.4893 - val_accuracy: 0.9082
Epoch 262/350
391/391 - 25s - loss: 0.0996 - accuracy: 0.9809 - val_loss: 0.4913 - val_accuracy: 0.9079
Epoch 263/350
391/391 - 25s - loss: 0.0997 - accuracy: 0.9813 - val_loss: 0.4927 - val_accuracy: 0.9082
Epoch 264/350
391/391 - 25s - loss: 0.0998 - accuracy: 0.9812 - val_loss: 0.4918 - val_accuracy: 0.9086
Epoch 265/350
391/391 - 25s - loss: 0.1021 - accuracy: 0.9801 - val_loss: 0.4936 - val_accuracy: 0.9087
Epoch 266/350
391/391 - 25s - loss: 0.1041 - accuracy: 0.9794 - val_loss: 0.4929 - val_accuracy: 0.9077
Epoch 267/350
391/391 - 25s - loss: 0.1018 - accuracy: 0.9801 - val_loss: 0.4908 - val_accuracy: 0.9079
Epoch 268/350
391/391 - 25s - loss: 0.1025 - accuracy: 0.9799 - val_loss: 0.4894 - val_accuracy: 0.9085
Epoch 269/350
391/391 - 25s - loss: 0.1054 - accuracy: 0.9790 - val_loss: 0.4912 - val_accuracy: 0.9079
Epoch 270/350
391/391 - 25s - loss: 0.1015 - accuracy: 0.9800 - val_loss: 0.4909 - val_accuracy: 0.9085
Epoch 271/350
391/391 - 25s - loss: 0.1007 - accuracy: 0.9807 - val_loss: 0.4903 - val_accuracy: 0.9076
Epoch 272/350
391/391 - 25s - loss: 0.0999 - accuracy: 0.9812 - val_loss: 0.4906 - val_accuracy: 0.9082
Epoch 273/350
391/391 - 25s - loss: 0.0989 - accuracy: 0.9814 - val_loss: 0.4912 - val_accuracy: 0.9080
Epoch 274/350
391/391 - 25s - loss: 0.0997 - accuracy: 0.9813 - val_loss: 0.4912 - val_accuracy: 0.9082
Epoch 275/350
391/391 - 25s - loss: 0.1012 - accuracy: 0.9803 - val_loss: 0.4921 - val_accuracy: 0.9087
Epoch 276/350
391/391 - 25s - loss: 0.1006 - accuracy: 0.9811 - val_loss: 0.4912 - val_accuracy: 0.9084
Epoch 277/350
391/391 - 25s - loss: 0.1011 - accuracy: 0.9806 - val_loss: 0.4929 - val_accuracy: 0.9084
Epoch 278/350
391/391 - 25s - loss: 0.1024 - accuracy: 0.9801 - val_loss: 0.4926 - val_accuracy: 0.9078
Epoch 279/350
391/391 - 25s - loss: 0.1020 - accuracy: 0.9802 - val_loss: 0.4917 - val_accuracy: 0.9085
Epoch 280/350
391/391 - 25s - loss: 0.1038 - accuracy: 0.9793 - val_loss: 0.4922 - val_accuracy: 0.9081
Epoch 281/350
391/391 - 25s - loss: 0.0997 - accuracy: 0.9810 - val_loss: 0.4918 - val_accuracy: 0.9084
Epoch 282/350
391/391 - 25s - loss: 0.1048 - accuracy: 0.9797 - val_loss: 0.4893 - val_accuracy: 0.9086
Epoch 283/350
391/391 - 25s - loss: 0.1008 - accuracy: 0.9803 - val_loss: 0.4912 - val_accuracy: 0.9089
Epoch 284/350
391/391 - 25s - loss: 0.1007 - accuracy: 0.9808 - val_loss: 0.4910 - val_accuracy: 0.9079
Epoch 285/350
391/391 - 25s - loss: 0.0996 - accuracy: 0.9804 - val_loss: 0.4914 - val_accuracy: 0.9081
Epoch 286/350
391/391 - 25s - loss: 0.1006 - accuracy: 0.9804 - val_loss: 0.4929 - val_accuracy: 0.9079
Epoch 287/350
391/391 - 25s - loss: 0.1015 - accuracy: 0.9803 - val_loss: 0.4927 - val_accuracy: 0.9088
Epoch 288/350
391/391 - 25s - loss: 0.1000 - accuracy: 0.9810 - val_loss: 0.4930 - val_accuracy: 0.9088
Epoch 289/350
391/391 - 25s - loss: 0.1011 - accuracy: 0.9798 - val_loss: 0.4905 - val_accuracy: 0.9090
Epoch 290/350
391/391 - 25s - loss: 0.1013 - accuracy: 0.9801 - val_loss: 0.4914 - val_accuracy: 0.9083
Epoch 291/350
391/391 - 25s - loss: 0.0993 - accuracy: 0.9815 - val_loss: 0.4922 - val_accuracy: 0.9085
Epoch 292/350
391/391 - 25s - loss: 0.0998 - accuracy: 0.9808 - val_loss: 0.4925 - val_accuracy: 0.9081
Epoch 293/350
391/391 - 25s - loss: 0.0982 - accuracy: 0.9813 - val_loss: 0.4937 - val_accuracy: 0.9084
Epoch 294/350
391/391 - 25s - loss: 0.0990 - accuracy: 0.9813 - val_loss: 0.4934 - val_accuracy: 0.9094
Epoch 295/350
391/391 - 25s - loss: 0.1004 - accuracy: 0.9806 - val_loss: 0.4938 - val_accuracy: 0.9089
Epoch 296/350
391/391 - 25s - loss: 0.1012 - accuracy: 0.9800 - val_loss: 0.4948 - val_accuracy: 0.9085
Epoch 297/350
391/391 - 25s - loss: 0.0987 - accuracy: 0.9816 - val_loss: 0.4964 - val_accuracy: 0.9088
Epoch 298/350
391/391 - 25s - loss: 0.1008 - accuracy: 0.9805 - val_loss: 0.4940 - val_accuracy: 0.9084
Epoch 299/350
391/391 - 25s - loss: 0.1031 - accuracy: 0.9794 - val_loss: 0.4932 - val_accuracy: 0.9079
Epoch 300/350


Snapshot weight 8 shuffle 3 at epoch 300
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1000 - accuracy: 0.9806 - val_loss: 0.4955 - val_accuracy: 0.9088
Epoch 301/350
391/391 - 25s - loss: 0.0994 - accuracy: 0.9810 - val_loss: 0.4954 - val_accuracy: 0.9090
Epoch 302/350
391/391 - 25s - loss: 0.1027 - accuracy: 0.9800 - val_loss: 0.4950 - val_accuracy: 0.9089
Epoch 303/350
391/391 - 25s - loss: 0.1003 - accuracy: 0.9808 - val_loss: 0.4947 - val_accuracy: 0.9083
Epoch 304/350
391/391 - 25s - loss: 0.0996 - accuracy: 0.9812 - val_loss: 0.4947 - val_accuracy: 0.9087
Epoch 305/350
391/391 - 25s - loss: 0.1009 - accuracy: 0.9807 - val_loss: 0.4947 - val_accuracy: 0.9084
Epoch 306/350
391/391 - 25s - loss: 0.0998 - accuracy: 0.9810 - val_loss: 0.4942 - val_accuracy: 0.9086
Epoch 307/350
391/391 - 25s - loss: 0.0991 - accuracy: 0.9816 - val_loss: 0.4944 - val_accuracy: 0.9086
Epoch 308/350
391/391 - 25s - loss: 0.0997 - accuracy: 0.9805 - val_loss: 0.4946 - val_accuracy: 0.9092
Epoch 309/350
391/391 - 25s - loss: 0.1008 - accuracy: 0.9807 - val_loss: 0.4948 - val_accuracy: 0.9087
Epoch 310/350
391/391 - 25s - loss: 0.1011 - accuracy: 0.9802 - val_loss: 0.4947 - val_accuracy: 0.9088
Epoch 311/350
391/391 - 25s - loss: 0.0994 - accuracy: 0.9802 - val_loss: 0.4947 - val_accuracy: 0.9088
Epoch 312/350
391/391 - 25s - loss: 0.0978 - accuracy: 0.9820 - val_loss: 0.4945 - val_accuracy: 0.9091
Epoch 313/350
391/391 - 25s - loss: 0.1004 - accuracy: 0.9798 - val_loss: 0.4945 - val_accuracy: 0.9090
Epoch 314/350
391/391 - 25s - loss: 0.1008 - accuracy: 0.9809 - val_loss: 0.4943 - val_accuracy: 0.9091
Epoch 315/350
391/391 - 25s - loss: 0.0998 - accuracy: 0.9811 - val_loss: 0.4945 - val_accuracy: 0.9087
Epoch 316/350
391/391 - 25s - loss: 0.0996 - accuracy: 0.9816 - val_loss: 0.4947 - val_accuracy: 0.9087
Epoch 317/350
391/391 - 25s - loss: 0.0999 - accuracy: 0.9806 - val_loss: 0.4948 - val_accuracy: 0.9087
Epoch 318/350
391/391 - 25s - loss: 0.0999 - accuracy: 0.9806 - val_loss: 0.4946 - val_accuracy: 0.9087
Epoch 319/350
391/391 - 25s - loss: 0.0994 - accuracy: 0.9809 - val_loss: 0.4947 - val_accuracy: 0.9089
Epoch 320/350
391/391 - 25s - loss: 0.0982 - accuracy: 0.9818 - val_loss: 0.4947 - val_accuracy: 0.9092
Epoch 321/350
391/391 - 25s - loss: 0.1002 - accuracy: 0.9809 - val_loss: 0.4943 - val_accuracy: 0.9097
Epoch 322/350
391/391 - 25s - loss: 0.1018 - accuracy: 0.9801 - val_loss: 0.4945 - val_accuracy: 0.9092
Epoch 323/350
391/391 - 25s - loss: 0.0996 - accuracy: 0.9807 - val_loss: 0.4944 - val_accuracy: 0.9086
Epoch 324/350
391/391 - 25s - loss: 0.0981 - accuracy: 0.9816 - val_loss: 0.4943 - val_accuracy: 0.9092
Epoch 325/350
391/391 - 25s - loss: 0.0997 - accuracy: 0.9807 - val_loss: 0.4946 - val_accuracy: 0.9092
Epoch 326/350
391/391 - 25s - loss: 0.1010 - accuracy: 0.9810 - val_loss: 0.4942 - val_accuracy: 0.9095
Epoch 327/350
391/391 - 25s - loss: 0.0999 - accuracy: 0.9816 - val_loss: 0.4941 - val_accuracy: 0.9094
Epoch 328/350
391/391 - 25s - loss: 0.1018 - accuracy: 0.9803 - val_loss: 0.4943 - val_accuracy: 0.9088
Epoch 329/350
391/391 - 25s - loss: 0.1019 - accuracy: 0.9797 - val_loss: 0.4943 - val_accuracy: 0.9089
Epoch 330/350
391/391 - 25s - loss: 0.1013 - accuracy: 0.9799 - val_loss: 0.4942 - val_accuracy: 0.9089
Epoch 331/350
391/391 - 25s - loss: 0.1008 - accuracy: 0.9810 - val_loss: 0.4947 - val_accuracy: 0.9086
Epoch 332/350
391/391 - 25s - loss: 0.0992 - accuracy: 0.9811 - val_loss: 0.4946 - val_accuracy: 0.9087
Epoch 333/350
391/391 - 25s - loss: 0.0998 - accuracy: 0.9809 - val_loss: 0.4947 - val_accuracy: 0.9093
Epoch 334/350
391/391 - 25s - loss: 0.1012 - accuracy: 0.9802 - val_loss: 0.4944 - val_accuracy: 0.9091
Epoch 335/350
391/391 - 25s - loss: 0.0984 - accuracy: 0.9813 - val_loss: 0.4942 - val_accuracy: 0.9092
Epoch 336/350
391/391 - 25s - loss: 0.0992 - accuracy: 0.9813 - val_loss: 0.4938 - val_accuracy: 0.9091
Epoch 337/350
391/391 - 25s - loss: 0.0997 - accuracy: 0.9806 - val_loss: 0.4938 - val_accuracy: 0.9093
Epoch 338/350
391/391 - 25s - loss: 0.0999 - accuracy: 0.9818 - val_loss: 0.4939 - val_accuracy: 0.9090
Epoch 339/350
391/391 - 25s - loss: 0.1023 - accuracy: 0.9796 - val_loss: 0.4937 - val_accuracy: 0.9088
Epoch 340/350
391/391 - 25s - loss: 0.0996 - accuracy: 0.9806 - val_loss: 0.4939 - val_accuracy: 0.9090
Epoch 341/350
391/391 - 25s - loss: 0.0986 - accuracy: 0.9810 - val_loss: 0.4940 - val_accuracy: 0.9090
Epoch 342/350
391/391 - 25s - loss: 0.0981 - accuracy: 0.9812 - val_loss: 0.4940 - val_accuracy: 0.9090
Epoch 343/350
391/391 - 25s - loss: 0.1008 - accuracy: 0.9808 - val_loss: 0.4940 - val_accuracy: 0.9095
Epoch 344/350
391/391 - 25s - loss: 0.1011 - accuracy: 0.9808 - val_loss: 0.4938 - val_accuracy: 0.9091
Epoch 345/350
391/391 - 25s - loss: 0.1021 - accuracy: 0.9803 - val_loss: 0.4939 - val_accuracy: 0.9090
Epoch 346/350
391/391 - 25s - loss: 0.1014 - accuracy: 0.9805 - val_loss: 0.4940 - val_accuracy: 0.9091
Epoch 347/350
391/391 - 25s - loss: 0.1002 - accuracy: 0.9807 - val_loss: 0.4945 - val_accuracy: 0.9092
Epoch 348/350
391/391 - 25s - loss: 0.1000 - accuracy: 0.9807 - val_loss: 0.4948 - val_accuracy: 0.9088
Epoch 349/350
391/391 - 25s - loss: 0.1001 - accuracy: 0.9808 - val_loss: 0.4945 - val_accuracy: 0.9091
Epoch 350/350


Snapshot weight 8 shuffle 3 at epoch 350
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1007 - accuracy: 0.9807 - val_loss: 0.4944 - val_accuracy: 0.9086
/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:493: UserWarning: fill_value is not supported and is always 0 for TensorFlow < 2.4.0.
  return py_builtins.overload_of(f)(*args)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-07-02 04:52:18.448004: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
Saving, final validation acc: 0.9085999727249146
