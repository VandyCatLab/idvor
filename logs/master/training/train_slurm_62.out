2021-07-02 09:42:23.811738: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 09:43:46.450292: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-07-02 09:43:46.489625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:82:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-02 09:43:46.489705: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 09:43:46.532629: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-02 09:43:46.554086: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-02 09:43:46.562675: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-02 09:43:46.607126: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-02 09:43:46.615969: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-02 09:43:46.695155: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 09:43:46.697556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-02 09:43:46.701331: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-02 09:43:46.718417: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599990000 Hz
2021-07-02 09:43:46.718548: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x48957a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-07-02 09:43:46.718570: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-07-02 09:43:46.844755: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4866470 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-07-02 09:43:46.844830: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN X (Pascal), Compute Capability 6.1
2021-07-02 09:43:46.847214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:82:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-02 09:43:46.847254: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 09:43:46.847287: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-02 09:43:46.847308: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-02 09:43:46.847328: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-02 09:43:46.847349: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-02 09:43:46.847368: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-02 09:43:46.848043: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 09:43:46.849671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-02 09:43:46.851476: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 09:43:48.630254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-02 09:43:48.630334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-07-02 09:43:48.630349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-07-02 09:43:48.636209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11228 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:82:00.0, compute capability: 6.1)
2021-07-02 09:43:54.584026: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 09:43:57.104199: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
Using model index: 62
Making train data...
GCN...
ZCA...
Done!
Making test data...
Done!
Epoch 1/350


Snapshot weight 2 shuffle 6 at epoch 1
Layer 11
Getting activations...


391/391 - 25s - loss: 2.2852 - accuracy: 0.1373 - val_loss: 2.1324 - val_accuracy: 0.2320
Epoch 2/350


Snapshot weight 2 shuffle 6 at epoch 2
Layer 11
Getting activations...


391/391 - 25s - loss: 1.9931 - accuracy: 0.2701 - val_loss: 1.8975 - val_accuracy: 0.3028
Epoch 3/350


Snapshot weight 2 shuffle 6 at epoch 3
Layer 11
Getting activations...


391/391 - 26s - loss: 1.6851 - accuracy: 0.3932 - val_loss: 1.5314 - val_accuracy: 0.4593
Epoch 4/350


Snapshot weight 2 shuffle 6 at epoch 4
Layer 11
Getting activations...


391/391 - 26s - loss: 1.4593 - accuracy: 0.4807 - val_loss: 1.3983 - val_accuracy: 0.5154
Epoch 5/350


Snapshot weight 2 shuffle 6 at epoch 5
Layer 11
Getting activations...


391/391 - 25s - loss: 1.3046 - accuracy: 0.5386 - val_loss: 1.1686 - val_accuracy: 0.5936
Epoch 6/350


Snapshot weight 2 shuffle 6 at epoch 6
Layer 11
Getting activations...


391/391 - 25s - loss: 1.2260 - accuracy: 0.5672 - val_loss: 1.0962 - val_accuracy: 0.6148
Epoch 7/350


Snapshot weight 2 shuffle 6 at epoch 7
Layer 11
Getting activations...


391/391 - 26s - loss: 1.1477 - accuracy: 0.5962 - val_loss: 1.0463 - val_accuracy: 0.6359
Epoch 8/350


Snapshot weight 2 shuffle 6 at epoch 8
Layer 11
Getting activations...


391/391 - 26s - loss: 1.0855 - accuracy: 0.6220 - val_loss: 1.0808 - val_accuracy: 0.6230
Epoch 9/350


Snapshot weight 2 shuffle 6 at epoch 9
Layer 11
Getting activations...


391/391 - 26s - loss: 1.0336 - accuracy: 0.6412 - val_loss: 0.9728 - val_accuracy: 0.6642
Epoch 10/350


Snapshot weight 2 shuffle 6 at epoch 10
Layer 11
Getting activations...


391/391 - 26s - loss: 0.9838 - accuracy: 0.6588 - val_loss: 0.9345 - val_accuracy: 0.6814
Epoch 11/350
391/391 - 26s - loss: 0.9496 - accuracy: 0.6737 - val_loss: 0.8447 - val_accuracy: 0.7093
Epoch 12/350
391/391 - 25s - loss: 0.9150 - accuracy: 0.6860 - val_loss: 0.9128 - val_accuracy: 0.6785
Epoch 13/350
391/391 - 25s - loss: 0.8770 - accuracy: 0.7011 - val_loss: 0.9420 - val_accuracy: 0.6886
Epoch 14/350
391/391 - 25s - loss: 0.8542 - accuracy: 0.7086 - val_loss: 0.7886 - val_accuracy: 0.7264
Epoch 15/350
391/391 - 26s - loss: 0.8282 - accuracy: 0.7183 - val_loss: 0.7376 - val_accuracy: 0.7499
Epoch 16/350
391/391 - 25s - loss: 0.7910 - accuracy: 0.7321 - val_loss: 0.7350 - val_accuracy: 0.7500
Epoch 17/350
391/391 - 25s - loss: 0.7622 - accuracy: 0.7425 - val_loss: 0.6878 - val_accuracy: 0.7677
Epoch 18/350
391/391 - 25s - loss: 0.7439 - accuracy: 0.7488 - val_loss: 0.6562 - val_accuracy: 0.7755
Epoch 19/350
391/391 - 25s - loss: 0.7190 - accuracy: 0.7581 - val_loss: 0.6898 - val_accuracy: 0.7740
Epoch 20/350
391/391 - 25s - loss: 0.7034 - accuracy: 0.7648 - val_loss: 0.6691 - val_accuracy: 0.7736
Epoch 21/350
391/391 - 25s - loss: 0.6737 - accuracy: 0.7736 - val_loss: 0.6729 - val_accuracy: 0.7816
Epoch 22/350
391/391 - 25s - loss: 0.6593 - accuracy: 0.7796 - val_loss: 0.6438 - val_accuracy: 0.7884
Epoch 23/350
391/391 - 25s - loss: 0.6418 - accuracy: 0.7882 - val_loss: 0.6083 - val_accuracy: 0.8010
Epoch 24/350
391/391 - 25s - loss: 0.6327 - accuracy: 0.7899 - val_loss: 0.6402 - val_accuracy: 0.7895
Epoch 25/350
391/391 - 25s - loss: 0.6170 - accuracy: 0.7974 - val_loss: 0.6605 - val_accuracy: 0.7895
Epoch 26/350
391/391 - 25s - loss: 0.5974 - accuracy: 0.8021 - val_loss: 0.5729 - val_accuracy: 0.8105
Epoch 27/350
391/391 - 25s - loss: 0.5911 - accuracy: 0.8061 - val_loss: 0.5331 - val_accuracy: 0.8286
Epoch 28/350
391/391 - 25s - loss: 0.5732 - accuracy: 0.8120 - val_loss: 0.5582 - val_accuracy: 0.8204
Epoch 29/350
391/391 - 25s - loss: 0.5609 - accuracy: 0.8145 - val_loss: 0.5449 - val_accuracy: 0.8265
Epoch 30/350
391/391 - 25s - loss: 0.5503 - accuracy: 0.8191 - val_loss: 0.5654 - val_accuracy: 0.8192
Epoch 31/350
391/391 - 25s - loss: 0.5446 - accuracy: 0.8218 - val_loss: 0.5439 - val_accuracy: 0.8304
Epoch 32/350
391/391 - 25s - loss: 0.5271 - accuracy: 0.8269 - val_loss: 0.5888 - val_accuracy: 0.8187
Epoch 33/350
391/391 - 25s - loss: 0.5207 - accuracy: 0.8277 - val_loss: 0.5223 - val_accuracy: 0.8347
Epoch 34/350
391/391 - 25s - loss: 0.5072 - accuracy: 0.8343 - val_loss: 0.4998 - val_accuracy: 0.8421
Epoch 35/350
391/391 - 26s - loss: 0.4943 - accuracy: 0.8375 - val_loss: 0.4980 - val_accuracy: 0.8444
Epoch 36/350
391/391 - 25s - loss: 0.4946 - accuracy: 0.8379 - val_loss: 0.4938 - val_accuracy: 0.8430
Epoch 37/350
391/391 - 25s - loss: 0.4848 - accuracy: 0.8413 - val_loss: 0.4936 - val_accuracy: 0.8444
Epoch 38/350
391/391 - 25s - loss: 0.4824 - accuracy: 0.8437 - val_loss: 0.5075 - val_accuracy: 0.8372
Epoch 39/350
391/391 - 25s - loss: 0.4722 - accuracy: 0.8471 - val_loss: 0.4952 - val_accuracy: 0.8455
Epoch 40/350
391/391 - 25s - loss: 0.4616 - accuracy: 0.8495 - val_loss: 0.5954 - val_accuracy: 0.8230
Epoch 41/350
391/391 - 25s - loss: 0.4611 - accuracy: 0.8515 - val_loss: 0.4691 - val_accuracy: 0.8508
Epoch 42/350
391/391 - 25s - loss: 0.4495 - accuracy: 0.8545 - val_loss: 0.4762 - val_accuracy: 0.8538
Epoch 43/350
391/391 - 25s - loss: 0.4415 - accuracy: 0.8566 - val_loss: 0.5010 - val_accuracy: 0.8484
Epoch 44/350
391/391 - 25s - loss: 0.4438 - accuracy: 0.8565 - val_loss: 0.4951 - val_accuracy: 0.8451
Epoch 45/350
391/391 - 25s - loss: 0.4347 - accuracy: 0.8597 - val_loss: 0.4825 - val_accuracy: 0.8549
Epoch 46/350
391/391 - 25s - loss: 0.4260 - accuracy: 0.8628 - val_loss: 0.5101 - val_accuracy: 0.8492
Epoch 47/350
391/391 - 25s - loss: 0.4252 - accuracy: 0.8633 - val_loss: 0.4496 - val_accuracy: 0.8593
Epoch 48/350
391/391 - 25s - loss: 0.4198 - accuracy: 0.8644 - val_loss: 0.4887 - val_accuracy: 0.8561
Epoch 49/350
391/391 - 25s - loss: 0.4095 - accuracy: 0.8683 - val_loss: 0.4488 - val_accuracy: 0.8639
Epoch 50/350


Snapshot weight 2 shuffle 6 at epoch 50
Layer 11
Getting activations...


391/391 - 25s - loss: 0.4020 - accuracy: 0.8697 - val_loss: 0.5237 - val_accuracy: 0.8461
Epoch 51/350
391/391 - 26s - loss: 0.4041 - accuracy: 0.8717 - val_loss: 0.4597 - val_accuracy: 0.8608
Epoch 52/350
391/391 - 25s - loss: 0.3888 - accuracy: 0.8764 - val_loss: 0.4345 - val_accuracy: 0.8679
Epoch 53/350
391/391 - 25s - loss: 0.3898 - accuracy: 0.8748 - val_loss: 0.4352 - val_accuracy: 0.8698
Epoch 54/350
391/391 - 25s - loss: 0.3877 - accuracy: 0.8764 - val_loss: 0.4563 - val_accuracy: 0.8650
Epoch 55/350
391/391 - 25s - loss: 0.3790 - accuracy: 0.8789 - val_loss: 0.4262 - val_accuracy: 0.8691
Epoch 56/350
391/391 - 25s - loss: 0.3729 - accuracy: 0.8800 - val_loss: 0.4484 - val_accuracy: 0.8688
Epoch 57/350
391/391 - 26s - loss: 0.3704 - accuracy: 0.8812 - val_loss: 0.4694 - val_accuracy: 0.8622
Epoch 58/350
391/391 - 25s - loss: 0.3714 - accuracy: 0.8816 - val_loss: 0.4532 - val_accuracy: 0.8670
Epoch 59/350
391/391 - 25s - loss: 0.3698 - accuracy: 0.8824 - val_loss: 0.4317 - val_accuracy: 0.8698
Epoch 60/350
391/391 - 25s - loss: 0.3609 - accuracy: 0.8856 - val_loss: 0.4389 - val_accuracy: 0.8711
Epoch 61/350
391/391 - 25s - loss: 0.3567 - accuracy: 0.8871 - val_loss: 0.4242 - val_accuracy: 0.8750
Epoch 62/350
391/391 - 26s - loss: 0.3538 - accuracy: 0.8876 - val_loss: 0.4775 - val_accuracy: 0.8637
Epoch 63/350
391/391 - 25s - loss: 0.3500 - accuracy: 0.8881 - val_loss: 0.4305 - val_accuracy: 0.8738
Epoch 64/350
391/391 - 25s - loss: 0.3452 - accuracy: 0.8908 - val_loss: 0.4159 - val_accuracy: 0.8768
Epoch 65/350
391/391 - 25s - loss: 0.3424 - accuracy: 0.8911 - val_loss: 0.4267 - val_accuracy: 0.8758
Epoch 66/350
391/391 - 25s - loss: 0.3393 - accuracy: 0.8929 - val_loss: 0.4453 - val_accuracy: 0.8709
Epoch 67/350
391/391 - 25s - loss: 0.3364 - accuracy: 0.8945 - val_loss: 0.4218 - val_accuracy: 0.8779
Epoch 68/350
391/391 - 25s - loss: 0.3353 - accuracy: 0.8937 - val_loss: 0.4444 - val_accuracy: 0.8739
Epoch 69/350
391/391 - 25s - loss: 0.3370 - accuracy: 0.8936 - val_loss: 0.4691 - val_accuracy: 0.8671
Epoch 70/350
391/391 - 25s - loss: 0.3224 - accuracy: 0.8983 - val_loss: 0.4282 - val_accuracy: 0.8749
Epoch 71/350
391/391 - 25s - loss: 0.3234 - accuracy: 0.8986 - val_loss: 0.4362 - val_accuracy: 0.8752
Epoch 72/350
391/391 - 25s - loss: 0.3203 - accuracy: 0.8995 - val_loss: 0.4279 - val_accuracy: 0.8748
Epoch 73/350
391/391 - 25s - loss: 0.3169 - accuracy: 0.9020 - val_loss: 0.4494 - val_accuracy: 0.8702
Epoch 74/350
391/391 - 25s - loss: 0.3177 - accuracy: 0.8994 - val_loss: 0.4370 - val_accuracy: 0.8761
Epoch 75/350
391/391 - 25s - loss: 0.3074 - accuracy: 0.9039 - val_loss: 0.4433 - val_accuracy: 0.8740
Epoch 76/350
391/391 - 25s - loss: 0.3111 - accuracy: 0.9032 - val_loss: 0.4818 - val_accuracy: 0.8639
Epoch 77/350
391/391 - 25s - loss: 0.3019 - accuracy: 0.9066 - val_loss: 0.4269 - val_accuracy: 0.8795
Epoch 78/350
391/391 - 25s - loss: 0.3055 - accuracy: 0.9046 - val_loss: 0.4283 - val_accuracy: 0.8804
Epoch 79/350
391/391 - 25s - loss: 0.2980 - accuracy: 0.9075 - val_loss: 0.4360 - val_accuracy: 0.8800
Epoch 80/350
391/391 - 25s - loss: 0.2995 - accuracy: 0.9077 - val_loss: 0.4120 - val_accuracy: 0.8869
Epoch 81/350
391/391 - 25s - loss: 0.2962 - accuracy: 0.9079 - val_loss: 0.4512 - val_accuracy: 0.8760
Epoch 82/350
391/391 - 25s - loss: 0.2928 - accuracy: 0.9097 - val_loss: 0.4283 - val_accuracy: 0.8825
Epoch 83/350
391/391 - 25s - loss: 0.2904 - accuracy: 0.9108 - val_loss: 0.4476 - val_accuracy: 0.8794
Epoch 84/350
391/391 - 25s - loss: 0.2839 - accuracy: 0.9127 - val_loss: 0.4034 - val_accuracy: 0.8870
Epoch 85/350
391/391 - 25s - loss: 0.2917 - accuracy: 0.9101 - val_loss: 0.4123 - val_accuracy: 0.8836
Epoch 86/350
391/391 - 26s - loss: 0.2832 - accuracy: 0.9120 - val_loss: 0.4430 - val_accuracy: 0.8781
Epoch 87/350
391/391 - 25s - loss: 0.2809 - accuracy: 0.9138 - val_loss: 0.4458 - val_accuracy: 0.8805
Epoch 88/350
391/391 - 25s - loss: 0.2741 - accuracy: 0.9168 - val_loss: 0.4368 - val_accuracy: 0.8791
Epoch 89/350
391/391 - 25s - loss: 0.2832 - accuracy: 0.9131 - val_loss: 0.4105 - val_accuracy: 0.8899
Epoch 90/350
391/391 - 25s - loss: 0.2784 - accuracy: 0.9137 - val_loss: 0.4559 - val_accuracy: 0.8792
Epoch 91/350
391/391 - 25s - loss: 0.2764 - accuracy: 0.9164 - val_loss: 0.4362 - val_accuracy: 0.8818
Epoch 92/350
391/391 - 25s - loss: 0.2722 - accuracy: 0.9174 - val_loss: 0.4203 - val_accuracy: 0.8860
Epoch 93/350
391/391 - 25s - loss: 0.2744 - accuracy: 0.9153 - val_loss: 0.4283 - val_accuracy: 0.8827
Epoch 94/350
391/391 - 26s - loss: 0.2713 - accuracy: 0.9171 - val_loss: 0.4278 - val_accuracy: 0.8799
Epoch 95/350
391/391 - 25s - loss: 0.2652 - accuracy: 0.9176 - val_loss: 0.4150 - val_accuracy: 0.8895
Epoch 96/350
391/391 - 25s - loss: 0.2640 - accuracy: 0.9190 - val_loss: 0.4137 - val_accuracy: 0.8917
Epoch 97/350
391/391 - 25s - loss: 0.2592 - accuracy: 0.9209 - val_loss: 0.4233 - val_accuracy: 0.8907
Epoch 98/350
391/391 - 26s - loss: 0.2587 - accuracy: 0.9219 - val_loss: 0.4473 - val_accuracy: 0.8866
Epoch 99/350
391/391 - 25s - loss: 0.2610 - accuracy: 0.9189 - val_loss: 0.4163 - val_accuracy: 0.8887
Epoch 100/350


Snapshot weight 2 shuffle 6 at epoch 100
Layer 11
Getting activations...


391/391 - 26s - loss: 0.2560 - accuracy: 0.9221 - val_loss: 0.4185 - val_accuracy: 0.8896
Epoch 101/350
391/391 - 25s - loss: 0.2556 - accuracy: 0.9221 - val_loss: 0.4510 - val_accuracy: 0.8887
Epoch 102/350
391/391 - 25s - loss: 0.2535 - accuracy: 0.9235 - val_loss: 0.4288 - val_accuracy: 0.8841
Epoch 103/350
391/391 - 25s - loss: 0.2487 - accuracy: 0.9257 - val_loss: 0.3996 - val_accuracy: 0.8947
Epoch 104/350
391/391 - 25s - loss: 0.2489 - accuracy: 0.9252 - val_loss: 0.4301 - val_accuracy: 0.8814
Epoch 105/350
391/391 - 26s - loss: 0.2523 - accuracy: 0.9231 - val_loss: 0.4125 - val_accuracy: 0.8848
Epoch 106/350
391/391 - 25s - loss: 0.2488 - accuracy: 0.9257 - val_loss: 0.4653 - val_accuracy: 0.8780
Epoch 107/350
391/391 - 25s - loss: 0.2472 - accuracy: 0.9263 - val_loss: 0.4444 - val_accuracy: 0.8831
Epoch 108/350
391/391 - 25s - loss: 0.2433 - accuracy: 0.9273 - val_loss: 0.4303 - val_accuracy: 0.8876
Epoch 109/350
391/391 - 25s - loss: 0.2385 - accuracy: 0.9286 - val_loss: 0.4175 - val_accuracy: 0.8929
Epoch 110/350
391/391 - 25s - loss: 0.2414 - accuracy: 0.9281 - val_loss: 0.4280 - val_accuracy: 0.8909
Epoch 111/350
391/391 - 25s - loss: 0.2419 - accuracy: 0.9278 - val_loss: 0.4171 - val_accuracy: 0.8907
Epoch 112/350
391/391 - 25s - loss: 0.2378 - accuracy: 0.9293 - val_loss: 0.4236 - val_accuracy: 0.8910
Epoch 113/350
391/391 - 25s - loss: 0.2358 - accuracy: 0.9294 - val_loss: 0.4154 - val_accuracy: 0.8924
Epoch 114/350
391/391 - 25s - loss: 0.2341 - accuracy: 0.9305 - val_loss: 0.4396 - val_accuracy: 0.8878
Epoch 115/350
391/391 - 25s - loss: 0.2343 - accuracy: 0.9306 - val_loss: 0.4347 - val_accuracy: 0.8881
Epoch 116/350
391/391 - 25s - loss: 0.2326 - accuracy: 0.9323 - val_loss: 0.4242 - val_accuracy: 0.8924
Epoch 117/350
391/391 - 25s - loss: 0.2301 - accuracy: 0.9325 - val_loss: 0.4506 - val_accuracy: 0.8894
Epoch 118/350
391/391 - 25s - loss: 0.2280 - accuracy: 0.9327 - val_loss: 0.4706 - val_accuracy: 0.8848
Epoch 119/350
391/391 - 25s - loss: 0.2265 - accuracy: 0.9342 - val_loss: 0.4733 - val_accuracy: 0.8866
Epoch 120/350
391/391 - 25s - loss: 0.2272 - accuracy: 0.9342 - val_loss: 0.4746 - val_accuracy: 0.8810
Epoch 121/350
391/391 - 25s - loss: 0.2251 - accuracy: 0.9346 - val_loss: 0.4559 - val_accuracy: 0.8875
Epoch 122/350
391/391 - 25s - loss: 0.2213 - accuracy: 0.9359 - val_loss: 0.4306 - val_accuracy: 0.8963
Epoch 123/350
391/391 - 25s - loss: 0.2239 - accuracy: 0.9350 - val_loss: 0.4063 - val_accuracy: 0.8973
Epoch 124/350
391/391 - 25s - loss: 0.2184 - accuracy: 0.9365 - val_loss: 0.4240 - val_accuracy: 0.8888
Epoch 125/350
391/391 - 25s - loss: 0.2218 - accuracy: 0.9354 - val_loss: 0.4469 - val_accuracy: 0.8893
Epoch 126/350
391/391 - 25s - loss: 0.2218 - accuracy: 0.9360 - val_loss: 0.4379 - val_accuracy: 0.8912
Epoch 127/350
391/391 - 25s - loss: 0.2165 - accuracy: 0.9380 - val_loss: 0.4353 - val_accuracy: 0.8875
Epoch 128/350
391/391 - 26s - loss: 0.2175 - accuracy: 0.9365 - val_loss: 0.4325 - val_accuracy: 0.8920
Epoch 129/350
391/391 - 26s - loss: 0.2184 - accuracy: 0.9372 - val_loss: 0.4453 - val_accuracy: 0.8892
Epoch 130/350
391/391 - 25s - loss: 0.2109 - accuracy: 0.9398 - val_loss: 0.4452 - val_accuracy: 0.8896
Epoch 131/350
391/391 - 25s - loss: 0.2102 - accuracy: 0.9389 - val_loss: 0.4280 - val_accuracy: 0.8976
Epoch 132/350
391/391 - 25s - loss: 0.2135 - accuracy: 0.9389 - val_loss: 0.4499 - val_accuracy: 0.8870
Epoch 133/350
391/391 - 25s - loss: 0.2125 - accuracy: 0.9378 - val_loss: 0.4535 - val_accuracy: 0.8853
Epoch 134/350
391/391 - 25s - loss: 0.2072 - accuracy: 0.9414 - val_loss: 0.4329 - val_accuracy: 0.8901
Epoch 135/350
391/391 - 25s - loss: 0.2052 - accuracy: 0.9426 - val_loss: 0.4438 - val_accuracy: 0.8910
Epoch 136/350
391/391 - 26s - loss: 0.2108 - accuracy: 0.9402 - val_loss: 0.4454 - val_accuracy: 0.8930
Epoch 137/350
391/391 - 25s - loss: 0.2110 - accuracy: 0.9411 - val_loss: 0.4457 - val_accuracy: 0.8961
Epoch 138/350
391/391 - 25s - loss: 0.2053 - accuracy: 0.9410 - val_loss: 0.4175 - val_accuracy: 0.8952
Epoch 139/350
391/391 - 25s - loss: 0.2034 - accuracy: 0.9439 - val_loss: 0.4270 - val_accuracy: 0.8970
Epoch 140/350
391/391 - 25s - loss: 0.2070 - accuracy: 0.9421 - val_loss: 0.4668 - val_accuracy: 0.8896
Epoch 141/350
391/391 - 25s - loss: 0.1999 - accuracy: 0.9442 - val_loss: 0.4556 - val_accuracy: 0.8927
Epoch 142/350
391/391 - 25s - loss: 0.2021 - accuracy: 0.9444 - val_loss: 0.4519 - val_accuracy: 0.8974
Epoch 143/350
391/391 - 25s - loss: 0.2022 - accuracy: 0.9432 - val_loss: 0.4226 - val_accuracy: 0.8968
Epoch 144/350
391/391 - 25s - loss: 0.2019 - accuracy: 0.9425 - val_loss: 0.4767 - val_accuracy: 0.8904
Epoch 145/350
391/391 - 25s - loss: 0.2022 - accuracy: 0.9436 - val_loss: 0.4624 - val_accuracy: 0.8889
Epoch 146/350
391/391 - 25s - loss: 0.1963 - accuracy: 0.9459 - val_loss: 0.4419 - val_accuracy: 0.8951
Epoch 147/350
391/391 - 25s - loss: 0.1926 - accuracy: 0.9470 - val_loss: 0.4843 - val_accuracy: 0.8911
Epoch 148/350
391/391 - 25s - loss: 0.2010 - accuracy: 0.9441 - val_loss: 0.4689 - val_accuracy: 0.8910
Epoch 149/350
391/391 - 25s - loss: 0.1967 - accuracy: 0.9455 - val_loss: 0.4427 - val_accuracy: 0.8958
Epoch 150/350


Snapshot weight 2 shuffle 6 at epoch 150
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1958 - accuracy: 0.9455 - val_loss: 0.4502 - val_accuracy: 0.8933
Epoch 151/350
391/391 - 25s - loss: 0.1888 - accuracy: 0.9471 - val_loss: 0.4605 - val_accuracy: 0.8939
Epoch 152/350
391/391 - 25s - loss: 0.1938 - accuracy: 0.9459 - val_loss: 0.4713 - val_accuracy: 0.8937
Epoch 153/350
391/391 - 25s - loss: 0.1893 - accuracy: 0.9470 - val_loss: 0.4531 - val_accuracy: 0.8942
Epoch 154/350
391/391 - 25s - loss: 0.1894 - accuracy: 0.9476 - val_loss: 0.4825 - val_accuracy: 0.8877
Epoch 155/350
391/391 - 25s - loss: 0.1923 - accuracy: 0.9459 - val_loss: 0.4647 - val_accuracy: 0.8949
Epoch 156/350
391/391 - 25s - loss: 0.1918 - accuracy: 0.9477 - val_loss: 0.4518 - val_accuracy: 0.8941
Epoch 157/350
391/391 - 25s - loss: 0.1875 - accuracy: 0.9486 - val_loss: 0.4824 - val_accuracy: 0.8876
Epoch 158/350
391/391 - 25s - loss: 0.1906 - accuracy: 0.9475 - val_loss: 0.4476 - val_accuracy: 0.8941
Epoch 159/350
391/391 - 25s - loss: 0.1895 - accuracy: 0.9476 - val_loss: 0.4244 - val_accuracy: 0.8999
Epoch 160/350
391/391 - 25s - loss: 0.1833 - accuracy: 0.9503 - val_loss: 0.4680 - val_accuracy: 0.8954
Epoch 161/350
391/391 - 25s - loss: 0.1914 - accuracy: 0.9465 - val_loss: 0.4374 - val_accuracy: 0.8903
Epoch 162/350
391/391 - 25s - loss: 0.1834 - accuracy: 0.9508 - val_loss: 0.4881 - val_accuracy: 0.8902
Epoch 163/350
391/391 - 25s - loss: 0.1865 - accuracy: 0.9494 - val_loss: 0.4633 - val_accuracy: 0.8934
Epoch 164/350
391/391 - 25s - loss: 0.1825 - accuracy: 0.9500 - val_loss: 0.4755 - val_accuracy: 0.8911
Epoch 165/350
391/391 - 25s - loss: 0.1868 - accuracy: 0.9495 - val_loss: 0.4456 - val_accuracy: 0.8961
Epoch 166/350
391/391 - 25s - loss: 0.1860 - accuracy: 0.9492 - val_loss: 0.5078 - val_accuracy: 0.8893
Epoch 167/350
391/391 - 25s - loss: 0.1835 - accuracy: 0.9501 - val_loss: 0.4617 - val_accuracy: 0.8947
Epoch 168/350
391/391 - 25s - loss: 0.1812 - accuracy: 0.9518 - val_loss: 0.4840 - val_accuracy: 0.8940
Epoch 169/350
391/391 - 25s - loss: 0.1796 - accuracy: 0.9513 - val_loss: 0.4658 - val_accuracy: 0.8954
Epoch 170/350
391/391 - 26s - loss: 0.1818 - accuracy: 0.9506 - val_loss: 0.4498 - val_accuracy: 0.8998
Epoch 171/350
391/391 - 25s - loss: 0.1810 - accuracy: 0.9515 - val_loss: 0.4390 - val_accuracy: 0.9002
Epoch 172/350
391/391 - 25s - loss: 0.1766 - accuracy: 0.9524 - val_loss: 0.4722 - val_accuracy: 0.8950
Epoch 173/350
391/391 - 25s - loss: 0.1753 - accuracy: 0.9536 - val_loss: 0.4675 - val_accuracy: 0.8961
Epoch 174/350
391/391 - 25s - loss: 0.1743 - accuracy: 0.9543 - val_loss: 0.4821 - val_accuracy: 0.8934
Epoch 175/350
391/391 - 25s - loss: 0.1748 - accuracy: 0.9541 - val_loss: 0.4583 - val_accuracy: 0.8930
Epoch 176/350
391/391 - 25s - loss: 0.1732 - accuracy: 0.9543 - val_loss: 0.4606 - val_accuracy: 0.8956
Epoch 177/350
391/391 - 25s - loss: 0.1760 - accuracy: 0.9533 - val_loss: 0.4875 - val_accuracy: 0.8972
Epoch 178/350
391/391 - 25s - loss: 0.1737 - accuracy: 0.9532 - val_loss: 0.4388 - val_accuracy: 0.8998
Epoch 179/350
391/391 - 25s - loss: 0.1768 - accuracy: 0.9530 - val_loss: 0.4635 - val_accuracy: 0.9013
Epoch 180/350
391/391 - 25s - loss: 0.1741 - accuracy: 0.9555 - val_loss: 0.4777 - val_accuracy: 0.8948
Epoch 181/350
391/391 - 25s - loss: 0.1718 - accuracy: 0.9559 - val_loss: 0.4928 - val_accuracy: 0.8900
Epoch 182/350
391/391 - 25s - loss: 0.1752 - accuracy: 0.9536 - val_loss: 0.4785 - val_accuracy: 0.8906
Epoch 183/350
391/391 - 25s - loss: 0.1683 - accuracy: 0.9560 - val_loss: 0.5307 - val_accuracy: 0.8900
Epoch 184/350
391/391 - 25s - loss: 0.1700 - accuracy: 0.9554 - val_loss: 0.4848 - val_accuracy: 0.8925
Epoch 185/350
391/391 - 25s - loss: 0.1687 - accuracy: 0.9556 - val_loss: 0.4799 - val_accuracy: 0.8945
Epoch 186/350
391/391 - 25s - loss: 0.1702 - accuracy: 0.9559 - val_loss: 0.4792 - val_accuracy: 0.8945
Epoch 187/350
391/391 - 25s - loss: 0.1708 - accuracy: 0.9552 - val_loss: 0.4509 - val_accuracy: 0.9003
Epoch 188/350
391/391 - 25s - loss: 0.1695 - accuracy: 0.9554 - val_loss: 0.4870 - val_accuracy: 0.8955
Epoch 189/350
391/391 - 25s - loss: 0.1717 - accuracy: 0.9558 - val_loss: 0.4686 - val_accuracy: 0.8971
Epoch 190/350
391/391 - 25s - loss: 0.1687 - accuracy: 0.9566 - val_loss: 0.4853 - val_accuracy: 0.8952
Epoch 191/350
391/391 - 25s - loss: 0.1724 - accuracy: 0.9554 - val_loss: 0.4535 - val_accuracy: 0.8977
Epoch 192/350
391/391 - 25s - loss: 0.1645 - accuracy: 0.9573 - val_loss: 0.5051 - val_accuracy: 0.8965
Epoch 193/350
391/391 - 26s - loss: 0.1678 - accuracy: 0.9563 - val_loss: 0.4832 - val_accuracy: 0.8963
Epoch 194/350
391/391 - 25s - loss: 0.1643 - accuracy: 0.9581 - val_loss: 0.5123 - val_accuracy: 0.8920
Epoch 195/350
391/391 - 25s - loss: 0.1683 - accuracy: 0.9565 - val_loss: 0.4637 - val_accuracy: 0.8997
Epoch 196/350
391/391 - 25s - loss: 0.1649 - accuracy: 0.9584 - val_loss: 0.4754 - val_accuracy: 0.8993
Epoch 197/350
391/391 - 25s - loss: 0.1700 - accuracy: 0.9568 - val_loss: 0.4940 - val_accuracy: 0.8966
Epoch 198/350
391/391 - 25s - loss: 0.1685 - accuracy: 0.9563 - val_loss: 0.4730 - val_accuracy: 0.9010
Epoch 199/350
391/391 - 25s - loss: 0.1635 - accuracy: 0.9588 - val_loss: 0.4797 - val_accuracy: 0.8951
Epoch 200/350


Snapshot weight 2 shuffle 6 at epoch 200
Layer 11
Getting activations...


391/391 - 26s - loss: 0.1656 - accuracy: 0.9577 - val_loss: 0.5000 - val_accuracy: 0.8995
Epoch 201/350
391/391 - 25s - loss: 0.1379 - accuracy: 0.9672 - val_loss: 0.4638 - val_accuracy: 0.9035
Epoch 202/350
391/391 - 26s - loss: 0.1244 - accuracy: 0.9722 - val_loss: 0.4653 - val_accuracy: 0.9061
Epoch 203/350
391/391 - 25s - loss: 0.1195 - accuracy: 0.9743 - val_loss: 0.4676 - val_accuracy: 0.9067
Epoch 204/350
391/391 - 25s - loss: 0.1192 - accuracy: 0.9742 - val_loss: 0.4710 - val_accuracy: 0.9070
Epoch 205/350
391/391 - 25s - loss: 0.1170 - accuracy: 0.9751 - val_loss: 0.4836 - val_accuracy: 0.9060
Epoch 206/350
391/391 - 26s - loss: 0.1170 - accuracy: 0.9751 - val_loss: 0.4733 - val_accuracy: 0.9089
Epoch 207/350
391/391 - 25s - loss: 0.1165 - accuracy: 0.9752 - val_loss: 0.4750 - val_accuracy: 0.9071
Epoch 208/350
391/391 - 25s - loss: 0.1156 - accuracy: 0.9758 - val_loss: 0.4768 - val_accuracy: 0.9081
Epoch 209/350
391/391 - 25s - loss: 0.1163 - accuracy: 0.9751 - val_loss: 0.4762 - val_accuracy: 0.9077
Epoch 210/350
391/391 - 25s - loss: 0.1132 - accuracy: 0.9758 - val_loss: 0.4859 - val_accuracy: 0.9087
Epoch 211/350
391/391 - 25s - loss: 0.1141 - accuracy: 0.9754 - val_loss: 0.4790 - val_accuracy: 0.9080
Epoch 212/350
391/391 - 25s - loss: 0.1139 - accuracy: 0.9761 - val_loss: 0.4798 - val_accuracy: 0.9085
Epoch 213/350
391/391 - 25s - loss: 0.1156 - accuracy: 0.9754 - val_loss: 0.4858 - val_accuracy: 0.9080
Epoch 214/350
391/391 - 25s - loss: 0.1131 - accuracy: 0.9760 - val_loss: 0.4867 - val_accuracy: 0.9088
Epoch 215/350
391/391 - 25s - loss: 0.1113 - accuracy: 0.9769 - val_loss: 0.4843 - val_accuracy: 0.9084
Epoch 216/350
391/391 - 26s - loss: 0.1114 - accuracy: 0.9777 - val_loss: 0.4849 - val_accuracy: 0.9082
Epoch 217/350
391/391 - 25s - loss: 0.1103 - accuracy: 0.9772 - val_loss: 0.4894 - val_accuracy: 0.9097
Epoch 218/350
391/391 - 25s - loss: 0.1108 - accuracy: 0.9769 - val_loss: 0.4938 - val_accuracy: 0.9071
Epoch 219/350
391/391 - 25s - loss: 0.1112 - accuracy: 0.9770 - val_loss: 0.4922 - val_accuracy: 0.9086
Epoch 220/350
391/391 - 25s - loss: 0.1081 - accuracy: 0.9776 - val_loss: 0.4918 - val_accuracy: 0.9071
Epoch 221/350
391/391 - 25s - loss: 0.1088 - accuracy: 0.9781 - val_loss: 0.4916 - val_accuracy: 0.9088
Epoch 222/350
391/391 - 25s - loss: 0.1083 - accuracy: 0.9781 - val_loss: 0.5006 - val_accuracy: 0.9071
Epoch 223/350
391/391 - 25s - loss: 0.1088 - accuracy: 0.9784 - val_loss: 0.4985 - val_accuracy: 0.9072
Epoch 224/350
391/391 - 25s - loss: 0.1050 - accuracy: 0.9792 - val_loss: 0.5052 - val_accuracy: 0.9082
Epoch 225/350
391/391 - 25s - loss: 0.1059 - accuracy: 0.9791 - val_loss: 0.5102 - val_accuracy: 0.9071
Epoch 226/350
391/391 - 25s - loss: 0.1085 - accuracy: 0.9780 - val_loss: 0.5047 - val_accuracy: 0.9082
Epoch 227/350
391/391 - 25s - loss: 0.1078 - accuracy: 0.9782 - val_loss: 0.5002 - val_accuracy: 0.9080
Epoch 228/350
391/391 - 25s - loss: 0.1075 - accuracy: 0.9782 - val_loss: 0.5018 - val_accuracy: 0.9075
Epoch 229/350
391/391 - 25s - loss: 0.1061 - accuracy: 0.9786 - val_loss: 0.5065 - val_accuracy: 0.9064
Epoch 230/350
391/391 - 25s - loss: 0.1080 - accuracy: 0.9783 - val_loss: 0.5039 - val_accuracy: 0.9083
Epoch 231/350
391/391 - 25s - loss: 0.1057 - accuracy: 0.9786 - val_loss: 0.4977 - val_accuracy: 0.9077
Epoch 232/350
391/391 - 26s - loss: 0.1084 - accuracy: 0.9772 - val_loss: 0.5058 - val_accuracy: 0.9071
Epoch 233/350
391/391 - 25s - loss: 0.1076 - accuracy: 0.9784 - val_loss: 0.4948 - val_accuracy: 0.9073
Epoch 234/350
391/391 - 25s - loss: 0.1053 - accuracy: 0.9793 - val_loss: 0.5022 - val_accuracy: 0.9079
Epoch 235/350
391/391 - 25s - loss: 0.1063 - accuracy: 0.9789 - val_loss: 0.5036 - val_accuracy: 0.9079
Epoch 236/350
391/391 - 25s - loss: 0.1060 - accuracy: 0.9791 - val_loss: 0.5079 - val_accuracy: 0.9077
Epoch 237/350
391/391 - 25s - loss: 0.1062 - accuracy: 0.9787 - val_loss: 0.4977 - val_accuracy: 0.9078
Epoch 238/350
391/391 - 25s - loss: 0.1041 - accuracy: 0.9791 - val_loss: 0.5106 - val_accuracy: 0.9086
Epoch 239/350
391/391 - 25s - loss: 0.1029 - accuracy: 0.9798 - val_loss: 0.5197 - val_accuracy: 0.9082
Epoch 240/350
391/391 - 25s - loss: 0.1050 - accuracy: 0.9790 - val_loss: 0.5077 - val_accuracy: 0.9087
Epoch 241/350
391/391 - 25s - loss: 0.1044 - accuracy: 0.9793 - val_loss: 0.5093 - val_accuracy: 0.9086
Epoch 242/350
391/391 - 25s - loss: 0.1061 - accuracy: 0.9791 - val_loss: 0.5054 - val_accuracy: 0.9072
Epoch 243/350
391/391 - 25s - loss: 0.1037 - accuracy: 0.9799 - val_loss: 0.5064 - val_accuracy: 0.9066
Epoch 244/350
391/391 - 25s - loss: 0.1028 - accuracy: 0.9797 - val_loss: 0.5009 - val_accuracy: 0.9075
Epoch 245/350
391/391 - 25s - loss: 0.1051 - accuracy: 0.9777 - val_loss: 0.5071 - val_accuracy: 0.9071
Epoch 246/350
391/391 - 25s - loss: 0.1026 - accuracy: 0.9796 - val_loss: 0.5092 - val_accuracy: 0.9071
Epoch 247/350
391/391 - 25s - loss: 0.1041 - accuracy: 0.9803 - val_loss: 0.4980 - val_accuracy: 0.9089
Epoch 248/350
391/391 - 25s - loss: 0.1052 - accuracy: 0.9789 - val_loss: 0.5139 - val_accuracy: 0.9081
Epoch 249/350
391/391 - 25s - loss: 0.1005 - accuracy: 0.9805 - val_loss: 0.5206 - val_accuracy: 0.9075
Epoch 250/350


Snapshot weight 2 shuffle 6 at epoch 250
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1021 - accuracy: 0.9797 - val_loss: 0.5153 - val_accuracy: 0.9081
Epoch 251/350
391/391 - 25s - loss: 0.0987 - accuracy: 0.9807 - val_loss: 0.5108 - val_accuracy: 0.9074
Epoch 252/350
391/391 - 25s - loss: 0.1001 - accuracy: 0.9813 - val_loss: 0.5096 - val_accuracy: 0.9085
Epoch 253/350
391/391 - 25s - loss: 0.1024 - accuracy: 0.9803 - val_loss: 0.5087 - val_accuracy: 0.9089
Epoch 254/350
391/391 - 25s - loss: 0.1025 - accuracy: 0.9796 - val_loss: 0.5102 - val_accuracy: 0.9083
Epoch 255/350
391/391 - 25s - loss: 0.0992 - accuracy: 0.9808 - val_loss: 0.5091 - val_accuracy: 0.9092
Epoch 256/350
391/391 - 25s - loss: 0.1021 - accuracy: 0.9798 - val_loss: 0.5088 - val_accuracy: 0.9090
Epoch 257/350
391/391 - 25s - loss: 0.0996 - accuracy: 0.9803 - val_loss: 0.5095 - val_accuracy: 0.9080
Epoch 258/350
391/391 - 25s - loss: 0.0994 - accuracy: 0.9814 - val_loss: 0.5097 - val_accuracy: 0.9081
Epoch 259/350
391/391 - 25s - loss: 0.1013 - accuracy: 0.9802 - val_loss: 0.5077 - val_accuracy: 0.9085
Epoch 260/350
391/391 - 25s - loss: 0.0992 - accuracy: 0.9809 - val_loss: 0.5078 - val_accuracy: 0.9095
Epoch 261/350
391/391 - 25s - loss: 0.1004 - accuracy: 0.9801 - val_loss: 0.5103 - val_accuracy: 0.9072
Epoch 262/350
391/391 - 25s - loss: 0.0980 - accuracy: 0.9817 - val_loss: 0.5099 - val_accuracy: 0.9077
Epoch 263/350
391/391 - 25s - loss: 0.0975 - accuracy: 0.9821 - val_loss: 0.5084 - val_accuracy: 0.9084
Epoch 264/350
391/391 - 25s - loss: 0.0983 - accuracy: 0.9813 - val_loss: 0.5117 - val_accuracy: 0.9086
Epoch 265/350
391/391 - 26s - loss: 0.1005 - accuracy: 0.9805 - val_loss: 0.5093 - val_accuracy: 0.9079
Epoch 266/350
391/391 - 25s - loss: 0.1011 - accuracy: 0.9804 - val_loss: 0.5072 - val_accuracy: 0.9092
Epoch 267/350
391/391 - 25s - loss: 0.0975 - accuracy: 0.9818 - val_loss: 0.5124 - val_accuracy: 0.9080
Epoch 268/350
391/391 - 25s - loss: 0.0970 - accuracy: 0.9819 - val_loss: 0.5105 - val_accuracy: 0.9088
Epoch 269/350
391/391 - 25s - loss: 0.0972 - accuracy: 0.9819 - val_loss: 0.5115 - val_accuracy: 0.9087
Epoch 270/350
391/391 - 25s - loss: 0.0981 - accuracy: 0.9819 - val_loss: 0.5091 - val_accuracy: 0.9087
Epoch 271/350
391/391 - 26s - loss: 0.0967 - accuracy: 0.9821 - val_loss: 0.5101 - val_accuracy: 0.9079
Epoch 272/350
391/391 - 25s - loss: 0.0972 - accuracy: 0.9820 - val_loss: 0.5097 - val_accuracy: 0.9079
Epoch 273/350
391/391 - 25s - loss: 0.0992 - accuracy: 0.9815 - val_loss: 0.5095 - val_accuracy: 0.9091
Epoch 274/350
391/391 - 25s - loss: 0.1001 - accuracy: 0.9809 - val_loss: 0.5103 - val_accuracy: 0.9086
Epoch 275/350
391/391 - 25s - loss: 0.0968 - accuracy: 0.9814 - val_loss: 0.5093 - val_accuracy: 0.9094
Epoch 276/350
391/391 - 25s - loss: 0.0974 - accuracy: 0.9817 - val_loss: 0.5105 - val_accuracy: 0.9092
Epoch 277/350
391/391 - 25s - loss: 0.0989 - accuracy: 0.9816 - val_loss: 0.5127 - val_accuracy: 0.9093
Epoch 278/350
391/391 - 25s - loss: 0.0978 - accuracy: 0.9818 - val_loss: 0.5107 - val_accuracy: 0.9093
Epoch 279/350
391/391 - 25s - loss: 0.0997 - accuracy: 0.9806 - val_loss: 0.5104 - val_accuracy: 0.9089
Epoch 280/350
391/391 - 25s - loss: 0.0987 - accuracy: 0.9815 - val_loss: 0.5110 - val_accuracy: 0.9083
Epoch 281/350
391/391 - 25s - loss: 0.0953 - accuracy: 0.9827 - val_loss: 0.5121 - val_accuracy: 0.9090
Epoch 282/350
391/391 - 25s - loss: 0.1007 - accuracy: 0.9812 - val_loss: 0.5119 - val_accuracy: 0.9092
Epoch 283/350
391/391 - 25s - loss: 0.0993 - accuracy: 0.9812 - val_loss: 0.5110 - val_accuracy: 0.9086
Epoch 284/350
391/391 - 25s - loss: 0.1001 - accuracy: 0.9802 - val_loss: 0.5107 - val_accuracy: 0.9083
Epoch 285/350
391/391 - 25s - loss: 0.0997 - accuracy: 0.9809 - val_loss: 0.5097 - val_accuracy: 0.9078
Epoch 286/350
391/391 - 25s - loss: 0.0994 - accuracy: 0.9810 - val_loss: 0.5095 - val_accuracy: 0.9083
Epoch 287/350
391/391 - 25s - loss: 0.0985 - accuracy: 0.9816 - val_loss: 0.5081 - val_accuracy: 0.9095
Epoch 288/350
391/391 - 25s - loss: 0.0953 - accuracy: 0.9828 - val_loss: 0.5125 - val_accuracy: 0.9089
Epoch 289/350
391/391 - 25s - loss: 0.0989 - accuracy: 0.9812 - val_loss: 0.5108 - val_accuracy: 0.9088
Epoch 290/350
391/391 - 25s - loss: 0.1008 - accuracy: 0.9809 - val_loss: 0.5111 - val_accuracy: 0.9095
Epoch 291/350
391/391 - 25s - loss: 0.0982 - accuracy: 0.9813 - val_loss: 0.5119 - val_accuracy: 0.9087
Epoch 292/350
391/391 - 25s - loss: 0.0959 - accuracy: 0.9822 - val_loss: 0.5129 - val_accuracy: 0.9093
Epoch 293/350
391/391 - 25s - loss: 0.0982 - accuracy: 0.9817 - val_loss: 0.5121 - val_accuracy: 0.9089
Epoch 294/350
391/391 - 25s - loss: 0.0976 - accuracy: 0.9814 - val_loss: 0.5108 - val_accuracy: 0.9092
Epoch 295/350
391/391 - 25s - loss: 0.0985 - accuracy: 0.9813 - val_loss: 0.5120 - val_accuracy: 0.9090
Epoch 296/350
391/391 - 25s - loss: 0.0958 - accuracy: 0.9825 - val_loss: 0.5115 - val_accuracy: 0.9092
Epoch 297/350
391/391 - 25s - loss: 0.0994 - accuracy: 0.9810 - val_loss: 0.5116 - val_accuracy: 0.9087
Epoch 298/350
391/391 - 25s - loss: 0.0993 - accuracy: 0.9815 - val_loss: 0.5131 - val_accuracy: 0.9088
Epoch 299/350
391/391 - 25s - loss: 0.0975 - accuracy: 0.9816 - val_loss: 0.5117 - val_accuracy: 0.9094
Epoch 300/350


Snapshot weight 2 shuffle 6 at epoch 300
Layer 11
Getting activations...


391/391 - 26s - loss: 0.0956 - accuracy: 0.9828 - val_loss: 0.5122 - val_accuracy: 0.9087
Epoch 301/350
391/391 - 25s - loss: 0.0986 - accuracy: 0.9809 - val_loss: 0.5118 - val_accuracy: 0.9086
Epoch 302/350
391/391 - 25s - loss: 0.0989 - accuracy: 0.9810 - val_loss: 0.5118 - val_accuracy: 0.9083
Epoch 303/350
391/391 - 25s - loss: 0.0975 - accuracy: 0.9819 - val_loss: 0.5117 - val_accuracy: 0.9084
Epoch 304/350
391/391 - 25s - loss: 0.0964 - accuracy: 0.9819 - val_loss: 0.5118 - val_accuracy: 0.9087
Epoch 305/350
391/391 - 25s - loss: 0.0983 - accuracy: 0.9812 - val_loss: 0.5119 - val_accuracy: 0.9087
Epoch 306/350
391/391 - 25s - loss: 0.0967 - accuracy: 0.9821 - val_loss: 0.5120 - val_accuracy: 0.9086
Epoch 307/350
391/391 - 25s - loss: 0.0978 - accuracy: 0.9807 - val_loss: 0.5119 - val_accuracy: 0.9085
Epoch 308/350
391/391 - 25s - loss: 0.0986 - accuracy: 0.9818 - val_loss: 0.5116 - val_accuracy: 0.9086
Epoch 309/350
391/391 - 25s - loss: 0.0991 - accuracy: 0.9816 - val_loss: 0.5109 - val_accuracy: 0.9088
Epoch 310/350
391/391 - 25s - loss: 0.0979 - accuracy: 0.9820 - val_loss: 0.5112 - val_accuracy: 0.9086
Epoch 311/350
391/391 - 25s - loss: 0.0954 - accuracy: 0.9823 - val_loss: 0.5116 - val_accuracy: 0.9081
Epoch 312/350
391/391 - 25s - loss: 0.1016 - accuracy: 0.9794 - val_loss: 0.5120 - val_accuracy: 0.9082
Epoch 313/350
391/391 - 25s - loss: 0.0985 - accuracy: 0.9816 - val_loss: 0.5116 - val_accuracy: 0.9085
Epoch 314/350
391/391 - 26s - loss: 0.0962 - accuracy: 0.9818 - val_loss: 0.5115 - val_accuracy: 0.9086
Epoch 315/350
391/391 - 25s - loss: 0.0961 - accuracy: 0.9822 - val_loss: 0.5118 - val_accuracy: 0.9085
Epoch 316/350
391/391 - 25s - loss: 0.0947 - accuracy: 0.9827 - val_loss: 0.5119 - val_accuracy: 0.9087
Epoch 317/350
391/391 - 25s - loss: 0.0990 - accuracy: 0.9812 - val_loss: 0.5118 - val_accuracy: 0.9090
Epoch 318/350
391/391 - 25s - loss: 0.0976 - accuracy: 0.9818 - val_loss: 0.5121 - val_accuracy: 0.9087
Epoch 319/350
391/391 - 25s - loss: 0.0975 - accuracy: 0.9815 - val_loss: 0.5120 - val_accuracy: 0.9087
Epoch 320/350
391/391 - 25s - loss: 0.0983 - accuracy: 0.9813 - val_loss: 0.5122 - val_accuracy: 0.9090
Epoch 321/350
391/391 - 25s - loss: 0.0978 - accuracy: 0.9819 - val_loss: 0.5129 - val_accuracy: 0.9085
Epoch 322/350
391/391 - 25s - loss: 0.0986 - accuracy: 0.9809 - val_loss: 0.5130 - val_accuracy: 0.9085
Epoch 323/350
391/391 - 25s - loss: 0.0989 - accuracy: 0.9811 - val_loss: 0.5130 - val_accuracy: 0.9090
Epoch 324/350
391/391 - 25s - loss: 0.0988 - accuracy: 0.9813 - val_loss: 0.5125 - val_accuracy: 0.9091
Epoch 325/350
391/391 - 25s - loss: 0.0989 - accuracy: 0.9809 - val_loss: 0.5124 - val_accuracy: 0.9088
Epoch 326/350
391/391 - 25s - loss: 0.0975 - accuracy: 0.9821 - val_loss: 0.5125 - val_accuracy: 0.9090
Epoch 327/350
391/391 - 25s - loss: 0.0992 - accuracy: 0.9820 - val_loss: 0.5123 - val_accuracy: 0.9089
Epoch 328/350
391/391 - 25s - loss: 0.0983 - accuracy: 0.9809 - val_loss: 0.5124 - val_accuracy: 0.9090
Epoch 329/350
391/391 - 25s - loss: 0.1007 - accuracy: 0.9808 - val_loss: 0.5119 - val_accuracy: 0.9088
Epoch 330/350
391/391 - 25s - loss: 0.0996 - accuracy: 0.9814 - val_loss: 0.5119 - val_accuracy: 0.9085
Epoch 331/350
391/391 - 25s - loss: 0.0970 - accuracy: 0.9820 - val_loss: 0.5118 - val_accuracy: 0.9087
Epoch 332/350
391/391 - 25s - loss: 0.0977 - accuracy: 0.9817 - val_loss: 0.5120 - val_accuracy: 0.9088
Epoch 333/350
391/391 - 25s - loss: 0.0992 - accuracy: 0.9811 - val_loss: 0.5121 - val_accuracy: 0.9088
Epoch 334/350
391/391 - 25s - loss: 0.0951 - accuracy: 0.9824 - val_loss: 0.5123 - val_accuracy: 0.9089
Epoch 335/350
391/391 - 25s - loss: 0.0978 - accuracy: 0.9817 - val_loss: 0.5124 - val_accuracy: 0.9090
Epoch 336/350
391/391 - 25s - loss: 0.0970 - accuracy: 0.9820 - val_loss: 0.5122 - val_accuracy: 0.9088
Epoch 337/350
391/391 - 25s - loss: 0.0977 - accuracy: 0.9821 - val_loss: 0.5123 - val_accuracy: 0.9089
Epoch 338/350
391/391 - 25s - loss: 0.0968 - accuracy: 0.9816 - val_loss: 0.5121 - val_accuracy: 0.9088
Epoch 339/350
391/391 - 25s - loss: 0.0972 - accuracy: 0.9817 - val_loss: 0.5122 - val_accuracy: 0.9084
Epoch 340/350
391/391 - 26s - loss: 0.0989 - accuracy: 0.9809 - val_loss: 0.5120 - val_accuracy: 0.9088
Epoch 341/350
391/391 - 25s - loss: 0.0982 - accuracy: 0.9816 - val_loss: 0.5120 - val_accuracy: 0.9088
Epoch 342/350
391/391 - 25s - loss: 0.0970 - accuracy: 0.9822 - val_loss: 0.5124 - val_accuracy: 0.9091
Epoch 343/350
391/391 - 25s - loss: 0.0952 - accuracy: 0.9823 - val_loss: 0.5122 - val_accuracy: 0.9086
Epoch 344/350
391/391 - 25s - loss: 0.0961 - accuracy: 0.9826 - val_loss: 0.5125 - val_accuracy: 0.9088
Epoch 345/350
391/391 - 25s - loss: 0.0977 - accuracy: 0.9816 - val_loss: 0.5128 - val_accuracy: 0.9090
Epoch 346/350
391/391 - 25s - loss: 0.0977 - accuracy: 0.9813 - val_loss: 0.5130 - val_accuracy: 0.9087
Epoch 347/350
391/391 - 25s - loss: 0.0977 - accuracy: 0.9817 - val_loss: 0.5131 - val_accuracy: 0.9085
Epoch 348/350
391/391 - 25s - loss: 0.0958 - accuracy: 0.9823 - val_loss: 0.5129 - val_accuracy: 0.9085
Epoch 349/350
391/391 - 25s - loss: 0.0962 - accuracy: 0.9821 - val_loss: 0.5128 - val_accuracy: 0.9086
Epoch 350/350


Snapshot weight 2 shuffle 6 at epoch 350
Layer 11
Getting activations...


391/391 - 26s - loss: 0.0964 - accuracy: 0.9825 - val_loss: 0.5129 - val_accuracy: 0.9085
/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:493: UserWarning: fill_value is not supported and is always 0 for TensorFlow < 2.4.0.
  return py_builtins.overload_of(f)(*args)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-07-02 12:18:22.542981: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
Saving, final validation acc: 0.9085000157356262
