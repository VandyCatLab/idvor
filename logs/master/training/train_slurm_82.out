2021-07-02 16:40:19.586217: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 16:41:44.465539: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-07-02 16:41:44.502423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2021-07-02 16:41:44.502497: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 16:41:44.544458: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-02 16:41:44.566083: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-02 16:41:44.574793: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-02 16:41:44.621239: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-02 16:41:44.629976: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-02 16:41:44.716221: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 16:41:44.718459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-02 16:41:44.722267: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-02 16:41:44.738530: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600205000 Hz
2021-07-02 16:41:44.738653: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5c54ad0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-07-02 16:41:44.738673: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-07-02 16:41:44.892331: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5c36420 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-07-02 16:41:44.892397: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN Xp, Compute Capability 6.1
2021-07-02 16:41:44.894790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2021-07-02 16:41:44.894827: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 16:41:44.894857: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-02 16:41:44.894876: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-02 16:41:44.894894: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-02 16:41:44.894912: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-02 16:41:44.894930: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-02 16:41:44.894957: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 16:41:44.899279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-02 16:41:44.901060: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 16:41:46.726289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-02 16:41:46.726366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-07-02 16:41:46.726380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-07-02 16:41:46.733591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11218 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
2021-07-02 16:41:52.508945: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 16:41:55.064023: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:493: UserWarning: fill_value is not supported and is always 0 for TensorFlow < 2.4.0.
  return py_builtins.overload_of(f)(*args)
WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0208s vs `on_train_batch_end` time: 0.0319s). Check your callbacks.
Using model index: 82
Making train data...
GCN...
ZCA...
Done!
Making test data...
Done!
Epoch 1/350


Snapshot weight 2 shuffle 8 at epoch 1
Layer 11
Getting activations...


391/391 - 24s - loss: 2.3101 - accuracy: 0.1189 - val_loss: 2.2921 - val_accuracy: 0.1521
Epoch 2/350


Snapshot weight 2 shuffle 8 at epoch 2
Layer 11
Getting activations...


391/391 - 23s - loss: 2.2392 - accuracy: 0.1738 - val_loss: 2.1015 - val_accuracy: 0.2585
Epoch 3/350


Snapshot weight 2 shuffle 8 at epoch 3
Layer 11
Getting activations...


391/391 - 23s - loss: 1.9173 - accuracy: 0.2952 - val_loss: 1.7648 - val_accuracy: 0.3461
Epoch 4/350


Snapshot weight 2 shuffle 8 at epoch 4
Layer 11
Getting activations...


391/391 - 23s - loss: 1.6270 - accuracy: 0.4133 - val_loss: 1.4675 - val_accuracy: 0.4794
Epoch 5/350


Snapshot weight 2 shuffle 8 at epoch 5
Layer 11
Getting activations...


391/391 - 23s - loss: 1.4211 - accuracy: 0.4979 - val_loss: 1.2969 - val_accuracy: 0.5574
Epoch 6/350


Snapshot weight 2 shuffle 8 at epoch 6
Layer 11
Getting activations...


391/391 - 23s - loss: 1.2986 - accuracy: 0.5442 - val_loss: 1.3473 - val_accuracy: 0.5471
Epoch 7/350


Snapshot weight 2 shuffle 8 at epoch 7
Layer 11
Getting activations...


391/391 - 23s - loss: 1.1992 - accuracy: 0.5789 - val_loss: 1.2908 - val_accuracy: 0.5708
Epoch 8/350


Snapshot weight 2 shuffle 8 at epoch 8
Layer 11
Getting activations...


391/391 - 23s - loss: 1.1324 - accuracy: 0.6093 - val_loss: 1.1954 - val_accuracy: 0.6021
Epoch 9/350


Snapshot weight 2 shuffle 8 at epoch 9
Layer 11
Getting activations...


391/391 - 23s - loss: 1.0703 - accuracy: 0.6286 - val_loss: 1.1550 - val_accuracy: 0.6110
Epoch 10/350


Snapshot weight 2 shuffle 8 at epoch 10
Layer 11
Getting activations...


391/391 - 23s - loss: 1.0108 - accuracy: 0.6505 - val_loss: 0.9645 - val_accuracy: 0.6720
Epoch 11/350
391/391 - 23s - loss: 0.9740 - accuracy: 0.6625 - val_loss: 0.8906 - val_accuracy: 0.6908
Epoch 12/350
391/391 - 23s - loss: 0.9313 - accuracy: 0.6784 - val_loss: 0.9323 - val_accuracy: 0.6824
Epoch 13/350
391/391 - 23s - loss: 0.8994 - accuracy: 0.6912 - val_loss: 0.8971 - val_accuracy: 0.7006
Epoch 14/350
391/391 - 23s - loss: 0.8770 - accuracy: 0.6986 - val_loss: 0.8206 - val_accuracy: 0.7252
Epoch 15/350
391/391 - 23s - loss: 0.8394 - accuracy: 0.7123 - val_loss: 0.8912 - val_accuracy: 0.7017
Epoch 16/350
391/391 - 23s - loss: 0.8055 - accuracy: 0.7276 - val_loss: 0.7727 - val_accuracy: 0.7428
Epoch 17/350
391/391 - 23s - loss: 0.7719 - accuracy: 0.7403 - val_loss: 0.7233 - val_accuracy: 0.7589
Epoch 18/350
391/391 - 23s - loss: 0.7506 - accuracy: 0.7450 - val_loss: 0.7317 - val_accuracy: 0.7571
Epoch 19/350
391/391 - 23s - loss: 0.7322 - accuracy: 0.7524 - val_loss: 0.7280 - val_accuracy: 0.7559
Epoch 20/350
391/391 - 23s - loss: 0.7014 - accuracy: 0.7639 - val_loss: 0.6580 - val_accuracy: 0.7867
Epoch 21/350
391/391 - 23s - loss: 0.6885 - accuracy: 0.7685 - val_loss: 0.6575 - val_accuracy: 0.7851
Epoch 22/350
391/391 - 23s - loss: 0.6743 - accuracy: 0.7732 - val_loss: 0.6389 - val_accuracy: 0.7909
Epoch 23/350
391/391 - 23s - loss: 0.6523 - accuracy: 0.7830 - val_loss: 0.6145 - val_accuracy: 0.7960
Epoch 24/350
391/391 - 23s - loss: 0.6239 - accuracy: 0.7919 - val_loss: 0.5720 - val_accuracy: 0.8149
Epoch 25/350
391/391 - 23s - loss: 0.6208 - accuracy: 0.7941 - val_loss: 0.5769 - val_accuracy: 0.8129
Epoch 26/350
391/391 - 23s - loss: 0.5970 - accuracy: 0.8033 - val_loss: 0.5986 - val_accuracy: 0.8133
Epoch 27/350
391/391 - 23s - loss: 0.5954 - accuracy: 0.8023 - val_loss: 0.5627 - val_accuracy: 0.8201
Epoch 28/350
391/391 - 23s - loss: 0.5693 - accuracy: 0.8120 - val_loss: 0.5670 - val_accuracy: 0.8220
Epoch 29/350
391/391 - 23s - loss: 0.5674 - accuracy: 0.8131 - val_loss: 0.5923 - val_accuracy: 0.8202
Epoch 30/350
391/391 - 23s - loss: 0.5544 - accuracy: 0.8181 - val_loss: 0.5575 - val_accuracy: 0.8245
Epoch 31/350
391/391 - 23s - loss: 0.5411 - accuracy: 0.8197 - val_loss: 0.5342 - val_accuracy: 0.8324
Epoch 32/350
391/391 - 23s - loss: 0.5320 - accuracy: 0.8226 - val_loss: 0.5307 - val_accuracy: 0.8270
Epoch 33/350
391/391 - 23s - loss: 0.5224 - accuracy: 0.8295 - val_loss: 0.5274 - val_accuracy: 0.8299
Epoch 34/350
391/391 - 23s - loss: 0.5067 - accuracy: 0.8346 - val_loss: 0.5275 - val_accuracy: 0.8404
Epoch 35/350
391/391 - 23s - loss: 0.5024 - accuracy: 0.8356 - val_loss: 0.4986 - val_accuracy: 0.8446
Epoch 36/350
391/391 - 23s - loss: 0.4923 - accuracy: 0.8381 - val_loss: 0.5318 - val_accuracy: 0.8297
Epoch 37/350
391/391 - 23s - loss: 0.4868 - accuracy: 0.8411 - val_loss: 0.4983 - val_accuracy: 0.8475
Epoch 38/350
391/391 - 23s - loss: 0.4807 - accuracy: 0.8430 - val_loss: 0.5167 - val_accuracy: 0.8427
Epoch 39/350
391/391 - 23s - loss: 0.4678 - accuracy: 0.8467 - val_loss: 0.5073 - val_accuracy: 0.8458
Epoch 40/350
391/391 - 23s - loss: 0.4643 - accuracy: 0.8491 - val_loss: 0.4890 - val_accuracy: 0.8480
Epoch 41/350
391/391 - 23s - loss: 0.4541 - accuracy: 0.8524 - val_loss: 0.5617 - val_accuracy: 0.8350
Epoch 42/350
391/391 - 23s - loss: 0.4516 - accuracy: 0.8530 - val_loss: 0.4987 - val_accuracy: 0.8473
Epoch 43/350
391/391 - 23s - loss: 0.4436 - accuracy: 0.8568 - val_loss: 0.4864 - val_accuracy: 0.8506
Epoch 44/350
391/391 - 23s - loss: 0.4420 - accuracy: 0.8576 - val_loss: 0.5093 - val_accuracy: 0.8450
Epoch 45/350
391/391 - 23s - loss: 0.4342 - accuracy: 0.8591 - val_loss: 0.4644 - val_accuracy: 0.8524
Epoch 46/350
391/391 - 23s - loss: 0.4240 - accuracy: 0.8637 - val_loss: 0.4633 - val_accuracy: 0.8565
Epoch 47/350
391/391 - 23s - loss: 0.4225 - accuracy: 0.8622 - val_loss: 0.4629 - val_accuracy: 0.8601
Epoch 48/350
391/391 - 23s - loss: 0.4192 - accuracy: 0.8658 - val_loss: 0.4974 - val_accuracy: 0.8471
Epoch 49/350
391/391 - 23s - loss: 0.4089 - accuracy: 0.8697 - val_loss: 0.4545 - val_accuracy: 0.8626
Epoch 50/350


Snapshot weight 2 shuffle 8 at epoch 50
Layer 11
Getting activations...


391/391 - 23s - loss: 0.4073 - accuracy: 0.8694 - val_loss: 0.4524 - val_accuracy: 0.8656
Epoch 51/350
391/391 - 23s - loss: 0.4019 - accuracy: 0.8700 - val_loss: 0.4472 - val_accuracy: 0.8664
Epoch 52/350
391/391 - 23s - loss: 0.3930 - accuracy: 0.8745 - val_loss: 0.4671 - val_accuracy: 0.8622
Epoch 53/350
391/391 - 23s - loss: 0.3882 - accuracy: 0.8756 - val_loss: 0.4693 - val_accuracy: 0.8591
Epoch 54/350
391/391 - 23s - loss: 0.3911 - accuracy: 0.8744 - val_loss: 0.4822 - val_accuracy: 0.8567
Epoch 55/350
391/391 - 23s - loss: 0.3862 - accuracy: 0.8761 - val_loss: 0.4534 - val_accuracy: 0.8667
Epoch 56/350
391/391 - 23s - loss: 0.3778 - accuracy: 0.8809 - val_loss: 0.4350 - val_accuracy: 0.8694
Epoch 57/350
391/391 - 23s - loss: 0.3756 - accuracy: 0.8805 - val_loss: 0.4875 - val_accuracy: 0.8586
Epoch 58/350
391/391 - 23s - loss: 0.3676 - accuracy: 0.8834 - val_loss: 0.4639 - val_accuracy: 0.8681
Epoch 59/350
391/391 - 23s - loss: 0.3613 - accuracy: 0.8864 - val_loss: 0.4373 - val_accuracy: 0.8677
Epoch 60/350
391/391 - 23s - loss: 0.3599 - accuracy: 0.8851 - val_loss: 0.4338 - val_accuracy: 0.8733
Epoch 61/350
391/391 - 23s - loss: 0.3581 - accuracy: 0.8865 - val_loss: 0.4292 - val_accuracy: 0.8754
Epoch 62/350
391/391 - 23s - loss: 0.3591 - accuracy: 0.8864 - val_loss: 0.4584 - val_accuracy: 0.8632
Epoch 63/350
391/391 - 23s - loss: 0.3464 - accuracy: 0.8910 - val_loss: 0.4512 - val_accuracy: 0.8692
Epoch 64/350
391/391 - 23s - loss: 0.3466 - accuracy: 0.8901 - val_loss: 0.4517 - val_accuracy: 0.8695
Epoch 65/350
391/391 - 23s - loss: 0.3387 - accuracy: 0.8935 - val_loss: 0.4348 - val_accuracy: 0.8727
Epoch 66/350
391/391 - 23s - loss: 0.3408 - accuracy: 0.8917 - val_loss: 0.4457 - val_accuracy: 0.8780
Epoch 67/350
391/391 - 23s - loss: 0.3420 - accuracy: 0.8921 - val_loss: 0.4549 - val_accuracy: 0.8642
Epoch 68/350
391/391 - 23s - loss: 0.3377 - accuracy: 0.8929 - val_loss: 0.4281 - val_accuracy: 0.8766
Epoch 69/350
391/391 - 23s - loss: 0.3310 - accuracy: 0.8959 - val_loss: 0.4405 - val_accuracy: 0.8762
Epoch 70/350
391/391 - 23s - loss: 0.3262 - accuracy: 0.8989 - val_loss: 0.4386 - val_accuracy: 0.8744
Epoch 71/350
391/391 - 23s - loss: 0.3219 - accuracy: 0.8997 - val_loss: 0.4320 - val_accuracy: 0.8801
Epoch 72/350
391/391 - 23s - loss: 0.3212 - accuracy: 0.8990 - val_loss: 0.4452 - val_accuracy: 0.8709
Epoch 73/350
391/391 - 23s - loss: 0.3172 - accuracy: 0.9002 - val_loss: 0.4243 - val_accuracy: 0.8761
Epoch 74/350
391/391 - 23s - loss: 0.3107 - accuracy: 0.9029 - val_loss: 0.4326 - val_accuracy: 0.8777
Epoch 75/350
391/391 - 23s - loss: 0.3126 - accuracy: 0.9030 - val_loss: 0.4335 - val_accuracy: 0.8768
Epoch 76/350
391/391 - 23s - loss: 0.3103 - accuracy: 0.9033 - val_loss: 0.4213 - val_accuracy: 0.8786
Epoch 77/350
391/391 - 23s - loss: 0.3112 - accuracy: 0.9038 - val_loss: 0.4173 - val_accuracy: 0.8828
Epoch 78/350
391/391 - 23s - loss: 0.3054 - accuracy: 0.9043 - val_loss: 0.4516 - val_accuracy: 0.8717
Epoch 79/350
391/391 - 23s - loss: 0.2983 - accuracy: 0.9069 - val_loss: 0.4256 - val_accuracy: 0.8816
Epoch 80/350
391/391 - 23s - loss: 0.3061 - accuracy: 0.9044 - val_loss: 0.4414 - val_accuracy: 0.8762
Epoch 81/350
391/391 - 23s - loss: 0.2983 - accuracy: 0.9066 - val_loss: 0.4626 - val_accuracy: 0.8716
Epoch 82/350
391/391 - 23s - loss: 0.3000 - accuracy: 0.9062 - val_loss: 0.4008 - val_accuracy: 0.8835
Epoch 83/350
391/391 - 23s - loss: 0.2902 - accuracy: 0.9109 - val_loss: 0.4255 - val_accuracy: 0.8787
Epoch 84/350
391/391 - 23s - loss: 0.2929 - accuracy: 0.9085 - val_loss: 0.4476 - val_accuracy: 0.8768
Epoch 85/350
391/391 - 23s - loss: 0.2883 - accuracy: 0.9105 - val_loss: 0.4411 - val_accuracy: 0.8770
Epoch 86/350
391/391 - 23s - loss: 0.2815 - accuracy: 0.9139 - val_loss: 0.4350 - val_accuracy: 0.8869
Epoch 87/350
391/391 - 23s - loss: 0.2784 - accuracy: 0.9138 - val_loss: 0.4493 - val_accuracy: 0.8820
Epoch 88/350
391/391 - 23s - loss: 0.2801 - accuracy: 0.9148 - val_loss: 0.4221 - val_accuracy: 0.8835
Epoch 89/350
391/391 - 23s - loss: 0.2743 - accuracy: 0.9173 - val_loss: 0.4163 - val_accuracy: 0.8871
Epoch 90/350
391/391 - 23s - loss: 0.2753 - accuracy: 0.9166 - val_loss: 0.4340 - val_accuracy: 0.8833
Epoch 91/350
391/391 - 23s - loss: 0.2683 - accuracy: 0.9180 - val_loss: 0.4556 - val_accuracy: 0.8781
Epoch 92/350
391/391 - 23s - loss: 0.2761 - accuracy: 0.9140 - val_loss: 0.4328 - val_accuracy: 0.8801
Epoch 93/350
391/391 - 23s - loss: 0.2697 - accuracy: 0.9188 - val_loss: 0.4263 - val_accuracy: 0.8860
Epoch 94/350
391/391 - 23s - loss: 0.2663 - accuracy: 0.9191 - val_loss: 0.4183 - val_accuracy: 0.8882
Epoch 95/350
391/391 - 23s - loss: 0.2656 - accuracy: 0.9184 - val_loss: 0.4280 - val_accuracy: 0.8831
Epoch 96/350
391/391 - 23s - loss: 0.2660 - accuracy: 0.9198 - val_loss: 0.4143 - val_accuracy: 0.8884
Epoch 97/350
391/391 - 23s - loss: 0.2607 - accuracy: 0.9222 - val_loss: 0.4245 - val_accuracy: 0.8851
Epoch 98/350
391/391 - 23s - loss: 0.2578 - accuracy: 0.9213 - val_loss: 0.4316 - val_accuracy: 0.8846
Epoch 99/350
391/391 - 23s - loss: 0.2594 - accuracy: 0.9215 - val_loss: 0.4435 - val_accuracy: 0.8834
Epoch 100/350


Snapshot weight 2 shuffle 8 at epoch 100
Layer 11
Getting activations...


391/391 - 23s - loss: 0.2582 - accuracy: 0.9218 - val_loss: 0.4411 - val_accuracy: 0.8819
Epoch 101/350
391/391 - 23s - loss: 0.2520 - accuracy: 0.9243 - val_loss: 0.4273 - val_accuracy: 0.8842
Epoch 102/350
391/391 - 23s - loss: 0.2554 - accuracy: 0.9228 - val_loss: 0.4679 - val_accuracy: 0.8756
Epoch 103/350
391/391 - 23s - loss: 0.2504 - accuracy: 0.9245 - val_loss: 0.4389 - val_accuracy: 0.8866
Epoch 104/350
391/391 - 23s - loss: 0.2509 - accuracy: 0.9252 - val_loss: 0.4446 - val_accuracy: 0.8843
Epoch 105/350
391/391 - 23s - loss: 0.2476 - accuracy: 0.9258 - val_loss: 0.4470 - val_accuracy: 0.8848
Epoch 106/350
391/391 - 23s - loss: 0.2473 - accuracy: 0.9261 - val_loss: 0.4251 - val_accuracy: 0.8857
Epoch 107/350
391/391 - 23s - loss: 0.2475 - accuracy: 0.9243 - val_loss: 0.4435 - val_accuracy: 0.8865
Epoch 108/350
391/391 - 23s - loss: 0.2489 - accuracy: 0.9251 - val_loss: 0.4445 - val_accuracy: 0.8860
Epoch 109/350
391/391 - 23s - loss: 0.2436 - accuracy: 0.9270 - val_loss: 0.4375 - val_accuracy: 0.8856
Epoch 110/350
391/391 - 23s - loss: 0.2406 - accuracy: 0.9286 - val_loss: 0.4267 - val_accuracy: 0.8899
Epoch 111/350
391/391 - 23s - loss: 0.2362 - accuracy: 0.9307 - val_loss: 0.4874 - val_accuracy: 0.8760
Epoch 112/350
391/391 - 23s - loss: 0.2416 - accuracy: 0.9264 - val_loss: 0.4434 - val_accuracy: 0.8895
Epoch 113/350
391/391 - 23s - loss: 0.2387 - accuracy: 0.9292 - val_loss: 0.4602 - val_accuracy: 0.8837
Epoch 114/350
391/391 - 23s - loss: 0.2337 - accuracy: 0.9313 - val_loss: 0.4374 - val_accuracy: 0.8855
Epoch 115/350
391/391 - 23s - loss: 0.2385 - accuracy: 0.9302 - val_loss: 0.4518 - val_accuracy: 0.8846
Epoch 116/350
391/391 - 23s - loss: 0.2356 - accuracy: 0.9303 - val_loss: 0.4322 - val_accuracy: 0.8932
Epoch 117/350
391/391 - 23s - loss: 0.2312 - accuracy: 0.9318 - val_loss: 0.4485 - val_accuracy: 0.8852
Epoch 118/350
391/391 - 23s - loss: 0.2324 - accuracy: 0.9313 - val_loss: 0.4304 - val_accuracy: 0.8861
Epoch 119/350
391/391 - 23s - loss: 0.2273 - accuracy: 0.9329 - val_loss: 0.4788 - val_accuracy: 0.8820
Epoch 120/350
391/391 - 23s - loss: 0.2268 - accuracy: 0.9336 - val_loss: 0.4256 - val_accuracy: 0.8892
Epoch 121/350
391/391 - 23s - loss: 0.2289 - accuracy: 0.9345 - val_loss: 0.4137 - val_accuracy: 0.8901
Epoch 122/350
391/391 - 23s - loss: 0.2249 - accuracy: 0.9345 - val_loss: 0.4264 - val_accuracy: 0.8895
Epoch 123/350
391/391 - 23s - loss: 0.2266 - accuracy: 0.9339 - val_loss: 0.4425 - val_accuracy: 0.8883
Epoch 124/350
391/391 - 23s - loss: 0.2221 - accuracy: 0.9354 - val_loss: 0.4255 - val_accuracy: 0.8905
Epoch 125/350
391/391 - 23s - loss: 0.2196 - accuracy: 0.9361 - val_loss: 0.4442 - val_accuracy: 0.8920
Epoch 126/350
391/391 - 23s - loss: 0.2249 - accuracy: 0.9351 - val_loss: 0.4226 - val_accuracy: 0.8927
Epoch 127/350
391/391 - 23s - loss: 0.2234 - accuracy: 0.9357 - val_loss: 0.4031 - val_accuracy: 0.8966
Epoch 128/350
391/391 - 23s - loss: 0.2165 - accuracy: 0.9379 - val_loss: 0.4354 - val_accuracy: 0.8914
Epoch 129/350
391/391 - 23s - loss: 0.2206 - accuracy: 0.9368 - val_loss: 0.4338 - val_accuracy: 0.8915
Epoch 130/350
391/391 - 23s - loss: 0.2118 - accuracy: 0.9398 - val_loss: 0.4270 - val_accuracy: 0.8931
Epoch 131/350
391/391 - 23s - loss: 0.2142 - accuracy: 0.9388 - val_loss: 0.4467 - val_accuracy: 0.8903
Epoch 132/350
391/391 - 23s - loss: 0.2148 - accuracy: 0.9379 - val_loss: 0.4304 - val_accuracy: 0.8912
Epoch 133/350
391/391 - 23s - loss: 0.2143 - accuracy: 0.9384 - val_loss: 0.4479 - val_accuracy: 0.8889
Epoch 134/350
391/391 - 23s - loss: 0.2129 - accuracy: 0.9390 - val_loss: 0.4323 - val_accuracy: 0.8944
Epoch 135/350
391/391 - 23s - loss: 0.2088 - accuracy: 0.9402 - val_loss: 0.4464 - val_accuracy: 0.8906
Epoch 136/350
391/391 - 23s - loss: 0.2130 - accuracy: 0.9385 - val_loss: 0.4522 - val_accuracy: 0.8880
Epoch 137/350
391/391 - 23s - loss: 0.2086 - accuracy: 0.9400 - val_loss: 0.4266 - val_accuracy: 0.8937
Epoch 138/350
391/391 - 23s - loss: 0.2092 - accuracy: 0.9401 - val_loss: 0.4718 - val_accuracy: 0.8866
Epoch 139/350
391/391 - 23s - loss: 0.2060 - accuracy: 0.9405 - val_loss: 0.4644 - val_accuracy: 0.8916
Epoch 140/350
391/391 - 23s - loss: 0.2047 - accuracy: 0.9420 - val_loss: 0.4540 - val_accuracy: 0.8902
Epoch 141/350
391/391 - 23s - loss: 0.2024 - accuracy: 0.9427 - val_loss: 0.4808 - val_accuracy: 0.8887
Epoch 142/350
391/391 - 23s - loss: 0.2009 - accuracy: 0.9430 - val_loss: 0.4413 - val_accuracy: 0.8906
Epoch 143/350
391/391 - 23s - loss: 0.2025 - accuracy: 0.9434 - val_loss: 0.4655 - val_accuracy: 0.8897
Epoch 144/350
391/391 - 23s - loss: 0.2017 - accuracy: 0.9425 - val_loss: 0.4288 - val_accuracy: 0.8913
Epoch 145/350
391/391 - 23s - loss: 0.2024 - accuracy: 0.9433 - val_loss: 0.4611 - val_accuracy: 0.8885
Epoch 146/350
391/391 - 23s - loss: 0.2074 - accuracy: 0.9418 - val_loss: 0.4261 - val_accuracy: 0.8930
Epoch 147/350
391/391 - 23s - loss: 0.1963 - accuracy: 0.9446 - val_loss: 0.4564 - val_accuracy: 0.8915
Epoch 148/350
391/391 - 23s - loss: 0.1985 - accuracy: 0.9458 - val_loss: 0.4565 - val_accuracy: 0.8861
Epoch 149/350
391/391 - 23s - loss: 0.1967 - accuracy: 0.9457 - val_loss: 0.4575 - val_accuracy: 0.8945
Epoch 150/350


Snapshot weight 2 shuffle 8 at epoch 150
Layer 11
Getting activations...


391/391 - 23s - loss: 0.1971 - accuracy: 0.9457 - val_loss: 0.4562 - val_accuracy: 0.8907
Epoch 151/350
391/391 - 23s - loss: 0.1998 - accuracy: 0.9441 - val_loss: 0.4713 - val_accuracy: 0.8876
Epoch 152/350
391/391 - 23s - loss: 0.1979 - accuracy: 0.9447 - val_loss: 0.4697 - val_accuracy: 0.8897
Epoch 153/350
391/391 - 23s - loss: 0.1917 - accuracy: 0.9468 - val_loss: 0.4631 - val_accuracy: 0.8910
Epoch 154/350
391/391 - 23s - loss: 0.1887 - accuracy: 0.9480 - val_loss: 0.4406 - val_accuracy: 0.8969
Epoch 155/350
391/391 - 23s - loss: 0.1961 - accuracy: 0.9452 - val_loss: 0.4854 - val_accuracy: 0.8864
Epoch 156/350
391/391 - 23s - loss: 0.1913 - accuracy: 0.9474 - val_loss: 0.4404 - val_accuracy: 0.8923
Epoch 157/350
391/391 - 23s - loss: 0.1857 - accuracy: 0.9490 - val_loss: 0.4332 - val_accuracy: 0.8993
Epoch 158/350
391/391 - 23s - loss: 0.1909 - accuracy: 0.9475 - val_loss: 0.4532 - val_accuracy: 0.8946
Epoch 159/350
391/391 - 23s - loss: 0.1856 - accuracy: 0.9497 - val_loss: 0.4498 - val_accuracy: 0.8973
Epoch 160/350
391/391 - 23s - loss: 0.1906 - accuracy: 0.9477 - val_loss: 0.4830 - val_accuracy: 0.8925
Epoch 161/350
391/391 - 23s - loss: 0.1929 - accuracy: 0.9473 - val_loss: 0.4469 - val_accuracy: 0.8913
Epoch 162/350
391/391 - 23s - loss: 0.1851 - accuracy: 0.9499 - val_loss: 0.4864 - val_accuracy: 0.8876
Epoch 163/350
391/391 - 23s - loss: 0.1844 - accuracy: 0.9505 - val_loss: 0.4619 - val_accuracy: 0.8953
Epoch 164/350
391/391 - 23s - loss: 0.1851 - accuracy: 0.9498 - val_loss: 0.4449 - val_accuracy: 0.8930
Epoch 165/350
391/391 - 23s - loss: 0.1870 - accuracy: 0.9485 - val_loss: 0.4626 - val_accuracy: 0.8939
Epoch 166/350
391/391 - 23s - loss: 0.1856 - accuracy: 0.9494 - val_loss: 0.4298 - val_accuracy: 0.8969
Epoch 167/350
391/391 - 23s - loss: 0.1834 - accuracy: 0.9504 - val_loss: 0.5065 - val_accuracy: 0.8908
Epoch 168/350
391/391 - 23s - loss: 0.1840 - accuracy: 0.9492 - val_loss: 0.4850 - val_accuracy: 0.8873
Epoch 169/350
391/391 - 23s - loss: 0.1853 - accuracy: 0.9501 - val_loss: 0.4616 - val_accuracy: 0.8957
Epoch 170/350
391/391 - 23s - loss: 0.1849 - accuracy: 0.9495 - val_loss: 0.4752 - val_accuracy: 0.8925
Epoch 171/350
391/391 - 23s - loss: 0.1816 - accuracy: 0.9522 - val_loss: 0.4544 - val_accuracy: 0.8950
Epoch 172/350
391/391 - 23s - loss: 0.1815 - accuracy: 0.9506 - val_loss: 0.4786 - val_accuracy: 0.8929
Epoch 173/350
391/391 - 23s - loss: 0.1810 - accuracy: 0.9511 - val_loss: 0.4729 - val_accuracy: 0.8940
Epoch 174/350
391/391 - 23s - loss: 0.1767 - accuracy: 0.9530 - val_loss: 0.4694 - val_accuracy: 0.8946
Epoch 175/350
391/391 - 23s - loss: 0.1788 - accuracy: 0.9523 - val_loss: 0.4649 - val_accuracy: 0.8904
Epoch 176/350
391/391 - 23s - loss: 0.1757 - accuracy: 0.9536 - val_loss: 0.4576 - val_accuracy: 0.8972
Epoch 177/350
391/391 - 23s - loss: 0.1797 - accuracy: 0.9519 - val_loss: 0.4583 - val_accuracy: 0.8963
Epoch 178/350
391/391 - 23s - loss: 0.1776 - accuracy: 0.9533 - val_loss: 0.4527 - val_accuracy: 0.8971
Epoch 179/350
391/391 - 23s - loss: 0.1710 - accuracy: 0.9558 - val_loss: 0.4891 - val_accuracy: 0.8945
Epoch 180/350
391/391 - 23s - loss: 0.1771 - accuracy: 0.9525 - val_loss: 0.5000 - val_accuracy: 0.8891
Epoch 181/350
391/391 - 23s - loss: 0.1736 - accuracy: 0.9542 - val_loss: 0.4730 - val_accuracy: 0.8996
Epoch 182/350
391/391 - 23s - loss: 0.1763 - accuracy: 0.9530 - val_loss: 0.4706 - val_accuracy: 0.8920
Epoch 183/350
391/391 - 23s - loss: 0.1705 - accuracy: 0.9563 - val_loss: 0.4871 - val_accuracy: 0.8938
Epoch 184/350
391/391 - 23s - loss: 0.1696 - accuracy: 0.9555 - val_loss: 0.4686 - val_accuracy: 0.8981
Epoch 185/350
391/391 - 23s - loss: 0.1715 - accuracy: 0.9544 - val_loss: 0.4719 - val_accuracy: 0.8963
Epoch 186/350
391/391 - 23s - loss: 0.1718 - accuracy: 0.9549 - val_loss: 0.5086 - val_accuracy: 0.8915
Epoch 187/350
391/391 - 23s - loss: 0.1708 - accuracy: 0.9560 - val_loss: 0.4500 - val_accuracy: 0.8966
Epoch 188/350
391/391 - 23s - loss: 0.1722 - accuracy: 0.9541 - val_loss: 0.4923 - val_accuracy: 0.8948
Epoch 189/350
391/391 - 23s - loss: 0.1717 - accuracy: 0.9546 - val_loss: 0.4839 - val_accuracy: 0.8867
Epoch 190/350
391/391 - 23s - loss: 0.1670 - accuracy: 0.9566 - val_loss: 0.4691 - val_accuracy: 0.8997
Epoch 191/350
391/391 - 23s - loss: 0.1723 - accuracy: 0.9555 - val_loss: 0.4704 - val_accuracy: 0.8953
Epoch 192/350
391/391 - 23s - loss: 0.1698 - accuracy: 0.9555 - val_loss: 0.5214 - val_accuracy: 0.8899
Epoch 193/350
391/391 - 23s - loss: 0.1670 - accuracy: 0.9573 - val_loss: 0.4440 - val_accuracy: 0.8970
Epoch 194/350
391/391 - 23s - loss: 0.1667 - accuracy: 0.9574 - val_loss: 0.4706 - val_accuracy: 0.8966
Epoch 195/350
391/391 - 23s - loss: 0.1669 - accuracy: 0.9572 - val_loss: 0.4890 - val_accuracy: 0.9001
Epoch 196/350
391/391 - 23s - loss: 0.1627 - accuracy: 0.9580 - val_loss: 0.4944 - val_accuracy: 0.8969
Epoch 197/350
391/391 - 23s - loss: 0.1670 - accuracy: 0.9566 - val_loss: 0.4863 - val_accuracy: 0.8887
Epoch 198/350
391/391 - 23s - loss: 0.1682 - accuracy: 0.9571 - val_loss: 0.4685 - val_accuracy: 0.8979
Epoch 199/350
391/391 - 23s - loss: 0.1678 - accuracy: 0.9567 - val_loss: 0.4733 - val_accuracy: 0.8936
Epoch 200/350


Snapshot weight 2 shuffle 8 at epoch 200
Layer 11
Getting activations...


391/391 - 23s - loss: 0.1628 - accuracy: 0.9591 - val_loss: 0.4708 - val_accuracy: 0.8997
Epoch 201/350
391/391 - 23s - loss: 0.1368 - accuracy: 0.9672 - val_loss: 0.4576 - val_accuracy: 0.9038
Epoch 202/350
391/391 - 23s - loss: 0.1239 - accuracy: 0.9736 - val_loss: 0.4635 - val_accuracy: 0.9015
Epoch 203/350
391/391 - 23s - loss: 0.1261 - accuracy: 0.9713 - val_loss: 0.4646 - val_accuracy: 0.9030
Epoch 204/350
391/391 - 23s - loss: 0.1178 - accuracy: 0.9744 - val_loss: 0.4791 - val_accuracy: 0.9022
Epoch 205/350
391/391 - 23s - loss: 0.1203 - accuracy: 0.9737 - val_loss: 0.4742 - val_accuracy: 0.9048
Epoch 206/350
391/391 - 23s - loss: 0.1174 - accuracy: 0.9747 - val_loss: 0.4805 - val_accuracy: 0.9041
Epoch 207/350
391/391 - 23s - loss: 0.1177 - accuracy: 0.9748 - val_loss: 0.4840 - val_accuracy: 0.9033
Epoch 208/350
391/391 - 23s - loss: 0.1139 - accuracy: 0.9755 - val_loss: 0.4875 - val_accuracy: 0.9029
Epoch 209/350
391/391 - 23s - loss: 0.1174 - accuracy: 0.9745 - val_loss: 0.4877 - val_accuracy: 0.9035
Epoch 210/350
391/391 - 23s - loss: 0.1160 - accuracy: 0.9755 - val_loss: 0.4899 - val_accuracy: 0.9038
Epoch 211/350
391/391 - 23s - loss: 0.1116 - accuracy: 0.9766 - val_loss: 0.4951 - val_accuracy: 0.9024
Epoch 212/350
391/391 - 23s - loss: 0.1141 - accuracy: 0.9760 - val_loss: 0.4938 - val_accuracy: 0.9043
Epoch 213/350
391/391 - 23s - loss: 0.1134 - accuracy: 0.9766 - val_loss: 0.4916 - val_accuracy: 0.9031
Epoch 214/350
391/391 - 23s - loss: 0.1114 - accuracy: 0.9772 - val_loss: 0.4901 - val_accuracy: 0.9045
Epoch 215/350
391/391 - 23s - loss: 0.1081 - accuracy: 0.9782 - val_loss: 0.5051 - val_accuracy: 0.9034
Epoch 216/350
391/391 - 23s - loss: 0.1120 - accuracy: 0.9759 - val_loss: 0.4995 - val_accuracy: 0.9051
Epoch 217/350
391/391 - 22s - loss: 0.1134 - accuracy: 0.9762 - val_loss: 0.4952 - val_accuracy: 0.9038
Epoch 218/350
391/391 - 23s - loss: 0.1109 - accuracy: 0.9765 - val_loss: 0.4954 - val_accuracy: 0.9046
Epoch 219/350
391/391 - 23s - loss: 0.1130 - accuracy: 0.9767 - val_loss: 0.4940 - val_accuracy: 0.9047
Epoch 220/350
391/391 - 23s - loss: 0.1119 - accuracy: 0.9773 - val_loss: 0.4966 - val_accuracy: 0.9043
Epoch 221/350
391/391 - 23s - loss: 0.1077 - accuracy: 0.9781 - val_loss: 0.4928 - val_accuracy: 0.9055
Epoch 222/350
391/391 - 23s - loss: 0.1095 - accuracy: 0.9778 - val_loss: 0.4999 - val_accuracy: 0.9040
Epoch 223/350
391/391 - 23s - loss: 0.1085 - accuracy: 0.9781 - val_loss: 0.4935 - val_accuracy: 0.9044
Epoch 224/350
391/391 - 23s - loss: 0.1099 - accuracy: 0.9775 - val_loss: 0.5043 - val_accuracy: 0.9044
Epoch 225/350
391/391 - 23s - loss: 0.1091 - accuracy: 0.9772 - val_loss: 0.4996 - val_accuracy: 0.9036
Epoch 226/350
391/391 - 23s - loss: 0.1081 - accuracy: 0.9778 - val_loss: 0.5107 - val_accuracy: 0.9035
Epoch 227/350
391/391 - 23s - loss: 0.1062 - accuracy: 0.9778 - val_loss: 0.5128 - val_accuracy: 0.9030
Epoch 228/350
391/391 - 23s - loss: 0.1103 - accuracy: 0.9772 - val_loss: 0.4977 - val_accuracy: 0.9050
Epoch 229/350
391/391 - 23s - loss: 0.1058 - accuracy: 0.9792 - val_loss: 0.5083 - val_accuracy: 0.9055
Epoch 230/350
391/391 - 23s - loss: 0.1085 - accuracy: 0.9779 - val_loss: 0.5032 - val_accuracy: 0.9040
Epoch 231/350
391/391 - 23s - loss: 0.1067 - accuracy: 0.9779 - val_loss: 0.5068 - val_accuracy: 0.9038
Epoch 232/350
391/391 - 23s - loss: 0.1061 - accuracy: 0.9791 - val_loss: 0.5097 - val_accuracy: 0.9035
Epoch 233/350
391/391 - 23s - loss: 0.1056 - accuracy: 0.9789 - val_loss: 0.5065 - val_accuracy: 0.9017
Epoch 234/350
391/391 - 23s - loss: 0.1059 - accuracy: 0.9788 - val_loss: 0.5010 - val_accuracy: 0.9055
Epoch 235/350
391/391 - 23s - loss: 0.1092 - accuracy: 0.9775 - val_loss: 0.5049 - val_accuracy: 0.9044
Epoch 236/350
391/391 - 23s - loss: 0.1058 - accuracy: 0.9785 - val_loss: 0.5067 - val_accuracy: 0.9032
Epoch 237/350
391/391 - 23s - loss: 0.1085 - accuracy: 0.9782 - val_loss: 0.5055 - val_accuracy: 0.9049
Epoch 238/350
391/391 - 23s - loss: 0.1045 - accuracy: 0.9792 - val_loss: 0.5069 - val_accuracy: 0.9058
Epoch 239/350
391/391 - 23s - loss: 0.1056 - accuracy: 0.9785 - val_loss: 0.5108 - val_accuracy: 0.9047
Epoch 240/350
391/391 - 23s - loss: 0.1040 - accuracy: 0.9798 - val_loss: 0.5078 - val_accuracy: 0.9048
Epoch 241/350
391/391 - 23s - loss: 0.1063 - accuracy: 0.9788 - val_loss: 0.5038 - val_accuracy: 0.9062
Epoch 242/350
391/391 - 23s - loss: 0.1038 - accuracy: 0.9792 - val_loss: 0.5111 - val_accuracy: 0.9046
Epoch 243/350
391/391 - 23s - loss: 0.1049 - accuracy: 0.9791 - val_loss: 0.5153 - val_accuracy: 0.9040
Epoch 244/350
391/391 - 23s - loss: 0.1057 - accuracy: 0.9791 - val_loss: 0.5110 - val_accuracy: 0.9035
Epoch 245/350
391/391 - 23s - loss: 0.1015 - accuracy: 0.9805 - val_loss: 0.5151 - val_accuracy: 0.9027
Epoch 246/350
391/391 - 23s - loss: 0.1037 - accuracy: 0.9796 - val_loss: 0.5203 - val_accuracy: 0.9057
Epoch 247/350
391/391 - 23s - loss: 0.1034 - accuracy: 0.9793 - val_loss: 0.5177 - val_accuracy: 0.9032
Epoch 248/350
391/391 - 23s - loss: 0.1024 - accuracy: 0.9803 - val_loss: 0.5186 - val_accuracy: 0.9040
Epoch 249/350
391/391 - 22s - loss: 0.1046 - accuracy: 0.9791 - val_loss: 0.5169 - val_accuracy: 0.9031
Epoch 250/350


Snapshot weight 2 shuffle 8 at epoch 250
Layer 11
Getting activations...


391/391 - 23s - loss: 0.1036 - accuracy: 0.9796 - val_loss: 0.5102 - val_accuracy: 0.9044
Epoch 251/350
391/391 - 23s - loss: 0.1030 - accuracy: 0.9799 - val_loss: 0.5072 - val_accuracy: 0.9041
Epoch 252/350
391/391 - 23s - loss: 0.1043 - accuracy: 0.9793 - val_loss: 0.5074 - val_accuracy: 0.9043
Epoch 253/350
391/391 - 23s - loss: 0.0997 - accuracy: 0.9814 - val_loss: 0.5107 - val_accuracy: 0.9049
Epoch 254/350
391/391 - 23s - loss: 0.1009 - accuracy: 0.9804 - val_loss: 0.5117 - val_accuracy: 0.9051
Epoch 255/350
391/391 - 23s - loss: 0.0999 - accuracy: 0.9808 - val_loss: 0.5102 - val_accuracy: 0.9051
Epoch 256/350
391/391 - 23s - loss: 0.1020 - accuracy: 0.9799 - val_loss: 0.5111 - val_accuracy: 0.9058
Epoch 257/350
391/391 - 23s - loss: 0.1013 - accuracy: 0.9806 - val_loss: 0.5099 - val_accuracy: 0.9051
Epoch 258/350
391/391 - 23s - loss: 0.1016 - accuracy: 0.9805 - val_loss: 0.5116 - val_accuracy: 0.9052
Epoch 259/350
391/391 - 23s - loss: 0.1008 - accuracy: 0.9801 - val_loss: 0.5131 - val_accuracy: 0.9056
Epoch 260/350
391/391 - 23s - loss: 0.0979 - accuracy: 0.9816 - val_loss: 0.5140 - val_accuracy: 0.9050
Epoch 261/350
391/391 - 23s - loss: 0.0992 - accuracy: 0.9816 - val_loss: 0.5127 - val_accuracy: 0.9062
Epoch 262/350
391/391 - 23s - loss: 0.0990 - accuracy: 0.9815 - val_loss: 0.5135 - val_accuracy: 0.9058
Epoch 263/350
391/391 - 23s - loss: 0.0998 - accuracy: 0.9808 - val_loss: 0.5128 - val_accuracy: 0.9060
Epoch 264/350
391/391 - 23s - loss: 0.0998 - accuracy: 0.9806 - val_loss: 0.5122 - val_accuracy: 0.9060
Epoch 265/350
391/391 - 23s - loss: 0.0983 - accuracy: 0.9816 - val_loss: 0.5123 - val_accuracy: 0.9063
Epoch 266/350
391/391 - 23s - loss: 0.0988 - accuracy: 0.9811 - val_loss: 0.5143 - val_accuracy: 0.9050
Epoch 267/350
391/391 - 23s - loss: 0.1016 - accuracy: 0.9799 - val_loss: 0.5130 - val_accuracy: 0.9060
Epoch 268/350
391/391 - 23s - loss: 0.0999 - accuracy: 0.9810 - val_loss: 0.5129 - val_accuracy: 0.9062
Epoch 269/350
391/391 - 23s - loss: 0.0988 - accuracy: 0.9821 - val_loss: 0.5140 - val_accuracy: 0.9060
Epoch 270/350
391/391 - 23s - loss: 0.0992 - accuracy: 0.9814 - val_loss: 0.5155 - val_accuracy: 0.9062
Epoch 271/350
391/391 - 23s - loss: 0.0979 - accuracy: 0.9813 - val_loss: 0.5175 - val_accuracy: 0.9063
Epoch 272/350
391/391 - 23s - loss: 0.0982 - accuracy: 0.9813 - val_loss: 0.5182 - val_accuracy: 0.9071
Epoch 273/350
391/391 - 23s - loss: 0.1016 - accuracy: 0.9807 - val_loss: 0.5158 - val_accuracy: 0.9069
Epoch 274/350
391/391 - 23s - loss: 0.0989 - accuracy: 0.9811 - val_loss: 0.5152 - val_accuracy: 0.9071
Epoch 275/350
391/391 - 23s - loss: 0.0980 - accuracy: 0.9816 - val_loss: 0.5153 - val_accuracy: 0.9060
Epoch 276/350
391/391 - 23s - loss: 0.1002 - accuracy: 0.9802 - val_loss: 0.5161 - val_accuracy: 0.9061
Epoch 277/350
391/391 - 23s - loss: 0.0996 - accuracy: 0.9813 - val_loss: 0.5131 - val_accuracy: 0.9060
Epoch 278/350
391/391 - 23s - loss: 0.0963 - accuracy: 0.9821 - val_loss: 0.5171 - val_accuracy: 0.9067
Epoch 279/350
391/391 - 23s - loss: 0.0987 - accuracy: 0.9817 - val_loss: 0.5193 - val_accuracy: 0.9062
Epoch 280/350
391/391 - 23s - loss: 0.0992 - accuracy: 0.9813 - val_loss: 0.5182 - val_accuracy: 0.9053
Epoch 281/350
391/391 - 23s - loss: 0.1003 - accuracy: 0.9808 - val_loss: 0.5141 - val_accuracy: 0.9059
Epoch 282/350
391/391 - 23s - loss: 0.0997 - accuracy: 0.9811 - val_loss: 0.5162 - val_accuracy: 0.9054
Epoch 283/350
391/391 - 23s - loss: 0.0990 - accuracy: 0.9814 - val_loss: 0.5168 - val_accuracy: 0.9055
Epoch 284/350
391/391 - 23s - loss: 0.0992 - accuracy: 0.9806 - val_loss: 0.5159 - val_accuracy: 0.9061
Epoch 285/350
391/391 - 23s - loss: 0.0979 - accuracy: 0.9816 - val_loss: 0.5153 - val_accuracy: 0.9056
Epoch 286/350
391/391 - 23s - loss: 0.0999 - accuracy: 0.9809 - val_loss: 0.5128 - val_accuracy: 0.9058
Epoch 287/350
391/391 - 23s - loss: 0.0993 - accuracy: 0.9810 - val_loss: 0.5133 - val_accuracy: 0.9059
Epoch 288/350
391/391 - 23s - loss: 0.0994 - accuracy: 0.9816 - val_loss: 0.5154 - val_accuracy: 0.9058
Epoch 289/350
391/391 - 23s - loss: 0.0969 - accuracy: 0.9818 - val_loss: 0.5154 - val_accuracy: 0.9058
Epoch 290/350
391/391 - 23s - loss: 0.0997 - accuracy: 0.9812 - val_loss: 0.5161 - val_accuracy: 0.9053
Epoch 291/350
391/391 - 23s - loss: 0.1011 - accuracy: 0.9808 - val_loss: 0.5160 - val_accuracy: 0.9053
Epoch 292/350
391/391 - 23s - loss: 0.1003 - accuracy: 0.9803 - val_loss: 0.5140 - val_accuracy: 0.9056
Epoch 293/350
391/391 - 23s - loss: 0.1011 - accuracy: 0.9800 - val_loss: 0.5140 - val_accuracy: 0.9061
Epoch 294/350
391/391 - 23s - loss: 0.0997 - accuracy: 0.9812 - val_loss: 0.5151 - val_accuracy: 0.9060
Epoch 295/350
391/391 - 23s - loss: 0.0995 - accuracy: 0.9814 - val_loss: 0.5145 - val_accuracy: 0.9056
Epoch 296/350
391/391 - 23s - loss: 0.1007 - accuracy: 0.9808 - val_loss: 0.5162 - val_accuracy: 0.9057
Epoch 297/350
391/391 - 23s - loss: 0.1000 - accuracy: 0.9808 - val_loss: 0.5167 - val_accuracy: 0.9055
Epoch 298/350
391/391 - 23s - loss: 0.0981 - accuracy: 0.9819 - val_loss: 0.5175 - val_accuracy: 0.9055
Epoch 299/350
391/391 - 23s - loss: 0.0975 - accuracy: 0.9821 - val_loss: 0.5179 - val_accuracy: 0.9052
Epoch 300/350


Snapshot weight 2 shuffle 8 at epoch 300
Layer 11
Getting activations...


391/391 - 23s - loss: 0.0986 - accuracy: 0.9810 - val_loss: 0.5166 - val_accuracy: 0.9057
Epoch 301/350
391/391 - 23s - loss: 0.0983 - accuracy: 0.9813 - val_loss: 0.5166 - val_accuracy: 0.9059
Epoch 302/350
391/391 - 23s - loss: 0.0987 - accuracy: 0.9807 - val_loss: 0.5164 - val_accuracy: 0.9060
Epoch 303/350
391/391 - 23s - loss: 0.0994 - accuracy: 0.9808 - val_loss: 0.5163 - val_accuracy: 0.9062
Epoch 304/350
391/391 - 23s - loss: 0.0994 - accuracy: 0.9810 - val_loss: 0.5161 - val_accuracy: 0.9063
Epoch 305/350
391/391 - 23s - loss: 0.0985 - accuracy: 0.9816 - val_loss: 0.5163 - val_accuracy: 0.9058
Epoch 306/350
391/391 - 23s - loss: 0.0991 - accuracy: 0.9809 - val_loss: 0.5162 - val_accuracy: 0.9056
Epoch 307/350
391/391 - 23s - loss: 0.0998 - accuracy: 0.9817 - val_loss: 0.5159 - val_accuracy: 0.9055
Epoch 308/350
391/391 - 23s - loss: 0.1001 - accuracy: 0.9808 - val_loss: 0.5160 - val_accuracy: 0.9054
Epoch 309/350
391/391 - 23s - loss: 0.0998 - accuracy: 0.9808 - val_loss: 0.5159 - val_accuracy: 0.9058
Epoch 310/350
391/391 - 23s - loss: 0.0982 - accuracy: 0.9820 - val_loss: 0.5160 - val_accuracy: 0.9059
Epoch 311/350
391/391 - 23s - loss: 0.0969 - accuracy: 0.9814 - val_loss: 0.5161 - val_accuracy: 0.9055
Epoch 312/350
391/391 - 23s - loss: 0.0989 - accuracy: 0.9816 - val_loss: 0.5160 - val_accuracy: 0.9053
Epoch 313/350
391/391 - 23s - loss: 0.0978 - accuracy: 0.9811 - val_loss: 0.5161 - val_accuracy: 0.9057
Epoch 314/350
391/391 - 23s - loss: 0.0986 - accuracy: 0.9807 - val_loss: 0.5162 - val_accuracy: 0.9058
Epoch 315/350
391/391 - 23s - loss: 0.0967 - accuracy: 0.9817 - val_loss: 0.5163 - val_accuracy: 0.9056
Epoch 316/350
391/391 - 23s - loss: 0.0977 - accuracy: 0.9814 - val_loss: 0.5164 - val_accuracy: 0.9059
Epoch 317/350
391/391 - 23s - loss: 0.0990 - accuracy: 0.9810 - val_loss: 0.5164 - val_accuracy: 0.9058
Epoch 318/350
391/391 - 23s - loss: 0.0969 - accuracy: 0.9819 - val_loss: 0.5166 - val_accuracy: 0.9057
Epoch 319/350
391/391 - 23s - loss: 0.0971 - accuracy: 0.9816 - val_loss: 0.5169 - val_accuracy: 0.9056
Epoch 320/350
391/391 - 23s - loss: 0.0994 - accuracy: 0.9811 - val_loss: 0.5166 - val_accuracy: 0.9057
Epoch 321/350
391/391 - 23s - loss: 0.0991 - accuracy: 0.9805 - val_loss: 0.5168 - val_accuracy: 0.9060
Epoch 322/350
391/391 - 23s - loss: 0.0985 - accuracy: 0.9810 - val_loss: 0.5166 - val_accuracy: 0.9056
Epoch 323/350
391/391 - 23s - loss: 0.0988 - accuracy: 0.9810 - val_loss: 0.5168 - val_accuracy: 0.9056
Epoch 324/350
391/391 - 23s - loss: 0.0986 - accuracy: 0.9813 - val_loss: 0.5166 - val_accuracy: 0.9052
Epoch 325/350
391/391 - 23s - loss: 0.0983 - accuracy: 0.9823 - val_loss: 0.5166 - val_accuracy: 0.9055
Epoch 326/350
391/391 - 23s - loss: 0.0973 - accuracy: 0.9825 - val_loss: 0.5168 - val_accuracy: 0.9054
Epoch 327/350
391/391 - 23s - loss: 0.1009 - accuracy: 0.9806 - val_loss: 0.5167 - val_accuracy: 0.9054
Epoch 328/350
391/391 - 23s - loss: 0.0972 - accuracy: 0.9820 - val_loss: 0.5166 - val_accuracy: 0.9054
Epoch 329/350
391/391 - 23s - loss: 0.0989 - accuracy: 0.9813 - val_loss: 0.5165 - val_accuracy: 0.9054
Epoch 330/350
391/391 - 23s - loss: 0.0987 - accuracy: 0.9814 - val_loss: 0.5163 - val_accuracy: 0.9056
Epoch 331/350
391/391 - 23s - loss: 0.0998 - accuracy: 0.9801 - val_loss: 0.5164 - val_accuracy: 0.9059
Epoch 332/350
391/391 - 23s - loss: 0.0987 - accuracy: 0.9814 - val_loss: 0.5166 - val_accuracy: 0.9057
Epoch 333/350
391/391 - 23s - loss: 0.0995 - accuracy: 0.9804 - val_loss: 0.5164 - val_accuracy: 0.9058
Epoch 334/350
391/391 - 23s - loss: 0.1003 - accuracy: 0.9805 - val_loss: 0.5165 - val_accuracy: 0.9056
Epoch 335/350
391/391 - 23s - loss: 0.0979 - accuracy: 0.9815 - val_loss: 0.5163 - val_accuracy: 0.9058
Epoch 336/350
391/391 - 23s - loss: 0.0991 - accuracy: 0.9820 - val_loss: 0.5162 - val_accuracy: 0.9056
Epoch 337/350
391/391 - 23s - loss: 0.1015 - accuracy: 0.9800 - val_loss: 0.5159 - val_accuracy: 0.9055
Epoch 338/350
391/391 - 23s - loss: 0.0982 - accuracy: 0.9813 - val_loss: 0.5160 - val_accuracy: 0.9055
Epoch 339/350
391/391 - 23s - loss: 0.0965 - accuracy: 0.9821 - val_loss: 0.5160 - val_accuracy: 0.9058
Epoch 340/350
391/391 - 23s - loss: 0.0960 - accuracy: 0.9823 - val_loss: 0.5162 - val_accuracy: 0.9061
Epoch 341/350
391/391 - 23s - loss: 0.0989 - accuracy: 0.9808 - val_loss: 0.5162 - val_accuracy: 0.9057
Epoch 342/350
391/391 - 23s - loss: 0.0994 - accuracy: 0.9811 - val_loss: 0.5161 - val_accuracy: 0.9054
Epoch 343/350
391/391 - 23s - loss: 0.0975 - accuracy: 0.9822 - val_loss: 0.5164 - val_accuracy: 0.9054
Epoch 344/350
391/391 - 23s - loss: 0.0964 - accuracy: 0.9827 - val_loss: 0.5165 - val_accuracy: 0.9062
Epoch 345/350
391/391 - 23s - loss: 0.0994 - accuracy: 0.9809 - val_loss: 0.5164 - val_accuracy: 0.9062
Epoch 346/350
391/391 - 23s - loss: 0.0964 - accuracy: 0.9824 - val_loss: 0.5162 - val_accuracy: 0.9062
Epoch 347/350
391/391 - 23s - loss: 0.0968 - accuracy: 0.9823 - val_loss: 0.5159 - val_accuracy: 0.9061
Epoch 348/350
391/391 - 23s - loss: 0.0995 - accuracy: 0.9808 - val_loss: 0.5162 - val_accuracy: 0.9058
Epoch 349/350
391/391 - 23s - loss: 0.0994 - accuracy: 0.9809 - val_loss: 0.5161 - val_accuracy: 0.9056
Epoch 350/350


Snapshot weight 2 shuffle 8 at epoch 350
Layer 11
Getting activations...


391/391 - 23s - loss: 0.0975 - accuracy: 0.9818 - val_loss: 0.5161 - val_accuracy: 0.9059
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-07-02 19:01:13.688187: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
Saving, final validation acc: 0.9059000015258789
