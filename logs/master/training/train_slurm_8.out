2021-07-01 18:34:24.552213: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 18:36:02.940499: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-07-01 18:36:02.967453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2021-07-01 18:36:02.967525: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 18:36:03.008920: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-01 18:36:03.030086: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-01 18:36:03.038663: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-01 18:36:03.081929: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-01 18:36:03.090700: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-01 18:36:03.167617: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-01 18:36:03.169523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-01 18:36:03.173202: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-01 18:36:03.190386: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600000000 Hz
2021-07-01 18:36:03.190542: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x481cf90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-07-01 18:36:03.190560: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-07-01 18:36:03.340121: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x481b190 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-07-01 18:36:03.340186: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN Xp, Compute Capability 6.1
2021-07-01 18:36:03.342623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2021-07-01 18:36:03.342677: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 18:36:03.342711: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-01 18:36:03.342730: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-01 18:36:03.342747: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-01 18:36:03.342765: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-01 18:36:03.342782: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-01 18:36:03.342800: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-01 18:36:03.353300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-01 18:36:03.355123: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 18:36:05.178354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-01 18:36:05.178454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-07-01 18:36:05.178470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-07-01 18:36:05.185758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11218 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
2021-07-01 18:36:11.132037: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-01 18:36:13.728762: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
Using model index: 8
Making train data...
GCN...
ZCA...
Done!
Making test data...
Done!
Epoch 1/350


Snapshot weight 8 shuffle 0 at epoch 1
Layer 11
Getting activations...


391/391 - 23s - loss: 2.3172 - accuracy: 0.1162 - val_loss: 2.3010 - val_accuracy: 0.1320
Epoch 2/350


Snapshot weight 8 shuffle 0 at epoch 2
Layer 11
Getting activations...


391/391 - 23s - loss: 2.1241 - accuracy: 0.2356 - val_loss: 1.9291 - val_accuracy: 0.3298
Epoch 3/350


Snapshot weight 8 shuffle 0 at epoch 3
Layer 11
Getting activations...


391/391 - 23s - loss: 1.8393 - accuracy: 0.3324 - val_loss: 1.7573 - val_accuracy: 0.3543
Epoch 4/350


Snapshot weight 8 shuffle 0 at epoch 4
Layer 11
Getting activations...


391/391 - 23s - loss: 1.5958 - accuracy: 0.4213 - val_loss: 1.3818 - val_accuracy: 0.5083
Epoch 5/350


Snapshot weight 8 shuffle 0 at epoch 5
Layer 11
Getting activations...


391/391 - 23s - loss: 1.4161 - accuracy: 0.4974 - val_loss: 1.3389 - val_accuracy: 0.5282
Epoch 6/350


Snapshot weight 8 shuffle 0 at epoch 6
Layer 11
Getting activations...


391/391 - 23s - loss: 1.3236 - accuracy: 0.5317 - val_loss: 1.3355 - val_accuracy: 0.5424
Epoch 7/350


Snapshot weight 8 shuffle 0 at epoch 7
Layer 11
Getting activations...


391/391 - 23s - loss: 1.2288 - accuracy: 0.5699 - val_loss: 1.1152 - val_accuracy: 0.6056
Epoch 8/350


Snapshot weight 8 shuffle 0 at epoch 8
Layer 11
Getting activations...


391/391 - 23s - loss: 1.1635 - accuracy: 0.5949 - val_loss: 1.2390 - val_accuracy: 0.5839
Epoch 9/350


Snapshot weight 8 shuffle 0 at epoch 9
Layer 11
Getting activations...


391/391 - 23s - loss: 1.1161 - accuracy: 0.6138 - val_loss: 1.1707 - val_accuracy: 0.6094
Epoch 10/350


Snapshot weight 8 shuffle 0 at epoch 10
Layer 11
Getting activations...


391/391 - 23s - loss: 1.0587 - accuracy: 0.6310 - val_loss: 1.0299 - val_accuracy: 0.6403
Epoch 11/350
391/391 - 23s - loss: 1.0155 - accuracy: 0.6490 - val_loss: 1.0106 - val_accuracy: 0.6532
Epoch 12/350
391/391 - 23s - loss: 0.9829 - accuracy: 0.6620 - val_loss: 1.0174 - val_accuracy: 0.6641
Epoch 13/350
391/391 - 23s - loss: 0.9398 - accuracy: 0.6777 - val_loss: 0.8787 - val_accuracy: 0.7038
Epoch 14/350
391/391 - 23s - loss: 0.9093 - accuracy: 0.6884 - val_loss: 0.8503 - val_accuracy: 0.7048
Epoch 15/350
391/391 - 23s - loss: 0.8708 - accuracy: 0.7021 - val_loss: 0.9622 - val_accuracy: 0.6892
Epoch 16/350
391/391 - 23s - loss: 0.8393 - accuracy: 0.7159 - val_loss: 0.8941 - val_accuracy: 0.7123
Epoch 17/350
391/391 - 23s - loss: 0.8147 - accuracy: 0.7238 - val_loss: 0.9084 - val_accuracy: 0.7110
Epoch 18/350
391/391 - 23s - loss: 0.7814 - accuracy: 0.7369 - val_loss: 0.8150 - val_accuracy: 0.7204
Epoch 19/350
391/391 - 23s - loss: 0.7602 - accuracy: 0.7431 - val_loss: 0.7355 - val_accuracy: 0.7553
Epoch 20/350
391/391 - 23s - loss: 0.7366 - accuracy: 0.7524 - val_loss: 0.7263 - val_accuracy: 0.7593
Epoch 21/350
391/391 - 23s - loss: 0.7129 - accuracy: 0.7605 - val_loss: 0.8643 - val_accuracy: 0.7326
Epoch 22/350
391/391 - 23s - loss: 0.6909 - accuracy: 0.7686 - val_loss: 0.7039 - val_accuracy: 0.7659
Epoch 23/350
391/391 - 23s - loss: 0.6714 - accuracy: 0.7751 - val_loss: 0.7316 - val_accuracy: 0.7640
Epoch 24/350
391/391 - 23s - loss: 0.6490 - accuracy: 0.7849 - val_loss: 0.7128 - val_accuracy: 0.7726
Epoch 25/350
391/391 - 23s - loss: 0.6338 - accuracy: 0.7896 - val_loss: 0.7317 - val_accuracy: 0.7710
Epoch 26/350
391/391 - 23s - loss: 0.6214 - accuracy: 0.7936 - val_loss: 0.6010 - val_accuracy: 0.8051
Epoch 27/350
391/391 - 23s - loss: 0.6077 - accuracy: 0.7984 - val_loss: 0.6025 - val_accuracy: 0.8081
Epoch 28/350
391/391 - 23s - loss: 0.5936 - accuracy: 0.8034 - val_loss: 0.5993 - val_accuracy: 0.8063
Epoch 29/350
391/391 - 23s - loss: 0.5884 - accuracy: 0.8055 - val_loss: 0.5682 - val_accuracy: 0.8192
Epoch 30/350
391/391 - 24s - loss: 0.5769 - accuracy: 0.8096 - val_loss: 0.5554 - val_accuracy: 0.8177
Epoch 31/350
391/391 - 23s - loss: 0.5597 - accuracy: 0.8160 - val_loss: 0.5437 - val_accuracy: 0.8270
Epoch 32/350
391/391 - 23s - loss: 0.5536 - accuracy: 0.8184 - val_loss: 0.5343 - val_accuracy: 0.8214
Epoch 33/350
391/391 - 23s - loss: 0.5433 - accuracy: 0.8223 - val_loss: 0.6691 - val_accuracy: 0.7923
Epoch 34/350
391/391 - 23s - loss: 0.5328 - accuracy: 0.8250 - val_loss: 0.5719 - val_accuracy: 0.8132
Epoch 35/350
391/391 - 23s - loss: 0.5212 - accuracy: 0.8271 - val_loss: 0.5983 - val_accuracy: 0.8150
Epoch 36/350
391/391 - 23s - loss: 0.5106 - accuracy: 0.8304 - val_loss: 0.6081 - val_accuracy: 0.8092
Epoch 37/350
391/391 - 23s - loss: 0.5011 - accuracy: 0.8361 - val_loss: 0.5490 - val_accuracy: 0.8271
Epoch 38/350
391/391 - 23s - loss: 0.4984 - accuracy: 0.8363 - val_loss: 0.5487 - val_accuracy: 0.8245
Epoch 39/350
391/391 - 23s - loss: 0.4919 - accuracy: 0.8389 - val_loss: 0.5807 - val_accuracy: 0.8222
Epoch 40/350
391/391 - 23s - loss: 0.4878 - accuracy: 0.8419 - val_loss: 0.5463 - val_accuracy: 0.8270
Epoch 41/350
391/391 - 23s - loss: 0.4757 - accuracy: 0.8445 - val_loss: 0.5054 - val_accuracy: 0.8392
Epoch 42/350
391/391 - 23s - loss: 0.4714 - accuracy: 0.8461 - val_loss: 0.5046 - val_accuracy: 0.8447
Epoch 43/350
391/391 - 23s - loss: 0.4603 - accuracy: 0.8506 - val_loss: 0.5046 - val_accuracy: 0.8384
Epoch 44/350
391/391 - 23s - loss: 0.4542 - accuracy: 0.8514 - val_loss: 0.5241 - val_accuracy: 0.8329
Epoch 45/350
391/391 - 23s - loss: 0.4485 - accuracy: 0.8532 - val_loss: 0.6037 - val_accuracy: 0.8130
Epoch 46/350
391/391 - 23s - loss: 0.4418 - accuracy: 0.8562 - val_loss: 0.5239 - val_accuracy: 0.8403
Epoch 47/350
391/391 - 23s - loss: 0.4339 - accuracy: 0.8594 - val_loss: 0.4587 - val_accuracy: 0.8586
Epoch 48/350
391/391 - 23s - loss: 0.4312 - accuracy: 0.8594 - val_loss: 0.5035 - val_accuracy: 0.8428
Epoch 49/350
391/391 - 23s - loss: 0.4308 - accuracy: 0.8600 - val_loss: 0.5251 - val_accuracy: 0.8388
Epoch 50/350


Snapshot weight 8 shuffle 0 at epoch 50
Layer 11
Getting activations...


391/391 - 23s - loss: 0.4232 - accuracy: 0.8625 - val_loss: 0.4948 - val_accuracy: 0.8477
Epoch 51/350
391/391 - 23s - loss: 0.4162 - accuracy: 0.8659 - val_loss: 0.4969 - val_accuracy: 0.8454
Epoch 52/350
391/391 - 23s - loss: 0.4104 - accuracy: 0.8673 - val_loss: 0.5231 - val_accuracy: 0.8405
Epoch 53/350
391/391 - 23s - loss: 0.4029 - accuracy: 0.8701 - val_loss: 0.4948 - val_accuracy: 0.8519
Epoch 54/350
391/391 - 23s - loss: 0.4044 - accuracy: 0.8691 - val_loss: 0.4542 - val_accuracy: 0.8572
Epoch 55/350
391/391 - 23s - loss: 0.3999 - accuracy: 0.8711 - val_loss: 0.4723 - val_accuracy: 0.8581
Epoch 56/350
391/391 - 23s - loss: 0.3935 - accuracy: 0.8735 - val_loss: 0.4861 - val_accuracy: 0.8571
Epoch 57/350
391/391 - 23s - loss: 0.3887 - accuracy: 0.8749 - val_loss: 0.4573 - val_accuracy: 0.8600
Epoch 58/350
391/391 - 23s - loss: 0.3816 - accuracy: 0.8762 - val_loss: 0.4658 - val_accuracy: 0.8533
Epoch 59/350
391/391 - 23s - loss: 0.3815 - accuracy: 0.8773 - val_loss: 0.4659 - val_accuracy: 0.8533
Epoch 60/350
391/391 - 23s - loss: 0.3749 - accuracy: 0.8808 - val_loss: 0.4702 - val_accuracy: 0.8593
Epoch 61/350
391/391 - 23s - loss: 0.3754 - accuracy: 0.8804 - val_loss: 0.4964 - val_accuracy: 0.8587
Epoch 62/350
391/391 - 23s - loss: 0.3693 - accuracy: 0.8828 - val_loss: 0.4548 - val_accuracy: 0.8587
Epoch 63/350
391/391 - 23s - loss: 0.3695 - accuracy: 0.8827 - val_loss: 0.5095 - val_accuracy: 0.8520
Epoch 64/350
391/391 - 23s - loss: 0.3608 - accuracy: 0.8858 - val_loss: 0.4368 - val_accuracy: 0.8663
Epoch 65/350
391/391 - 23s - loss: 0.3573 - accuracy: 0.8860 - val_loss: 0.4448 - val_accuracy: 0.8623
Epoch 66/350
391/391 - 23s - loss: 0.3563 - accuracy: 0.8875 - val_loss: 0.4654 - val_accuracy: 0.8530
Epoch 67/350
391/391 - 23s - loss: 0.3521 - accuracy: 0.8868 - val_loss: 0.4471 - val_accuracy: 0.8637
Epoch 68/350
391/391 - 23s - loss: 0.3520 - accuracy: 0.8883 - val_loss: 0.5391 - val_accuracy: 0.8514
Epoch 69/350
391/391 - 23s - loss: 0.3415 - accuracy: 0.8922 - val_loss: 0.4638 - val_accuracy: 0.8689
Epoch 70/350
391/391 - 23s - loss: 0.3410 - accuracy: 0.8923 - val_loss: 0.4744 - val_accuracy: 0.8610
Epoch 71/350
391/391 - 23s - loss: 0.3360 - accuracy: 0.8939 - val_loss: 0.4921 - val_accuracy: 0.8556
Epoch 72/350
391/391 - 23s - loss: 0.3401 - accuracy: 0.8930 - val_loss: 0.4683 - val_accuracy: 0.8652
Epoch 73/350
391/391 - 23s - loss: 0.3259 - accuracy: 0.8952 - val_loss: 0.4775 - val_accuracy: 0.8607
Epoch 74/350
391/391 - 23s - loss: 0.3284 - accuracy: 0.8959 - val_loss: 0.4301 - val_accuracy: 0.8734
Epoch 75/350
391/391 - 23s - loss: 0.3241 - accuracy: 0.8988 - val_loss: 0.4322 - val_accuracy: 0.8731
Epoch 76/350
391/391 - 23s - loss: 0.3217 - accuracy: 0.8992 - val_loss: 0.4607 - val_accuracy: 0.8662
Epoch 77/350
391/391 - 23s - loss: 0.3237 - accuracy: 0.8981 - val_loss: 0.4182 - val_accuracy: 0.8736
Epoch 78/350
391/391 - 23s - loss: 0.3181 - accuracy: 0.9004 - val_loss: 0.4344 - val_accuracy: 0.8679
Epoch 79/350
391/391 - 23s - loss: 0.3130 - accuracy: 0.9027 - val_loss: 0.4299 - val_accuracy: 0.8728
Epoch 80/350
391/391 - 23s - loss: 0.3118 - accuracy: 0.9024 - val_loss: 0.4512 - val_accuracy: 0.8698
Epoch 81/350
391/391 - 23s - loss: 0.3077 - accuracy: 0.9047 - val_loss: 0.4341 - val_accuracy: 0.8738
Epoch 82/350
391/391 - 23s - loss: 0.3097 - accuracy: 0.9012 - val_loss: 0.4732 - val_accuracy: 0.8640
Epoch 83/350
391/391 - 23s - loss: 0.3071 - accuracy: 0.9046 - val_loss: 0.4205 - val_accuracy: 0.8739
Epoch 84/350
391/391 - 23s - loss: 0.3041 - accuracy: 0.9051 - val_loss: 0.4268 - val_accuracy: 0.8763
Epoch 85/350
391/391 - 23s - loss: 0.2985 - accuracy: 0.9072 - val_loss: 0.4301 - val_accuracy: 0.8758
Epoch 86/350
391/391 - 23s - loss: 0.2968 - accuracy: 0.9080 - val_loss: 0.4821 - val_accuracy: 0.8687
Epoch 87/350
391/391 - 23s - loss: 0.2990 - accuracy: 0.9066 - val_loss: 0.4514 - val_accuracy: 0.8703
Epoch 88/350
391/391 - 23s - loss: 0.2899 - accuracy: 0.9099 - val_loss: 0.4367 - val_accuracy: 0.8736
Epoch 89/350
391/391 - 23s - loss: 0.2917 - accuracy: 0.9089 - val_loss: 0.4371 - val_accuracy: 0.8735
Epoch 90/350
391/391 - 23s - loss: 0.2893 - accuracy: 0.9120 - val_loss: 0.4494 - val_accuracy: 0.8706
Epoch 91/350
391/391 - 23s - loss: 0.2866 - accuracy: 0.9114 - val_loss: 0.4823 - val_accuracy: 0.8672
Epoch 92/350
391/391 - 23s - loss: 0.2860 - accuracy: 0.9120 - val_loss: 0.4152 - val_accuracy: 0.8815
Epoch 93/350
391/391 - 23s - loss: 0.2847 - accuracy: 0.9132 - val_loss: 0.4450 - val_accuracy: 0.8741
Epoch 94/350
391/391 - 23s - loss: 0.2798 - accuracy: 0.9142 - val_loss: 0.4540 - val_accuracy: 0.8732
Epoch 95/350
391/391 - 23s - loss: 0.2787 - accuracy: 0.9143 - val_loss: 0.4702 - val_accuracy: 0.8722
Epoch 96/350
391/391 - 23s - loss: 0.2748 - accuracy: 0.9149 - val_loss: 0.4328 - val_accuracy: 0.8805
Epoch 97/350
391/391 - 23s - loss: 0.2754 - accuracy: 0.9145 - val_loss: 0.4560 - val_accuracy: 0.8711
Epoch 98/350
391/391 - 23s - loss: 0.2719 - accuracy: 0.9175 - val_loss: 0.4572 - val_accuracy: 0.8772
Epoch 99/350
391/391 - 23s - loss: 0.2715 - accuracy: 0.9163 - val_loss: 0.4386 - val_accuracy: 0.8743
Epoch 100/350


Snapshot weight 8 shuffle 0 at epoch 100
Layer 11
Getting activations...


391/391 - 24s - loss: 0.2656 - accuracy: 0.9198 - val_loss: 0.4560 - val_accuracy: 0.8716
Epoch 101/350
391/391 - 23s - loss: 0.2640 - accuracy: 0.9189 - val_loss: 0.4460 - val_accuracy: 0.8795
Epoch 102/350
391/391 - 23s - loss: 0.2680 - accuracy: 0.9180 - val_loss: 0.4484 - val_accuracy: 0.8789
Epoch 103/350
391/391 - 23s - loss: 0.2630 - accuracy: 0.9199 - val_loss: 0.4400 - val_accuracy: 0.8742
Epoch 104/350
391/391 - 23s - loss: 0.2597 - accuracy: 0.9208 - val_loss: 0.4596 - val_accuracy: 0.8720
Epoch 105/350
391/391 - 23s - loss: 0.2606 - accuracy: 0.9212 - val_loss: 0.4578 - val_accuracy: 0.8750
Epoch 106/350
391/391 - 23s - loss: 0.2584 - accuracy: 0.9229 - val_loss: 0.4198 - val_accuracy: 0.8885
Epoch 107/350
391/391 - 23s - loss: 0.2582 - accuracy: 0.9200 - val_loss: 0.4302 - val_accuracy: 0.8823
Epoch 108/350
391/391 - 23s - loss: 0.2559 - accuracy: 0.9223 - val_loss: 0.4302 - val_accuracy: 0.8811
Epoch 109/350
391/391 - 23s - loss: 0.2545 - accuracy: 0.9235 - val_loss: 0.4273 - val_accuracy: 0.8820
Epoch 110/350
391/391 - 23s - loss: 0.2530 - accuracy: 0.9223 - val_loss: 0.4416 - val_accuracy: 0.8868
Epoch 111/350
391/391 - 23s - loss: 0.2527 - accuracy: 0.9240 - val_loss: 0.4609 - val_accuracy: 0.8752
Epoch 112/350
391/391 - 23s - loss: 0.2524 - accuracy: 0.9242 - val_loss: 0.4484 - val_accuracy: 0.8803
Epoch 113/350
391/391 - 23s - loss: 0.2457 - accuracy: 0.9265 - val_loss: 0.4481 - val_accuracy: 0.8821
Epoch 114/350
391/391 - 23s - loss: 0.2442 - accuracy: 0.9262 - val_loss: 0.4559 - val_accuracy: 0.8782
Epoch 115/350
391/391 - 23s - loss: 0.2448 - accuracy: 0.9266 - val_loss: 0.4686 - val_accuracy: 0.8780
Epoch 116/350
391/391 - 23s - loss: 0.2420 - accuracy: 0.9278 - val_loss: 0.4206 - val_accuracy: 0.8878
Epoch 117/350
391/391 - 23s - loss: 0.2379 - accuracy: 0.9306 - val_loss: 0.4422 - val_accuracy: 0.8822
Epoch 118/350
391/391 - 23s - loss: 0.2416 - accuracy: 0.9287 - val_loss: 0.4145 - val_accuracy: 0.8868
Epoch 119/350
391/391 - 23s - loss: 0.2342 - accuracy: 0.9302 - val_loss: 0.4237 - val_accuracy: 0.8857
Epoch 120/350
391/391 - 23s - loss: 0.2394 - accuracy: 0.9295 - val_loss: 0.4418 - val_accuracy: 0.8876
Epoch 121/350
391/391 - 24s - loss: 0.2329 - accuracy: 0.9295 - val_loss: 0.4573 - val_accuracy: 0.8827
Epoch 122/350
391/391 - 23s - loss: 0.2346 - accuracy: 0.9302 - val_loss: 0.4588 - val_accuracy: 0.8847
Epoch 123/350
391/391 - 23s - loss: 0.2380 - accuracy: 0.9301 - val_loss: 0.4367 - val_accuracy: 0.8886
Epoch 124/350
391/391 - 23s - loss: 0.2378 - accuracy: 0.9289 - val_loss: 0.4417 - val_accuracy: 0.8868
Epoch 125/350
391/391 - 23s - loss: 0.2297 - accuracy: 0.9317 - val_loss: 0.4666 - val_accuracy: 0.8813
Epoch 126/350
391/391 - 23s - loss: 0.2315 - accuracy: 0.9312 - val_loss: 0.4569 - val_accuracy: 0.8828
Epoch 127/350
391/391 - 23s - loss: 0.2261 - accuracy: 0.9318 - val_loss: 0.4333 - val_accuracy: 0.8847
Epoch 128/350
391/391 - 23s - loss: 0.2283 - accuracy: 0.9333 - val_loss: 0.4379 - val_accuracy: 0.8871
Epoch 129/350
391/391 - 23s - loss: 0.2251 - accuracy: 0.9338 - val_loss: 0.4245 - val_accuracy: 0.8903
Epoch 130/350
391/391 - 23s - loss: 0.2213 - accuracy: 0.9350 - val_loss: 0.4587 - val_accuracy: 0.8875
Epoch 131/350
391/391 - 23s - loss: 0.2254 - accuracy: 0.9341 - val_loss: 0.4307 - val_accuracy: 0.8843
Epoch 132/350
391/391 - 23s - loss: 0.2213 - accuracy: 0.9344 - val_loss: 0.4433 - val_accuracy: 0.8902
Epoch 133/350
391/391 - 24s - loss: 0.2237 - accuracy: 0.9355 - val_loss: 0.4392 - val_accuracy: 0.8886
Epoch 134/350
391/391 - 23s - loss: 0.2209 - accuracy: 0.9354 - val_loss: 0.4341 - val_accuracy: 0.8912
Epoch 135/350
391/391 - 23s - loss: 0.2151 - accuracy: 0.9389 - val_loss: 0.4640 - val_accuracy: 0.8863
Epoch 136/350
391/391 - 23s - loss: 0.2174 - accuracy: 0.9364 - val_loss: 0.4427 - val_accuracy: 0.8901
Epoch 137/350
391/391 - 23s - loss: 0.2145 - accuracy: 0.9393 - val_loss: 0.4845 - val_accuracy: 0.8855
Epoch 138/350
391/391 - 23s - loss: 0.2164 - accuracy: 0.9383 - val_loss: 0.4727 - val_accuracy: 0.8814
Epoch 139/350
391/391 - 23s - loss: 0.2161 - accuracy: 0.9384 - val_loss: 0.4571 - val_accuracy: 0.8867
Epoch 140/350
391/391 - 23s - loss: 0.2147 - accuracy: 0.9387 - val_loss: 0.4451 - val_accuracy: 0.8858
Epoch 141/350
391/391 - 23s - loss: 0.2135 - accuracy: 0.9391 - val_loss: 0.4511 - val_accuracy: 0.8856
Epoch 142/350
391/391 - 23s - loss: 0.2138 - accuracy: 0.9387 - val_loss: 0.4446 - val_accuracy: 0.8887
Epoch 143/350
391/391 - 23s - loss: 0.2082 - accuracy: 0.9403 - val_loss: 0.4319 - val_accuracy: 0.8921
Epoch 144/350
391/391 - 23s - loss: 0.2152 - accuracy: 0.9393 - val_loss: 0.4432 - val_accuracy: 0.8849
Epoch 145/350
391/391 - 23s - loss: 0.2092 - accuracy: 0.9418 - val_loss: 0.4749 - val_accuracy: 0.8830
Epoch 146/350
391/391 - 23s - loss: 0.2057 - accuracy: 0.9417 - val_loss: 0.4329 - val_accuracy: 0.8881
Epoch 147/350
391/391 - 23s - loss: 0.2069 - accuracy: 0.9415 - val_loss: 0.4530 - val_accuracy: 0.8856
Epoch 148/350
391/391 - 23s - loss: 0.2035 - accuracy: 0.9421 - val_loss: 0.4355 - val_accuracy: 0.8866
Epoch 149/350
391/391 - 23s - loss: 0.2036 - accuracy: 0.9425 - val_loss: 0.4143 - val_accuracy: 0.8966
Epoch 150/350


Snapshot weight 8 shuffle 0 at epoch 150
Layer 11
Getting activations...


391/391 - 23s - loss: 0.1990 - accuracy: 0.9450 - val_loss: 0.4690 - val_accuracy: 0.8843
Epoch 151/350
391/391 - 23s - loss: 0.2030 - accuracy: 0.9420 - val_loss: 0.4634 - val_accuracy: 0.8899
Epoch 152/350
391/391 - 23s - loss: 0.2024 - accuracy: 0.9429 - val_loss: 0.4714 - val_accuracy: 0.8899
Epoch 153/350
391/391 - 23s - loss: 0.2006 - accuracy: 0.9432 - val_loss: 0.4401 - val_accuracy: 0.8928
Epoch 154/350
391/391 - 23s - loss: 0.2029 - accuracy: 0.9427 - val_loss: 0.4336 - val_accuracy: 0.8901
Epoch 155/350
391/391 - 23s - loss: 0.2002 - accuracy: 0.9440 - val_loss: 0.4350 - val_accuracy: 0.8905
Epoch 156/350
391/391 - 23s - loss: 0.2001 - accuracy: 0.9429 - val_loss: 0.5002 - val_accuracy: 0.8842
Epoch 157/350
391/391 - 23s - loss: 0.1985 - accuracy: 0.9434 - val_loss: 0.5095 - val_accuracy: 0.8808
Epoch 158/350
391/391 - 23s - loss: 0.1985 - accuracy: 0.9443 - val_loss: 0.4717 - val_accuracy: 0.8883
Epoch 159/350
391/391 - 23s - loss: 0.1980 - accuracy: 0.9449 - val_loss: 0.4390 - val_accuracy: 0.8900
Epoch 160/350
391/391 - 23s - loss: 0.1965 - accuracy: 0.9454 - val_loss: 0.4429 - val_accuracy: 0.8916
Epoch 161/350
391/391 - 23s - loss: 0.1917 - accuracy: 0.9478 - val_loss: 0.4469 - val_accuracy: 0.8950
Epoch 162/350
391/391 - 23s - loss: 0.1936 - accuracy: 0.9460 - val_loss: 0.4678 - val_accuracy: 0.8900
Epoch 163/350
391/391 - 23s - loss: 0.1937 - accuracy: 0.9454 - val_loss: 0.4354 - val_accuracy: 0.8940
Epoch 164/350
391/391 - 23s - loss: 0.1955 - accuracy: 0.9465 - val_loss: 0.4687 - val_accuracy: 0.8870
Epoch 165/350
391/391 - 23s - loss: 0.1946 - accuracy: 0.9464 - val_loss: 0.4510 - val_accuracy: 0.8931
Epoch 166/350
391/391 - 23s - loss: 0.1860 - accuracy: 0.9502 - val_loss: 0.4675 - val_accuracy: 0.8923
Epoch 167/350
391/391 - 23s - loss: 0.1899 - accuracy: 0.9486 - val_loss: 0.4625 - val_accuracy: 0.8916
Epoch 168/350
391/391 - 23s - loss: 0.1904 - accuracy: 0.9469 - val_loss: 0.4428 - val_accuracy: 0.8937
Epoch 169/350
391/391 - 23s - loss: 0.1917 - accuracy: 0.9461 - val_loss: 0.4595 - val_accuracy: 0.8932
Epoch 170/350
391/391 - 23s - loss: 0.1902 - accuracy: 0.9483 - val_loss: 0.4485 - val_accuracy: 0.8931
Epoch 171/350
391/391 - 23s - loss: 0.1835 - accuracy: 0.9506 - val_loss: 0.4758 - val_accuracy: 0.8873
Epoch 172/350
391/391 - 23s - loss: 0.1866 - accuracy: 0.9488 - val_loss: 0.4516 - val_accuracy: 0.8945
Epoch 173/350
391/391 - 23s - loss: 0.1851 - accuracy: 0.9496 - val_loss: 0.4860 - val_accuracy: 0.8880
Epoch 174/350
391/391 - 23s - loss: 0.1876 - accuracy: 0.9487 - val_loss: 0.4612 - val_accuracy: 0.8876
Epoch 175/350
391/391 - 23s - loss: 0.1841 - accuracy: 0.9503 - val_loss: 0.4832 - val_accuracy: 0.8895
Epoch 176/350
391/391 - 23s - loss: 0.1842 - accuracy: 0.9506 - val_loss: 0.4525 - val_accuracy: 0.8934
Epoch 177/350
391/391 - 23s - loss: 0.1822 - accuracy: 0.9507 - val_loss: 0.4686 - val_accuracy: 0.8919
Epoch 178/350
391/391 - 23s - loss: 0.1858 - accuracy: 0.9499 - val_loss: 0.4549 - val_accuracy: 0.8893
Epoch 179/350
391/391 - 23s - loss: 0.1780 - accuracy: 0.9521 - val_loss: 0.4914 - val_accuracy: 0.8887
Epoch 180/350
391/391 - 23s - loss: 0.1834 - accuracy: 0.9499 - val_loss: 0.4661 - val_accuracy: 0.8869
Epoch 181/350
391/391 - 23s - loss: 0.1803 - accuracy: 0.9527 - val_loss: 0.4469 - val_accuracy: 0.8940
Epoch 182/350
391/391 - 23s - loss: 0.1824 - accuracy: 0.9512 - val_loss: 0.4567 - val_accuracy: 0.8920
Epoch 183/350
391/391 - 23s - loss: 0.1823 - accuracy: 0.9510 - val_loss: 0.4621 - val_accuracy: 0.8900
Epoch 184/350
391/391 - 23s - loss: 0.1838 - accuracy: 0.9507 - val_loss: 0.4622 - val_accuracy: 0.8919
Epoch 185/350
391/391 - 23s - loss: 0.1746 - accuracy: 0.9537 - val_loss: 0.5024 - val_accuracy: 0.8904
Epoch 186/350
391/391 - 23s - loss: 0.1814 - accuracy: 0.9516 - val_loss: 0.4378 - val_accuracy: 0.8955
Epoch 187/350
391/391 - 23s - loss: 0.1754 - accuracy: 0.9532 - val_loss: 0.4648 - val_accuracy: 0.8921
Epoch 188/350
391/391 - 23s - loss: 0.1750 - accuracy: 0.9532 - val_loss: 0.5046 - val_accuracy: 0.8886
Epoch 189/350
391/391 - 23s - loss: 0.1849 - accuracy: 0.9505 - val_loss: 0.4842 - val_accuracy: 0.8881
Epoch 190/350
391/391 - 23s - loss: 0.1753 - accuracy: 0.9533 - val_loss: 0.4587 - val_accuracy: 0.8940
Epoch 191/350
391/391 - 23s - loss: 0.1734 - accuracy: 0.9549 - val_loss: 0.4576 - val_accuracy: 0.8948
Epoch 192/350
391/391 - 23s - loss: 0.1748 - accuracy: 0.9535 - val_loss: 0.4922 - val_accuracy: 0.8933
Epoch 193/350
391/391 - 23s - loss: 0.1729 - accuracy: 0.9558 - val_loss: 0.4908 - val_accuracy: 0.8917
Epoch 194/350
391/391 - 23s - loss: 0.1725 - accuracy: 0.9553 - val_loss: 0.5272 - val_accuracy: 0.8845
Epoch 195/350
391/391 - 23s - loss: 0.1737 - accuracy: 0.9546 - val_loss: 0.4574 - val_accuracy: 0.8951
Epoch 196/350
391/391 - 23s - loss: 0.1706 - accuracy: 0.9551 - val_loss: 0.4952 - val_accuracy: 0.8946
Epoch 197/350
391/391 - 23s - loss: 0.1690 - accuracy: 0.9567 - val_loss: 0.4807 - val_accuracy: 0.8933
Epoch 198/350
391/391 - 23s - loss: 0.1701 - accuracy: 0.9566 - val_loss: 0.4678 - val_accuracy: 0.8932
Epoch 199/350
391/391 - 23s - loss: 0.1733 - accuracy: 0.9553 - val_loss: 0.4536 - val_accuracy: 0.8958
Epoch 200/350


Snapshot weight 8 shuffle 0 at epoch 200
Layer 11
Getting activations...


391/391 - 23s - loss: 0.1705 - accuracy: 0.9554 - val_loss: 0.4695 - val_accuracy: 0.8958
Epoch 201/350
391/391 - 23s - loss: 0.1429 - accuracy: 0.9662 - val_loss: 0.4555 - val_accuracy: 0.9020
Epoch 202/350
391/391 - 23s - loss: 0.1308 - accuracy: 0.9706 - val_loss: 0.4510 - val_accuracy: 0.9033
Epoch 203/350
391/391 - 23s - loss: 0.1314 - accuracy: 0.9705 - val_loss: 0.4627 - val_accuracy: 0.9012
Epoch 204/350
391/391 - 23s - loss: 0.1269 - accuracy: 0.9715 - val_loss: 0.4753 - val_accuracy: 0.9035
Epoch 205/350
391/391 - 23s - loss: 0.1266 - accuracy: 0.9714 - val_loss: 0.4719 - val_accuracy: 0.9013
Epoch 206/350
391/391 - 23s - loss: 0.1236 - accuracy: 0.9726 - val_loss: 0.4772 - val_accuracy: 0.9021
Epoch 207/350
391/391 - 23s - loss: 0.1238 - accuracy: 0.9733 - val_loss: 0.4642 - val_accuracy: 0.9017
Epoch 208/350
391/391 - 23s - loss: 0.1227 - accuracy: 0.9730 - val_loss: 0.4921 - val_accuracy: 0.8997
Epoch 209/350
391/391 - 23s - loss: 0.1212 - accuracy: 0.9732 - val_loss: 0.4763 - val_accuracy: 0.9044
Epoch 210/350
391/391 - 23s - loss: 0.1229 - accuracy: 0.9718 - val_loss: 0.4762 - val_accuracy: 0.9033
Epoch 211/350
391/391 - 23s - loss: 0.1200 - accuracy: 0.9736 - val_loss: 0.4785 - val_accuracy: 0.9011
Epoch 212/350
391/391 - 23s - loss: 0.1200 - accuracy: 0.9731 - val_loss: 0.4825 - val_accuracy: 0.9036
Epoch 213/350
391/391 - 23s - loss: 0.1178 - accuracy: 0.9738 - val_loss: 0.4957 - val_accuracy: 0.9010
Epoch 214/350
391/391 - 23s - loss: 0.1188 - accuracy: 0.9739 - val_loss: 0.4785 - val_accuracy: 0.9019
Epoch 215/350
391/391 - 23s - loss: 0.1153 - accuracy: 0.9760 - val_loss: 0.4866 - val_accuracy: 0.9011
Epoch 216/350
391/391 - 23s - loss: 0.1170 - accuracy: 0.9756 - val_loss: 0.4837 - val_accuracy: 0.9036
Epoch 217/350
391/391 - 23s - loss: 0.1151 - accuracy: 0.9757 - val_loss: 0.4898 - val_accuracy: 0.9018
Epoch 218/350
391/391 - 23s - loss: 0.1161 - accuracy: 0.9748 - val_loss: 0.4856 - val_accuracy: 0.9015
Epoch 219/350
391/391 - 23s - loss: 0.1157 - accuracy: 0.9741 - val_loss: 0.4988 - val_accuracy: 0.9028
Epoch 220/350
391/391 - 23s - loss: 0.1136 - accuracy: 0.9762 - val_loss: 0.4934 - val_accuracy: 0.9024
Epoch 221/350
391/391 - 23s - loss: 0.1164 - accuracy: 0.9751 - val_loss: 0.4915 - val_accuracy: 0.9026
Epoch 222/350
391/391 - 23s - loss: 0.1168 - accuracy: 0.9743 - val_loss: 0.4912 - val_accuracy: 0.9024
Epoch 223/350
391/391 - 23s - loss: 0.1158 - accuracy: 0.9753 - val_loss: 0.4885 - val_accuracy: 0.9027
Epoch 224/350
391/391 - 23s - loss: 0.1151 - accuracy: 0.9753 - val_loss: 0.4956 - val_accuracy: 0.9035
Epoch 225/350
391/391 - 23s - loss: 0.1125 - accuracy: 0.9760 - val_loss: 0.4997 - val_accuracy: 0.9013
Epoch 226/350
391/391 - 23s - loss: 0.1141 - accuracy: 0.9759 - val_loss: 0.5018 - val_accuracy: 0.9016
Epoch 227/350
391/391 - 23s - loss: 0.1131 - accuracy: 0.9762 - val_loss: 0.4909 - val_accuracy: 0.9049
Epoch 228/350
391/391 - 23s - loss: 0.1141 - accuracy: 0.9752 - val_loss: 0.4907 - val_accuracy: 0.9044
Epoch 229/350
391/391 - 23s - loss: 0.1092 - accuracy: 0.9775 - val_loss: 0.5056 - val_accuracy: 0.9036
Epoch 230/350
391/391 - 23s - loss: 0.1129 - accuracy: 0.9767 - val_loss: 0.4931 - val_accuracy: 0.9027
Epoch 231/350
391/391 - 23s - loss: 0.1129 - accuracy: 0.9767 - val_loss: 0.4915 - val_accuracy: 0.9036
Epoch 232/350
391/391 - 23s - loss: 0.1115 - accuracy: 0.9774 - val_loss: 0.5061 - val_accuracy: 0.9017
Epoch 233/350
391/391 - 23s - loss: 0.1110 - accuracy: 0.9765 - val_loss: 0.5028 - val_accuracy: 0.9016
Epoch 234/350
391/391 - 23s - loss: 0.1123 - accuracy: 0.9769 - val_loss: 0.5100 - val_accuracy: 0.9003
Epoch 235/350
391/391 - 23s - loss: 0.1121 - accuracy: 0.9764 - val_loss: 0.4934 - val_accuracy: 0.9034
Epoch 236/350
391/391 - 23s - loss: 0.1093 - accuracy: 0.9778 - val_loss: 0.5155 - val_accuracy: 0.9018
Epoch 237/350
391/391 - 23s - loss: 0.1101 - accuracy: 0.9774 - val_loss: 0.5004 - val_accuracy: 0.9024
Epoch 238/350
391/391 - 23s - loss: 0.1106 - accuracy: 0.9770 - val_loss: 0.5000 - val_accuracy: 0.9029
Epoch 239/350
391/391 - 23s - loss: 0.1076 - accuracy: 0.9787 - val_loss: 0.5160 - val_accuracy: 0.9019
Epoch 240/350
391/391 - 23s - loss: 0.1081 - accuracy: 0.9781 - val_loss: 0.5068 - val_accuracy: 0.9025
Epoch 241/350
391/391 - 23s - loss: 0.1109 - accuracy: 0.9761 - val_loss: 0.5060 - val_accuracy: 0.9009
Epoch 242/350
391/391 - 23s - loss: 0.1086 - accuracy: 0.9785 - val_loss: 0.5106 - val_accuracy: 0.9014
Epoch 243/350
391/391 - 23s - loss: 0.1081 - accuracy: 0.9770 - val_loss: 0.5043 - val_accuracy: 0.9027
Epoch 244/350
391/391 - 23s - loss: 0.1083 - accuracy: 0.9783 - val_loss: 0.5068 - val_accuracy: 0.9038
Epoch 245/350
391/391 - 23s - loss: 0.1101 - accuracy: 0.9775 - val_loss: 0.5031 - val_accuracy: 0.9017
Epoch 246/350
391/391 - 23s - loss: 0.1106 - accuracy: 0.9771 - val_loss: 0.5162 - val_accuracy: 0.9013
Epoch 247/350
391/391 - 23s - loss: 0.1093 - accuracy: 0.9766 - val_loss: 0.5084 - val_accuracy: 0.9009
Epoch 248/350
391/391 - 23s - loss: 0.1088 - accuracy: 0.9782 - val_loss: 0.5039 - val_accuracy: 0.9034
Epoch 249/350
391/391 - 23s - loss: 0.1067 - accuracy: 0.9782 - val_loss: 0.5013 - val_accuracy: 0.9021
Epoch 250/350


Snapshot weight 8 shuffle 0 at epoch 250
Layer 11
Getting activations...


391/391 - 23s - loss: 0.1066 - accuracy: 0.9782 - val_loss: 0.5072 - val_accuracy: 0.9039
Epoch 251/350
391/391 - 23s - loss: 0.1067 - accuracy: 0.9782 - val_loss: 0.5017 - val_accuracy: 0.9038
Epoch 252/350
391/391 - 23s - loss: 0.1058 - accuracy: 0.9788 - val_loss: 0.5022 - val_accuracy: 0.9031
Epoch 253/350
391/391 - 23s - loss: 0.1082 - accuracy: 0.9779 - val_loss: 0.5023 - val_accuracy: 0.9027
Epoch 254/350
391/391 - 23s - loss: 0.1053 - accuracy: 0.9789 - val_loss: 0.5012 - val_accuracy: 0.9033
Epoch 255/350
391/391 - 23s - loss: 0.1033 - accuracy: 0.9796 - val_loss: 0.5035 - val_accuracy: 0.9030
Epoch 256/350
391/391 - 23s - loss: 0.1073 - accuracy: 0.9781 - val_loss: 0.5033 - val_accuracy: 0.9029
Epoch 257/350
391/391 - 23s - loss: 0.1043 - accuracy: 0.9789 - val_loss: 0.5037 - val_accuracy: 0.9036
Epoch 258/350
391/391 - 23s - loss: 0.1031 - accuracy: 0.9800 - val_loss: 0.5059 - val_accuracy: 0.9032
Epoch 259/350
391/391 - 23s - loss: 0.1035 - accuracy: 0.9798 - val_loss: 0.5069 - val_accuracy: 0.9022
Epoch 260/350
391/391 - 23s - loss: 0.1055 - accuracy: 0.9790 - val_loss: 0.5044 - val_accuracy: 0.9036
Epoch 261/350
391/391 - 23s - loss: 0.1033 - accuracy: 0.9804 - val_loss: 0.5058 - val_accuracy: 0.9039
Epoch 262/350
391/391 - 23s - loss: 0.1042 - accuracy: 0.9793 - val_loss: 0.5046 - val_accuracy: 0.9042
Epoch 263/350
391/391 - 23s - loss: 0.1033 - accuracy: 0.9795 - val_loss: 0.5044 - val_accuracy: 0.9031
Epoch 264/350
391/391 - 23s - loss: 0.1050 - accuracy: 0.9796 - val_loss: 0.5050 - val_accuracy: 0.9033
Epoch 265/350
391/391 - 23s - loss: 0.1038 - accuracy: 0.9791 - val_loss: 0.5095 - val_accuracy: 0.9023
Epoch 266/350
391/391 - 23s - loss: 0.1054 - accuracy: 0.9790 - val_loss: 0.5058 - val_accuracy: 0.9039
Epoch 267/350
391/391 - 23s - loss: 0.1041 - accuracy: 0.9797 - val_loss: 0.5080 - val_accuracy: 0.9034
Epoch 268/350
391/391 - 23s - loss: 0.1037 - accuracy: 0.9796 - val_loss: 0.5081 - val_accuracy: 0.9035
Epoch 269/350
391/391 - 23s - loss: 0.1066 - accuracy: 0.9786 - val_loss: 0.5063 - val_accuracy: 0.9037
Epoch 270/350
391/391 - 23s - loss: 0.1045 - accuracy: 0.9794 - val_loss: 0.5054 - val_accuracy: 0.9043
Epoch 271/350
391/391 - 23s - loss: 0.1043 - accuracy: 0.9787 - val_loss: 0.5067 - val_accuracy: 0.9030
Epoch 272/350
391/391 - 23s - loss: 0.1032 - accuracy: 0.9797 - val_loss: 0.5070 - val_accuracy: 0.9041
Epoch 273/350
391/391 - 23s - loss: 0.1037 - accuracy: 0.9798 - val_loss: 0.5065 - val_accuracy: 0.9034
Epoch 274/350
391/391 - 23s - loss: 0.1042 - accuracy: 0.9790 - val_loss: 0.5085 - val_accuracy: 0.9027
Epoch 275/350
391/391 - 23s - loss: 0.1035 - accuracy: 0.9792 - val_loss: 0.5093 - val_accuracy: 0.9033
Epoch 276/350
391/391 - 23s - loss: 0.1024 - accuracy: 0.9796 - val_loss: 0.5116 - val_accuracy: 0.9038
Epoch 277/350
391/391 - 23s - loss: 0.1045 - accuracy: 0.9794 - val_loss: 0.5083 - val_accuracy: 0.9039
Epoch 278/350
391/391 - 23s - loss: 0.1033 - accuracy: 0.9799 - val_loss: 0.5088 - val_accuracy: 0.9029
Epoch 279/350
391/391 - 23s - loss: 0.1021 - accuracy: 0.9805 - val_loss: 0.5094 - val_accuracy: 0.9031
Epoch 280/350
391/391 - 23s - loss: 0.1035 - accuracy: 0.9798 - val_loss: 0.5077 - val_accuracy: 0.9032
Epoch 281/350
391/391 - 23s - loss: 0.1034 - accuracy: 0.9796 - val_loss: 0.5075 - val_accuracy: 0.9040
Epoch 282/350
391/391 - 23s - loss: 0.1033 - accuracy: 0.9795 - val_loss: 0.5071 - val_accuracy: 0.9033
Epoch 283/350
391/391 - 23s - loss: 0.1034 - accuracy: 0.9801 - val_loss: 0.5091 - val_accuracy: 0.9021
Epoch 284/350
391/391 - 23s - loss: 0.1043 - accuracy: 0.9790 - val_loss: 0.5089 - val_accuracy: 0.9033
Epoch 285/350
391/391 - 23s - loss: 0.1026 - accuracy: 0.9801 - val_loss: 0.5083 - val_accuracy: 0.9035
Epoch 286/350
391/391 - 23s - loss: 0.1051 - accuracy: 0.9795 - val_loss: 0.5086 - val_accuracy: 0.9031
Epoch 287/350
391/391 - 23s - loss: 0.1064 - accuracy: 0.9791 - val_loss: 0.5069 - val_accuracy: 0.9030
Epoch 288/350
391/391 - 23s - loss: 0.1043 - accuracy: 0.9786 - val_loss: 0.5056 - val_accuracy: 0.9022
Epoch 289/350
391/391 - 23s - loss: 0.1034 - accuracy: 0.9799 - val_loss: 0.5081 - val_accuracy: 0.9029
Epoch 290/350
391/391 - 23s - loss: 0.1039 - accuracy: 0.9794 - val_loss: 0.5088 - val_accuracy: 0.9028
Epoch 291/350
391/391 - 23s - loss: 0.1022 - accuracy: 0.9807 - val_loss: 0.5083 - val_accuracy: 0.9028
Epoch 292/350
391/391 - 23s - loss: 0.1045 - accuracy: 0.9793 - val_loss: 0.5091 - val_accuracy: 0.9029
Epoch 293/350
391/391 - 23s - loss: 0.1034 - accuracy: 0.9793 - val_loss: 0.5083 - val_accuracy: 0.9040
Epoch 294/350
391/391 - 23s - loss: 0.1044 - accuracy: 0.9798 - val_loss: 0.5061 - val_accuracy: 0.9033
Epoch 295/350
391/391 - 23s - loss: 0.1024 - accuracy: 0.9806 - val_loss: 0.5098 - val_accuracy: 0.9032
Epoch 296/350
391/391 - 23s - loss: 0.1041 - accuracy: 0.9789 - val_loss: 0.5100 - val_accuracy: 0.9036
Epoch 297/350
391/391 - 23s - loss: 0.1043 - accuracy: 0.9793 - val_loss: 0.5106 - val_accuracy: 0.9036
Epoch 298/350
391/391 - 23s - loss: 0.1051 - accuracy: 0.9786 - val_loss: 0.5090 - val_accuracy: 0.9034
Epoch 299/350
391/391 - 23s - loss: 0.1051 - accuracy: 0.9790 - val_loss: 0.5091 - val_accuracy: 0.9028
Epoch 300/350


Snapshot weight 8 shuffle 0 at epoch 300
Layer 11
Getting activations...


391/391 - 24s - loss: 0.1024 - accuracy: 0.9802 - val_loss: 0.5079 - val_accuracy: 0.9031
Epoch 301/350
391/391 - 23s - loss: 0.1033 - accuracy: 0.9794 - val_loss: 0.5082 - val_accuracy: 0.9025
Epoch 302/350
391/391 - 23s - loss: 0.1024 - accuracy: 0.9802 - val_loss: 0.5086 - val_accuracy: 0.9031
Epoch 303/350
391/391 - 23s - loss: 0.1021 - accuracy: 0.9808 - val_loss: 0.5088 - val_accuracy: 0.9027
Epoch 304/350
391/391 - 23s - loss: 0.1043 - accuracy: 0.9793 - val_loss: 0.5094 - val_accuracy: 0.9026
Epoch 305/350
391/391 - 23s - loss: 0.1058 - accuracy: 0.9784 - val_loss: 0.5085 - val_accuracy: 0.9029
Epoch 306/350
391/391 - 23s - loss: 0.1037 - accuracy: 0.9797 - val_loss: 0.5088 - val_accuracy: 0.9030
Epoch 307/350
391/391 - 23s - loss: 0.1017 - accuracy: 0.9806 - val_loss: 0.5091 - val_accuracy: 0.9026
Epoch 308/350
391/391 - 23s - loss: 0.1036 - accuracy: 0.9798 - val_loss: 0.5093 - val_accuracy: 0.9028
Epoch 309/350
391/391 - 23s - loss: 0.1023 - accuracy: 0.9797 - val_loss: 0.5091 - val_accuracy: 0.9032
Epoch 310/350
391/391 - 23s - loss: 0.1041 - accuracy: 0.9789 - val_loss: 0.5084 - val_accuracy: 0.9031
Epoch 311/350
391/391 - 23s - loss: 0.1024 - accuracy: 0.9801 - val_loss: 0.5084 - val_accuracy: 0.9030
Epoch 312/350
391/391 - 23s - loss: 0.1051 - accuracy: 0.9793 - val_loss: 0.5082 - val_accuracy: 0.9029
Epoch 313/350
391/391 - 23s - loss: 0.1041 - accuracy: 0.9791 - val_loss: 0.5081 - val_accuracy: 0.9034
Epoch 314/350
391/391 - 23s - loss: 0.1036 - accuracy: 0.9798 - val_loss: 0.5087 - val_accuracy: 0.9030
Epoch 315/350
391/391 - 23s - loss: 0.1046 - accuracy: 0.9795 - val_loss: 0.5086 - val_accuracy: 0.9030
Epoch 316/350
391/391 - 23s - loss: 0.1028 - accuracy: 0.9805 - val_loss: 0.5089 - val_accuracy: 0.9030
Epoch 317/350
391/391 - 23s - loss: 0.1036 - accuracy: 0.9791 - val_loss: 0.5092 - val_accuracy: 0.9027
Epoch 318/350
391/391 - 23s - loss: 0.1017 - accuracy: 0.9808 - val_loss: 0.5091 - val_accuracy: 0.9025
Epoch 319/350
391/391 - 23s - loss: 0.1022 - accuracy: 0.9797 - val_loss: 0.5091 - val_accuracy: 0.9028
Epoch 320/350
391/391 - 23s - loss: 0.1013 - accuracy: 0.9805 - val_loss: 0.5090 - val_accuracy: 0.9031
Epoch 321/350
391/391 - 23s - loss: 0.1021 - accuracy: 0.9799 - val_loss: 0.5091 - val_accuracy: 0.9029
Epoch 322/350
391/391 - 23s - loss: 0.1021 - accuracy: 0.9796 - val_loss: 0.5091 - val_accuracy: 0.9028
Epoch 323/350
391/391 - 23s - loss: 0.1031 - accuracy: 0.9793 - val_loss: 0.5094 - val_accuracy: 0.9025
Epoch 324/350
391/391 - 23s - loss: 0.1011 - accuracy: 0.9800 - val_loss: 0.5090 - val_accuracy: 0.9027
Epoch 325/350
391/391 - 23s - loss: 0.1006 - accuracy: 0.9809 - val_loss: 0.5094 - val_accuracy: 0.9028
Epoch 326/350
391/391 - 23s - loss: 0.1015 - accuracy: 0.9797 - val_loss: 0.5093 - val_accuracy: 0.9028
Epoch 327/350
391/391 - 23s - loss: 0.1038 - accuracy: 0.9798 - val_loss: 0.5093 - val_accuracy: 0.9024
Epoch 328/350
391/391 - 23s - loss: 0.1017 - accuracy: 0.9800 - val_loss: 0.5089 - val_accuracy: 0.9027
Epoch 329/350
391/391 - 23s - loss: 0.1029 - accuracy: 0.9797 - val_loss: 0.5091 - val_accuracy: 0.9023
Epoch 330/350
391/391 - 23s - loss: 0.1014 - accuracy: 0.9799 - val_loss: 0.5092 - val_accuracy: 0.9025
Epoch 331/350
391/391 - 23s - loss: 0.1048 - accuracy: 0.9793 - val_loss: 0.5095 - val_accuracy: 0.9023
Epoch 332/350
391/391 - 23s - loss: 0.1012 - accuracy: 0.9802 - val_loss: 0.5097 - val_accuracy: 0.9022
Epoch 333/350
391/391 - 23s - loss: 0.1017 - accuracy: 0.9800 - val_loss: 0.5097 - val_accuracy: 0.9025
Epoch 334/350
391/391 - 23s - loss: 0.1011 - accuracy: 0.9808 - val_loss: 0.5100 - val_accuracy: 0.9021
Epoch 335/350
391/391 - 23s - loss: 0.1027 - accuracy: 0.9796 - val_loss: 0.5098 - val_accuracy: 0.9024
Epoch 336/350
391/391 - 23s - loss: 0.1032 - accuracy: 0.9801 - val_loss: 0.5097 - val_accuracy: 0.9026
Epoch 337/350
391/391 - 23s - loss: 0.1027 - accuracy: 0.9799 - val_loss: 0.5098 - val_accuracy: 0.9028
Epoch 338/350
391/391 - 23s - loss: 0.1032 - accuracy: 0.9796 - val_loss: 0.5098 - val_accuracy: 0.9026
Epoch 339/350
391/391 - 23s - loss: 0.1036 - accuracy: 0.9791 - val_loss: 0.5094 - val_accuracy: 0.9030
Epoch 340/350
391/391 - 23s - loss: 0.1018 - accuracy: 0.9805 - val_loss: 0.5097 - val_accuracy: 0.9027
Epoch 341/350
391/391 - 23s - loss: 0.1024 - accuracy: 0.9797 - val_loss: 0.5098 - val_accuracy: 0.9028
Epoch 342/350
391/391 - 23s - loss: 0.1020 - accuracy: 0.9798 - val_loss: 0.5099 - val_accuracy: 0.9027
Epoch 343/350
391/391 - 23s - loss: 0.1038 - accuracy: 0.9796 - val_loss: 0.5098 - val_accuracy: 0.9023
Epoch 344/350
391/391 - 23s - loss: 0.1056 - accuracy: 0.9787 - val_loss: 0.5099 - val_accuracy: 0.9027
Epoch 345/350
391/391 - 23s - loss: 0.1040 - accuracy: 0.9799 - val_loss: 0.5093 - val_accuracy: 0.9023
Epoch 346/350
391/391 - 23s - loss: 0.1008 - accuracy: 0.9804 - val_loss: 0.5096 - val_accuracy: 0.9027
Epoch 347/350
391/391 - 23s - loss: 0.1014 - accuracy: 0.9802 - val_loss: 0.5097 - val_accuracy: 0.9026
Epoch 348/350
391/391 - 23s - loss: 0.1016 - accuracy: 0.9794 - val_loss: 0.5095 - val_accuracy: 0.9028
Epoch 349/350
391/391 - 23s - loss: 0.1009 - accuracy: 0.9805 - val_loss: 0.5094 - val_accuracy: 0.9027
Epoch 350/350


Snapshot weight 8 shuffle 0 at epoch 350
Layer 11
Getting activations...


391/391 - 24s - loss: 0.1034 - accuracy: 0.9796 - val_loss: 0.5094 - val_accuracy: 0.9029
/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:493: UserWarning: fill_value is not supported and is always 0 for TensorFlow < 2.4.0.
  return py_builtins.overload_of(f)(*args)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-07-01 20:58:14.852766: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
Saving, final validation acc: 0.902899980545044
