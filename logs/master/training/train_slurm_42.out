2021-07-02 04:30:09.982340: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 04:31:27.287936: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-07-02 04:31:27.327687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:82:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-02 04:31:27.327767: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 04:31:27.370530: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-02 04:31:27.392205: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-02 04:31:27.400775: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-02 04:31:27.445275: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-02 04:31:27.454122: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-02 04:31:27.533055: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 04:31:27.535713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-02 04:31:27.539427: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-02 04:31:27.555934: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599990000 Hz
2021-07-02 04:31:27.556059: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x432f9f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-07-02 04:31:27.556080: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-07-02 04:31:27.687373: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4316ab0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-07-02 04:31:27.687439: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN X (Pascal), Compute Capability 6.1
2021-07-02 04:31:27.693753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:82:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-02 04:31:27.693796: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 04:31:27.693853: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-02 04:31:27.693877: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-02 04:31:27.693898: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-02 04:31:27.693918: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-02 04:31:27.693939: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-02 04:31:27.694575: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 04:31:27.696182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-02 04:31:27.697957: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 04:31:29.487729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-02 04:31:29.487804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-07-02 04:31:29.487818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-07-02 04:31:29.496028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11228 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:82:00.0, compute capability: 6.1)
2021-07-02 04:31:35.407625: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 04:31:39.092034: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
Using model index: 42
Making train data...
GCN...
ZCA...
Done!
Making test data...
Done!
Epoch 1/350


Snapshot weight 2 shuffle 4 at epoch 1
Layer 11
Getting activations...


391/391 - 25s - loss: 2.3155 - accuracy: 0.1181 - val_loss: 2.2981 - val_accuracy: 0.1089
Epoch 2/350


Snapshot weight 2 shuffle 4 at epoch 2
Layer 11
Getting activations...


391/391 - 26s - loss: 2.2871 - accuracy: 0.1567 - val_loss: 2.2309 - val_accuracy: 0.2302
Epoch 3/350


Snapshot weight 2 shuffle 4 at epoch 3
Layer 11
Getting activations...


391/391 - 26s - loss: 2.1791 - accuracy: 0.2297 - val_loss: 1.9249 - val_accuracy: 0.3208
Epoch 4/350


Snapshot weight 2 shuffle 4 at epoch 4
Layer 11
Getting activations...


391/391 - 25s - loss: 1.8060 - accuracy: 0.3492 - val_loss: 1.5553 - val_accuracy: 0.4344
Epoch 5/350


Snapshot weight 2 shuffle 4 at epoch 5
Layer 11
Getting activations...


391/391 - 26s - loss: 1.4970 - accuracy: 0.4661 - val_loss: 1.2952 - val_accuracy: 0.5409
Epoch 6/350


Snapshot weight 2 shuffle 4 at epoch 6
Layer 11
Getting activations...


391/391 - 26s - loss: 1.3329 - accuracy: 0.5311 - val_loss: 1.2718 - val_accuracy: 0.5643
Epoch 7/350


Snapshot weight 2 shuffle 4 at epoch 7
Layer 11
Getting activations...


391/391 - 26s - loss: 1.2308 - accuracy: 0.5710 - val_loss: 1.1684 - val_accuracy: 0.6013
Epoch 8/350


Snapshot weight 2 shuffle 4 at epoch 8
Layer 11
Getting activations...


391/391 - 26s - loss: 1.1540 - accuracy: 0.6002 - val_loss: 1.1561 - val_accuracy: 0.6121
Epoch 9/350


Snapshot weight 2 shuffle 4 at epoch 9
Layer 11
Getting activations...


391/391 - 26s - loss: 1.1037 - accuracy: 0.6171 - val_loss: 1.0195 - val_accuracy: 0.6544
Epoch 10/350


Snapshot weight 2 shuffle 4 at epoch 10
Layer 11
Getting activations...


391/391 - 25s - loss: 1.0384 - accuracy: 0.6424 - val_loss: 0.9985 - val_accuracy: 0.6578
Epoch 11/350
391/391 - 25s - loss: 1.0005 - accuracy: 0.6568 - val_loss: 0.9212 - val_accuracy: 0.6814
Epoch 12/350
391/391 - 25s - loss: 0.9558 - accuracy: 0.6696 - val_loss: 0.9451 - val_accuracy: 0.6805
Epoch 13/350
391/391 - 25s - loss: 0.9123 - accuracy: 0.6870 - val_loss: 0.8912 - val_accuracy: 0.6987
Epoch 14/350
391/391 - 25s - loss: 0.8893 - accuracy: 0.6968 - val_loss: 0.9540 - val_accuracy: 0.6795
Epoch 15/350
391/391 - 25s - loss: 0.8504 - accuracy: 0.7097 - val_loss: 0.8172 - val_accuracy: 0.7240
Epoch 16/350
391/391 - 25s - loss: 0.8336 - accuracy: 0.7147 - val_loss: 0.7537 - val_accuracy: 0.7473
Epoch 17/350
391/391 - 25s - loss: 0.7903 - accuracy: 0.7322 - val_loss: 0.7350 - val_accuracy: 0.7489
Epoch 18/350
391/391 - 25s - loss: 0.7710 - accuracy: 0.7399 - val_loss: 0.6963 - val_accuracy: 0.7626
Epoch 19/350
391/391 - 25s - loss: 0.7418 - accuracy: 0.7509 - val_loss: 0.6616 - val_accuracy: 0.7795
Epoch 20/350
391/391 - 25s - loss: 0.7137 - accuracy: 0.7611 - val_loss: 0.6455 - val_accuracy: 0.7856
Epoch 21/350
391/391 - 25s - loss: 0.7017 - accuracy: 0.7645 - val_loss: 0.6856 - val_accuracy: 0.7704
Epoch 22/350
391/391 - 25s - loss: 0.6814 - accuracy: 0.7736 - val_loss: 0.6485 - val_accuracy: 0.7869
Epoch 23/350
391/391 - 25s - loss: 0.6590 - accuracy: 0.7790 - val_loss: 0.6446 - val_accuracy: 0.7898
Epoch 24/350
391/391 - 25s - loss: 0.6463 - accuracy: 0.7839 - val_loss: 0.6031 - val_accuracy: 0.8000
Epoch 25/350
391/391 - 25s - loss: 0.6290 - accuracy: 0.7894 - val_loss: 0.6002 - val_accuracy: 0.8034
Epoch 26/350
391/391 - 25s - loss: 0.6187 - accuracy: 0.7945 - val_loss: 0.5756 - val_accuracy: 0.8083
Epoch 27/350
391/391 - 25s - loss: 0.6012 - accuracy: 0.8021 - val_loss: 0.6221 - val_accuracy: 0.8028
Epoch 28/350
391/391 - 25s - loss: 0.5864 - accuracy: 0.8060 - val_loss: 0.5974 - val_accuracy: 0.8124
Epoch 29/350
391/391 - 25s - loss: 0.5702 - accuracy: 0.8133 - val_loss: 0.5689 - val_accuracy: 0.8202
Epoch 30/350
391/391 - 25s - loss: 0.5646 - accuracy: 0.8146 - val_loss: 0.5726 - val_accuracy: 0.8164
Epoch 31/350
391/391 - 25s - loss: 0.5548 - accuracy: 0.8179 - val_loss: 0.5189 - val_accuracy: 0.8298
Epoch 32/350
391/391 - 25s - loss: 0.5383 - accuracy: 0.8232 - val_loss: 0.6054 - val_accuracy: 0.8109
Epoch 33/350
391/391 - 25s - loss: 0.5319 - accuracy: 0.8267 - val_loss: 0.4943 - val_accuracy: 0.8407
Epoch 34/350
391/391 - 25s - loss: 0.5189 - accuracy: 0.8297 - val_loss: 0.5351 - val_accuracy: 0.8255
Epoch 35/350
391/391 - 25s - loss: 0.5166 - accuracy: 0.8303 - val_loss: 0.5073 - val_accuracy: 0.8352
Epoch 36/350
391/391 - 25s - loss: 0.4983 - accuracy: 0.8349 - val_loss: 0.4791 - val_accuracy: 0.8488
Epoch 37/350
391/391 - 25s - loss: 0.4967 - accuracy: 0.8390 - val_loss: 0.5164 - val_accuracy: 0.8344
Epoch 38/350
391/391 - 25s - loss: 0.4816 - accuracy: 0.8423 - val_loss: 0.5206 - val_accuracy: 0.8366
Epoch 39/350
391/391 - 26s - loss: 0.4840 - accuracy: 0.8422 - val_loss: 0.4959 - val_accuracy: 0.8435
Epoch 40/350
391/391 - 25s - loss: 0.4697 - accuracy: 0.8475 - val_loss: 0.4896 - val_accuracy: 0.8442
Epoch 41/350
391/391 - 25s - loss: 0.4669 - accuracy: 0.8488 - val_loss: 0.4981 - val_accuracy: 0.8390
Epoch 42/350
391/391 - 25s - loss: 0.4616 - accuracy: 0.8495 - val_loss: 0.5424 - val_accuracy: 0.8299
Epoch 43/350
391/391 - 25s - loss: 0.4520 - accuracy: 0.8550 - val_loss: 0.4984 - val_accuracy: 0.8473
Epoch 44/350
391/391 - 25s - loss: 0.4471 - accuracy: 0.8546 - val_loss: 0.4879 - val_accuracy: 0.8459
Epoch 45/350
391/391 - 25s - loss: 0.4410 - accuracy: 0.8566 - val_loss: 0.4639 - val_accuracy: 0.8522
Epoch 46/350
391/391 - 25s - loss: 0.4348 - accuracy: 0.8592 - val_loss: 0.5042 - val_accuracy: 0.8478
Epoch 47/350
391/391 - 25s - loss: 0.4263 - accuracy: 0.8615 - val_loss: 0.4616 - val_accuracy: 0.8594
Epoch 48/350
391/391 - 25s - loss: 0.4228 - accuracy: 0.8634 - val_loss: 0.4556 - val_accuracy: 0.8574
Epoch 49/350
391/391 - 25s - loss: 0.4160 - accuracy: 0.8664 - val_loss: 0.4583 - val_accuracy: 0.8592
Epoch 50/350


Snapshot weight 2 shuffle 4 at epoch 50
Layer 11
Getting activations...


391/391 - 26s - loss: 0.4030 - accuracy: 0.8699 - val_loss: 0.4614 - val_accuracy: 0.8599
Epoch 51/350
391/391 - 25s - loss: 0.4061 - accuracy: 0.8686 - val_loss: 0.4626 - val_accuracy: 0.8625
Epoch 52/350
391/391 - 25s - loss: 0.4052 - accuracy: 0.8689 - val_loss: 0.4677 - val_accuracy: 0.8589
Epoch 53/350
391/391 - 25s - loss: 0.4037 - accuracy: 0.8717 - val_loss: 0.4566 - val_accuracy: 0.8584
Epoch 54/350
391/391 - 25s - loss: 0.3907 - accuracy: 0.8745 - val_loss: 0.4272 - val_accuracy: 0.8671
Epoch 55/350
391/391 - 25s - loss: 0.3929 - accuracy: 0.8726 - val_loss: 0.4479 - val_accuracy: 0.8633
Epoch 56/350
391/391 - 25s - loss: 0.3866 - accuracy: 0.8766 - val_loss: 0.4491 - val_accuracy: 0.8663
Epoch 57/350
391/391 - 25s - loss: 0.3731 - accuracy: 0.8803 - val_loss: 0.4833 - val_accuracy: 0.8538
Epoch 58/350
391/391 - 25s - loss: 0.3759 - accuracy: 0.8792 - val_loss: 0.4355 - val_accuracy: 0.8677
Epoch 59/350
391/391 - 25s - loss: 0.3673 - accuracy: 0.8825 - val_loss: 0.5053 - val_accuracy: 0.8478
Epoch 60/350
391/391 - 25s - loss: 0.3685 - accuracy: 0.8844 - val_loss: 0.4483 - val_accuracy: 0.8672
Epoch 61/350
391/391 - 26s - loss: 0.3611 - accuracy: 0.8848 - val_loss: 0.4838 - val_accuracy: 0.8592
Epoch 62/350
391/391 - 25s - loss: 0.3594 - accuracy: 0.8864 - val_loss: 0.4564 - val_accuracy: 0.8609
Epoch 63/350
391/391 - 25s - loss: 0.3530 - accuracy: 0.8877 - val_loss: 0.4391 - val_accuracy: 0.8681
Epoch 64/350
391/391 - 25s - loss: 0.3507 - accuracy: 0.8882 - val_loss: 0.4190 - val_accuracy: 0.8783
Epoch 65/350
391/391 - 25s - loss: 0.3406 - accuracy: 0.8908 - val_loss: 0.4283 - val_accuracy: 0.8753
Epoch 66/350
391/391 - 25s - loss: 0.3421 - accuracy: 0.8920 - val_loss: 0.4221 - val_accuracy: 0.8776
Epoch 67/350
391/391 - 25s - loss: 0.3428 - accuracy: 0.8912 - val_loss: 0.4463 - val_accuracy: 0.8734
Epoch 68/350
391/391 - 25s - loss: 0.3409 - accuracy: 0.8914 - val_loss: 0.4326 - val_accuracy: 0.8752
Epoch 69/350
391/391 - 25s - loss: 0.3374 - accuracy: 0.8938 - val_loss: 0.4622 - val_accuracy: 0.8635
Epoch 70/350
391/391 - 25s - loss: 0.3303 - accuracy: 0.8960 - val_loss: 0.4360 - val_accuracy: 0.8762
Epoch 71/350
391/391 - 25s - loss: 0.3301 - accuracy: 0.8955 - val_loss: 0.4173 - val_accuracy: 0.8803
Epoch 72/350
391/391 - 25s - loss: 0.3264 - accuracy: 0.8976 - val_loss: 0.4118 - val_accuracy: 0.8808
Epoch 73/350
391/391 - 25s - loss: 0.3225 - accuracy: 0.8983 - val_loss: 0.4644 - val_accuracy: 0.8731
Epoch 74/350
391/391 - 25s - loss: 0.3205 - accuracy: 0.8994 - val_loss: 0.4191 - val_accuracy: 0.8798
Epoch 75/350
391/391 - 25s - loss: 0.3169 - accuracy: 0.8999 - val_loss: 0.4388 - val_accuracy: 0.8706
Epoch 76/350
391/391 - 25s - loss: 0.3160 - accuracy: 0.9023 - val_loss: 0.4363 - val_accuracy: 0.8718
Epoch 77/350
391/391 - 25s - loss: 0.3108 - accuracy: 0.9030 - val_loss: 0.4339 - val_accuracy: 0.8738
Epoch 78/350
391/391 - 25s - loss: 0.3037 - accuracy: 0.9050 - val_loss: 0.4396 - val_accuracy: 0.8796
Epoch 79/350
391/391 - 25s - loss: 0.3080 - accuracy: 0.9044 - val_loss: 0.4281 - val_accuracy: 0.8784
Epoch 80/350
391/391 - 25s - loss: 0.3101 - accuracy: 0.9035 - val_loss: 0.4106 - val_accuracy: 0.8846
Epoch 81/350
391/391 - 25s - loss: 0.2967 - accuracy: 0.9068 - val_loss: 0.4222 - val_accuracy: 0.8761
Epoch 82/350
391/391 - 25s - loss: 0.3001 - accuracy: 0.9079 - val_loss: 0.4229 - val_accuracy: 0.8848
Epoch 83/350
391/391 - 25s - loss: 0.2992 - accuracy: 0.9063 - val_loss: 0.4166 - val_accuracy: 0.8806
Epoch 84/350
391/391 - 25s - loss: 0.2921 - accuracy: 0.9099 - val_loss: 0.4241 - val_accuracy: 0.8792
Epoch 85/350
391/391 - 25s - loss: 0.2916 - accuracy: 0.9099 - val_loss: 0.4190 - val_accuracy: 0.8856
Epoch 86/350
391/391 - 25s - loss: 0.2907 - accuracy: 0.9110 - val_loss: 0.4089 - val_accuracy: 0.8854
Epoch 87/350
391/391 - 25s - loss: 0.2854 - accuracy: 0.9119 - val_loss: 0.4420 - val_accuracy: 0.8796
Epoch 88/350
391/391 - 25s - loss: 0.2816 - accuracy: 0.9135 - val_loss: 0.4536 - val_accuracy: 0.8863
Epoch 89/350
391/391 - 25s - loss: 0.2824 - accuracy: 0.9135 - val_loss: 0.4157 - val_accuracy: 0.8865
Epoch 90/350
391/391 - 25s - loss: 0.2827 - accuracy: 0.9138 - val_loss: 0.4226 - val_accuracy: 0.8845
Epoch 91/350
391/391 - 25s - loss: 0.2775 - accuracy: 0.9146 - val_loss: 0.4159 - val_accuracy: 0.8861
Epoch 92/350
391/391 - 25s - loss: 0.2801 - accuracy: 0.9131 - val_loss: 0.4289 - val_accuracy: 0.8814
Epoch 93/350
391/391 - 25s - loss: 0.2720 - accuracy: 0.9162 - val_loss: 0.4447 - val_accuracy: 0.8812
Epoch 94/350
391/391 - 25s - loss: 0.2719 - accuracy: 0.9169 - val_loss: 0.4256 - val_accuracy: 0.8863
Epoch 95/350
391/391 - 25s - loss: 0.2774 - accuracy: 0.9155 - val_loss: 0.4144 - val_accuracy: 0.8852
Epoch 96/350
391/391 - 26s - loss: 0.2703 - accuracy: 0.9188 - val_loss: 0.4539 - val_accuracy: 0.8774
Epoch 97/350
391/391 - 25s - loss: 0.2648 - accuracy: 0.9185 - val_loss: 0.4310 - val_accuracy: 0.8832
Epoch 98/350
391/391 - 25s - loss: 0.2665 - accuracy: 0.9192 - val_loss: 0.4180 - val_accuracy: 0.8904
Epoch 99/350
391/391 - 25s - loss: 0.2657 - accuracy: 0.9204 - val_loss: 0.4110 - val_accuracy: 0.8871
Epoch 100/350


Snapshot weight 2 shuffle 4 at epoch 100
Layer 11
Getting activations...


391/391 - 26s - loss: 0.2650 - accuracy: 0.9195 - val_loss: 0.4185 - val_accuracy: 0.8880
Epoch 101/350
391/391 - 25s - loss: 0.2594 - accuracy: 0.9216 - val_loss: 0.4082 - val_accuracy: 0.8875
Epoch 102/350
391/391 - 25s - loss: 0.2599 - accuracy: 0.9212 - val_loss: 0.4111 - val_accuracy: 0.8892
Epoch 103/350
391/391 - 25s - loss: 0.2540 - accuracy: 0.9240 - val_loss: 0.4481 - val_accuracy: 0.8843
Epoch 104/350
391/391 - 25s - loss: 0.2555 - accuracy: 0.9220 - val_loss: 0.4159 - val_accuracy: 0.8902
Epoch 105/350
391/391 - 25s - loss: 0.2485 - accuracy: 0.9265 - val_loss: 0.4263 - val_accuracy: 0.8856
Epoch 106/350
391/391 - 25s - loss: 0.2532 - accuracy: 0.9226 - val_loss: 0.4188 - val_accuracy: 0.8895
Epoch 107/350
391/391 - 25s - loss: 0.2499 - accuracy: 0.9247 - val_loss: 0.4169 - val_accuracy: 0.8884
Epoch 108/350
391/391 - 25s - loss: 0.2460 - accuracy: 0.9261 - val_loss: 0.4427 - val_accuracy: 0.8871
Epoch 109/350
391/391 - 25s - loss: 0.2501 - accuracy: 0.9251 - val_loss: 0.3959 - val_accuracy: 0.8935
Epoch 110/350
391/391 - 25s - loss: 0.2399 - accuracy: 0.9287 - val_loss: 0.4148 - val_accuracy: 0.8900
Epoch 111/350
391/391 - 25s - loss: 0.2420 - accuracy: 0.9283 - val_loss: 0.4233 - val_accuracy: 0.8880
Epoch 112/350
391/391 - 25s - loss: 0.2462 - accuracy: 0.9265 - val_loss: 0.4260 - val_accuracy: 0.8915
Epoch 113/350
391/391 - 25s - loss: 0.2374 - accuracy: 0.9292 - val_loss: 0.4323 - val_accuracy: 0.8878
Epoch 114/350
391/391 - 25s - loss: 0.2395 - accuracy: 0.9286 - val_loss: 0.4188 - val_accuracy: 0.8936
Epoch 115/350
391/391 - 25s - loss: 0.2375 - accuracy: 0.9298 - val_loss: 0.4467 - val_accuracy: 0.8818
Epoch 116/350
391/391 - 25s - loss: 0.2346 - accuracy: 0.9308 - val_loss: 0.4520 - val_accuracy: 0.8885
Epoch 117/350
391/391 - 25s - loss: 0.2324 - accuracy: 0.9305 - val_loss: 0.4429 - val_accuracy: 0.8875
Epoch 118/350
391/391 - 25s - loss: 0.2356 - accuracy: 0.9317 - val_loss: 0.4607 - val_accuracy: 0.8807
Epoch 119/350
391/391 - 25s - loss: 0.2355 - accuracy: 0.9313 - val_loss: 0.4261 - val_accuracy: 0.8891
Epoch 120/350
391/391 - 25s - loss: 0.2304 - accuracy: 0.9320 - val_loss: 0.4554 - val_accuracy: 0.8864
Epoch 121/350
391/391 - 25s - loss: 0.2286 - accuracy: 0.9335 - val_loss: 0.4228 - val_accuracy: 0.8909
Epoch 122/350
391/391 - 25s - loss: 0.2214 - accuracy: 0.9353 - val_loss: 0.4323 - val_accuracy: 0.8890
Epoch 123/350
391/391 - 25s - loss: 0.2221 - accuracy: 0.9353 - val_loss: 0.4286 - val_accuracy: 0.8901
Epoch 124/350
391/391 - 25s - loss: 0.2221 - accuracy: 0.9364 - val_loss: 0.4351 - val_accuracy: 0.8901
Epoch 125/350
391/391 - 25s - loss: 0.2265 - accuracy: 0.9344 - val_loss: 0.4606 - val_accuracy: 0.8885
Epoch 126/350
391/391 - 25s - loss: 0.2206 - accuracy: 0.9364 - val_loss: 0.4707 - val_accuracy: 0.8885
Epoch 127/350
391/391 - 25s - loss: 0.2232 - accuracy: 0.9348 - val_loss: 0.4270 - val_accuracy: 0.8924
Epoch 128/350
391/391 - 25s - loss: 0.2185 - accuracy: 0.9366 - val_loss: 0.4273 - val_accuracy: 0.8904
Epoch 129/350
391/391 - 25s - loss: 0.2208 - accuracy: 0.9370 - val_loss: 0.4312 - val_accuracy: 0.8910
Epoch 130/350
391/391 - 25s - loss: 0.2219 - accuracy: 0.9369 - val_loss: 0.4494 - val_accuracy: 0.8884
Epoch 131/350
391/391 - 25s - loss: 0.2216 - accuracy: 0.9353 - val_loss: 0.4338 - val_accuracy: 0.8927
Epoch 132/350
391/391 - 25s - loss: 0.2178 - accuracy: 0.9369 - val_loss: 0.4412 - val_accuracy: 0.8928
Epoch 133/350
391/391 - 25s - loss: 0.2125 - accuracy: 0.9394 - val_loss: 0.4445 - val_accuracy: 0.8901
Epoch 134/350
391/391 - 25s - loss: 0.2131 - accuracy: 0.9397 - val_loss: 0.4568 - val_accuracy: 0.8902
Epoch 135/350
391/391 - 25s - loss: 0.2176 - accuracy: 0.9369 - val_loss: 0.4797 - val_accuracy: 0.8885
Epoch 136/350
391/391 - 25s - loss: 0.2128 - accuracy: 0.9389 - val_loss: 0.4297 - val_accuracy: 0.8963
Epoch 137/350
391/391 - 25s - loss: 0.2146 - accuracy: 0.9374 - val_loss: 0.4500 - val_accuracy: 0.8945
Epoch 138/350
391/391 - 25s - loss: 0.2154 - accuracy: 0.9386 - val_loss: 0.4423 - val_accuracy: 0.8928
Epoch 139/350
391/391 - 25s - loss: 0.2082 - accuracy: 0.9414 - val_loss: 0.4628 - val_accuracy: 0.8900
Epoch 140/350
391/391 - 25s - loss: 0.2112 - accuracy: 0.9393 - val_loss: 0.4232 - val_accuracy: 0.8984
Epoch 141/350
391/391 - 25s - loss: 0.2093 - accuracy: 0.9405 - val_loss: 0.4313 - val_accuracy: 0.8963
Epoch 142/350
391/391 - 25s - loss: 0.2103 - accuracy: 0.9393 - val_loss: 0.4686 - val_accuracy: 0.8929
Epoch 143/350
391/391 - 25s - loss: 0.2064 - accuracy: 0.9422 - val_loss: 0.4374 - val_accuracy: 0.8950
Epoch 144/350
391/391 - 25s - loss: 0.2063 - accuracy: 0.9411 - val_loss: 0.4453 - val_accuracy: 0.8886
Epoch 145/350
391/391 - 25s - loss: 0.2020 - accuracy: 0.9418 - val_loss: 0.4293 - val_accuracy: 0.8996
Epoch 146/350
391/391 - 25s - loss: 0.2048 - accuracy: 0.9423 - val_loss: 0.4293 - val_accuracy: 0.8938
Epoch 147/350
391/391 - 25s - loss: 0.2029 - accuracy: 0.9435 - val_loss: 0.4660 - val_accuracy: 0.8903
Epoch 148/350
391/391 - 25s - loss: 0.2010 - accuracy: 0.9430 - val_loss: 0.4925 - val_accuracy: 0.8841
Epoch 149/350
391/391 - 25s - loss: 0.2008 - accuracy: 0.9438 - val_loss: 0.4515 - val_accuracy: 0.8915
Epoch 150/350


Snapshot weight 2 shuffle 4 at epoch 150
Layer 11
Getting activations...


391/391 - 25s - loss: 0.2000 - accuracy: 0.9439 - val_loss: 0.4409 - val_accuracy: 0.8969
Epoch 151/350
391/391 - 25s - loss: 0.2010 - accuracy: 0.9429 - val_loss: 0.4473 - val_accuracy: 0.8946
Epoch 152/350
391/391 - 25s - loss: 0.1936 - accuracy: 0.9466 - val_loss: 0.4444 - val_accuracy: 0.8949
Epoch 153/350
391/391 - 25s - loss: 0.2001 - accuracy: 0.9436 - val_loss: 0.4620 - val_accuracy: 0.8924
Epoch 154/350
391/391 - 25s - loss: 0.1942 - accuracy: 0.9457 - val_loss: 0.4661 - val_accuracy: 0.8938
Epoch 155/350
391/391 - 25s - loss: 0.1944 - accuracy: 0.9455 - val_loss: 0.4620 - val_accuracy: 0.8907
Epoch 156/350
391/391 - 25s - loss: 0.1986 - accuracy: 0.9452 - val_loss: 0.4413 - val_accuracy: 0.8972
Epoch 157/350
391/391 - 25s - loss: 0.1921 - accuracy: 0.9465 - val_loss: 0.4525 - val_accuracy: 0.8952
Epoch 158/350
391/391 - 25s - loss: 0.1928 - accuracy: 0.9478 - val_loss: 0.5241 - val_accuracy: 0.8844
Epoch 159/350
391/391 - 25s - loss: 0.1934 - accuracy: 0.9462 - val_loss: 0.4597 - val_accuracy: 0.8932
Epoch 160/350
391/391 - 25s - loss: 0.1928 - accuracy: 0.9475 - val_loss: 0.4310 - val_accuracy: 0.8977
Epoch 161/350
391/391 - 25s - loss: 0.1878 - accuracy: 0.9480 - val_loss: 0.4926 - val_accuracy: 0.8865
Epoch 162/350
391/391 - 26s - loss: 0.1900 - accuracy: 0.9480 - val_loss: 0.4508 - val_accuracy: 0.8949
Epoch 163/350
391/391 - 25s - loss: 0.1898 - accuracy: 0.9484 - val_loss: 0.4327 - val_accuracy: 0.8978
Epoch 164/350
391/391 - 25s - loss: 0.1877 - accuracy: 0.9488 - val_loss: 0.4717 - val_accuracy: 0.8918
Epoch 165/350
391/391 - 25s - loss: 0.1849 - accuracy: 0.9500 - val_loss: 0.4965 - val_accuracy: 0.8909
Epoch 166/350
391/391 - 25s - loss: 0.1855 - accuracy: 0.9492 - val_loss: 0.4415 - val_accuracy: 0.8990
Epoch 167/350
391/391 - 25s - loss: 0.1904 - accuracy: 0.9484 - val_loss: 0.4535 - val_accuracy: 0.8935
Epoch 168/350
391/391 - 26s - loss: 0.1894 - accuracy: 0.9493 - val_loss: 0.4274 - val_accuracy: 0.8952
Epoch 169/350
391/391 - 25s - loss: 0.1838 - accuracy: 0.9493 - val_loss: 0.4472 - val_accuracy: 0.8997
Epoch 170/350
391/391 - 25s - loss: 0.1810 - accuracy: 0.9512 - val_loss: 0.4625 - val_accuracy: 0.8939
Epoch 171/350
391/391 - 25s - loss: 0.1794 - accuracy: 0.9518 - val_loss: 0.4519 - val_accuracy: 0.8966
Epoch 172/350
391/391 - 25s - loss: 0.1797 - accuracy: 0.9525 - val_loss: 0.4756 - val_accuracy: 0.8934
Epoch 173/350
391/391 - 25s - loss: 0.1855 - accuracy: 0.9507 - val_loss: 0.5005 - val_accuracy: 0.8903
Epoch 174/350
391/391 - 25s - loss: 0.1793 - accuracy: 0.9520 - val_loss: 0.4667 - val_accuracy: 0.8939
Epoch 175/350
391/391 - 25s - loss: 0.1853 - accuracy: 0.9504 - val_loss: 0.4878 - val_accuracy: 0.8937
Epoch 176/350
391/391 - 26s - loss: 0.1858 - accuracy: 0.9499 - val_loss: 0.4472 - val_accuracy: 0.8985
Epoch 177/350
391/391 - 25s - loss: 0.1779 - accuracy: 0.9523 - val_loss: 0.4655 - val_accuracy: 0.8963
Epoch 178/350
391/391 - 25s - loss: 0.1765 - accuracy: 0.9534 - val_loss: 0.4279 - val_accuracy: 0.8978
Epoch 179/350
391/391 - 25s - loss: 0.1721 - accuracy: 0.9540 - val_loss: 0.4672 - val_accuracy: 0.8969
Epoch 180/350
391/391 - 26s - loss: 0.1746 - accuracy: 0.9537 - val_loss: 0.4557 - val_accuracy: 0.9014
Epoch 181/350
391/391 - 25s - loss: 0.1749 - accuracy: 0.9537 - val_loss: 0.4842 - val_accuracy: 0.9007
Epoch 182/350
391/391 - 25s - loss: 0.1730 - accuracy: 0.9549 - val_loss: 0.4907 - val_accuracy: 0.8933
Epoch 183/350
391/391 - 25s - loss: 0.1790 - accuracy: 0.9533 - val_loss: 0.4737 - val_accuracy: 0.8960
Epoch 184/350
391/391 - 25s - loss: 0.1729 - accuracy: 0.9548 - val_loss: 0.4492 - val_accuracy: 0.9010
Epoch 185/350
391/391 - 25s - loss: 0.1745 - accuracy: 0.9538 - val_loss: 0.4641 - val_accuracy: 0.8955
Epoch 186/350
391/391 - 25s - loss: 0.1718 - accuracy: 0.9551 - val_loss: 0.4824 - val_accuracy: 0.8953
Epoch 187/350
391/391 - 25s - loss: 0.1728 - accuracy: 0.9550 - val_loss: 0.5028 - val_accuracy: 0.8951
Epoch 188/350
391/391 - 26s - loss: 0.1734 - accuracy: 0.9540 - val_loss: 0.4908 - val_accuracy: 0.8900
Epoch 189/350
391/391 - 25s - loss: 0.1728 - accuracy: 0.9548 - val_loss: 0.4907 - val_accuracy: 0.8956
Epoch 190/350
391/391 - 25s - loss: 0.1723 - accuracy: 0.9557 - val_loss: 0.4508 - val_accuracy: 0.8968
Epoch 191/350
391/391 - 25s - loss: 0.1730 - accuracy: 0.9552 - val_loss: 0.4719 - val_accuracy: 0.8979
Epoch 192/350
391/391 - 25s - loss: 0.1730 - accuracy: 0.9553 - val_loss: 0.4827 - val_accuracy: 0.8920
Epoch 193/350
391/391 - 25s - loss: 0.1663 - accuracy: 0.9573 - val_loss: 0.4597 - val_accuracy: 0.8996
Epoch 194/350
391/391 - 25s - loss: 0.1683 - accuracy: 0.9565 - val_loss: 0.4500 - val_accuracy: 0.8999
Epoch 195/350
391/391 - 25s - loss: 0.1655 - accuracy: 0.9575 - val_loss: 0.5033 - val_accuracy: 0.8901
Epoch 196/350
391/391 - 25s - loss: 0.1656 - accuracy: 0.9587 - val_loss: 0.4986 - val_accuracy: 0.8939
Epoch 197/350
391/391 - 25s - loss: 0.1651 - accuracy: 0.9584 - val_loss: 0.4810 - val_accuracy: 0.8961
Epoch 198/350
391/391 - 25s - loss: 0.1710 - accuracy: 0.9563 - val_loss: 0.4937 - val_accuracy: 0.8944
Epoch 199/350
391/391 - 25s - loss: 0.1684 - accuracy: 0.9578 - val_loss: 0.4661 - val_accuracy: 0.9032
Epoch 200/350


Snapshot weight 2 shuffle 4 at epoch 200
Layer 11
Getting activations...


391/391 - 26s - loss: 0.1630 - accuracy: 0.9585 - val_loss: 0.5002 - val_accuracy: 0.8969
Epoch 201/350
391/391 - 25s - loss: 0.1397 - accuracy: 0.9667 - val_loss: 0.4646 - val_accuracy: 0.9038
Epoch 202/350
391/391 - 25s - loss: 0.1264 - accuracy: 0.9721 - val_loss: 0.4680 - val_accuracy: 0.9039
Epoch 203/350
391/391 - 25s - loss: 0.1245 - accuracy: 0.9726 - val_loss: 0.4671 - val_accuracy: 0.9065
Epoch 204/350
391/391 - 25s - loss: 0.1247 - accuracy: 0.9722 - val_loss: 0.4703 - val_accuracy: 0.9059
Epoch 205/350
391/391 - 25s - loss: 0.1240 - accuracy: 0.9729 - val_loss: 0.4727 - val_accuracy: 0.9080
Epoch 206/350
391/391 - 25s - loss: 0.1193 - accuracy: 0.9741 - val_loss: 0.4775 - val_accuracy: 0.9060
Epoch 207/350
391/391 - 25s - loss: 0.1172 - accuracy: 0.9744 - val_loss: 0.4773 - val_accuracy: 0.9061
Epoch 208/350
391/391 - 25s - loss: 0.1177 - accuracy: 0.9745 - val_loss: 0.4897 - val_accuracy: 0.9063
Epoch 209/350
391/391 - 25s - loss: 0.1174 - accuracy: 0.9748 - val_loss: 0.4796 - val_accuracy: 0.9074
Epoch 210/350
391/391 - 25s - loss: 0.1170 - accuracy: 0.9746 - val_loss: 0.4861 - val_accuracy: 0.9071
Epoch 211/350
391/391 - 25s - loss: 0.1173 - accuracy: 0.9746 - val_loss: 0.4791 - val_accuracy: 0.9060
Epoch 212/350
391/391 - 25s - loss: 0.1170 - accuracy: 0.9749 - val_loss: 0.4865 - val_accuracy: 0.9067
Epoch 213/350
391/391 - 25s - loss: 0.1126 - accuracy: 0.9766 - val_loss: 0.4897 - val_accuracy: 0.9078
Epoch 214/350
391/391 - 25s - loss: 0.1176 - accuracy: 0.9749 - val_loss: 0.4828 - val_accuracy: 0.9080
Epoch 215/350
391/391 - 25s - loss: 0.1124 - accuracy: 0.9756 - val_loss: 0.4911 - val_accuracy: 0.9056
Epoch 216/350
391/391 - 25s - loss: 0.1131 - accuracy: 0.9764 - val_loss: 0.4879 - val_accuracy: 0.9079
Epoch 217/350
391/391 - 25s - loss: 0.1154 - accuracy: 0.9752 - val_loss: 0.4884 - val_accuracy: 0.9072
Epoch 218/350
391/391 - 25s - loss: 0.1115 - accuracy: 0.9765 - val_loss: 0.4874 - val_accuracy: 0.9068
Epoch 219/350
391/391 - 25s - loss: 0.1128 - accuracy: 0.9760 - val_loss: 0.4968 - val_accuracy: 0.9078
Epoch 220/350
391/391 - 25s - loss: 0.1109 - accuracy: 0.9766 - val_loss: 0.4941 - val_accuracy: 0.9057
Epoch 221/350
391/391 - 25s - loss: 0.1127 - accuracy: 0.9762 - val_loss: 0.4965 - val_accuracy: 0.9055
Epoch 222/350
391/391 - 25s - loss: 0.1114 - accuracy: 0.9772 - val_loss: 0.4962 - val_accuracy: 0.9075
Epoch 223/350
391/391 - 25s - loss: 0.1107 - accuracy: 0.9769 - val_loss: 0.5006 - val_accuracy: 0.9063
Epoch 224/350
391/391 - 25s - loss: 0.1098 - accuracy: 0.9771 - val_loss: 0.5012 - val_accuracy: 0.9070
Epoch 225/350
391/391 - 25s - loss: 0.1111 - accuracy: 0.9763 - val_loss: 0.5042 - val_accuracy: 0.9054
Epoch 226/350
391/391 - 25s - loss: 0.1116 - accuracy: 0.9766 - val_loss: 0.5019 - val_accuracy: 0.9057
Epoch 227/350
391/391 - 25s - loss: 0.1072 - accuracy: 0.9785 - val_loss: 0.5088 - val_accuracy: 0.9062
Epoch 228/350
391/391 - 25s - loss: 0.1078 - accuracy: 0.9777 - val_loss: 0.5035 - val_accuracy: 0.9076
Epoch 229/350
391/391 - 25s - loss: 0.1105 - accuracy: 0.9771 - val_loss: 0.4940 - val_accuracy: 0.9071
Epoch 230/350
391/391 - 25s - loss: 0.1108 - accuracy: 0.9771 - val_loss: 0.5042 - val_accuracy: 0.9064
Epoch 231/350
391/391 - 25s - loss: 0.1074 - accuracy: 0.9773 - val_loss: 0.4980 - val_accuracy: 0.9083
Epoch 232/350
391/391 - 26s - loss: 0.1089 - accuracy: 0.9771 - val_loss: 0.4990 - val_accuracy: 0.9098
Epoch 233/350
391/391 - 25s - loss: 0.1077 - accuracy: 0.9780 - val_loss: 0.4956 - val_accuracy: 0.9067
Epoch 234/350
391/391 - 25s - loss: 0.1071 - accuracy: 0.9786 - val_loss: 0.5141 - val_accuracy: 0.9076
Epoch 235/350
391/391 - 25s - loss: 0.1058 - accuracy: 0.9794 - val_loss: 0.5082 - val_accuracy: 0.9080
Epoch 236/350
391/391 - 25s - loss: 0.1033 - accuracy: 0.9798 - val_loss: 0.5103 - val_accuracy: 0.9085
Epoch 237/350
391/391 - 25s - loss: 0.1086 - accuracy: 0.9779 - val_loss: 0.5078 - val_accuracy: 0.9074
Epoch 238/350
391/391 - 25s - loss: 0.1080 - accuracy: 0.9784 - val_loss: 0.5109 - val_accuracy: 0.9074
Epoch 239/350
391/391 - 25s - loss: 0.1079 - accuracy: 0.9780 - val_loss: 0.5031 - val_accuracy: 0.9072
Epoch 240/350
391/391 - 25s - loss: 0.1063 - accuracy: 0.9783 - val_loss: 0.5090 - val_accuracy: 0.9080
Epoch 241/350
391/391 - 25s - loss: 0.1059 - accuracy: 0.9789 - val_loss: 0.5103 - val_accuracy: 0.9068
Epoch 242/350
391/391 - 26s - loss: 0.1044 - accuracy: 0.9791 - val_loss: 0.5213 - val_accuracy: 0.9050
Epoch 243/350
391/391 - 25s - loss: 0.1052 - accuracy: 0.9791 - val_loss: 0.5079 - val_accuracy: 0.9058
Epoch 244/350
391/391 - 25s - loss: 0.1054 - accuracy: 0.9791 - val_loss: 0.5195 - val_accuracy: 0.9056
Epoch 245/350
391/391 - 25s - loss: 0.1045 - accuracy: 0.9792 - val_loss: 0.5136 - val_accuracy: 0.9048
Epoch 246/350
391/391 - 25s - loss: 0.1066 - accuracy: 0.9789 - val_loss: 0.5069 - val_accuracy: 0.9048
Epoch 247/350
391/391 - 25s - loss: 0.1051 - accuracy: 0.9799 - val_loss: 0.5141 - val_accuracy: 0.9056
Epoch 248/350
391/391 - 25s - loss: 0.1060 - accuracy: 0.9786 - val_loss: 0.4987 - val_accuracy: 0.9077
Epoch 249/350
391/391 - 25s - loss: 0.1053 - accuracy: 0.9794 - val_loss: 0.5198 - val_accuracy: 0.9047
Epoch 250/350


Snapshot weight 2 shuffle 4 at epoch 250
Layer 11
Getting activations...


391/391 - 26s - loss: 0.1034 - accuracy: 0.9800 - val_loss: 0.5186 - val_accuracy: 0.9046
Epoch 251/350
391/391 - 25s - loss: 0.1032 - accuracy: 0.9795 - val_loss: 0.5150 - val_accuracy: 0.9063
Epoch 252/350
391/391 - 25s - loss: 0.0986 - accuracy: 0.9812 - val_loss: 0.5162 - val_accuracy: 0.9063
Epoch 253/350
391/391 - 25s - loss: 0.1008 - accuracy: 0.9808 - val_loss: 0.5168 - val_accuracy: 0.9062
Epoch 254/350
391/391 - 25s - loss: 0.1006 - accuracy: 0.9804 - val_loss: 0.5166 - val_accuracy: 0.9063
Epoch 255/350
391/391 - 25s - loss: 0.1017 - accuracy: 0.9799 - val_loss: 0.5149 - val_accuracy: 0.9064
Epoch 256/350
391/391 - 25s - loss: 0.1035 - accuracy: 0.9806 - val_loss: 0.5153 - val_accuracy: 0.9072
Epoch 257/350
391/391 - 25s - loss: 0.1012 - accuracy: 0.9805 - val_loss: 0.5172 - val_accuracy: 0.9066
Epoch 258/350
391/391 - 25s - loss: 0.1010 - accuracy: 0.9801 - val_loss: 0.5156 - val_accuracy: 0.9063
Epoch 259/350
391/391 - 25s - loss: 0.0999 - accuracy: 0.9814 - val_loss: 0.5138 - val_accuracy: 0.9061
Epoch 260/350
391/391 - 25s - loss: 0.1006 - accuracy: 0.9805 - val_loss: 0.5167 - val_accuracy: 0.9061
Epoch 261/350
391/391 - 25s - loss: 0.1003 - accuracy: 0.9810 - val_loss: 0.5173 - val_accuracy: 0.9066
Epoch 262/350
391/391 - 25s - loss: 0.0985 - accuracy: 0.9817 - val_loss: 0.5157 - val_accuracy: 0.9067
Epoch 263/350
391/391 - 25s - loss: 0.1024 - accuracy: 0.9804 - val_loss: 0.5156 - val_accuracy: 0.9061
Epoch 264/350
391/391 - 25s - loss: 0.1006 - accuracy: 0.9805 - val_loss: 0.5153 - val_accuracy: 0.9061
Epoch 265/350
391/391 - 25s - loss: 0.0988 - accuracy: 0.9812 - val_loss: 0.5181 - val_accuracy: 0.9062
Epoch 266/350
391/391 - 25s - loss: 0.0989 - accuracy: 0.9811 - val_loss: 0.5172 - val_accuracy: 0.9066
Epoch 267/350
391/391 - 25s - loss: 0.1021 - accuracy: 0.9804 - val_loss: 0.5162 - val_accuracy: 0.9067
Epoch 268/350
391/391 - 25s - loss: 0.0994 - accuracy: 0.9812 - val_loss: 0.5159 - val_accuracy: 0.9065
Epoch 269/350
391/391 - 25s - loss: 0.1015 - accuracy: 0.9805 - val_loss: 0.5167 - val_accuracy: 0.9066
Epoch 270/350
391/391 - 25s - loss: 0.1003 - accuracy: 0.9802 - val_loss: 0.5200 - val_accuracy: 0.9061
Epoch 271/350
391/391 - 25s - loss: 0.1001 - accuracy: 0.9812 - val_loss: 0.5169 - val_accuracy: 0.9058
Epoch 272/350
391/391 - 25s - loss: 0.1031 - accuracy: 0.9795 - val_loss: 0.5162 - val_accuracy: 0.9064
Epoch 273/350
391/391 - 25s - loss: 0.1008 - accuracy: 0.9808 - val_loss: 0.5169 - val_accuracy: 0.9064
Epoch 274/350
391/391 - 25s - loss: 0.1006 - accuracy: 0.9808 - val_loss: 0.5174 - val_accuracy: 0.9071
Epoch 275/350
391/391 - 25s - loss: 0.0999 - accuracy: 0.9808 - val_loss: 0.5179 - val_accuracy: 0.9064
Epoch 276/350
391/391 - 25s - loss: 0.1003 - accuracy: 0.9811 - val_loss: 0.5152 - val_accuracy: 0.9063
Epoch 277/350
391/391 - 25s - loss: 0.1034 - accuracy: 0.9799 - val_loss: 0.5146 - val_accuracy: 0.9068
Epoch 278/350
391/391 - 26s - loss: 0.0995 - accuracy: 0.9804 - val_loss: 0.5119 - val_accuracy: 0.9066
Epoch 279/350
391/391 - 25s - loss: 0.1004 - accuracy: 0.9807 - val_loss: 0.5147 - val_accuracy: 0.9061
Epoch 280/350
391/391 - 25s - loss: 0.1002 - accuracy: 0.9809 - val_loss: 0.5153 - val_accuracy: 0.9062
Epoch 281/350
391/391 - 25s - loss: 0.1014 - accuracy: 0.9801 - val_loss: 0.5148 - val_accuracy: 0.9066
Epoch 282/350
391/391 - 25s - loss: 0.1005 - accuracy: 0.9809 - val_loss: 0.5175 - val_accuracy: 0.9071
Epoch 283/350
391/391 - 25s - loss: 0.1025 - accuracy: 0.9801 - val_loss: 0.5165 - val_accuracy: 0.9066
Epoch 284/350
391/391 - 25s - loss: 0.1031 - accuracy: 0.9796 - val_loss: 0.5136 - val_accuracy: 0.9070
Epoch 285/350
391/391 - 25s - loss: 0.1010 - accuracy: 0.9800 - val_loss: 0.5137 - val_accuracy: 0.9056
Epoch 286/350
391/391 - 25s - loss: 0.1013 - accuracy: 0.9808 - val_loss: 0.5159 - val_accuracy: 0.9063
Epoch 287/350
391/391 - 25s - loss: 0.0984 - accuracy: 0.9810 - val_loss: 0.5152 - val_accuracy: 0.9067
Epoch 288/350
391/391 - 25s - loss: 0.1003 - accuracy: 0.9802 - val_loss: 0.5154 - val_accuracy: 0.9061
Epoch 289/350
391/391 - 25s - loss: 0.0993 - accuracy: 0.9812 - val_loss: 0.5149 - val_accuracy: 0.9067
Epoch 290/350
391/391 - 26s - loss: 0.1019 - accuracy: 0.9803 - val_loss: 0.5159 - val_accuracy: 0.9069
Epoch 291/350
391/391 - 25s - loss: 0.0983 - accuracy: 0.9818 - val_loss: 0.5183 - val_accuracy: 0.9061
Epoch 292/350
391/391 - 25s - loss: 0.1002 - accuracy: 0.9809 - val_loss: 0.5169 - val_accuracy: 0.9066
Epoch 293/350
391/391 - 25s - loss: 0.1014 - accuracy: 0.9804 - val_loss: 0.5176 - val_accuracy: 0.9069
Epoch 294/350
391/391 - 25s - loss: 0.0985 - accuracy: 0.9818 - val_loss: 0.5179 - val_accuracy: 0.9076
Epoch 295/350
391/391 - 25s - loss: 0.0984 - accuracy: 0.9810 - val_loss: 0.5173 - val_accuracy: 0.9064
Epoch 296/350
391/391 - 25s - loss: 0.1002 - accuracy: 0.9800 - val_loss: 0.5178 - val_accuracy: 0.9067
Epoch 297/350
391/391 - 25s - loss: 0.1018 - accuracy: 0.9808 - val_loss: 0.5161 - val_accuracy: 0.9068
Epoch 298/350
391/391 - 25s - loss: 0.1013 - accuracy: 0.9808 - val_loss: 0.5188 - val_accuracy: 0.9061
Epoch 299/350
391/391 - 25s - loss: 0.1007 - accuracy: 0.9806 - val_loss: 0.5172 - val_accuracy: 0.9074
Epoch 300/350


Snapshot weight 2 shuffle 4 at epoch 300
Layer 11
Getting activations...


391/391 - 26s - loss: 0.0981 - accuracy: 0.9817 - val_loss: 0.5197 - val_accuracy: 0.9072
Epoch 301/350
391/391 - 25s - loss: 0.1010 - accuracy: 0.9808 - val_loss: 0.5198 - val_accuracy: 0.9070
Epoch 302/350
391/391 - 25s - loss: 0.0995 - accuracy: 0.9815 - val_loss: 0.5192 - val_accuracy: 0.9070
Epoch 303/350
391/391 - 25s - loss: 0.0997 - accuracy: 0.9809 - val_loss: 0.5187 - val_accuracy: 0.9067
Epoch 304/350
391/391 - 25s - loss: 0.1010 - accuracy: 0.9807 - val_loss: 0.5183 - val_accuracy: 0.9066
Epoch 305/350
391/391 - 25s - loss: 0.0987 - accuracy: 0.9806 - val_loss: 0.5185 - val_accuracy: 0.9065
Epoch 306/350
391/391 - 25s - loss: 0.1003 - accuracy: 0.9805 - val_loss: 0.5185 - val_accuracy: 0.9069
Epoch 307/350
391/391 - 25s - loss: 0.1001 - accuracy: 0.9809 - val_loss: 0.5183 - val_accuracy: 0.9068
Epoch 308/350
391/391 - 25s - loss: 0.0990 - accuracy: 0.9810 - val_loss: 0.5183 - val_accuracy: 0.9064
Epoch 309/350
391/391 - 25s - loss: 0.0988 - accuracy: 0.9810 - val_loss: 0.5180 - val_accuracy: 0.9065
Epoch 310/350
391/391 - 25s - loss: 0.1004 - accuracy: 0.9815 - val_loss: 0.5176 - val_accuracy: 0.9065
Epoch 311/350
391/391 - 25s - loss: 0.1005 - accuracy: 0.9805 - val_loss: 0.5173 - val_accuracy: 0.9067
Epoch 312/350
391/391 - 25s - loss: 0.1008 - accuracy: 0.9811 - val_loss: 0.5172 - val_accuracy: 0.9068
Epoch 313/350
391/391 - 25s - loss: 0.1008 - accuracy: 0.9806 - val_loss: 0.5170 - val_accuracy: 0.9068
Epoch 314/350
391/391 - 25s - loss: 0.0989 - accuracy: 0.9818 - val_loss: 0.5170 - val_accuracy: 0.9070
Epoch 315/350
391/391 - 25s - loss: 0.0977 - accuracy: 0.9816 - val_loss: 0.5172 - val_accuracy: 0.9069
Epoch 316/350
391/391 - 25s - loss: 0.1003 - accuracy: 0.9812 - val_loss: 0.5172 - val_accuracy: 0.9066
Epoch 317/350
391/391 - 26s - loss: 0.0998 - accuracy: 0.9807 - val_loss: 0.5178 - val_accuracy: 0.9068
Epoch 318/350
391/391 - 25s - loss: 0.0986 - accuracy: 0.9812 - val_loss: 0.5177 - val_accuracy: 0.9070
Epoch 319/350
391/391 - 25s - loss: 0.0986 - accuracy: 0.9806 - val_loss: 0.5176 - val_accuracy: 0.9070
Epoch 320/350
391/391 - 25s - loss: 0.0972 - accuracy: 0.9821 - val_loss: 0.5175 - val_accuracy: 0.9071
Epoch 321/350
391/391 - 25s - loss: 0.1000 - accuracy: 0.9818 - val_loss: 0.5179 - val_accuracy: 0.9066
Epoch 322/350
391/391 - 25s - loss: 0.1015 - accuracy: 0.9801 - val_loss: 0.5176 - val_accuracy: 0.9071
Epoch 323/350
391/391 - 25s - loss: 0.1002 - accuracy: 0.9817 - val_loss: 0.5172 - val_accuracy: 0.9069
Epoch 324/350
391/391 - 25s - loss: 0.0980 - accuracy: 0.9812 - val_loss: 0.5171 - val_accuracy: 0.9067
Epoch 325/350
391/391 - 25s - loss: 0.1005 - accuracy: 0.9807 - val_loss: 0.5171 - val_accuracy: 0.9070
Epoch 326/350
391/391 - 25s - loss: 0.0977 - accuracy: 0.9824 - val_loss: 0.5170 - val_accuracy: 0.9073
Epoch 327/350
391/391 - 25s - loss: 0.1011 - accuracy: 0.9805 - val_loss: 0.5172 - val_accuracy: 0.9071
Epoch 328/350
391/391 - 25s - loss: 0.0992 - accuracy: 0.9817 - val_loss: 0.5176 - val_accuracy: 0.9071
Epoch 329/350
391/391 - 25s - loss: 0.1009 - accuracy: 0.9805 - val_loss: 0.5177 - val_accuracy: 0.9071
Epoch 330/350
391/391 - 25s - loss: 0.0995 - accuracy: 0.9810 - val_loss: 0.5176 - val_accuracy: 0.9073
Epoch 331/350
391/391 - 25s - loss: 0.0986 - accuracy: 0.9804 - val_loss: 0.5177 - val_accuracy: 0.9070
Epoch 332/350
391/391 - 25s - loss: 0.0992 - accuracy: 0.9810 - val_loss: 0.5180 - val_accuracy: 0.9073
Epoch 333/350
391/391 - 25s - loss: 0.1000 - accuracy: 0.9811 - val_loss: 0.5179 - val_accuracy: 0.9073
Epoch 334/350
391/391 - 25s - loss: 0.0981 - accuracy: 0.9816 - val_loss: 0.5179 - val_accuracy: 0.9074
Epoch 335/350
391/391 - 25s - loss: 0.0986 - accuracy: 0.9807 - val_loss: 0.5178 - val_accuracy: 0.9070
Epoch 336/350
391/391 - 25s - loss: 0.0985 - accuracy: 0.9815 - val_loss: 0.5179 - val_accuracy: 0.9070
Epoch 337/350
391/391 - 25s - loss: 0.0985 - accuracy: 0.9812 - val_loss: 0.5177 - val_accuracy: 0.9070
Epoch 338/350
391/391 - 25s - loss: 0.0992 - accuracy: 0.9805 - val_loss: 0.5179 - val_accuracy: 0.9071
Epoch 339/350
391/391 - 25s - loss: 0.0972 - accuracy: 0.9820 - val_loss: 0.5181 - val_accuracy: 0.9071
Epoch 340/350
391/391 - 25s - loss: 0.1000 - accuracy: 0.9811 - val_loss: 0.5182 - val_accuracy: 0.9071
Epoch 341/350
391/391 - 25s - loss: 0.0998 - accuracy: 0.9817 - val_loss: 0.5181 - val_accuracy: 0.9069
Epoch 342/350
391/391 - 25s - loss: 0.0985 - accuracy: 0.9818 - val_loss: 0.5182 - val_accuracy: 0.9071
Epoch 343/350
391/391 - 25s - loss: 0.0993 - accuracy: 0.9810 - val_loss: 0.5182 - val_accuracy: 0.9072
Epoch 344/350
391/391 - 25s - loss: 0.1004 - accuracy: 0.9807 - val_loss: 0.5177 - val_accuracy: 0.9072
Epoch 345/350
391/391 - 25s - loss: 0.0992 - accuracy: 0.9817 - val_loss: 0.5176 - val_accuracy: 0.9072
Epoch 346/350
391/391 - 25s - loss: 0.1006 - accuracy: 0.9807 - val_loss: 0.5173 - val_accuracy: 0.9071
Epoch 347/350
391/391 - 25s - loss: 0.0995 - accuracy: 0.9810 - val_loss: 0.5176 - val_accuracy: 0.9070
Epoch 348/350
391/391 - 25s - loss: 0.0990 - accuracy: 0.9813 - val_loss: 0.5174 - val_accuracy: 0.9069
Epoch 349/350
391/391 - 25s - loss: 0.0996 - accuracy: 0.9809 - val_loss: 0.5179 - val_accuracy: 0.9066
Epoch 350/350


Snapshot weight 2 shuffle 4 at epoch 350
Layer 11
Getting activations...


391/391 - 26s - loss: 0.1013 - accuracy: 0.9801 - val_loss: 0.5180 - val_accuracy: 0.9066
/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:493: UserWarning: fill_value is not supported and is always 0 for TensorFlow < 2.4.0.
  return py_builtins.overload_of(f)(*args)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-07-02 07:05:44.908597: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
Saving, final validation acc: 0.9065999984741211
