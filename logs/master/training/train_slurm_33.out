2021-07-02 01:53:20.748146: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 01:55:38.071815: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-07-02 01:55:38.112251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:82:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-02 01:55:38.112334: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 01:55:38.152389: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-02 01:55:38.172618: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-02 01:55:38.180675: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-02 01:55:38.222430: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-02 01:55:38.230785: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-02 01:55:38.306976: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 01:55:38.313488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-02 01:55:38.317080: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-02 01:55:38.333036: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599990000 Hz
2021-07-02 01:55:38.333154: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x442a0f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-07-02 01:55:38.333174: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-07-02 01:55:38.462571: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4411d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-07-02 01:55:38.462640: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN X (Pascal), Compute Capability 6.1
2021-07-02 01:55:38.466214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:82:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-02 01:55:38.466260: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 01:55:38.466301: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-02 01:55:38.466325: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-02 01:55:38.466348: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-02 01:55:38.466371: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-02 01:55:38.466393: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-02 01:55:38.466947: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 01:55:38.468604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-02 01:55:38.470357: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 01:55:44.063845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-02 01:55:44.063923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-07-02 01:55:44.063937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-07-02 01:55:44.071274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11228 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:82:00.0, compute capability: 6.1)
2021-07-02 01:55:49.993523: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 01:55:52.526247: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
Using model index: 33
Making train data...
GCN...
ZCA...
Done!
Making test data...
Done!
Epoch 1/350


Snapshot weight 3 shuffle 3 at epoch 1
Layer 11
Getting activations...


391/391 - 25s - loss: 2.3205 - accuracy: 0.1131 - val_loss: 2.2860 - val_accuracy: 0.1735
Epoch 2/350


Snapshot weight 3 shuffle 3 at epoch 2
Layer 11
Getting activations...


391/391 - 25s - loss: 2.2414 - accuracy: 0.1647 - val_loss: 2.1438 - val_accuracy: 0.2162
Epoch 3/350


Snapshot weight 3 shuffle 3 at epoch 3
Layer 11
Getting activations...


391/391 - 25s - loss: 2.1048 - accuracy: 0.2262 - val_loss: 1.9571 - val_accuracy: 0.3182
Epoch 4/350


Snapshot weight 3 shuffle 3 at epoch 4
Layer 11
Getting activations...


391/391 - 26s - loss: 1.9106 - accuracy: 0.3229 - val_loss: 1.7450 - val_accuracy: 0.3932
Epoch 5/350


Snapshot weight 3 shuffle 3 at epoch 5
Layer 11
Getting activations...


391/391 - 26s - loss: 1.7388 - accuracy: 0.4034 - val_loss: 1.6863 - val_accuracy: 0.4410
Epoch 6/350


Snapshot weight 3 shuffle 3 at epoch 6
Layer 11
Getting activations...


391/391 - 25s - loss: 1.5845 - accuracy: 0.4515 - val_loss: 1.4558 - val_accuracy: 0.4943
Epoch 7/350


Snapshot weight 3 shuffle 3 at epoch 7
Layer 11
Getting activations...


391/391 - 26s - loss: 1.4612 - accuracy: 0.4953 - val_loss: 1.4640 - val_accuracy: 0.5102
Epoch 8/350


Snapshot weight 3 shuffle 3 at epoch 8
Layer 11
Getting activations...


391/391 - 26s - loss: 1.3953 - accuracy: 0.5226 - val_loss: 1.3216 - val_accuracy: 0.5514
Epoch 9/350


Snapshot weight 3 shuffle 3 at epoch 9
Layer 11
Getting activations...


391/391 - 25s - loss: 1.1926 - accuracy: 0.5867 - val_loss: 1.0927 - val_accuracy: 0.6189
Epoch 10/350


Snapshot weight 3 shuffle 3 at epoch 10
Layer 11
Getting activations...


391/391 - 25s - loss: 1.1118 - accuracy: 0.6129 - val_loss: 1.0076 - val_accuracy: 0.6492
Epoch 11/350
391/391 - 25s - loss: 1.0625 - accuracy: 0.6327 - val_loss: 0.9735 - val_accuracy: 0.6604
Epoch 12/350
391/391 - 25s - loss: 0.9989 - accuracy: 0.6548 - val_loss: 0.9823 - val_accuracy: 0.6669
Epoch 13/350
391/391 - 25s - loss: 0.9679 - accuracy: 0.6667 - val_loss: 0.8849 - val_accuracy: 0.6976
Epoch 14/350
391/391 - 25s - loss: 0.9297 - accuracy: 0.6817 - val_loss: 0.8241 - val_accuracy: 0.7158
Epoch 15/350
391/391 - 25s - loss: 0.8958 - accuracy: 0.6910 - val_loss: 0.8365 - val_accuracy: 0.7229
Epoch 16/350
391/391 - 25s - loss: 0.8641 - accuracy: 0.7064 - val_loss: 0.7988 - val_accuracy: 0.7327
Epoch 17/350
391/391 - 25s - loss: 0.8258 - accuracy: 0.7191 - val_loss: 0.7332 - val_accuracy: 0.7588
Epoch 18/350
391/391 - 25s - loss: 0.7963 - accuracy: 0.7325 - val_loss: 0.7343 - val_accuracy: 0.7570
Epoch 19/350
391/391 - 25s - loss: 0.7850 - accuracy: 0.7361 - val_loss: 0.6803 - val_accuracy: 0.7720
Epoch 20/350
391/391 - 25s - loss: 0.7568 - accuracy: 0.7475 - val_loss: 0.6683 - val_accuracy: 0.7765
Epoch 21/350
391/391 - 25s - loss: 0.7184 - accuracy: 0.7588 - val_loss: 0.7060 - val_accuracy: 0.7699
Epoch 22/350
391/391 - 25s - loss: 0.7048 - accuracy: 0.7630 - val_loss: 0.6536 - val_accuracy: 0.7865
Epoch 23/350
391/391 - 25s - loss: 0.6855 - accuracy: 0.7717 - val_loss: 0.6768 - val_accuracy: 0.7779
Epoch 24/350
391/391 - 25s - loss: 0.6648 - accuracy: 0.7796 - val_loss: 0.6332 - val_accuracy: 0.7917
Epoch 25/350
391/391 - 25s - loss: 0.6453 - accuracy: 0.7849 - val_loss: 0.6979 - val_accuracy: 0.7830
Epoch 26/350
391/391 - 25s - loss: 0.6337 - accuracy: 0.7904 - val_loss: 0.6559 - val_accuracy: 0.7943
Epoch 27/350
391/391 - 25s - loss: 0.6203 - accuracy: 0.7949 - val_loss: 0.5969 - val_accuracy: 0.8062
Epoch 28/350
391/391 - 25s - loss: 0.5997 - accuracy: 0.8019 - val_loss: 0.5498 - val_accuracy: 0.8202
Epoch 29/350
391/391 - 25s - loss: 0.5887 - accuracy: 0.8064 - val_loss: 0.6111 - val_accuracy: 0.8027
Epoch 30/350
391/391 - 26s - loss: 0.5786 - accuracy: 0.8083 - val_loss: 0.5738 - val_accuracy: 0.8165
Epoch 31/350
391/391 - 25s - loss: 0.5661 - accuracy: 0.8134 - val_loss: 0.5576 - val_accuracy: 0.8163
Epoch 32/350
391/391 - 25s - loss: 0.5558 - accuracy: 0.8159 - val_loss: 0.5834 - val_accuracy: 0.8063
Epoch 33/350
391/391 - 25s - loss: 0.5408 - accuracy: 0.8221 - val_loss: 0.5435 - val_accuracy: 0.8244
Epoch 34/350
391/391 - 25s - loss: 0.5394 - accuracy: 0.8215 - val_loss: 0.5175 - val_accuracy: 0.8326
Epoch 35/350
391/391 - 25s - loss: 0.5282 - accuracy: 0.8281 - val_loss: 0.5097 - val_accuracy: 0.8388
Epoch 36/350
391/391 - 25s - loss: 0.5188 - accuracy: 0.8302 - val_loss: 0.5017 - val_accuracy: 0.8382
Epoch 37/350
391/391 - 25s - loss: 0.5145 - accuracy: 0.8310 - val_loss: 0.5102 - val_accuracy: 0.8384
Epoch 38/350
391/391 - 25s - loss: 0.4981 - accuracy: 0.8365 - val_loss: 0.5200 - val_accuracy: 0.8332
Epoch 39/350
391/391 - 25s - loss: 0.4909 - accuracy: 0.8394 - val_loss: 0.5190 - val_accuracy: 0.8361
Epoch 40/350
391/391 - 25s - loss: 0.4842 - accuracy: 0.8414 - val_loss: 0.5077 - val_accuracy: 0.8396
Epoch 41/350
391/391 - 25s - loss: 0.4748 - accuracy: 0.8464 - val_loss: 0.4819 - val_accuracy: 0.8467
Epoch 42/350
391/391 - 25s - loss: 0.4728 - accuracy: 0.8442 - val_loss: 0.5214 - val_accuracy: 0.8347
Epoch 43/350
391/391 - 25s - loss: 0.4635 - accuracy: 0.8490 - val_loss: 0.4949 - val_accuracy: 0.8435
Epoch 44/350
391/391 - 25s - loss: 0.4529 - accuracy: 0.8531 - val_loss: 0.4950 - val_accuracy: 0.8447
Epoch 45/350
391/391 - 25s - loss: 0.4501 - accuracy: 0.8529 - val_loss: 0.4769 - val_accuracy: 0.8501
Epoch 46/350
391/391 - 25s - loss: 0.4483 - accuracy: 0.8549 - val_loss: 0.4874 - val_accuracy: 0.8467
Epoch 47/350
391/391 - 25s - loss: 0.4365 - accuracy: 0.8597 - val_loss: 0.4644 - val_accuracy: 0.8527
Epoch 48/350
391/391 - 25s - loss: 0.4274 - accuracy: 0.8623 - val_loss: 0.4924 - val_accuracy: 0.8466
Epoch 49/350
391/391 - 25s - loss: 0.4345 - accuracy: 0.8588 - val_loss: 0.5317 - val_accuracy: 0.8357
Epoch 50/350


Snapshot weight 3 shuffle 3 at epoch 50
Layer 11
Getting activations...


391/391 - 26s - loss: 0.4278 - accuracy: 0.8624 - val_loss: 0.4635 - val_accuracy: 0.8558
Epoch 51/350
391/391 - 25s - loss: 0.4182 - accuracy: 0.8650 - val_loss: 0.4594 - val_accuracy: 0.8539
Epoch 52/350
391/391 - 25s - loss: 0.4126 - accuracy: 0.8668 - val_loss: 0.4493 - val_accuracy: 0.8601
Epoch 53/350
391/391 - 26s - loss: 0.4078 - accuracy: 0.8694 - val_loss: 0.4952 - val_accuracy: 0.8520
Epoch 54/350
391/391 - 25s - loss: 0.4115 - accuracy: 0.8678 - val_loss: 0.4312 - val_accuracy: 0.8630
Epoch 55/350
391/391 - 25s - loss: 0.4022 - accuracy: 0.8718 - val_loss: 0.4270 - val_accuracy: 0.8690
Epoch 56/350
391/391 - 25s - loss: 0.3932 - accuracy: 0.8755 - val_loss: 0.4559 - val_accuracy: 0.8635
Epoch 57/350
391/391 - 25s - loss: 0.3867 - accuracy: 0.8770 - val_loss: 0.4656 - val_accuracy: 0.8564
Epoch 58/350
391/391 - 25s - loss: 0.3863 - accuracy: 0.8770 - val_loss: 0.4548 - val_accuracy: 0.8609
Epoch 59/350
391/391 - 25s - loss: 0.3802 - accuracy: 0.8779 - val_loss: 0.4658 - val_accuracy: 0.8588
Epoch 60/350
391/391 - 25s - loss: 0.3750 - accuracy: 0.8800 - val_loss: 0.4493 - val_accuracy: 0.8637
Epoch 61/350
391/391 - 25s - loss: 0.3732 - accuracy: 0.8814 - val_loss: 0.4558 - val_accuracy: 0.8610
Epoch 62/350
391/391 - 25s - loss: 0.3683 - accuracy: 0.8818 - val_loss: 0.4282 - val_accuracy: 0.8720
Epoch 63/350
391/391 - 25s - loss: 0.3659 - accuracy: 0.8850 - val_loss: 0.4416 - val_accuracy: 0.8704
Epoch 64/350
391/391 - 25s - loss: 0.3567 - accuracy: 0.8863 - val_loss: 0.4643 - val_accuracy: 0.8623
Epoch 65/350
391/391 - 25s - loss: 0.3592 - accuracy: 0.8862 - val_loss: 0.5015 - val_accuracy: 0.8523
Epoch 66/350
391/391 - 25s - loss: 0.3510 - accuracy: 0.8880 - val_loss: 0.4377 - val_accuracy: 0.8704
Epoch 67/350
391/391 - 25s - loss: 0.3516 - accuracy: 0.8887 - val_loss: 0.4772 - val_accuracy: 0.8575
Epoch 68/350
391/391 - 25s - loss: 0.3440 - accuracy: 0.8899 - val_loss: 0.4385 - val_accuracy: 0.8728
Epoch 69/350
391/391 - 25s - loss: 0.3433 - accuracy: 0.8913 - val_loss: 0.4448 - val_accuracy: 0.8696
Epoch 70/350
391/391 - 25s - loss: 0.3402 - accuracy: 0.8915 - val_loss: 0.4332 - val_accuracy: 0.8709
Epoch 71/350
391/391 - 25s - loss: 0.3346 - accuracy: 0.8941 - val_loss: 0.4579 - val_accuracy: 0.8692
Epoch 72/350
391/391 - 25s - loss: 0.3322 - accuracy: 0.8959 - val_loss: 0.4374 - val_accuracy: 0.8763
Epoch 73/350
391/391 - 25s - loss: 0.3331 - accuracy: 0.8956 - val_loss: 0.4473 - val_accuracy: 0.8728
Epoch 74/350
391/391 - 25s - loss: 0.3320 - accuracy: 0.8950 - val_loss: 0.4395 - val_accuracy: 0.8703
Epoch 75/350
391/391 - 25s - loss: 0.3209 - accuracy: 0.8992 - val_loss: 0.4514 - val_accuracy: 0.8701
Epoch 76/350
391/391 - 25s - loss: 0.3183 - accuracy: 0.8992 - val_loss: 0.4339 - val_accuracy: 0.8747
Epoch 77/350
391/391 - 25s - loss: 0.3149 - accuracy: 0.9012 - val_loss: 0.4553 - val_accuracy: 0.8717
Epoch 78/350
391/391 - 25s - loss: 0.3171 - accuracy: 0.9009 - val_loss: 0.4641 - val_accuracy: 0.8691
Epoch 79/350
391/391 - 25s - loss: 0.3104 - accuracy: 0.9022 - val_loss: 0.4195 - val_accuracy: 0.8777
Epoch 80/350
391/391 - 25s - loss: 0.3078 - accuracy: 0.9029 - val_loss: 0.4395 - val_accuracy: 0.8785
Epoch 81/350
391/391 - 25s - loss: 0.3152 - accuracy: 0.9020 - val_loss: 0.4304 - val_accuracy: 0.8782
Epoch 82/350
391/391 - 25s - loss: 0.3089 - accuracy: 0.9041 - val_loss: 0.4087 - val_accuracy: 0.8838
Epoch 83/350
391/391 - 25s - loss: 0.3070 - accuracy: 0.9044 - val_loss: 0.4279 - val_accuracy: 0.8764
Epoch 84/350
391/391 - 25s - loss: 0.3023 - accuracy: 0.9066 - val_loss: 0.4086 - val_accuracy: 0.8815
Epoch 85/350
391/391 - 25s - loss: 0.3009 - accuracy: 0.9060 - val_loss: 0.4271 - val_accuracy: 0.8769
Epoch 86/350
391/391 - 25s - loss: 0.2966 - accuracy: 0.9081 - val_loss: 0.4607 - val_accuracy: 0.8725
Epoch 87/350
391/391 - 25s - loss: 0.2920 - accuracy: 0.9105 - val_loss: 0.4418 - val_accuracy: 0.8747
Epoch 88/350
391/391 - 25s - loss: 0.2871 - accuracy: 0.9118 - val_loss: 0.4552 - val_accuracy: 0.8758
Epoch 89/350
391/391 - 25s - loss: 0.2882 - accuracy: 0.9096 - val_loss: 0.4384 - val_accuracy: 0.8770
Epoch 90/350
391/391 - 25s - loss: 0.2837 - accuracy: 0.9124 - val_loss: 0.4621 - val_accuracy: 0.8776
Epoch 91/350
391/391 - 25s - loss: 0.2849 - accuracy: 0.9120 - val_loss: 0.4372 - val_accuracy: 0.8753
Epoch 92/350
391/391 - 25s - loss: 0.2868 - accuracy: 0.9124 - val_loss: 0.4638 - val_accuracy: 0.8712
Epoch 93/350
391/391 - 25s - loss: 0.2796 - accuracy: 0.9134 - val_loss: 0.4171 - val_accuracy: 0.8864
Epoch 94/350
391/391 - 25s - loss: 0.2854 - accuracy: 0.9129 - val_loss: 0.4321 - val_accuracy: 0.8767
Epoch 95/350
391/391 - 25s - loss: 0.2751 - accuracy: 0.9161 - val_loss: 0.4337 - val_accuracy: 0.8808
Epoch 96/350
391/391 - 25s - loss: 0.2752 - accuracy: 0.9154 - val_loss: 0.4191 - val_accuracy: 0.8849
Epoch 97/350
391/391 - 25s - loss: 0.2718 - accuracy: 0.9183 - val_loss: 0.4353 - val_accuracy: 0.8819
Epoch 98/350
391/391 - 25s - loss: 0.2717 - accuracy: 0.9168 - val_loss: 0.4308 - val_accuracy: 0.8853
Epoch 99/350
391/391 - 25s - loss: 0.2734 - accuracy: 0.9160 - val_loss: 0.4050 - val_accuracy: 0.8872
Epoch 100/350


Snapshot weight 3 shuffle 3 at epoch 100
Layer 11
Getting activations...


391/391 - 26s - loss: 0.2638 - accuracy: 0.9201 - val_loss: 0.4157 - val_accuracy: 0.8846
Epoch 101/350
391/391 - 25s - loss: 0.2659 - accuracy: 0.9189 - val_loss: 0.4586 - val_accuracy: 0.8718
Epoch 102/350
391/391 - 25s - loss: 0.2673 - accuracy: 0.9191 - val_loss: 0.4160 - val_accuracy: 0.8853
Epoch 103/350
391/391 - 25s - loss: 0.2601 - accuracy: 0.9218 - val_loss: 0.4281 - val_accuracy: 0.8826
Epoch 104/350
391/391 - 25s - loss: 0.2617 - accuracy: 0.9210 - val_loss: 0.4343 - val_accuracy: 0.8863
Epoch 105/350
391/391 - 25s - loss: 0.2600 - accuracy: 0.9226 - val_loss: 0.4587 - val_accuracy: 0.8787
Epoch 106/350
391/391 - 25s - loss: 0.2554 - accuracy: 0.9230 - val_loss: 0.4470 - val_accuracy: 0.8821
Epoch 107/350
391/391 - 25s - loss: 0.2534 - accuracy: 0.9224 - val_loss: 0.4490 - val_accuracy: 0.8763
Epoch 108/350
391/391 - 25s - loss: 0.2546 - accuracy: 0.9232 - val_loss: 0.4442 - val_accuracy: 0.8755
Epoch 109/350
391/391 - 25s - loss: 0.2493 - accuracy: 0.9265 - val_loss: 0.4584 - val_accuracy: 0.8824
Epoch 110/350
391/391 - 25s - loss: 0.2503 - accuracy: 0.9247 - val_loss: 0.4152 - val_accuracy: 0.8829
Epoch 111/350
391/391 - 25s - loss: 0.2472 - accuracy: 0.9252 - val_loss: 0.4339 - val_accuracy: 0.8869
Epoch 112/350
391/391 - 25s - loss: 0.2490 - accuracy: 0.9263 - val_loss: 0.4446 - val_accuracy: 0.8837
Epoch 113/350
391/391 - 25s - loss: 0.2462 - accuracy: 0.9277 - val_loss: 0.4768 - val_accuracy: 0.8762
Epoch 114/350
391/391 - 25s - loss: 0.2425 - accuracy: 0.9274 - val_loss: 0.4291 - val_accuracy: 0.8843
Epoch 115/350
391/391 - 25s - loss: 0.2438 - accuracy: 0.9270 - val_loss: 0.4488 - val_accuracy: 0.8835
Epoch 116/350
391/391 - 25s - loss: 0.2376 - accuracy: 0.9292 - val_loss: 0.4543 - val_accuracy: 0.8838
Epoch 117/350
391/391 - 25s - loss: 0.2406 - accuracy: 0.9301 - val_loss: 0.4424 - val_accuracy: 0.8905
Epoch 118/350
391/391 - 25s - loss: 0.2354 - accuracy: 0.9306 - val_loss: 0.4431 - val_accuracy: 0.8829
Epoch 119/350
391/391 - 25s - loss: 0.2406 - accuracy: 0.9281 - val_loss: 0.4259 - val_accuracy: 0.8861
Epoch 120/350
391/391 - 25s - loss: 0.2408 - accuracy: 0.9282 - val_loss: 0.4347 - val_accuracy: 0.8792
Epoch 121/350
391/391 - 25s - loss: 0.2361 - accuracy: 0.9302 - val_loss: 0.4596 - val_accuracy: 0.8864
Epoch 122/350
391/391 - 25s - loss: 0.2330 - accuracy: 0.9336 - val_loss: 0.4496 - val_accuracy: 0.8856
Epoch 123/350
391/391 - 25s - loss: 0.2325 - accuracy: 0.9317 - val_loss: 0.4287 - val_accuracy: 0.8848
Epoch 124/350
391/391 - 25s - loss: 0.2289 - accuracy: 0.9312 - val_loss: 0.4596 - val_accuracy: 0.8851
Epoch 125/350
391/391 - 25s - loss: 0.2302 - accuracy: 0.9327 - val_loss: 0.5349 - val_accuracy: 0.8698
Epoch 126/350
391/391 - 25s - loss: 0.2255 - accuracy: 0.9348 - val_loss: 0.4452 - val_accuracy: 0.8871
Epoch 127/350
391/391 - 25s - loss: 0.2292 - accuracy: 0.9329 - val_loss: 0.4273 - val_accuracy: 0.8883
Epoch 128/350
391/391 - 25s - loss: 0.2241 - accuracy: 0.9344 - val_loss: 0.4576 - val_accuracy: 0.8836
Epoch 129/350
391/391 - 25s - loss: 0.2253 - accuracy: 0.9337 - val_loss: 0.4358 - val_accuracy: 0.8890
Epoch 130/350
391/391 - 25s - loss: 0.2245 - accuracy: 0.9347 - val_loss: 0.4549 - val_accuracy: 0.8823
Epoch 131/350
391/391 - 25s - loss: 0.2234 - accuracy: 0.9337 - val_loss: 0.4865 - val_accuracy: 0.8800
Epoch 132/350
391/391 - 25s - loss: 0.2206 - accuracy: 0.9365 - val_loss: 0.4527 - val_accuracy: 0.8880
Epoch 133/350
391/391 - 25s - loss: 0.2179 - accuracy: 0.9368 - val_loss: 0.4614 - val_accuracy: 0.8862
Epoch 134/350
391/391 - 25s - loss: 0.2191 - accuracy: 0.9363 - val_loss: 0.4126 - val_accuracy: 0.8938
Epoch 135/350
391/391 - 25s - loss: 0.2143 - accuracy: 0.9393 - val_loss: 0.4787 - val_accuracy: 0.8842
Epoch 136/350
391/391 - 25s - loss: 0.2140 - accuracy: 0.9377 - val_loss: 0.4267 - val_accuracy: 0.8924
Epoch 137/350
391/391 - 25s - loss: 0.2166 - accuracy: 0.9390 - val_loss: 0.4416 - val_accuracy: 0.8838
Epoch 138/350
391/391 - 25s - loss: 0.2167 - accuracy: 0.9384 - val_loss: 0.4302 - val_accuracy: 0.8876
Epoch 139/350
391/391 - 25s - loss: 0.2122 - accuracy: 0.9384 - val_loss: 0.4361 - val_accuracy: 0.8920
Epoch 140/350
391/391 - 25s - loss: 0.2124 - accuracy: 0.9391 - val_loss: 0.4461 - val_accuracy: 0.8900
Epoch 141/350
391/391 - 25s - loss: 0.2122 - accuracy: 0.9394 - val_loss: 0.4348 - val_accuracy: 0.8875
Epoch 142/350
391/391 - 25s - loss: 0.2114 - accuracy: 0.9405 - val_loss: 0.4506 - val_accuracy: 0.8886
Epoch 143/350
391/391 - 25s - loss: 0.2085 - accuracy: 0.9408 - val_loss: 0.4681 - val_accuracy: 0.8854
Epoch 144/350
391/391 - 25s - loss: 0.2093 - accuracy: 0.9402 - val_loss: 0.4330 - val_accuracy: 0.8894
Epoch 145/350
391/391 - 25s - loss: 0.2081 - accuracy: 0.9415 - val_loss: 0.4550 - val_accuracy: 0.8901
Epoch 146/350
391/391 - 25s - loss: 0.2061 - accuracy: 0.9410 - val_loss: 0.4405 - val_accuracy: 0.8917
Epoch 147/350
391/391 - 25s - loss: 0.2037 - accuracy: 0.9423 - val_loss: 0.4294 - val_accuracy: 0.8952
Epoch 148/350
391/391 - 25s - loss: 0.2047 - accuracy: 0.9420 - val_loss: 0.4309 - val_accuracy: 0.8943
Epoch 149/350
391/391 - 25s - loss: 0.2023 - accuracy: 0.9425 - val_loss: 0.4437 - val_accuracy: 0.8905
Epoch 150/350


Snapshot weight 3 shuffle 3 at epoch 150
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1997 - accuracy: 0.9436 - val_loss: 0.4431 - val_accuracy: 0.8930
Epoch 151/350
391/391 - 25s - loss: 0.2052 - accuracy: 0.9415 - val_loss: 0.4643 - val_accuracy: 0.8890
Epoch 152/350
391/391 - 25s - loss: 0.2001 - accuracy: 0.9444 - val_loss: 0.4228 - val_accuracy: 0.8972
Epoch 153/350
391/391 - 25s - loss: 0.1994 - accuracy: 0.9440 - val_loss: 0.4576 - val_accuracy: 0.8924
Epoch 154/350
391/391 - 25s - loss: 0.2044 - accuracy: 0.9423 - val_loss: 0.4506 - val_accuracy: 0.8911
Epoch 155/350
391/391 - 25s - loss: 0.1935 - accuracy: 0.9457 - val_loss: 0.4491 - val_accuracy: 0.8908
Epoch 156/350
391/391 - 25s - loss: 0.1957 - accuracy: 0.9456 - val_loss: 0.4278 - val_accuracy: 0.8933
Epoch 157/350
391/391 - 25s - loss: 0.1938 - accuracy: 0.9461 - val_loss: 0.4743 - val_accuracy: 0.8861
Epoch 158/350
391/391 - 25s - loss: 0.1968 - accuracy: 0.9457 - val_loss: 0.4486 - val_accuracy: 0.8927
Epoch 159/350
391/391 - 25s - loss: 0.1969 - accuracy: 0.9450 - val_loss: 0.4405 - val_accuracy: 0.8926
Epoch 160/350
391/391 - 25s - loss: 0.1938 - accuracy: 0.9460 - val_loss: 0.4436 - val_accuracy: 0.8946
Epoch 161/350
391/391 - 25s - loss: 0.1875 - accuracy: 0.9493 - val_loss: 0.4718 - val_accuracy: 0.8900
Epoch 162/350
391/391 - 25s - loss: 0.1897 - accuracy: 0.9468 - val_loss: 0.4530 - val_accuracy: 0.8939
Epoch 163/350
391/391 - 25s - loss: 0.1914 - accuracy: 0.9468 - val_loss: 0.4694 - val_accuracy: 0.8942
Epoch 164/350
391/391 - 25s - loss: 0.1889 - accuracy: 0.9470 - val_loss: 0.4513 - val_accuracy: 0.8958
Epoch 165/350
391/391 - 25s - loss: 0.1898 - accuracy: 0.9481 - val_loss: 0.4865 - val_accuracy: 0.8915
Epoch 166/350
391/391 - 25s - loss: 0.1899 - accuracy: 0.9484 - val_loss: 0.4385 - val_accuracy: 0.8922
Epoch 167/350
391/391 - 25s - loss: 0.1851 - accuracy: 0.9503 - val_loss: 0.4295 - val_accuracy: 0.8967
Epoch 168/350
391/391 - 25s - loss: 0.1836 - accuracy: 0.9505 - val_loss: 0.4302 - val_accuracy: 0.8959
Epoch 169/350
391/391 - 25s - loss: 0.1889 - accuracy: 0.9491 - val_loss: 0.4314 - val_accuracy: 0.8961
Epoch 170/350
391/391 - 25s - loss: 0.1843 - accuracy: 0.9506 - val_loss: 0.5217 - val_accuracy: 0.8853
Epoch 171/350
391/391 - 25s - loss: 0.1824 - accuracy: 0.9497 - val_loss: 0.4482 - val_accuracy: 0.8982
Epoch 172/350
391/391 - 25s - loss: 0.1858 - accuracy: 0.9481 - val_loss: 0.4704 - val_accuracy: 0.8913
Epoch 173/350
391/391 - 25s - loss: 0.1840 - accuracy: 0.9501 - val_loss: 0.4347 - val_accuracy: 0.8961
Epoch 174/350
391/391 - 25s - loss: 0.1861 - accuracy: 0.9484 - val_loss: 0.4511 - val_accuracy: 0.8951
Epoch 175/350
391/391 - 25s - loss: 0.1812 - accuracy: 0.9509 - val_loss: 0.4936 - val_accuracy: 0.8928
Epoch 176/350
391/391 - 25s - loss: 0.1831 - accuracy: 0.9508 - val_loss: 0.4683 - val_accuracy: 0.8931
Epoch 177/350
391/391 - 25s - loss: 0.1820 - accuracy: 0.9505 - val_loss: 0.5078 - val_accuracy: 0.8895
Epoch 178/350
391/391 - 25s - loss: 0.1808 - accuracy: 0.9512 - val_loss: 0.4397 - val_accuracy: 0.8973
Epoch 179/350
391/391 - 25s - loss: 0.1775 - accuracy: 0.9532 - val_loss: 0.4706 - val_accuracy: 0.8949
Epoch 180/350
391/391 - 25s - loss: 0.1785 - accuracy: 0.9532 - val_loss: 0.4802 - val_accuracy: 0.8924
Epoch 181/350
391/391 - 25s - loss: 0.1811 - accuracy: 0.9519 - val_loss: 0.4787 - val_accuracy: 0.8906
Epoch 182/350
391/391 - 25s - loss: 0.1796 - accuracy: 0.9529 - val_loss: 0.4793 - val_accuracy: 0.8941
Epoch 183/350
391/391 - 25s - loss: 0.1790 - accuracy: 0.9523 - val_loss: 0.4937 - val_accuracy: 0.8940
Epoch 184/350
391/391 - 25s - loss: 0.1793 - accuracy: 0.9521 - val_loss: 0.4729 - val_accuracy: 0.8963
Epoch 185/350
391/391 - 25s - loss: 0.1805 - accuracy: 0.9517 - val_loss: 0.5083 - val_accuracy: 0.8850
Epoch 186/350
391/391 - 25s - loss: 0.1738 - accuracy: 0.9544 - val_loss: 0.4371 - val_accuracy: 0.8943
Epoch 187/350
391/391 - 25s - loss: 0.1778 - accuracy: 0.9530 - val_loss: 0.4633 - val_accuracy: 0.8946
Epoch 188/350
391/391 - 25s - loss: 0.1717 - accuracy: 0.9542 - val_loss: 0.5362 - val_accuracy: 0.8907
Epoch 189/350
391/391 - 25s - loss: 0.1803 - accuracy: 0.9524 - val_loss: 0.4494 - val_accuracy: 0.8975
Epoch 190/350
391/391 - 25s - loss: 0.1707 - accuracy: 0.9555 - val_loss: 0.4490 - val_accuracy: 0.8993
Epoch 191/350
391/391 - 25s - loss: 0.1719 - accuracy: 0.9553 - val_loss: 0.4606 - val_accuracy: 0.8978
Epoch 192/350
391/391 - 25s - loss: 0.1733 - accuracy: 0.9541 - val_loss: 0.4611 - val_accuracy: 0.8974
Epoch 193/350
391/391 - 25s - loss: 0.1756 - accuracy: 0.9539 - val_loss: 0.4987 - val_accuracy: 0.8959
Epoch 194/350
391/391 - 25s - loss: 0.1713 - accuracy: 0.9544 - val_loss: 0.4914 - val_accuracy: 0.8918
Epoch 195/350
391/391 - 25s - loss: 0.1679 - accuracy: 0.9564 - val_loss: 0.4996 - val_accuracy: 0.8921
Epoch 196/350
391/391 - 26s - loss: 0.1716 - accuracy: 0.9560 - val_loss: 0.4842 - val_accuracy: 0.8958
Epoch 197/350
391/391 - 25s - loss: 0.1725 - accuracy: 0.9548 - val_loss: 0.4746 - val_accuracy: 0.8928
Epoch 198/350
391/391 - 25s - loss: 0.1713 - accuracy: 0.9551 - val_loss: 0.4762 - val_accuracy: 0.8962
Epoch 199/350
391/391 - 25s - loss: 0.1693 - accuracy: 0.9557 - val_loss: 0.4249 - val_accuracy: 0.9034
Epoch 200/350


Snapshot weight 3 shuffle 3 at epoch 200
Layer 11
Getting activations...


391/391 - 26s - loss: 0.1731 - accuracy: 0.9544 - val_loss: 0.4957 - val_accuracy: 0.8931
Epoch 201/350
391/391 - 25s - loss: 0.1434 - accuracy: 0.9655 - val_loss: 0.4560 - val_accuracy: 0.9025
Epoch 202/350
391/391 - 25s - loss: 0.1316 - accuracy: 0.9694 - val_loss: 0.4589 - val_accuracy: 0.9059
Epoch 203/350
391/391 - 25s - loss: 0.1260 - accuracy: 0.9712 - val_loss: 0.4602 - val_accuracy: 0.9055
Epoch 204/350
391/391 - 25s - loss: 0.1285 - accuracy: 0.9702 - val_loss: 0.4602 - val_accuracy: 0.9045
Epoch 205/350
391/391 - 25s - loss: 0.1254 - accuracy: 0.9719 - val_loss: 0.4662 - val_accuracy: 0.9057
Epoch 206/350
391/391 - 25s - loss: 0.1226 - accuracy: 0.9723 - val_loss: 0.4624 - val_accuracy: 0.9056
Epoch 207/350
391/391 - 26s - loss: 0.1195 - accuracy: 0.9738 - val_loss: 0.4721 - val_accuracy: 0.9066
Epoch 208/350
391/391 - 25s - loss: 0.1177 - accuracy: 0.9743 - val_loss: 0.4759 - val_accuracy: 0.9052
Epoch 209/350
391/391 - 25s - loss: 0.1177 - accuracy: 0.9752 - val_loss: 0.4770 - val_accuracy: 0.9075
Epoch 210/350
391/391 - 25s - loss: 0.1203 - accuracy: 0.9734 - val_loss: 0.4803 - val_accuracy: 0.9044
Epoch 211/350
391/391 - 25s - loss: 0.1187 - accuracy: 0.9738 - val_loss: 0.4768 - val_accuracy: 0.9045
Epoch 212/350
391/391 - 25s - loss: 0.1158 - accuracy: 0.9755 - val_loss: 0.4815 - val_accuracy: 0.9056
Epoch 213/350
391/391 - 25s - loss: 0.1207 - accuracy: 0.9741 - val_loss: 0.4796 - val_accuracy: 0.9070
Epoch 214/350
391/391 - 25s - loss: 0.1168 - accuracy: 0.9752 - val_loss: 0.4797 - val_accuracy: 0.9074
Epoch 215/350
391/391 - 25s - loss: 0.1163 - accuracy: 0.9749 - val_loss: 0.4812 - val_accuracy: 0.9048
Epoch 216/350
391/391 - 25s - loss: 0.1154 - accuracy: 0.9749 - val_loss: 0.4855 - val_accuracy: 0.9056
Epoch 217/350
391/391 - 25s - loss: 0.1134 - accuracy: 0.9765 - val_loss: 0.4845 - val_accuracy: 0.9069
Epoch 218/350
391/391 - 25s - loss: 0.1157 - accuracy: 0.9757 - val_loss: 0.4892 - val_accuracy: 0.9053
Epoch 219/350
391/391 - 25s - loss: 0.1136 - accuracy: 0.9759 - val_loss: 0.4854 - val_accuracy: 0.9068
Epoch 220/350
391/391 - 25s - loss: 0.1123 - accuracy: 0.9767 - val_loss: 0.4862 - val_accuracy: 0.9063
Epoch 221/350
391/391 - 25s - loss: 0.1132 - accuracy: 0.9761 - val_loss: 0.4941 - val_accuracy: 0.9057
Epoch 222/350
391/391 - 25s - loss: 0.1133 - accuracy: 0.9765 - val_loss: 0.4853 - val_accuracy: 0.9054
Epoch 223/350
391/391 - 25s - loss: 0.1124 - accuracy: 0.9762 - val_loss: 0.4876 - val_accuracy: 0.9050
Epoch 224/350
391/391 - 25s - loss: 0.1114 - accuracy: 0.9777 - val_loss: 0.4921 - val_accuracy: 0.9030
Epoch 225/350
391/391 - 25s - loss: 0.1122 - accuracy: 0.9765 - val_loss: 0.5034 - val_accuracy: 0.9052
Epoch 226/350
391/391 - 25s - loss: 0.1116 - accuracy: 0.9766 - val_loss: 0.4991 - val_accuracy: 0.9043
Epoch 227/350
391/391 - 25s - loss: 0.1137 - accuracy: 0.9760 - val_loss: 0.4893 - val_accuracy: 0.9061
Epoch 228/350
391/391 - 25s - loss: 0.1113 - accuracy: 0.9769 - val_loss: 0.4935 - val_accuracy: 0.9068
Epoch 229/350
391/391 - 25s - loss: 0.1101 - accuracy: 0.9775 - val_loss: 0.4987 - val_accuracy: 0.9048
Epoch 230/350
391/391 - 25s - loss: 0.1115 - accuracy: 0.9765 - val_loss: 0.4941 - val_accuracy: 0.9049
Epoch 231/350
391/391 - 26s - loss: 0.1112 - accuracy: 0.9770 - val_loss: 0.4957 - val_accuracy: 0.9050
Epoch 232/350
391/391 - 25s - loss: 0.1106 - accuracy: 0.9772 - val_loss: 0.4929 - val_accuracy: 0.9065
Epoch 233/350
391/391 - 25s - loss: 0.1111 - accuracy: 0.9775 - val_loss: 0.4896 - val_accuracy: 0.9071
Epoch 234/350
391/391 - 25s - loss: 0.1113 - accuracy: 0.9772 - val_loss: 0.4910 - val_accuracy: 0.9053
Epoch 235/350
391/391 - 25s - loss: 0.1066 - accuracy: 0.9783 - val_loss: 0.5003 - val_accuracy: 0.9048
Epoch 236/350
391/391 - 25s - loss: 0.1073 - accuracy: 0.9777 - val_loss: 0.4999 - val_accuracy: 0.9060
Epoch 237/350
391/391 - 25s - loss: 0.1085 - accuracy: 0.9777 - val_loss: 0.4977 - val_accuracy: 0.9074
Epoch 238/350
391/391 - 25s - loss: 0.1112 - accuracy: 0.9766 - val_loss: 0.4988 - val_accuracy: 0.9059
Epoch 239/350
391/391 - 25s - loss: 0.1080 - accuracy: 0.9777 - val_loss: 0.4982 - val_accuracy: 0.9054
Epoch 240/350
391/391 - 25s - loss: 0.1094 - accuracy: 0.9769 - val_loss: 0.5072 - val_accuracy: 0.9054
Epoch 241/350
391/391 - 25s - loss: 0.1067 - accuracy: 0.9784 - val_loss: 0.5024 - val_accuracy: 0.9059
Epoch 242/350
391/391 - 25s - loss: 0.1066 - accuracy: 0.9781 - val_loss: 0.5033 - val_accuracy: 0.9064
Epoch 243/350
391/391 - 25s - loss: 0.1081 - accuracy: 0.9779 - val_loss: 0.4991 - val_accuracy: 0.9057
Epoch 244/350
391/391 - 25s - loss: 0.1075 - accuracy: 0.9777 - val_loss: 0.4998 - val_accuracy: 0.9076
Epoch 245/350
391/391 - 25s - loss: 0.1074 - accuracy: 0.9782 - val_loss: 0.5080 - val_accuracy: 0.9061
Epoch 246/350
391/391 - 25s - loss: 0.1084 - accuracy: 0.9781 - val_loss: 0.4991 - val_accuracy: 0.9061
Epoch 247/350
391/391 - 25s - loss: 0.1072 - accuracy: 0.9788 - val_loss: 0.5056 - val_accuracy: 0.9066
Epoch 248/350
391/391 - 25s - loss: 0.1087 - accuracy: 0.9779 - val_loss: 0.4933 - val_accuracy: 0.9073
Epoch 249/350
391/391 - 25s - loss: 0.1051 - accuracy: 0.9796 - val_loss: 0.5067 - val_accuracy: 0.9067
Epoch 250/350


Snapshot weight 3 shuffle 3 at epoch 250
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1089 - accuracy: 0.9776 - val_loss: 0.4982 - val_accuracy: 0.9082
Epoch 251/350
391/391 - 25s - loss: 0.1055 - accuracy: 0.9788 - val_loss: 0.5020 - val_accuracy: 0.9088
Epoch 252/350
391/391 - 25s - loss: 0.1072 - accuracy: 0.9780 - val_loss: 0.5019 - val_accuracy: 0.9072
Epoch 253/350
391/391 - 25s - loss: 0.1036 - accuracy: 0.9792 - val_loss: 0.5028 - val_accuracy: 0.9073
Epoch 254/350
391/391 - 25s - loss: 0.1059 - accuracy: 0.9793 - val_loss: 0.5043 - val_accuracy: 0.9068
Epoch 255/350
391/391 - 25s - loss: 0.1057 - accuracy: 0.9795 - val_loss: 0.5044 - val_accuracy: 0.9071
Epoch 256/350
391/391 - 25s - loss: 0.1044 - accuracy: 0.9791 - val_loss: 0.5028 - val_accuracy: 0.9071
Epoch 257/350
391/391 - 25s - loss: 0.1070 - accuracy: 0.9780 - val_loss: 0.5032 - val_accuracy: 0.9063
Epoch 258/350
391/391 - 25s - loss: 0.1041 - accuracy: 0.9787 - val_loss: 0.5020 - val_accuracy: 0.9066
Epoch 259/350
391/391 - 25s - loss: 0.1021 - accuracy: 0.9807 - val_loss: 0.5025 - val_accuracy: 0.9066
Epoch 260/350
391/391 - 25s - loss: 0.1020 - accuracy: 0.9806 - val_loss: 0.5046 - val_accuracy: 0.9073
Epoch 261/350
391/391 - 25s - loss: 0.1045 - accuracy: 0.9789 - val_loss: 0.5037 - val_accuracy: 0.9075
Epoch 262/350
391/391 - 25s - loss: 0.1011 - accuracy: 0.9810 - val_loss: 0.5058 - val_accuracy: 0.9068
Epoch 263/350
391/391 - 25s - loss: 0.1030 - accuracy: 0.9795 - val_loss: 0.5052 - val_accuracy: 0.9069
Epoch 264/350
391/391 - 25s - loss: 0.1023 - accuracy: 0.9803 - val_loss: 0.5055 - val_accuracy: 0.9068
Epoch 265/350
391/391 - 25s - loss: 0.1029 - accuracy: 0.9796 - val_loss: 0.5061 - val_accuracy: 0.9069
Epoch 266/350
391/391 - 25s - loss: 0.1061 - accuracy: 0.9791 - val_loss: 0.5025 - val_accuracy: 0.9067
Epoch 267/350
391/391 - 25s - loss: 0.1011 - accuracy: 0.9809 - val_loss: 0.5042 - val_accuracy: 0.9058
Epoch 268/350
391/391 - 25s - loss: 0.1022 - accuracy: 0.9805 - val_loss: 0.5044 - val_accuracy: 0.9061
Epoch 269/350
391/391 - 25s - loss: 0.1043 - accuracy: 0.9793 - val_loss: 0.5048 - val_accuracy: 0.9054
Epoch 270/350
391/391 - 25s - loss: 0.1051 - accuracy: 0.9787 - val_loss: 0.5053 - val_accuracy: 0.9063
Epoch 271/350
391/391 - 25s - loss: 0.1039 - accuracy: 0.9791 - val_loss: 0.5059 - val_accuracy: 0.9066
Epoch 272/350
391/391 - 25s - loss: 0.1031 - accuracy: 0.9798 - val_loss: 0.5037 - val_accuracy: 0.9072
Epoch 273/350
391/391 - 25s - loss: 0.1029 - accuracy: 0.9799 - val_loss: 0.5058 - val_accuracy: 0.9062
Epoch 274/350
391/391 - 25s - loss: 0.1032 - accuracy: 0.9794 - val_loss: 0.5061 - val_accuracy: 0.9069
Epoch 275/350
391/391 - 25s - loss: 0.1009 - accuracy: 0.9808 - val_loss: 0.5094 - val_accuracy: 0.9064
Epoch 276/350
391/391 - 25s - loss: 0.1011 - accuracy: 0.9804 - val_loss: 0.5050 - val_accuracy: 0.9064
Epoch 277/350
391/391 - 25s - loss: 0.1012 - accuracy: 0.9808 - val_loss: 0.5086 - val_accuracy: 0.9068
Epoch 278/350
391/391 - 25s - loss: 0.1052 - accuracy: 0.9782 - val_loss: 0.5050 - val_accuracy: 0.9063
Epoch 279/350
391/391 - 26s - loss: 0.1025 - accuracy: 0.9801 - val_loss: 0.5094 - val_accuracy: 0.9061
Epoch 280/350
391/391 - 25s - loss: 0.1031 - accuracy: 0.9801 - val_loss: 0.5058 - val_accuracy: 0.9074
Epoch 281/350
391/391 - 25s - loss: 0.1009 - accuracy: 0.9802 - val_loss: 0.5051 - val_accuracy: 0.9066
Epoch 282/350
391/391 - 25s - loss: 0.1032 - accuracy: 0.9790 - val_loss: 0.5058 - val_accuracy: 0.9065
Epoch 283/350
391/391 - 25s - loss: 0.1009 - accuracy: 0.9804 - val_loss: 0.5090 - val_accuracy: 0.9064
Epoch 284/350
391/391 - 25s - loss: 0.1026 - accuracy: 0.9803 - val_loss: 0.5098 - val_accuracy: 0.9060
Epoch 285/350
391/391 - 25s - loss: 0.1048 - accuracy: 0.9793 - val_loss: 0.5061 - val_accuracy: 0.9069
Epoch 286/350
391/391 - 25s - loss: 0.1004 - accuracy: 0.9805 - val_loss: 0.5088 - val_accuracy: 0.9064
Epoch 287/350
391/391 - 25s - loss: 0.1028 - accuracy: 0.9800 - val_loss: 0.5085 - val_accuracy: 0.9061
Epoch 288/350
391/391 - 25s - loss: 0.1016 - accuracy: 0.9803 - val_loss: 0.5099 - val_accuracy: 0.9063
Epoch 289/350
391/391 - 25s - loss: 0.1024 - accuracy: 0.9794 - val_loss: 0.5080 - val_accuracy: 0.9069
Epoch 290/350
391/391 - 25s - loss: 0.1021 - accuracy: 0.9807 - val_loss: 0.5083 - val_accuracy: 0.9066
Epoch 291/350
391/391 - 26s - loss: 0.1011 - accuracy: 0.9799 - val_loss: 0.5072 - val_accuracy: 0.9066
Epoch 292/350
391/391 - 25s - loss: 0.1008 - accuracy: 0.9808 - val_loss: 0.5084 - val_accuracy: 0.9070
Epoch 293/350
391/391 - 25s - loss: 0.1025 - accuracy: 0.9803 - val_loss: 0.5091 - val_accuracy: 0.9065
Epoch 294/350
391/391 - 25s - loss: 0.1008 - accuracy: 0.9804 - val_loss: 0.5097 - val_accuracy: 0.9064
Epoch 295/350
391/391 - 25s - loss: 0.1040 - accuracy: 0.9794 - val_loss: 0.5071 - val_accuracy: 0.9055
Epoch 296/350
391/391 - 25s - loss: 0.1031 - accuracy: 0.9791 - val_loss: 0.5046 - val_accuracy: 0.9070
Epoch 297/350
391/391 - 25s - loss: 0.0999 - accuracy: 0.9816 - val_loss: 0.5058 - val_accuracy: 0.9067
Epoch 298/350
391/391 - 25s - loss: 0.1033 - accuracy: 0.9796 - val_loss: 0.5077 - val_accuracy: 0.9059
Epoch 299/350
391/391 - 25s - loss: 0.1019 - accuracy: 0.9798 - val_loss: 0.5088 - val_accuracy: 0.9053
Epoch 300/350


Snapshot weight 3 shuffle 3 at epoch 300
Layer 11
Getting activations...


391/391 - 26s - loss: 0.1025 - accuracy: 0.9804 - val_loss: 0.5084 - val_accuracy: 0.9059
Epoch 301/350
391/391 - 25s - loss: 0.1008 - accuracy: 0.9810 - val_loss: 0.5082 - val_accuracy: 0.9060
Epoch 302/350
391/391 - 26s - loss: 0.1020 - accuracy: 0.9801 - val_loss: 0.5081 - val_accuracy: 0.9059
Epoch 303/350
391/391 - 25s - loss: 0.1024 - accuracy: 0.9809 - val_loss: 0.5083 - val_accuracy: 0.9058
Epoch 304/350
391/391 - 25s - loss: 0.1034 - accuracy: 0.9789 - val_loss: 0.5077 - val_accuracy: 0.9060
Epoch 305/350
391/391 - 25s - loss: 0.1009 - accuracy: 0.9804 - val_loss: 0.5079 - val_accuracy: 0.9059
Epoch 306/350
391/391 - 25s - loss: 0.1046 - accuracy: 0.9791 - val_loss: 0.5079 - val_accuracy: 0.9059
Epoch 307/350
391/391 - 25s - loss: 0.1013 - accuracy: 0.9798 - val_loss: 0.5076 - val_accuracy: 0.9062
Epoch 308/350
391/391 - 25s - loss: 0.1048 - accuracy: 0.9794 - val_loss: 0.5080 - val_accuracy: 0.9061
Epoch 309/350
391/391 - 25s - loss: 0.1017 - accuracy: 0.9799 - val_loss: 0.5083 - val_accuracy: 0.9057
Epoch 310/350
391/391 - 25s - loss: 0.1043 - accuracy: 0.9796 - val_loss: 0.5077 - val_accuracy: 0.9059
Epoch 311/350
391/391 - 25s - loss: 0.0993 - accuracy: 0.9809 - val_loss: 0.5076 - val_accuracy: 0.9057
Epoch 312/350
391/391 - 25s - loss: 0.0997 - accuracy: 0.9814 - val_loss: 0.5074 - val_accuracy: 0.9057
Epoch 313/350
391/391 - 25s - loss: 0.0990 - accuracy: 0.9809 - val_loss: 0.5074 - val_accuracy: 0.9057
Epoch 314/350
391/391 - 26s - loss: 0.1009 - accuracy: 0.9806 - val_loss: 0.5077 - val_accuracy: 0.9058
Epoch 315/350
391/391 - 25s - loss: 0.1026 - accuracy: 0.9795 - val_loss: 0.5076 - val_accuracy: 0.9054
Epoch 316/350
391/391 - 25s - loss: 0.1003 - accuracy: 0.9802 - val_loss: 0.5080 - val_accuracy: 0.9056
Epoch 317/350
391/391 - 25s - loss: 0.1011 - accuracy: 0.9803 - val_loss: 0.5078 - val_accuracy: 0.9057
Epoch 318/350
391/391 - 25s - loss: 0.1038 - accuracy: 0.9797 - val_loss: 0.5078 - val_accuracy: 0.9062
Epoch 319/350
391/391 - 25s - loss: 0.0999 - accuracy: 0.9810 - val_loss: 0.5077 - val_accuracy: 0.9067
Epoch 320/350
391/391 - 25s - loss: 0.1049 - accuracy: 0.9788 - val_loss: 0.5079 - val_accuracy: 0.9061
Epoch 321/350
391/391 - 26s - loss: 0.0992 - accuracy: 0.9812 - val_loss: 0.5079 - val_accuracy: 0.9064
Epoch 322/350
391/391 - 25s - loss: 0.1031 - accuracy: 0.9802 - val_loss: 0.5083 - val_accuracy: 0.9064
Epoch 323/350
391/391 - 25s - loss: 0.1024 - accuracy: 0.9803 - val_loss: 0.5079 - val_accuracy: 0.9059
Epoch 324/350
391/391 - 25s - loss: 0.1020 - accuracy: 0.9806 - val_loss: 0.5078 - val_accuracy: 0.9057
Epoch 325/350
391/391 - 25s - loss: 0.1018 - accuracy: 0.9794 - val_loss: 0.5080 - val_accuracy: 0.9060
Epoch 326/350
391/391 - 25s - loss: 0.0998 - accuracy: 0.9809 - val_loss: 0.5082 - val_accuracy: 0.9056
Epoch 327/350
391/391 - 25s - loss: 0.1014 - accuracy: 0.9800 - val_loss: 0.5082 - val_accuracy: 0.9057
Epoch 328/350
391/391 - 25s - loss: 0.1025 - accuracy: 0.9797 - val_loss: 0.5083 - val_accuracy: 0.9054
Epoch 329/350
391/391 - 25s - loss: 0.1013 - accuracy: 0.9806 - val_loss: 0.5083 - val_accuracy: 0.9056
Epoch 330/350
391/391 - 25s - loss: 0.1015 - accuracy: 0.9808 - val_loss: 0.5081 - val_accuracy: 0.9054
Epoch 331/350
391/391 - 25s - loss: 0.0986 - accuracy: 0.9816 - val_loss: 0.5086 - val_accuracy: 0.9053
Epoch 332/350
391/391 - 25s - loss: 0.1000 - accuracy: 0.9811 - val_loss: 0.5083 - val_accuracy: 0.9059
Epoch 333/350
391/391 - 25s - loss: 0.1028 - accuracy: 0.9801 - val_loss: 0.5084 - val_accuracy: 0.9058
Epoch 334/350
391/391 - 25s - loss: 0.1010 - accuracy: 0.9805 - val_loss: 0.5081 - val_accuracy: 0.9058
Epoch 335/350
391/391 - 25s - loss: 0.1005 - accuracy: 0.9811 - val_loss: 0.5081 - val_accuracy: 0.9061
Epoch 336/350
391/391 - 25s - loss: 0.1022 - accuracy: 0.9798 - val_loss: 0.5081 - val_accuracy: 0.9060
Epoch 337/350
391/391 - 25s - loss: 0.1009 - accuracy: 0.9802 - val_loss: 0.5086 - val_accuracy: 0.9058
Epoch 338/350
391/391 - 25s - loss: 0.1032 - accuracy: 0.9798 - val_loss: 0.5084 - val_accuracy: 0.9055
Epoch 339/350
391/391 - 25s - loss: 0.1030 - accuracy: 0.9789 - val_loss: 0.5083 - val_accuracy: 0.9060
Epoch 340/350
391/391 - 25s - loss: 0.1020 - accuracy: 0.9794 - val_loss: 0.5082 - val_accuracy: 0.9057
Epoch 341/350
391/391 - 25s - loss: 0.1029 - accuracy: 0.9796 - val_loss: 0.5082 - val_accuracy: 0.9059
Epoch 342/350
391/391 - 25s - loss: 0.1021 - accuracy: 0.9805 - val_loss: 0.5083 - val_accuracy: 0.9059
Epoch 343/350
391/391 - 25s - loss: 0.0988 - accuracy: 0.9816 - val_loss: 0.5082 - val_accuracy: 0.9060
Epoch 344/350
391/391 - 25s - loss: 0.1030 - accuracy: 0.9801 - val_loss: 0.5080 - val_accuracy: 0.9057
Epoch 345/350
391/391 - 25s - loss: 0.0999 - accuracy: 0.9805 - val_loss: 0.5084 - val_accuracy: 0.9058
Epoch 346/350
391/391 - 25s - loss: 0.1012 - accuracy: 0.9801 - val_loss: 0.5087 - val_accuracy: 0.9053
Epoch 347/350
391/391 - 25s - loss: 0.1025 - accuracy: 0.9797 - val_loss: 0.5090 - val_accuracy: 0.9050
Epoch 348/350
391/391 - 26s - loss: 0.1022 - accuracy: 0.9801 - val_loss: 0.5091 - val_accuracy: 0.9050
Epoch 349/350
391/391 - 26s - loss: 0.1033 - accuracy: 0.9786 - val_loss: 0.5089 - val_accuracy: 0.9049
Epoch 350/350


Snapshot weight 3 shuffle 3 at epoch 350
Layer 11
Getting activations...


391/391 - 26s - loss: 0.1020 - accuracy: 0.9801 - val_loss: 0.5085 - val_accuracy: 0.9052
/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:493: UserWarning: fill_value is not supported and is always 0 for TensorFlow < 2.4.0.
  return py_builtins.overload_of(f)(*args)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-07-02 04:29:55.093882: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
Saving, final validation acc: 0.9052000045776367
