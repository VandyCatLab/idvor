2021-07-01 21:13:26.990042: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 21:15:01.671104: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-07-01 21:15:01.709620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-01 21:15:01.709696: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 21:15:01.755570: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-01 21:15:01.777597: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-01 21:15:01.786339: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-01 21:15:01.833575: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-01 21:15:01.842796: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-01 21:15:01.929209: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-01 21:15:01.937338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-01 21:15:01.941461: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-01 21:15:01.958920: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600150000 Hz
2021-07-01 21:15:01.959069: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x554ada0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-07-01 21:15:01.959090: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-07-01 21:15:02.124142: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x552bdc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-07-01 21:15:02.124205: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN X (Pascal), Compute Capability 6.1
2021-07-01 21:15:02.126780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-01 21:15:02.126835: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 21:15:02.126879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-01 21:15:02.126896: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-01 21:15:02.126912: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-01 21:15:02.126929: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-01 21:15:02.126944: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-01 21:15:02.127703: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-01 21:15:02.129521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-01 21:15:02.131370: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 21:15:04.057718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-01 21:15:04.057790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-07-01 21:15:04.057803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-07-01 21:15:04.070354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11228 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
2021-07-01 21:15:09.888923: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-01 21:15:12.480548: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
Using model index: 21
Making train data...
GCN...
ZCA...
Done!
Making test data...
Done!
Epoch 1/350


Snapshot weight 1 shuffle 2 at epoch 1
Layer 11
Getting activations...


391/391 - 25s - loss: 2.3168 - accuracy: 0.1131 - val_loss: 2.2599 - val_accuracy: 0.1927
Epoch 2/350


Snapshot weight 1 shuffle 2 at epoch 2
Layer 11
Getting activations...


391/391 - 25s - loss: 2.2002 - accuracy: 0.2064 - val_loss: 2.1229 - val_accuracy: 0.2443
Epoch 3/350


Snapshot weight 1 shuffle 2 at epoch 3
Layer 11
Getting activations...


391/391 - 25s - loss: 2.0181 - accuracy: 0.2977 - val_loss: 1.8477 - val_accuracy: 0.3634
Epoch 4/350


Snapshot weight 1 shuffle 2 at epoch 4
Layer 11
Getting activations...


391/391 - 25s - loss: 1.7528 - accuracy: 0.3906 - val_loss: 1.6591 - val_accuracy: 0.4440
Epoch 5/350


Snapshot weight 1 shuffle 2 at epoch 5
Layer 11
Getting activations...


391/391 - 25s - loss: 1.6013 - accuracy: 0.4610 - val_loss: 1.5393 - val_accuracy: 0.4860
Epoch 6/350


Snapshot weight 1 shuffle 2 at epoch 6
Layer 11
Getting activations...


391/391 - 25s - loss: 1.4871 - accuracy: 0.5097 - val_loss: 1.3857 - val_accuracy: 0.5499
Epoch 7/350


Snapshot weight 1 shuffle 2 at epoch 7
Layer 11
Getting activations...


391/391 - 25s - loss: 1.3925 - accuracy: 0.5417 - val_loss: 1.3423 - val_accuracy: 0.5633
Epoch 8/350


Snapshot weight 1 shuffle 2 at epoch 8
Layer 11
Getting activations...


391/391 - 25s - loss: 1.2764 - accuracy: 0.5701 - val_loss: 1.4351 - val_accuracy: 0.5570
Epoch 9/350


Snapshot weight 1 shuffle 2 at epoch 9
Layer 11
Getting activations...


391/391 - 25s - loss: 1.1435 - accuracy: 0.6054 - val_loss: 1.1621 - val_accuracy: 0.6089
Epoch 10/350


Snapshot weight 1 shuffle 2 at epoch 10
Layer 11
Getting activations...


391/391 - 25s - loss: 1.0748 - accuracy: 0.6302 - val_loss: 1.0954 - val_accuracy: 0.6323
Epoch 11/350
391/391 - 24s - loss: 1.0176 - accuracy: 0.6488 - val_loss: 0.9481 - val_accuracy: 0.6822
Epoch 12/350
391/391 - 25s - loss: 0.9785 - accuracy: 0.6621 - val_loss: 0.9425 - val_accuracy: 0.6853
Epoch 13/350
391/391 - 25s - loss: 0.9270 - accuracy: 0.6832 - val_loss: 0.8518 - val_accuracy: 0.7085
Epoch 14/350
391/391 - 25s - loss: 0.8909 - accuracy: 0.6961 - val_loss: 0.9577 - val_accuracy: 0.6930
Epoch 15/350
391/391 - 25s - loss: 0.8494 - accuracy: 0.7105 - val_loss: 0.8956 - val_accuracy: 0.6999
Epoch 16/350
391/391 - 25s - loss: 0.8155 - accuracy: 0.7246 - val_loss: 0.7786 - val_accuracy: 0.7421
Epoch 17/350
391/391 - 24s - loss: 0.7925 - accuracy: 0.7326 - val_loss: 0.7445 - val_accuracy: 0.7578
Epoch 18/350
391/391 - 25s - loss: 0.7564 - accuracy: 0.7472 - val_loss: 0.7323 - val_accuracy: 0.7686
Epoch 19/350
391/391 - 25s - loss: 0.7287 - accuracy: 0.7567 - val_loss: 0.7310 - val_accuracy: 0.7631
Epoch 20/350
391/391 - 24s - loss: 0.7143 - accuracy: 0.7627 - val_loss: 0.6869 - val_accuracy: 0.7820
Epoch 21/350
391/391 - 25s - loss: 0.6925 - accuracy: 0.7686 - val_loss: 0.6663 - val_accuracy: 0.7864
Epoch 22/350
391/391 - 25s - loss: 0.6666 - accuracy: 0.7773 - val_loss: 0.6806 - val_accuracy: 0.7825
Epoch 23/350
391/391 - 24s - loss: 0.6498 - accuracy: 0.7847 - val_loss: 0.6278 - val_accuracy: 0.7995
Epoch 24/350
391/391 - 25s - loss: 0.6415 - accuracy: 0.7881 - val_loss: 0.6918 - val_accuracy: 0.7884
Epoch 25/350
391/391 - 24s - loss: 0.6194 - accuracy: 0.7939 - val_loss: 0.6104 - val_accuracy: 0.8015
Epoch 26/350
391/391 - 24s - loss: 0.5985 - accuracy: 0.8021 - val_loss: 0.5969 - val_accuracy: 0.8077
Epoch 27/350
391/391 - 25s - loss: 0.5904 - accuracy: 0.8052 - val_loss: 0.6146 - val_accuracy: 0.8043
Epoch 28/350
391/391 - 25s - loss: 0.5743 - accuracy: 0.8116 - val_loss: 0.5838 - val_accuracy: 0.8171
Epoch 29/350
391/391 - 24s - loss: 0.5728 - accuracy: 0.8132 - val_loss: 0.5212 - val_accuracy: 0.8289
Epoch 30/350
391/391 - 24s - loss: 0.5542 - accuracy: 0.8190 - val_loss: 0.5375 - val_accuracy: 0.8295
Epoch 31/350
391/391 - 25s - loss: 0.5425 - accuracy: 0.8227 - val_loss: 0.6132 - val_accuracy: 0.8116
Epoch 32/350
391/391 - 25s - loss: 0.5309 - accuracy: 0.8254 - val_loss: 0.6167 - val_accuracy: 0.8104
Epoch 33/350
391/391 - 24s - loss: 0.5237 - accuracy: 0.8291 - val_loss: 0.5446 - val_accuracy: 0.8302
Epoch 34/350
391/391 - 24s - loss: 0.5244 - accuracy: 0.8302 - val_loss: 0.5828 - val_accuracy: 0.8196
Epoch 35/350
391/391 - 25s - loss: 0.5113 - accuracy: 0.8313 - val_loss: 0.4955 - val_accuracy: 0.8433
Epoch 36/350
391/391 - 24s - loss: 0.5013 - accuracy: 0.8370 - val_loss: 0.4983 - val_accuracy: 0.8425
Epoch 37/350
391/391 - 25s - loss: 0.4931 - accuracy: 0.8376 - val_loss: 0.4983 - val_accuracy: 0.8397
Epoch 38/350
391/391 - 24s - loss: 0.4864 - accuracy: 0.8410 - val_loss: 0.5326 - val_accuracy: 0.8353
Epoch 39/350
391/391 - 25s - loss: 0.4779 - accuracy: 0.8441 - val_loss: 0.5272 - val_accuracy: 0.8370
Epoch 40/350
391/391 - 25s - loss: 0.4732 - accuracy: 0.8452 - val_loss: 0.4898 - val_accuracy: 0.8460
Epoch 41/350
391/391 - 25s - loss: 0.4664 - accuracy: 0.8482 - val_loss: 0.5356 - val_accuracy: 0.8337
Epoch 42/350
391/391 - 24s - loss: 0.4523 - accuracy: 0.8546 - val_loss: 0.4922 - val_accuracy: 0.8499
Epoch 43/350
391/391 - 24s - loss: 0.4479 - accuracy: 0.8559 - val_loss: 0.5196 - val_accuracy: 0.8471
Epoch 44/350
391/391 - 24s - loss: 0.4424 - accuracy: 0.8566 - val_loss: 0.4809 - val_accuracy: 0.8498
Epoch 45/350
391/391 - 24s - loss: 0.4377 - accuracy: 0.8585 - val_loss: 0.4536 - val_accuracy: 0.8586
Epoch 46/350
391/391 - 24s - loss: 0.4329 - accuracy: 0.8614 - val_loss: 0.4650 - val_accuracy: 0.8590
Epoch 47/350
391/391 - 25s - loss: 0.4291 - accuracy: 0.8610 - val_loss: 0.4508 - val_accuracy: 0.8654
Epoch 48/350
391/391 - 24s - loss: 0.4179 - accuracy: 0.8666 - val_loss: 0.4769 - val_accuracy: 0.8570
Epoch 49/350
391/391 - 25s - loss: 0.4197 - accuracy: 0.8645 - val_loss: 0.4721 - val_accuracy: 0.8584
Epoch 50/350


Snapshot weight 1 shuffle 2 at epoch 50
Layer 11
Getting activations...


391/391 - 25s - loss: 0.4135 - accuracy: 0.8660 - val_loss: 0.4904 - val_accuracy: 0.8539
Epoch 51/350
391/391 - 25s - loss: 0.4071 - accuracy: 0.8695 - val_loss: 0.4708 - val_accuracy: 0.8584
Epoch 52/350
391/391 - 24s - loss: 0.4002 - accuracy: 0.8701 - val_loss: 0.4958 - val_accuracy: 0.8548
Epoch 53/350
391/391 - 25s - loss: 0.3957 - accuracy: 0.8743 - val_loss: 0.4679 - val_accuracy: 0.8625
Epoch 54/350
391/391 - 24s - loss: 0.3931 - accuracy: 0.8742 - val_loss: 0.4525 - val_accuracy: 0.8599
Epoch 55/350
391/391 - 24s - loss: 0.3835 - accuracy: 0.8772 - val_loss: 0.4451 - val_accuracy: 0.8684
Epoch 56/350
391/391 - 24s - loss: 0.3852 - accuracy: 0.8764 - val_loss: 0.4495 - val_accuracy: 0.8678
Epoch 57/350
391/391 - 24s - loss: 0.3809 - accuracy: 0.8781 - val_loss: 0.4736 - val_accuracy: 0.8638
Epoch 58/350
391/391 - 24s - loss: 0.3783 - accuracy: 0.8793 - val_loss: 0.4436 - val_accuracy: 0.8715
Epoch 59/350
391/391 - 24s - loss: 0.3719 - accuracy: 0.8812 - val_loss: 0.4644 - val_accuracy: 0.8589
Epoch 60/350
391/391 - 25s - loss: 0.3684 - accuracy: 0.8829 - val_loss: 0.4260 - val_accuracy: 0.8700
Epoch 61/350
391/391 - 24s - loss: 0.3604 - accuracy: 0.8846 - val_loss: 0.4508 - val_accuracy: 0.8689
Epoch 62/350
391/391 - 24s - loss: 0.3578 - accuracy: 0.8867 - val_loss: 0.4547 - val_accuracy: 0.8663
Epoch 63/350
391/391 - 24s - loss: 0.3469 - accuracy: 0.8909 - val_loss: 0.4211 - val_accuracy: 0.8761
Epoch 64/350
391/391 - 24s - loss: 0.3522 - accuracy: 0.8878 - val_loss: 0.4590 - val_accuracy: 0.8718
Epoch 65/350
391/391 - 25s - loss: 0.3464 - accuracy: 0.8908 - val_loss: 0.4182 - val_accuracy: 0.8790
Epoch 66/350
391/391 - 25s - loss: 0.3450 - accuracy: 0.8907 - val_loss: 0.4430 - val_accuracy: 0.8726
Epoch 67/350
391/391 - 24s - loss: 0.3430 - accuracy: 0.8914 - val_loss: 0.4262 - val_accuracy: 0.8795
Epoch 68/350
391/391 - 24s - loss: 0.3365 - accuracy: 0.8942 - val_loss: 0.4564 - val_accuracy: 0.8685
Epoch 69/350
391/391 - 24s - loss: 0.3417 - accuracy: 0.8903 - val_loss: 0.4186 - val_accuracy: 0.8780
Epoch 70/350
391/391 - 24s - loss: 0.3352 - accuracy: 0.8956 - val_loss: 0.4465 - val_accuracy: 0.8749
Epoch 71/350
391/391 - 24s - loss: 0.3289 - accuracy: 0.8965 - val_loss: 0.4421 - val_accuracy: 0.8748
Epoch 72/350
391/391 - 24s - loss: 0.3238 - accuracy: 0.8985 - val_loss: 0.4333 - val_accuracy: 0.8780
Epoch 73/350
391/391 - 25s - loss: 0.3210 - accuracy: 0.8991 - val_loss: 0.4311 - val_accuracy: 0.8771
Epoch 74/350
391/391 - 25s - loss: 0.3183 - accuracy: 0.9003 - val_loss: 0.4178 - val_accuracy: 0.8825
Epoch 75/350
391/391 - 24s - loss: 0.3143 - accuracy: 0.9015 - val_loss: 0.4256 - val_accuracy: 0.8793
Epoch 76/350
391/391 - 24s - loss: 0.3166 - accuracy: 0.9005 - val_loss: 0.4212 - val_accuracy: 0.8801
Epoch 77/350
391/391 - 24s - loss: 0.3105 - accuracy: 0.9043 - val_loss: 0.4054 - val_accuracy: 0.8823
Epoch 78/350
391/391 - 24s - loss: 0.3044 - accuracy: 0.9051 - val_loss: 0.4198 - val_accuracy: 0.8791
Epoch 79/350
391/391 - 25s - loss: 0.3054 - accuracy: 0.9048 - val_loss: 0.4373 - val_accuracy: 0.8788
Epoch 80/350
391/391 - 24s - loss: 0.3049 - accuracy: 0.9044 - val_loss: 0.4320 - val_accuracy: 0.8818
Epoch 81/350
391/391 - 25s - loss: 0.3001 - accuracy: 0.9065 - val_loss: 0.4283 - val_accuracy: 0.8786
Epoch 82/350
391/391 - 24s - loss: 0.2990 - accuracy: 0.9062 - val_loss: 0.4225 - val_accuracy: 0.8830
Epoch 83/350
391/391 - 25s - loss: 0.2996 - accuracy: 0.9071 - val_loss: 0.4311 - val_accuracy: 0.8859
Epoch 84/350
391/391 - 24s - loss: 0.2917 - accuracy: 0.9092 - val_loss: 0.4298 - val_accuracy: 0.8762
Epoch 85/350
391/391 - 25s - loss: 0.2931 - accuracy: 0.9083 - val_loss: 0.4214 - val_accuracy: 0.8830
Epoch 86/350
391/391 - 25s - loss: 0.2922 - accuracy: 0.9105 - val_loss: 0.4080 - val_accuracy: 0.8824
Epoch 87/350
391/391 - 24s - loss: 0.2823 - accuracy: 0.9137 - val_loss: 0.4393 - val_accuracy: 0.8813
Epoch 88/350
391/391 - 24s - loss: 0.2797 - accuracy: 0.9145 - val_loss: 0.4401 - val_accuracy: 0.8757
Epoch 89/350
391/391 - 25s - loss: 0.2817 - accuracy: 0.9137 - val_loss: 0.4480 - val_accuracy: 0.8770
Epoch 90/350
391/391 - 24s - loss: 0.2779 - accuracy: 0.9136 - val_loss: 0.4188 - val_accuracy: 0.8831
Epoch 91/350
391/391 - 24s - loss: 0.2825 - accuracy: 0.9121 - val_loss: 0.4023 - val_accuracy: 0.8892
Epoch 92/350
391/391 - 25s - loss: 0.2736 - accuracy: 0.9154 - val_loss: 0.4127 - val_accuracy: 0.8866
Epoch 93/350
391/391 - 24s - loss: 0.2730 - accuracy: 0.9166 - val_loss: 0.4176 - val_accuracy: 0.8873
Epoch 94/350
391/391 - 25s - loss: 0.2678 - accuracy: 0.9187 - val_loss: 0.4283 - val_accuracy: 0.8823
Epoch 95/350
391/391 - 24s - loss: 0.2667 - accuracy: 0.9199 - val_loss: 0.4370 - val_accuracy: 0.8850
Epoch 96/350
391/391 - 24s - loss: 0.2652 - accuracy: 0.9193 - val_loss: 0.4819 - val_accuracy: 0.8787
Epoch 97/350
391/391 - 24s - loss: 0.2651 - accuracy: 0.9195 - val_loss: 0.4176 - val_accuracy: 0.8846
Epoch 98/350
391/391 - 25s - loss: 0.2636 - accuracy: 0.9201 - val_loss: 0.4121 - val_accuracy: 0.8850
Epoch 99/350
391/391 - 25s - loss: 0.2628 - accuracy: 0.9212 - val_loss: 0.4183 - val_accuracy: 0.8901
Epoch 100/350


Snapshot weight 1 shuffle 2 at epoch 100
Layer 11
Getting activations...


391/391 - 25s - loss: 0.2602 - accuracy: 0.9219 - val_loss: 0.4435 - val_accuracy: 0.8853
Epoch 101/350
391/391 - 24s - loss: 0.2644 - accuracy: 0.9206 - val_loss: 0.3946 - val_accuracy: 0.8934
Epoch 102/350
391/391 - 24s - loss: 0.2533 - accuracy: 0.9232 - val_loss: 0.4735 - val_accuracy: 0.8790
Epoch 103/350
391/391 - 25s - loss: 0.2533 - accuracy: 0.9237 - val_loss: 0.4577 - val_accuracy: 0.8823
Epoch 104/350
391/391 - 25s - loss: 0.2559 - accuracy: 0.9232 - val_loss: 0.4332 - val_accuracy: 0.8890
Epoch 105/350
391/391 - 24s - loss: 0.2499 - accuracy: 0.9251 - val_loss: 0.4124 - val_accuracy: 0.8912
Epoch 106/350
391/391 - 24s - loss: 0.2467 - accuracy: 0.9257 - val_loss: 0.4179 - val_accuracy: 0.8853
Epoch 107/350
391/391 - 24s - loss: 0.2479 - accuracy: 0.9259 - val_loss: 0.4410 - val_accuracy: 0.8837
Epoch 108/350
391/391 - 24s - loss: 0.2462 - accuracy: 0.9266 - val_loss: 0.4225 - val_accuracy: 0.8898
Epoch 109/350
391/391 - 24s - loss: 0.2464 - accuracy: 0.9273 - val_loss: 0.4278 - val_accuracy: 0.8901
Epoch 110/350
391/391 - 25s - loss: 0.2487 - accuracy: 0.9253 - val_loss: 0.4181 - val_accuracy: 0.8890
Epoch 111/350
391/391 - 24s - loss: 0.2386 - accuracy: 0.9287 - val_loss: 0.4718 - val_accuracy: 0.8862
Epoch 112/350
391/391 - 25s - loss: 0.2424 - accuracy: 0.9278 - val_loss: 0.4284 - val_accuracy: 0.8879
Epoch 113/350
391/391 - 24s - loss: 0.2397 - accuracy: 0.9299 - val_loss: 0.4254 - val_accuracy: 0.8905
Epoch 114/350
391/391 - 24s - loss: 0.2347 - accuracy: 0.9307 - val_loss: 0.4106 - val_accuracy: 0.8927
Epoch 115/350
391/391 - 24s - loss: 0.2361 - accuracy: 0.9297 - val_loss: 0.4432 - val_accuracy: 0.8881
Epoch 116/350
391/391 - 24s - loss: 0.2383 - accuracy: 0.9289 - val_loss: 0.4533 - val_accuracy: 0.8911
Epoch 117/350
391/391 - 24s - loss: 0.2284 - accuracy: 0.9317 - val_loss: 0.4405 - val_accuracy: 0.8855
Epoch 118/350
391/391 - 24s - loss: 0.2374 - accuracy: 0.9291 - val_loss: 0.4419 - val_accuracy: 0.8823
Epoch 119/350
391/391 - 24s - loss: 0.2350 - accuracy: 0.9312 - val_loss: 0.4146 - val_accuracy: 0.8918
Epoch 120/350
391/391 - 24s - loss: 0.2296 - accuracy: 0.9331 - val_loss: 0.4266 - val_accuracy: 0.8913
Epoch 121/350
391/391 - 24s - loss: 0.2262 - accuracy: 0.9337 - val_loss: 0.4364 - val_accuracy: 0.8854
Epoch 122/350
391/391 - 24s - loss: 0.2299 - accuracy: 0.9329 - val_loss: 0.4730 - val_accuracy: 0.8851
Epoch 123/350
391/391 - 25s - loss: 0.2262 - accuracy: 0.9339 - val_loss: 0.4639 - val_accuracy: 0.8851
Epoch 124/350
391/391 - 24s - loss: 0.2254 - accuracy: 0.9342 - val_loss: 0.5255 - val_accuracy: 0.8769
Epoch 125/350
391/391 - 24s - loss: 0.2230 - accuracy: 0.9353 - val_loss: 0.4181 - val_accuracy: 0.8896
Epoch 126/350
391/391 - 24s - loss: 0.2278 - accuracy: 0.9331 - val_loss: 0.4144 - val_accuracy: 0.8952
Epoch 127/350
391/391 - 24s - loss: 0.2213 - accuracy: 0.9354 - val_loss: 0.4407 - val_accuracy: 0.8832
Epoch 128/350
391/391 - 24s - loss: 0.2196 - accuracy: 0.9373 - val_loss: 0.4498 - val_accuracy: 0.8925
Epoch 129/350
391/391 - 24s - loss: 0.2206 - accuracy: 0.9365 - val_loss: 0.4473 - val_accuracy: 0.8893
Epoch 130/350
391/391 - 24s - loss: 0.2152 - accuracy: 0.9387 - val_loss: 0.4333 - val_accuracy: 0.8932
Epoch 131/350
391/391 - 24s - loss: 0.2176 - accuracy: 0.9366 - val_loss: 0.4334 - val_accuracy: 0.8892
Epoch 132/350
391/391 - 24s - loss: 0.2116 - accuracy: 0.9397 - val_loss: 0.4324 - val_accuracy: 0.8895
Epoch 133/350
391/391 - 25s - loss: 0.2163 - accuracy: 0.9371 - val_loss: 0.4579 - val_accuracy: 0.8838
Epoch 134/350
391/391 - 24s - loss: 0.2138 - accuracy: 0.9388 - val_loss: 0.4217 - val_accuracy: 0.8896
Epoch 135/350
391/391 - 24s - loss: 0.2090 - accuracy: 0.9398 - val_loss: 0.4669 - val_accuracy: 0.8914
Epoch 136/350
391/391 - 24s - loss: 0.2082 - accuracy: 0.9402 - val_loss: 0.4442 - val_accuracy: 0.8931
Epoch 137/350
391/391 - 24s - loss: 0.2059 - accuracy: 0.9412 - val_loss: 0.4579 - val_accuracy: 0.8906
Epoch 138/350
391/391 - 24s - loss: 0.2113 - accuracy: 0.9407 - val_loss: 0.4372 - val_accuracy: 0.8911
Epoch 139/350
391/391 - 24s - loss: 0.2095 - accuracy: 0.9404 - val_loss: 0.4296 - val_accuracy: 0.8942
Epoch 140/350
391/391 - 24s - loss: 0.2043 - accuracy: 0.9428 - val_loss: 0.4405 - val_accuracy: 0.8944
Epoch 141/350
391/391 - 24s - loss: 0.2032 - accuracy: 0.9426 - val_loss: 0.4364 - val_accuracy: 0.8944
Epoch 142/350
391/391 - 24s - loss: 0.2022 - accuracy: 0.9421 - val_loss: 0.4776 - val_accuracy: 0.8898
Epoch 143/350
391/391 - 24s - loss: 0.2000 - accuracy: 0.9441 - val_loss: 0.4345 - val_accuracy: 0.8951
Epoch 144/350
391/391 - 24s - loss: 0.1953 - accuracy: 0.9456 - val_loss: 0.4311 - val_accuracy: 0.8980
Epoch 145/350
391/391 - 25s - loss: 0.2014 - accuracy: 0.9429 - val_loss: 0.4523 - val_accuracy: 0.8914
Epoch 146/350
391/391 - 24s - loss: 0.2030 - accuracy: 0.9428 - val_loss: 0.4336 - val_accuracy: 0.8925
Epoch 147/350
391/391 - 25s - loss: 0.2013 - accuracy: 0.9440 - val_loss: 0.4662 - val_accuracy: 0.8880
Epoch 148/350
391/391 - 24s - loss: 0.1978 - accuracy: 0.9450 - val_loss: 0.4487 - val_accuracy: 0.8926
Epoch 149/350
391/391 - 24s - loss: 0.2026 - accuracy: 0.9433 - val_loss: 0.4140 - val_accuracy: 0.8930
Epoch 150/350


Snapshot weight 1 shuffle 2 at epoch 150
Layer 11
Getting activations...


391/391 - 24s - loss: 0.1966 - accuracy: 0.9449 - val_loss: 0.4556 - val_accuracy: 0.8909
Epoch 151/350
391/391 - 24s - loss: 0.1963 - accuracy: 0.9451 - val_loss: 0.4383 - val_accuracy: 0.8926
Epoch 152/350
391/391 - 24s - loss: 0.1952 - accuracy: 0.9454 - val_loss: 0.4683 - val_accuracy: 0.8896
Epoch 153/350
391/391 - 24s - loss: 0.1951 - accuracy: 0.9450 - val_loss: 0.4469 - val_accuracy: 0.8910
Epoch 154/350
391/391 - 24s - loss: 0.1885 - accuracy: 0.9479 - val_loss: 0.4959 - val_accuracy: 0.8895
Epoch 155/350
391/391 - 24s - loss: 0.1953 - accuracy: 0.9460 - val_loss: 0.4479 - val_accuracy: 0.8924
Epoch 156/350
391/391 - 24s - loss: 0.1947 - accuracy: 0.9452 - val_loss: 0.4588 - val_accuracy: 0.8927
Epoch 157/350
391/391 - 25s - loss: 0.1917 - accuracy: 0.9483 - val_loss: 0.4501 - val_accuracy: 0.8911
Epoch 158/350
391/391 - 24s - loss: 0.1902 - accuracy: 0.9471 - val_loss: 0.4617 - val_accuracy: 0.8934
Epoch 159/350
391/391 - 24s - loss: 0.1878 - accuracy: 0.9490 - val_loss: 0.4870 - val_accuracy: 0.8925
Epoch 160/350
391/391 - 24s - loss: 0.1918 - accuracy: 0.9469 - val_loss: 0.4316 - val_accuracy: 0.8961
Epoch 161/350
391/391 - 24s - loss: 0.1829 - accuracy: 0.9506 - val_loss: 0.4946 - val_accuracy: 0.8945
Epoch 162/350
391/391 - 24s - loss: 0.1841 - accuracy: 0.9504 - val_loss: 0.4492 - val_accuracy: 0.8963
Epoch 163/350
391/391 - 24s - loss: 0.1903 - accuracy: 0.9483 - val_loss: 0.4962 - val_accuracy: 0.8861
Epoch 164/350
391/391 - 24s - loss: 0.1838 - accuracy: 0.9496 - val_loss: 0.4820 - val_accuracy: 0.8886
Epoch 165/350
391/391 - 24s - loss: 0.1793 - accuracy: 0.9530 - val_loss: 0.4462 - val_accuracy: 0.8972
Epoch 166/350
391/391 - 24s - loss: 0.1841 - accuracy: 0.9500 - val_loss: 0.4706 - val_accuracy: 0.8980
Epoch 167/350
391/391 - 24s - loss: 0.1817 - accuracy: 0.9506 - val_loss: 0.4822 - val_accuracy: 0.8988
Epoch 168/350
391/391 - 25s - loss: 0.1874 - accuracy: 0.9481 - val_loss: 0.4872 - val_accuracy: 0.8917
Epoch 169/350
391/391 - 24s - loss: 0.1839 - accuracy: 0.9504 - val_loss: 0.4483 - val_accuracy: 0.8995
Epoch 170/350
391/391 - 24s - loss: 0.1845 - accuracy: 0.9497 - val_loss: 0.4506 - val_accuracy: 0.8961
Epoch 171/350
391/391 - 24s - loss: 0.1817 - accuracy: 0.9503 - val_loss: 0.4899 - val_accuracy: 0.8928
Epoch 172/350
391/391 - 24s - loss: 0.1827 - accuracy: 0.9504 - val_loss: 0.4525 - val_accuracy: 0.8952
Epoch 173/350
391/391 - 24s - loss: 0.1832 - accuracy: 0.9505 - val_loss: 0.4483 - val_accuracy: 0.8917
Epoch 174/350
391/391 - 24s - loss: 0.1803 - accuracy: 0.9507 - val_loss: 0.4326 - val_accuracy: 0.8973
Epoch 175/350
391/391 - 24s - loss: 0.1790 - accuracy: 0.9522 - val_loss: 0.4441 - val_accuracy: 0.8960
Epoch 176/350
391/391 - 24s - loss: 0.1746 - accuracy: 0.9542 - val_loss: 0.4678 - val_accuracy: 0.8936
Epoch 177/350
391/391 - 24s - loss: 0.1737 - accuracy: 0.9526 - val_loss: 0.4432 - val_accuracy: 0.8971
Epoch 178/350
391/391 - 24s - loss: 0.1735 - accuracy: 0.9541 - val_loss: 0.4705 - val_accuracy: 0.8971
Epoch 179/350
391/391 - 24s - loss: 0.1745 - accuracy: 0.9541 - val_loss: 0.4589 - val_accuracy: 0.8945
Epoch 180/350
391/391 - 24s - loss: 0.1729 - accuracy: 0.9542 - val_loss: 0.4516 - val_accuracy: 0.8963
Epoch 181/350
391/391 - 24s - loss: 0.1758 - accuracy: 0.9534 - val_loss: 0.4637 - val_accuracy: 0.8937
Epoch 182/350
391/391 - 24s - loss: 0.1769 - accuracy: 0.9535 - val_loss: 0.4566 - val_accuracy: 0.8934
Epoch 183/350
391/391 - 24s - loss: 0.1736 - accuracy: 0.9539 - val_loss: 0.4500 - val_accuracy: 0.8964
Epoch 184/350
391/391 - 24s - loss: 0.1736 - accuracy: 0.9537 - val_loss: 0.4601 - val_accuracy: 0.8966
Epoch 185/350
391/391 - 24s - loss: 0.1738 - accuracy: 0.9549 - val_loss: 0.4695 - val_accuracy: 0.8930
Epoch 186/350
391/391 - 24s - loss: 0.1731 - accuracy: 0.9546 - val_loss: 0.4505 - val_accuracy: 0.8974
Epoch 187/350
391/391 - 24s - loss: 0.1699 - accuracy: 0.9561 - val_loss: 0.4537 - val_accuracy: 0.8948
Epoch 188/350
391/391 - 24s - loss: 0.1670 - accuracy: 0.9575 - val_loss: 0.4617 - val_accuracy: 0.8955
Epoch 189/350
391/391 - 24s - loss: 0.1708 - accuracy: 0.9550 - val_loss: 0.5014 - val_accuracy: 0.8888
Epoch 190/350
391/391 - 24s - loss: 0.1688 - accuracy: 0.9569 - val_loss: 0.5159 - val_accuracy: 0.8923
Epoch 191/350
391/391 - 24s - loss: 0.1699 - accuracy: 0.9551 - val_loss: 0.5083 - val_accuracy: 0.8909
Epoch 192/350
391/391 - 25s - loss: 0.1665 - accuracy: 0.9568 - val_loss: 0.5103 - val_accuracy: 0.8911
Epoch 193/350
391/391 - 24s - loss: 0.1665 - accuracy: 0.9570 - val_loss: 0.4798 - val_accuracy: 0.8961
Epoch 194/350
391/391 - 24s - loss: 0.1671 - accuracy: 0.9564 - val_loss: 0.4558 - val_accuracy: 0.8969
Epoch 195/350
391/391 - 24s - loss: 0.1672 - accuracy: 0.9572 - val_loss: 0.4543 - val_accuracy: 0.8941
Epoch 196/350
391/391 - 24s - loss: 0.1673 - accuracy: 0.9569 - val_loss: 0.4418 - val_accuracy: 0.8978
Epoch 197/350
391/391 - 25s - loss: 0.1645 - accuracy: 0.9583 - val_loss: 0.4638 - val_accuracy: 0.8966
Epoch 198/350
391/391 - 24s - loss: 0.1655 - accuracy: 0.9571 - val_loss: 0.4875 - val_accuracy: 0.8970
Epoch 199/350
391/391 - 24s - loss: 0.1660 - accuracy: 0.9577 - val_loss: 0.4592 - val_accuracy: 0.8950
Epoch 200/350


Snapshot weight 1 shuffle 2 at epoch 200
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1647 - accuracy: 0.9582 - val_loss: 0.4909 - val_accuracy: 0.8940
Epoch 201/350
391/391 - 24s - loss: 0.1405 - accuracy: 0.9669 - val_loss: 0.4563 - val_accuracy: 0.9035
Epoch 202/350
391/391 - 24s - loss: 0.1263 - accuracy: 0.9716 - val_loss: 0.4605 - val_accuracy: 0.9056
Epoch 203/350
391/391 - 24s - loss: 0.1229 - accuracy: 0.9727 - val_loss: 0.4753 - val_accuracy: 0.9041
Epoch 204/350
391/391 - 24s - loss: 0.1170 - accuracy: 0.9748 - val_loss: 0.4817 - val_accuracy: 0.9050
Epoch 205/350
391/391 - 24s - loss: 0.1190 - accuracy: 0.9744 - val_loss: 0.4648 - val_accuracy: 0.9052
Epoch 206/350
391/391 - 24s - loss: 0.1171 - accuracy: 0.9750 - val_loss: 0.4797 - val_accuracy: 0.9044
Epoch 207/350
391/391 - 24s - loss: 0.1156 - accuracy: 0.9750 - val_loss: 0.4727 - val_accuracy: 0.9077
Epoch 208/350
391/391 - 24s - loss: 0.1185 - accuracy: 0.9745 - val_loss: 0.4767 - val_accuracy: 0.9048
Epoch 209/350
391/391 - 24s - loss: 0.1158 - accuracy: 0.9754 - val_loss: 0.4708 - val_accuracy: 0.9073
Epoch 210/350
391/391 - 24s - loss: 0.1129 - accuracy: 0.9761 - val_loss: 0.4815 - val_accuracy: 0.9080
Epoch 211/350
391/391 - 24s - loss: 0.1145 - accuracy: 0.9761 - val_loss: 0.4805 - val_accuracy: 0.9064
Epoch 212/350
391/391 - 24s - loss: 0.1149 - accuracy: 0.9761 - val_loss: 0.4852 - val_accuracy: 0.9059
Epoch 213/350
391/391 - 24s - loss: 0.1141 - accuracy: 0.9753 - val_loss: 0.4816 - val_accuracy: 0.9089
Epoch 214/350
391/391 - 24s - loss: 0.1119 - accuracy: 0.9770 - val_loss: 0.4804 - val_accuracy: 0.9079
Epoch 215/350
391/391 - 24s - loss: 0.1117 - accuracy: 0.9769 - val_loss: 0.4877 - val_accuracy: 0.9080
Epoch 216/350
391/391 - 24s - loss: 0.1126 - accuracy: 0.9758 - val_loss: 0.4852 - val_accuracy: 0.9071
Epoch 217/350
391/391 - 24s - loss: 0.1131 - accuracy: 0.9765 - val_loss: 0.4834 - val_accuracy: 0.9060
Epoch 218/350
391/391 - 24s - loss: 0.1141 - accuracy: 0.9757 - val_loss: 0.4733 - val_accuracy: 0.9072
Epoch 219/350
391/391 - 25s - loss: 0.1091 - accuracy: 0.9782 - val_loss: 0.4877 - val_accuracy: 0.9077
Epoch 220/350
391/391 - 24s - loss: 0.1101 - accuracy: 0.9770 - val_loss: 0.4907 - val_accuracy: 0.9056
Epoch 221/350
391/391 - 24s - loss: 0.1110 - accuracy: 0.9762 - val_loss: 0.4881 - val_accuracy: 0.9072
Epoch 222/350
391/391 - 24s - loss: 0.1096 - accuracy: 0.9775 - val_loss: 0.4821 - val_accuracy: 0.9061
Epoch 223/350
391/391 - 24s - loss: 0.1105 - accuracy: 0.9767 - val_loss: 0.4862 - val_accuracy: 0.9067
Epoch 224/350
391/391 - 24s - loss: 0.1108 - accuracy: 0.9772 - val_loss: 0.4790 - val_accuracy: 0.9076
Epoch 225/350
391/391 - 24s - loss: 0.1077 - accuracy: 0.9778 - val_loss: 0.4935 - val_accuracy: 0.9073
Epoch 226/350
391/391 - 24s - loss: 0.1093 - accuracy: 0.9777 - val_loss: 0.4909 - val_accuracy: 0.9084
Epoch 227/350
391/391 - 25s - loss: 0.1076 - accuracy: 0.9783 - val_loss: 0.4852 - val_accuracy: 0.9058
Epoch 228/350
391/391 - 24s - loss: 0.1074 - accuracy: 0.9786 - val_loss: 0.4923 - val_accuracy: 0.9057
Epoch 229/350
391/391 - 24s - loss: 0.1087 - accuracy: 0.9776 - val_loss: 0.4904 - val_accuracy: 0.9080
Epoch 230/350
391/391 - 24s - loss: 0.1077 - accuracy: 0.9779 - val_loss: 0.4962 - val_accuracy: 0.9075
Epoch 231/350
391/391 - 24s - loss: 0.1077 - accuracy: 0.9778 - val_loss: 0.4923 - val_accuracy: 0.9066
Epoch 232/350
391/391 - 24s - loss: 0.1056 - accuracy: 0.9791 - val_loss: 0.4938 - val_accuracy: 0.9074
Epoch 233/350
391/391 - 25s - loss: 0.1065 - accuracy: 0.9785 - val_loss: 0.4936 - val_accuracy: 0.9081
Epoch 234/350
391/391 - 24s - loss: 0.1054 - accuracy: 0.9784 - val_loss: 0.5092 - val_accuracy: 0.9087
Epoch 235/350
391/391 - 24s - loss: 0.1061 - accuracy: 0.9790 - val_loss: 0.5046 - val_accuracy: 0.9069
Epoch 236/350
391/391 - 24s - loss: 0.1062 - accuracy: 0.9778 - val_loss: 0.4897 - val_accuracy: 0.9086
Epoch 237/350
391/391 - 24s - loss: 0.1038 - accuracy: 0.9798 - val_loss: 0.4972 - val_accuracy: 0.9091
Epoch 238/350
391/391 - 24s - loss: 0.1061 - accuracy: 0.9783 - val_loss: 0.5111 - val_accuracy: 0.9069
Epoch 239/350
391/391 - 25s - loss: 0.1066 - accuracy: 0.9787 - val_loss: 0.4975 - val_accuracy: 0.9093
Epoch 240/350
391/391 - 24s - loss: 0.1060 - accuracy: 0.9795 - val_loss: 0.4970 - val_accuracy: 0.9083
Epoch 241/350
391/391 - 24s - loss: 0.1064 - accuracy: 0.9788 - val_loss: 0.4976 - val_accuracy: 0.9092
Epoch 242/350
391/391 - 24s - loss: 0.1054 - accuracy: 0.9788 - val_loss: 0.4934 - val_accuracy: 0.9078
Epoch 243/350
391/391 - 25s - loss: 0.1057 - accuracy: 0.9789 - val_loss: 0.4907 - val_accuracy: 0.9092
Epoch 244/350
391/391 - 24s - loss: 0.1054 - accuracy: 0.9783 - val_loss: 0.4975 - val_accuracy: 0.9082
Epoch 245/350
391/391 - 24s - loss: 0.1030 - accuracy: 0.9797 - val_loss: 0.5041 - val_accuracy: 0.9077
Epoch 246/350
391/391 - 24s - loss: 0.1034 - accuracy: 0.9799 - val_loss: 0.5009 - val_accuracy: 0.9086
Epoch 247/350
391/391 - 24s - loss: 0.1070 - accuracy: 0.9790 - val_loss: 0.5008 - val_accuracy: 0.9089
Epoch 248/350
391/391 - 24s - loss: 0.1006 - accuracy: 0.9804 - val_loss: 0.5047 - val_accuracy: 0.9081
Epoch 249/350
391/391 - 25s - loss: 0.1042 - accuracy: 0.9790 - val_loss: 0.4974 - val_accuracy: 0.9101
Epoch 250/350


Snapshot weight 1 shuffle 2 at epoch 250
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1024 - accuracy: 0.9800 - val_loss: 0.4965 - val_accuracy: 0.9080
Epoch 251/350
391/391 - 24s - loss: 0.1031 - accuracy: 0.9793 - val_loss: 0.4955 - val_accuracy: 0.9076
Epoch 252/350
391/391 - 24s - loss: 0.0990 - accuracy: 0.9812 - val_loss: 0.4986 - val_accuracy: 0.9081
Epoch 253/350
391/391 - 24s - loss: 0.1026 - accuracy: 0.9799 - val_loss: 0.5004 - val_accuracy: 0.9075
Epoch 254/350
391/391 - 24s - loss: 0.1013 - accuracy: 0.9804 - val_loss: 0.4986 - val_accuracy: 0.9081
Epoch 255/350
391/391 - 24s - loss: 0.1026 - accuracy: 0.9810 - val_loss: 0.4990 - val_accuracy: 0.9079
Epoch 256/350
391/391 - 24s - loss: 0.0991 - accuracy: 0.9814 - val_loss: 0.4997 - val_accuracy: 0.9085
Epoch 257/350
391/391 - 24s - loss: 0.1010 - accuracy: 0.9810 - val_loss: 0.4998 - val_accuracy: 0.9084
Epoch 258/350
391/391 - 24s - loss: 0.0996 - accuracy: 0.9815 - val_loss: 0.4988 - val_accuracy: 0.9096
Epoch 259/350
391/391 - 24s - loss: 0.0999 - accuracy: 0.9810 - val_loss: 0.4999 - val_accuracy: 0.9095
Epoch 260/350
391/391 - 24s - loss: 0.0981 - accuracy: 0.9803 - val_loss: 0.4985 - val_accuracy: 0.9091
Epoch 261/350
391/391 - 24s - loss: 0.1017 - accuracy: 0.9808 - val_loss: 0.4992 - val_accuracy: 0.9096
Epoch 262/350
391/391 - 24s - loss: 0.0992 - accuracy: 0.9811 - val_loss: 0.5002 - val_accuracy: 0.9101
Epoch 263/350
391/391 - 24s - loss: 0.1013 - accuracy: 0.9800 - val_loss: 0.4996 - val_accuracy: 0.9094
Epoch 264/350
391/391 - 24s - loss: 0.0984 - accuracy: 0.9815 - val_loss: 0.5007 - val_accuracy: 0.9093
Epoch 265/350
391/391 - 24s - loss: 0.0987 - accuracy: 0.9814 - val_loss: 0.5019 - val_accuracy: 0.9093
Epoch 266/350
391/391 - 24s - loss: 0.1006 - accuracy: 0.9810 - val_loss: 0.5034 - val_accuracy: 0.9089
Epoch 267/350
391/391 - 24s - loss: 0.0985 - accuracy: 0.9814 - val_loss: 0.5039 - val_accuracy: 0.9082
Epoch 268/350
391/391 - 24s - loss: 0.0993 - accuracy: 0.9814 - val_loss: 0.5011 - val_accuracy: 0.9090
Epoch 269/350
391/391 - 24s - loss: 0.0988 - accuracy: 0.9810 - val_loss: 0.5029 - val_accuracy: 0.9094
Epoch 270/350
391/391 - 24s - loss: 0.0996 - accuracy: 0.9809 - val_loss: 0.5024 - val_accuracy: 0.9088
Epoch 271/350
391/391 - 24s - loss: 0.0994 - accuracy: 0.9811 - val_loss: 0.5042 - val_accuracy: 0.9086
Epoch 272/350
391/391 - 24s - loss: 0.0996 - accuracy: 0.9808 - val_loss: 0.5039 - val_accuracy: 0.9082
Epoch 273/350
391/391 - 24s - loss: 0.0993 - accuracy: 0.9813 - val_loss: 0.5022 - val_accuracy: 0.9097
Epoch 274/350
391/391 - 25s - loss: 0.1008 - accuracy: 0.9813 - val_loss: 0.5049 - val_accuracy: 0.9084
Epoch 275/350
391/391 - 24s - loss: 0.0979 - accuracy: 0.9818 - val_loss: 0.5033 - val_accuracy: 0.9094
Epoch 276/350
391/391 - 24s - loss: 0.0995 - accuracy: 0.9812 - val_loss: 0.5064 - val_accuracy: 0.9089
Epoch 277/350
391/391 - 24s - loss: 0.0991 - accuracy: 0.9811 - val_loss: 0.5059 - val_accuracy: 0.9091
Epoch 278/350
391/391 - 24s - loss: 0.0991 - accuracy: 0.9807 - val_loss: 0.5033 - val_accuracy: 0.9095
Epoch 279/350
391/391 - 24s - loss: 0.0988 - accuracy: 0.9815 - val_loss: 0.5039 - val_accuracy: 0.9098
Epoch 280/350
391/391 - 24s - loss: 0.1000 - accuracy: 0.9812 - val_loss: 0.5023 - val_accuracy: 0.9096
Epoch 281/350
391/391 - 24s - loss: 0.0983 - accuracy: 0.9818 - val_loss: 0.5051 - val_accuracy: 0.9094
Epoch 282/350
391/391 - 24s - loss: 0.0989 - accuracy: 0.9815 - val_loss: 0.5038 - val_accuracy: 0.9107
Epoch 283/350
391/391 - 24s - loss: 0.0994 - accuracy: 0.9809 - val_loss: 0.5043 - val_accuracy: 0.9090
Epoch 284/350
391/391 - 24s - loss: 0.0978 - accuracy: 0.9815 - val_loss: 0.5037 - val_accuracy: 0.9105
Epoch 285/350
391/391 - 24s - loss: 0.1002 - accuracy: 0.9812 - val_loss: 0.5063 - val_accuracy: 0.9094
Epoch 286/350
391/391 - 24s - loss: 0.0997 - accuracy: 0.9817 - val_loss: 0.5038 - val_accuracy: 0.9103
Epoch 287/350
391/391 - 24s - loss: 0.0999 - accuracy: 0.9808 - val_loss: 0.5034 - val_accuracy: 0.9092
Epoch 288/350
391/391 - 24s - loss: 0.1001 - accuracy: 0.9798 - val_loss: 0.5024 - val_accuracy: 0.9095
Epoch 289/350
391/391 - 24s - loss: 0.0986 - accuracy: 0.9811 - val_loss: 0.5020 - val_accuracy: 0.9101
Epoch 290/350
391/391 - 24s - loss: 0.0995 - accuracy: 0.9808 - val_loss: 0.5006 - val_accuracy: 0.9097
Epoch 291/350
391/391 - 24s - loss: 0.0979 - accuracy: 0.9814 - val_loss: 0.5007 - val_accuracy: 0.9098
Epoch 292/350
391/391 - 24s - loss: 0.1007 - accuracy: 0.9803 - val_loss: 0.5021 - val_accuracy: 0.9107
Epoch 293/350
391/391 - 24s - loss: 0.1006 - accuracy: 0.9802 - val_loss: 0.5024 - val_accuracy: 0.9100
Epoch 294/350
391/391 - 24s - loss: 0.0994 - accuracy: 0.9813 - val_loss: 0.5045 - val_accuracy: 0.9098
Epoch 295/350
391/391 - 24s - loss: 0.1002 - accuracy: 0.9805 - val_loss: 0.5033 - val_accuracy: 0.9090
Epoch 296/350
391/391 - 24s - loss: 0.1000 - accuracy: 0.9813 - val_loss: 0.5035 - val_accuracy: 0.9099
Epoch 297/350
391/391 - 24s - loss: 0.0997 - accuracy: 0.9812 - val_loss: 0.5060 - val_accuracy: 0.9098
Epoch 298/350
391/391 - 24s - loss: 0.0972 - accuracy: 0.9818 - val_loss: 0.5050 - val_accuracy: 0.9091
Epoch 299/350
391/391 - 24s - loss: 0.1003 - accuracy: 0.9812 - val_loss: 0.5072 - val_accuracy: 0.9097
Epoch 300/350


Snapshot weight 1 shuffle 2 at epoch 300
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1001 - accuracy: 0.9804 - val_loss: 0.5091 - val_accuracy: 0.9089
Epoch 301/350
391/391 - 24s - loss: 0.0963 - accuracy: 0.9822 - val_loss: 0.5088 - val_accuracy: 0.9084
Epoch 302/350
391/391 - 24s - loss: 0.0977 - accuracy: 0.9822 - val_loss: 0.5090 - val_accuracy: 0.9085
Epoch 303/350
391/391 - 24s - loss: 0.0978 - accuracy: 0.9818 - val_loss: 0.5084 - val_accuracy: 0.9085
Epoch 304/350
391/391 - 24s - loss: 0.0965 - accuracy: 0.9823 - val_loss: 0.5082 - val_accuracy: 0.9086
Epoch 305/350
391/391 - 24s - loss: 0.0971 - accuracy: 0.9821 - val_loss: 0.5082 - val_accuracy: 0.9085
Epoch 306/350
391/391 - 24s - loss: 0.0979 - accuracy: 0.9818 - val_loss: 0.5078 - val_accuracy: 0.9089
Epoch 307/350
391/391 - 24s - loss: 0.0992 - accuracy: 0.9811 - val_loss: 0.5078 - val_accuracy: 0.9089
Epoch 308/350
391/391 - 24s - loss: 0.0968 - accuracy: 0.9819 - val_loss: 0.5077 - val_accuracy: 0.9090
Epoch 309/350
391/391 - 24s - loss: 0.0997 - accuracy: 0.9808 - val_loss: 0.5077 - val_accuracy: 0.9089
Epoch 310/350
391/391 - 25s - loss: 0.1001 - accuracy: 0.9804 - val_loss: 0.5074 - val_accuracy: 0.9090
Epoch 311/350
391/391 - 24s - loss: 0.0982 - accuracy: 0.9817 - val_loss: 0.5071 - val_accuracy: 0.9091
Epoch 312/350
391/391 - 24s - loss: 0.0986 - accuracy: 0.9817 - val_loss: 0.5071 - val_accuracy: 0.9091
Epoch 313/350
391/391 - 24s - loss: 0.0991 - accuracy: 0.9808 - val_loss: 0.5066 - val_accuracy: 0.9091
Epoch 314/350
391/391 - 24s - loss: 0.0962 - accuracy: 0.9816 - val_loss: 0.5062 - val_accuracy: 0.9093
Epoch 315/350
391/391 - 24s - loss: 0.0992 - accuracy: 0.9806 - val_loss: 0.5061 - val_accuracy: 0.9092
Epoch 316/350
391/391 - 24s - loss: 0.1001 - accuracy: 0.9813 - val_loss: 0.5060 - val_accuracy: 0.9087
Epoch 317/350
391/391 - 24s - loss: 0.0985 - accuracy: 0.9815 - val_loss: 0.5058 - val_accuracy: 0.9092
Epoch 318/350
391/391 - 24s - loss: 0.0981 - accuracy: 0.9812 - val_loss: 0.5059 - val_accuracy: 0.9093
Epoch 319/350
391/391 - 24s - loss: 0.0985 - accuracy: 0.9819 - val_loss: 0.5062 - val_accuracy: 0.9091
Epoch 320/350
391/391 - 24s - loss: 0.0973 - accuracy: 0.9823 - val_loss: 0.5062 - val_accuracy: 0.9094
Epoch 321/350
391/391 - 24s - loss: 0.0984 - accuracy: 0.9815 - val_loss: 0.5063 - val_accuracy: 0.9089
Epoch 322/350
391/391 - 25s - loss: 0.0984 - accuracy: 0.9818 - val_loss: 0.5063 - val_accuracy: 0.9091
Epoch 323/350
391/391 - 24s - loss: 0.0975 - accuracy: 0.9818 - val_loss: 0.5060 - val_accuracy: 0.9092
Epoch 324/350
391/391 - 24s - loss: 0.0973 - accuracy: 0.9820 - val_loss: 0.5061 - val_accuracy: 0.9091
Epoch 325/350
391/391 - 24s - loss: 0.0990 - accuracy: 0.9811 - val_loss: 0.5064 - val_accuracy: 0.9092
Epoch 326/350
391/391 - 24s - loss: 0.1000 - accuracy: 0.9815 - val_loss: 0.5064 - val_accuracy: 0.9092
Epoch 327/350
391/391 - 24s - loss: 0.0981 - accuracy: 0.9816 - val_loss: 0.5064 - val_accuracy: 0.9093
Epoch 328/350
391/391 - 24s - loss: 0.1001 - accuracy: 0.9806 - val_loss: 0.5059 - val_accuracy: 0.9093
Epoch 329/350
391/391 - 24s - loss: 0.0987 - accuracy: 0.9819 - val_loss: 0.5057 - val_accuracy: 0.9093
Epoch 330/350
391/391 - 24s - loss: 0.0991 - accuracy: 0.9820 - val_loss: 0.5056 - val_accuracy: 0.9095
Epoch 331/350
391/391 - 24s - loss: 0.0997 - accuracy: 0.9814 - val_loss: 0.5061 - val_accuracy: 0.9092
Epoch 332/350
391/391 - 24s - loss: 0.0991 - accuracy: 0.9814 - val_loss: 0.5057 - val_accuracy: 0.9092
Epoch 333/350
391/391 - 25s - loss: 0.1022 - accuracy: 0.9797 - val_loss: 0.5052 - val_accuracy: 0.9093
Epoch 334/350
391/391 - 24s - loss: 0.0995 - accuracy: 0.9811 - val_loss: 0.5053 - val_accuracy: 0.9094
Epoch 335/350
391/391 - 24s - loss: 0.1018 - accuracy: 0.9806 - val_loss: 0.5051 - val_accuracy: 0.9094
Epoch 336/350
391/391 - 24s - loss: 0.0979 - accuracy: 0.9821 - val_loss: 0.5049 - val_accuracy: 0.9094
Epoch 337/350
391/391 - 24s - loss: 0.0977 - accuracy: 0.9815 - val_loss: 0.5053 - val_accuracy: 0.9094
Epoch 338/350
391/391 - 24s - loss: 0.0992 - accuracy: 0.9817 - val_loss: 0.5056 - val_accuracy: 0.9094
Epoch 339/350
391/391 - 24s - loss: 0.0974 - accuracy: 0.9815 - val_loss: 0.5059 - val_accuracy: 0.9095
Epoch 340/350
391/391 - 25s - loss: 0.0976 - accuracy: 0.9820 - val_loss: 0.5060 - val_accuracy: 0.9089
Epoch 341/350
391/391 - 24s - loss: 0.0971 - accuracy: 0.9821 - val_loss: 0.5060 - val_accuracy: 0.9091
Epoch 342/350
391/391 - 24s - loss: 0.0980 - accuracy: 0.9815 - val_loss: 0.5059 - val_accuracy: 0.9091
Epoch 343/350
391/391 - 24s - loss: 0.0982 - accuracy: 0.9811 - val_loss: 0.5063 - val_accuracy: 0.9091
Epoch 344/350
391/391 - 24s - loss: 0.1007 - accuracy: 0.9808 - val_loss: 0.5066 - val_accuracy: 0.9092
Epoch 345/350
391/391 - 25s - loss: 0.0999 - accuracy: 0.9813 - val_loss: 0.5062 - val_accuracy: 0.9091
Epoch 346/350
391/391 - 24s - loss: 0.0978 - accuracy: 0.9811 - val_loss: 0.5066 - val_accuracy: 0.9090
Epoch 347/350
391/391 - 24s - loss: 0.1009 - accuracy: 0.9804 - val_loss: 0.5060 - val_accuracy: 0.9091
Epoch 348/350
391/391 - 24s - loss: 0.0975 - accuracy: 0.9814 - val_loss: 0.5058 - val_accuracy: 0.9089
Epoch 349/350
391/391 - 24s - loss: 0.1009 - accuracy: 0.9805 - val_loss: 0.5058 - val_accuracy: 0.9090
Epoch 350/350


Snapshot weight 1 shuffle 2 at epoch 350
Layer 11
Getting activations...


391/391 - 24s - loss: 0.0973 - accuracy: 0.9825 - val_loss: 0.5055 - val_accuracy: 0.9089
/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:493: UserWarning: fill_value is not supported and is always 0 for TensorFlow < 2.4.0.
  return py_builtins.overload_of(f)(*args)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-07-01 23:44:04.931987: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
Saving, final validation acc: 0.9089000225067139
