2021-07-01 21:16:25.729457: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 21:17:50.997898: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-07-01 21:17:51.038799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-01 21:17:51.038872: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 21:17:51.083629: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-01 21:17:51.108800: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-01 21:17:51.117615: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-01 21:17:51.162499: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-01 21:17:51.171403: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-01 21:17:51.252400: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-01 21:17:51.258066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-01 21:17:51.261973: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-01 21:17:51.278796: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600235000 Hz
2021-07-01 21:17:51.278945: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x59bf800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-07-01 21:17:51.278965: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-07-01 21:17:51.432236: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x59a0490 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-07-01 21:17:51.432294: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN X (Pascal), Compute Capability 6.1
2021-07-01 21:17:51.434980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-01 21:17:51.435023: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 21:17:51.435070: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-01 21:17:51.435089: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-01 21:17:51.435107: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-01 21:17:51.435125: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-01 21:17:51.435143: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-01 21:17:51.435764: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-01 21:17:51.437478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-01 21:17:51.439286: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 21:17:53.701202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-01 21:17:53.701280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-07-01 21:17:53.701293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-07-01 21:17:53.707569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11228 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
2021-07-01 21:17:59.581862: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-01 21:18:02.180300: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
Using model index: 23
Making train data...
GCN...
ZCA...
Done!
Making test data...
Done!
Epoch 1/350


Snapshot weight 3 shuffle 2 at epoch 1
Layer 11
Getting activations...


391/391 - 25s - loss: 2.3250 - accuracy: 0.1127 - val_loss: 2.3226 - val_accuracy: 0.1058
Epoch 2/350


Snapshot weight 3 shuffle 2 at epoch 2
Layer 11
Getting activations...


391/391 - 24s - loss: 2.3024 - accuracy: 0.1391 - val_loss: 2.2934 - val_accuracy: 0.1598
Epoch 3/350


Snapshot weight 3 shuffle 2 at epoch 3
Layer 11
Getting activations...


391/391 - 25s - loss: 2.2805 - accuracy: 0.1620 - val_loss: 2.2712 - val_accuracy: 0.1898
Epoch 4/350


Snapshot weight 3 shuffle 2 at epoch 4
Layer 11
Getting activations...


391/391 - 25s - loss: 2.2590 - accuracy: 0.1652 - val_loss: 2.1783 - val_accuracy: 0.1754
Epoch 5/350


Snapshot weight 3 shuffle 2 at epoch 5
Layer 11
Getting activations...


391/391 - 24s - loss: 2.1012 - accuracy: 0.2188 - val_loss: 1.9757 - val_accuracy: 0.2962
Epoch 6/350


Snapshot weight 3 shuffle 2 at epoch 6
Layer 11
Getting activations...


391/391 - 24s - loss: 1.9840 - accuracy: 0.2845 - val_loss: 2.0163 - val_accuracy: 0.2784
Epoch 7/350


Snapshot weight 3 shuffle 2 at epoch 7
Layer 11
Getting activations...


391/391 - 25s - loss: 1.8374 - accuracy: 0.3562 - val_loss: 1.7151 - val_accuracy: 0.4139
Epoch 8/350


Snapshot weight 3 shuffle 2 at epoch 8
Layer 11
Getting activations...


391/391 - 25s - loss: 1.6103 - accuracy: 0.4424 - val_loss: 1.4580 - val_accuracy: 0.4995
Epoch 9/350


Snapshot weight 3 shuffle 2 at epoch 9
Layer 11
Getting activations...


391/391 - 25s - loss: 1.3786 - accuracy: 0.5240 - val_loss: 1.1825 - val_accuracy: 0.5936
Epoch 10/350


Snapshot weight 3 shuffle 2 at epoch 10
Layer 11
Getting activations...


391/391 - 25s - loss: 1.2114 - accuracy: 0.5776 - val_loss: 1.1064 - val_accuracy: 0.6150
Epoch 11/350
391/391 - 25s - loss: 1.1475 - accuracy: 0.6040 - val_loss: 1.0976 - val_accuracy: 0.6126
Epoch 12/350
391/391 - 25s - loss: 1.0821 - accuracy: 0.6259 - val_loss: 0.9931 - val_accuracy: 0.6583
Epoch 13/350
391/391 - 24s - loss: 1.0314 - accuracy: 0.6455 - val_loss: 0.9575 - val_accuracy: 0.6710
Epoch 14/350
391/391 - 24s - loss: 0.9807 - accuracy: 0.6610 - val_loss: 1.0555 - val_accuracy: 0.6512
Epoch 15/350
391/391 - 24s - loss: 0.9426 - accuracy: 0.6780 - val_loss: 1.0187 - val_accuracy: 0.6526
Epoch 16/350
391/391 - 24s - loss: 0.9092 - accuracy: 0.6908 - val_loss: 0.8611 - val_accuracy: 0.7025
Epoch 17/350
391/391 - 24s - loss: 0.8687 - accuracy: 0.7033 - val_loss: 0.7721 - val_accuracy: 0.7385
Epoch 18/350
391/391 - 24s - loss: 0.8398 - accuracy: 0.7145 - val_loss: 0.7586 - val_accuracy: 0.7497
Epoch 19/350
391/391 - 24s - loss: 0.8062 - accuracy: 0.7257 - val_loss: 0.8537 - val_accuracy: 0.7164
Epoch 20/350
391/391 - 24s - loss: 0.7849 - accuracy: 0.7334 - val_loss: 0.6962 - val_accuracy: 0.7674
Epoch 21/350
391/391 - 24s - loss: 0.7638 - accuracy: 0.7421 - val_loss: 0.6903 - val_accuracy: 0.7688
Epoch 22/350
391/391 - 24s - loss: 0.7266 - accuracy: 0.7552 - val_loss: 0.6821 - val_accuracy: 0.7758
Epoch 23/350
391/391 - 24s - loss: 0.7094 - accuracy: 0.7625 - val_loss: 0.6560 - val_accuracy: 0.7829
Epoch 24/350
391/391 - 25s - loss: 0.6918 - accuracy: 0.7675 - val_loss: 0.6652 - val_accuracy: 0.7860
Epoch 25/350
391/391 - 25s - loss: 0.6717 - accuracy: 0.7758 - val_loss: 0.6063 - val_accuracy: 0.7997
Epoch 26/350
391/391 - 24s - loss: 0.6514 - accuracy: 0.7858 - val_loss: 0.6854 - val_accuracy: 0.7791
Epoch 27/350
391/391 - 24s - loss: 0.6338 - accuracy: 0.7910 - val_loss: 0.6059 - val_accuracy: 0.8036
Epoch 28/350
391/391 - 25s - loss: 0.6185 - accuracy: 0.7956 - val_loss: 0.5981 - val_accuracy: 0.8071
Epoch 29/350
391/391 - 25s - loss: 0.6082 - accuracy: 0.7988 - val_loss: 0.5612 - val_accuracy: 0.8152
Epoch 30/350
391/391 - 24s - loss: 0.5913 - accuracy: 0.8041 - val_loss: 0.5709 - val_accuracy: 0.8151
Epoch 31/350
391/391 - 24s - loss: 0.5823 - accuracy: 0.8099 - val_loss: 0.5617 - val_accuracy: 0.8185
Epoch 32/350
391/391 - 24s - loss: 0.5623 - accuracy: 0.8137 - val_loss: 0.5512 - val_accuracy: 0.8220
Epoch 33/350
391/391 - 25s - loss: 0.5569 - accuracy: 0.8170 - val_loss: 0.5276 - val_accuracy: 0.8317
Epoch 34/350
391/391 - 24s - loss: 0.5567 - accuracy: 0.8172 - val_loss: 0.5528 - val_accuracy: 0.8201
Epoch 35/350
391/391 - 24s - loss: 0.5343 - accuracy: 0.8265 - val_loss: 0.5183 - val_accuracy: 0.8356
Epoch 36/350
391/391 - 25s - loss: 0.5279 - accuracy: 0.8267 - val_loss: 0.4981 - val_accuracy: 0.8403
Epoch 37/350
391/391 - 25s - loss: 0.5199 - accuracy: 0.8296 - val_loss: 0.4972 - val_accuracy: 0.8410
Epoch 38/350
391/391 - 24s - loss: 0.5096 - accuracy: 0.8319 - val_loss: 0.5042 - val_accuracy: 0.8409
Epoch 39/350
391/391 - 25s - loss: 0.4990 - accuracy: 0.8368 - val_loss: 0.4969 - val_accuracy: 0.8413
Epoch 40/350
391/391 - 25s - loss: 0.4913 - accuracy: 0.8405 - val_loss: 0.5240 - val_accuracy: 0.8361
Epoch 41/350
391/391 - 25s - loss: 0.4862 - accuracy: 0.8405 - val_loss: 0.5022 - val_accuracy: 0.8429
Epoch 42/350
391/391 - 24s - loss: 0.4736 - accuracy: 0.8461 - val_loss: 0.4676 - val_accuracy: 0.8552
Epoch 43/350
391/391 - 24s - loss: 0.4685 - accuracy: 0.8464 - val_loss: 0.4999 - val_accuracy: 0.8428
Epoch 44/350
391/391 - 24s - loss: 0.4590 - accuracy: 0.8508 - val_loss: 0.4671 - val_accuracy: 0.8558
Epoch 45/350
391/391 - 25s - loss: 0.4574 - accuracy: 0.8505 - val_loss: 0.4817 - val_accuracy: 0.8514
Epoch 46/350
391/391 - 25s - loss: 0.4474 - accuracy: 0.8547 - val_loss: 0.4946 - val_accuracy: 0.8499
Epoch 47/350
391/391 - 24s - loss: 0.4498 - accuracy: 0.8547 - val_loss: 0.4878 - val_accuracy: 0.8519
Epoch 48/350
391/391 - 24s - loss: 0.4362 - accuracy: 0.8587 - val_loss: 0.4565 - val_accuracy: 0.8598
Epoch 49/350
391/391 - 25s - loss: 0.4349 - accuracy: 0.8595 - val_loss: 0.5050 - val_accuracy: 0.8463
Epoch 50/350


Snapshot weight 3 shuffle 2 at epoch 50
Layer 11
Getting activations...


391/391 - 25s - loss: 0.4178 - accuracy: 0.8633 - val_loss: 0.4624 - val_accuracy: 0.8554
Epoch 51/350
391/391 - 25s - loss: 0.4169 - accuracy: 0.8634 - val_loss: 0.4918 - val_accuracy: 0.8513
Epoch 52/350
391/391 - 24s - loss: 0.4171 - accuracy: 0.8662 - val_loss: 0.4626 - val_accuracy: 0.8633
Epoch 53/350
391/391 - 25s - loss: 0.4038 - accuracy: 0.8715 - val_loss: 0.4557 - val_accuracy: 0.8579
Epoch 54/350
391/391 - 24s - loss: 0.4080 - accuracy: 0.8698 - val_loss: 0.4598 - val_accuracy: 0.8572
Epoch 55/350
391/391 - 24s - loss: 0.4022 - accuracy: 0.8714 - val_loss: 0.4517 - val_accuracy: 0.8662
Epoch 56/350
391/391 - 24s - loss: 0.3938 - accuracy: 0.8726 - val_loss: 0.4401 - val_accuracy: 0.8662
Epoch 57/350
391/391 - 24s - loss: 0.3904 - accuracy: 0.8744 - val_loss: 0.4774 - val_accuracy: 0.8575
Epoch 58/350
391/391 - 25s - loss: 0.3920 - accuracy: 0.8732 - val_loss: 0.4562 - val_accuracy: 0.8624
Epoch 59/350
391/391 - 25s - loss: 0.3817 - accuracy: 0.8772 - val_loss: 0.4945 - val_accuracy: 0.8583
Epoch 60/350
391/391 - 24s - loss: 0.3785 - accuracy: 0.8781 - val_loss: 0.4577 - val_accuracy: 0.8610
Epoch 61/350
391/391 - 25s - loss: 0.3693 - accuracy: 0.8811 - val_loss: 0.4341 - val_accuracy: 0.8746
Epoch 62/350
391/391 - 24s - loss: 0.3699 - accuracy: 0.8825 - val_loss: 0.4486 - val_accuracy: 0.8717
Epoch 63/350
391/391 - 24s - loss: 0.3617 - accuracy: 0.8850 - val_loss: 0.4773 - val_accuracy: 0.8628
Epoch 64/350
391/391 - 24s - loss: 0.3627 - accuracy: 0.8851 - val_loss: 0.4539 - val_accuracy: 0.8676
Epoch 65/350
391/391 - 25s - loss: 0.3522 - accuracy: 0.8881 - val_loss: 0.4299 - val_accuracy: 0.8744
Epoch 66/350
391/391 - 24s - loss: 0.3532 - accuracy: 0.8874 - val_loss: 0.4267 - val_accuracy: 0.8750
Epoch 67/350
391/391 - 24s - loss: 0.3543 - accuracy: 0.8884 - val_loss: 0.4506 - val_accuracy: 0.8670
Epoch 68/350
391/391 - 24s - loss: 0.3511 - accuracy: 0.8884 - val_loss: 0.4174 - val_accuracy: 0.8749
Epoch 69/350
391/391 - 25s - loss: 0.3419 - accuracy: 0.8913 - val_loss: 0.4572 - val_accuracy: 0.8709
Epoch 70/350
391/391 - 25s - loss: 0.3454 - accuracy: 0.8905 - val_loss: 0.4305 - val_accuracy: 0.8747
Epoch 71/350
391/391 - 24s - loss: 0.3373 - accuracy: 0.8934 - val_loss: 0.4497 - val_accuracy: 0.8653
Epoch 72/350
391/391 - 24s - loss: 0.3386 - accuracy: 0.8944 - val_loss: 0.4171 - val_accuracy: 0.8768
Epoch 73/350
391/391 - 25s - loss: 0.3295 - accuracy: 0.8971 - val_loss: 0.4149 - val_accuracy: 0.8795
Epoch 74/350
391/391 - 24s - loss: 0.3267 - accuracy: 0.8973 - val_loss: 0.4651 - val_accuracy: 0.8662
Epoch 75/350
391/391 - 25s - loss: 0.3201 - accuracy: 0.8984 - val_loss: 0.4313 - val_accuracy: 0.8765
Epoch 76/350
391/391 - 24s - loss: 0.3199 - accuracy: 0.9002 - val_loss: 0.4282 - val_accuracy: 0.8743
Epoch 77/350
391/391 - 25s - loss: 0.3189 - accuracy: 0.8998 - val_loss: 0.4526 - val_accuracy: 0.8646
Epoch 78/350
391/391 - 24s - loss: 0.3138 - accuracy: 0.9022 - val_loss: 0.4277 - val_accuracy: 0.8757
Epoch 79/350
391/391 - 25s - loss: 0.3112 - accuracy: 0.9021 - val_loss: 0.4020 - val_accuracy: 0.8847
Epoch 80/350
391/391 - 25s - loss: 0.3051 - accuracy: 0.9059 - val_loss: 0.4243 - val_accuracy: 0.8813
Epoch 81/350
391/391 - 24s - loss: 0.3066 - accuracy: 0.9046 - val_loss: 0.4347 - val_accuracy: 0.8766
Epoch 82/350
391/391 - 25s - loss: 0.3077 - accuracy: 0.9038 - val_loss: 0.4124 - val_accuracy: 0.8806
Epoch 83/350
391/391 - 25s - loss: 0.3034 - accuracy: 0.9052 - val_loss: 0.4255 - val_accuracy: 0.8855
Epoch 84/350
391/391 - 25s - loss: 0.2975 - accuracy: 0.9087 - val_loss: 0.4171 - val_accuracy: 0.8792
Epoch 85/350
391/391 - 25s - loss: 0.3003 - accuracy: 0.9075 - val_loss: 0.4283 - val_accuracy: 0.8802
Epoch 86/350
391/391 - 24s - loss: 0.2968 - accuracy: 0.9078 - val_loss: 0.3988 - val_accuracy: 0.8860
Epoch 87/350
391/391 - 24s - loss: 0.2895 - accuracy: 0.9117 - val_loss: 0.4070 - val_accuracy: 0.8829
Epoch 88/350
391/391 - 25s - loss: 0.2915 - accuracy: 0.9109 - val_loss: 0.4094 - val_accuracy: 0.8809
Epoch 89/350
391/391 - 24s - loss: 0.2940 - accuracy: 0.9086 - val_loss: 0.4309 - val_accuracy: 0.8784
Epoch 90/350
391/391 - 24s - loss: 0.2849 - accuracy: 0.9116 - val_loss: 0.4149 - val_accuracy: 0.8826
Epoch 91/350
391/391 - 24s - loss: 0.2834 - accuracy: 0.9124 - val_loss: 0.4231 - val_accuracy: 0.8860
Epoch 92/350
391/391 - 25s - loss: 0.2820 - accuracy: 0.9134 - val_loss: 0.4268 - val_accuracy: 0.8827
Epoch 93/350
391/391 - 25s - loss: 0.2799 - accuracy: 0.9156 - val_loss: 0.4322 - val_accuracy: 0.8792
Epoch 94/350
391/391 - 25s - loss: 0.2743 - accuracy: 0.9167 - val_loss: 0.4265 - val_accuracy: 0.8807
Epoch 95/350
391/391 - 24s - loss: 0.2709 - accuracy: 0.9186 - val_loss: 0.4144 - val_accuracy: 0.8865
Epoch 96/350
391/391 - 24s - loss: 0.2757 - accuracy: 0.9146 - val_loss: 0.4399 - val_accuracy: 0.8862
Epoch 97/350
391/391 - 25s - loss: 0.2730 - accuracy: 0.9168 - val_loss: 0.4243 - val_accuracy: 0.8857
Epoch 98/350
391/391 - 25s - loss: 0.2673 - accuracy: 0.9192 - val_loss: 0.4128 - val_accuracy: 0.8860
Epoch 99/350
391/391 - 24s - loss: 0.2700 - accuracy: 0.9172 - val_loss: 0.4339 - val_accuracy: 0.8853
Epoch 100/350


Snapshot weight 3 shuffle 2 at epoch 100
Layer 11
Getting activations...


391/391 - 25s - loss: 0.2689 - accuracy: 0.9189 - val_loss: 0.4190 - val_accuracy: 0.8800
Epoch 101/350
391/391 - 24s - loss: 0.2648 - accuracy: 0.9203 - val_loss: 0.3992 - val_accuracy: 0.8895
Epoch 102/350
391/391 - 24s - loss: 0.2648 - accuracy: 0.9203 - val_loss: 0.4242 - val_accuracy: 0.8842
Epoch 103/350
391/391 - 24s - loss: 0.2619 - accuracy: 0.9215 - val_loss: 0.4336 - val_accuracy: 0.8854
Epoch 104/350
391/391 - 25s - loss: 0.2546 - accuracy: 0.9228 - val_loss: 0.4284 - val_accuracy: 0.8869
Epoch 105/350
391/391 - 25s - loss: 0.2530 - accuracy: 0.9241 - val_loss: 0.4184 - val_accuracy: 0.8866
Epoch 106/350
391/391 - 24s - loss: 0.2540 - accuracy: 0.9235 - val_loss: 0.4202 - val_accuracy: 0.8823
Epoch 107/350
391/391 - 25s - loss: 0.2536 - accuracy: 0.9238 - val_loss: 0.4538 - val_accuracy: 0.8825
Epoch 108/350
391/391 - 24s - loss: 0.2561 - accuracy: 0.9226 - val_loss: 0.4142 - val_accuracy: 0.8865
Epoch 109/350
391/391 - 24s - loss: 0.2503 - accuracy: 0.9258 - val_loss: 0.4243 - val_accuracy: 0.8849
Epoch 110/350
391/391 - 24s - loss: 0.2511 - accuracy: 0.9247 - val_loss: 0.4198 - val_accuracy: 0.8862
Epoch 111/350
391/391 - 24s - loss: 0.2511 - accuracy: 0.9253 - val_loss: 0.4545 - val_accuracy: 0.8812
Epoch 112/350
391/391 - 24s - loss: 0.2483 - accuracy: 0.9263 - val_loss: 0.4432 - val_accuracy: 0.8872
Epoch 113/350
391/391 - 25s - loss: 0.2430 - accuracy: 0.9280 - val_loss: 0.4060 - val_accuracy: 0.8895
Epoch 114/350
391/391 - 24s - loss: 0.2432 - accuracy: 0.9279 - val_loss: 0.4227 - val_accuracy: 0.8887
Epoch 115/350
391/391 - 24s - loss: 0.2359 - accuracy: 0.9300 - val_loss: 0.4218 - val_accuracy: 0.8911
Epoch 116/350
391/391 - 25s - loss: 0.2412 - accuracy: 0.9278 - val_loss: 0.4376 - val_accuracy: 0.8895
Epoch 117/350
391/391 - 25s - loss: 0.2349 - accuracy: 0.9304 - val_loss: 0.4454 - val_accuracy: 0.8833
Epoch 118/350
391/391 - 24s - loss: 0.2400 - accuracy: 0.9295 - val_loss: 0.4578 - val_accuracy: 0.8808
Epoch 119/350
391/391 - 24s - loss: 0.2402 - accuracy: 0.9281 - val_loss: 0.4210 - val_accuracy: 0.8887
Epoch 120/350
391/391 - 24s - loss: 0.2340 - accuracy: 0.9304 - val_loss: 0.4542 - val_accuracy: 0.8819
Epoch 121/350
391/391 - 24s - loss: 0.2314 - accuracy: 0.9326 - val_loss: 0.4428 - val_accuracy: 0.8834
Epoch 122/350
391/391 - 24s - loss: 0.2308 - accuracy: 0.9328 - val_loss: 0.4079 - val_accuracy: 0.8940
Epoch 123/350
391/391 - 24s - loss: 0.2318 - accuracy: 0.9310 - val_loss: 0.4374 - val_accuracy: 0.8902
Epoch 124/350
391/391 - 25s - loss: 0.2273 - accuracy: 0.9336 - val_loss: 0.4454 - val_accuracy: 0.8808
Epoch 125/350
391/391 - 25s - loss: 0.2293 - accuracy: 0.9317 - val_loss: 0.4211 - val_accuracy: 0.8911
Epoch 126/350
391/391 - 24s - loss: 0.2230 - accuracy: 0.9350 - val_loss: 0.4227 - val_accuracy: 0.8913
Epoch 127/350
391/391 - 24s - loss: 0.2275 - accuracy: 0.9334 - val_loss: 0.4418 - val_accuracy: 0.8855
Epoch 128/350
391/391 - 25s - loss: 0.2219 - accuracy: 0.9352 - val_loss: 0.4225 - val_accuracy: 0.8924
Epoch 129/350
391/391 - 25s - loss: 0.2220 - accuracy: 0.9367 - val_loss: 0.4379 - val_accuracy: 0.8894
Epoch 130/350
391/391 - 24s - loss: 0.2241 - accuracy: 0.9344 - val_loss: 0.4427 - val_accuracy: 0.8864
Epoch 131/350
391/391 - 24s - loss: 0.2188 - accuracy: 0.9367 - val_loss: 0.4438 - val_accuracy: 0.8895
Epoch 132/350
391/391 - 25s - loss: 0.2196 - accuracy: 0.9372 - val_loss: 0.4514 - val_accuracy: 0.8873
Epoch 133/350
391/391 - 25s - loss: 0.2197 - accuracy: 0.9359 - val_loss: 0.4215 - val_accuracy: 0.8875
Epoch 134/350
391/391 - 24s - loss: 0.2129 - accuracy: 0.9388 - val_loss: 0.4472 - val_accuracy: 0.8885
Epoch 135/350
391/391 - 24s - loss: 0.2148 - accuracy: 0.9374 - val_loss: 0.4553 - val_accuracy: 0.8895
Epoch 136/350
391/391 - 24s - loss: 0.2169 - accuracy: 0.9388 - val_loss: 0.4490 - val_accuracy: 0.8895
Epoch 137/350
391/391 - 25s - loss: 0.2154 - accuracy: 0.9384 - val_loss: 0.4478 - val_accuracy: 0.8882
Epoch 138/350
391/391 - 24s - loss: 0.2151 - accuracy: 0.9382 - val_loss: 0.4325 - val_accuracy: 0.8915
Epoch 139/350
391/391 - 24s - loss: 0.2129 - accuracy: 0.9382 - val_loss: 0.4482 - val_accuracy: 0.8901
Epoch 140/350
391/391 - 24s - loss: 0.2117 - accuracy: 0.9399 - val_loss: 0.4162 - val_accuracy: 0.8958
Epoch 141/350
391/391 - 25s - loss: 0.2098 - accuracy: 0.9387 - val_loss: 0.4361 - val_accuracy: 0.8954
Epoch 142/350
391/391 - 24s - loss: 0.2108 - accuracy: 0.9390 - val_loss: 0.4484 - val_accuracy: 0.8940
Epoch 143/350
391/391 - 24s - loss: 0.2062 - accuracy: 0.9424 - val_loss: 0.4454 - val_accuracy: 0.8921
Epoch 144/350
391/391 - 24s - loss: 0.2074 - accuracy: 0.9414 - val_loss: 0.4334 - val_accuracy: 0.8908
Epoch 145/350
391/391 - 24s - loss: 0.2011 - accuracy: 0.9427 - val_loss: 0.4407 - val_accuracy: 0.8911
Epoch 146/350
391/391 - 24s - loss: 0.2077 - accuracy: 0.9410 - val_loss: 0.4325 - val_accuracy: 0.8957
Epoch 147/350
391/391 - 24s - loss: 0.2053 - accuracy: 0.9422 - val_loss: 0.4313 - val_accuracy: 0.8915
Epoch 148/350
391/391 - 24s - loss: 0.2052 - accuracy: 0.9410 - val_loss: 0.4582 - val_accuracy: 0.8930
Epoch 149/350
391/391 - 24s - loss: 0.1998 - accuracy: 0.9431 - val_loss: 0.4306 - val_accuracy: 0.8912
Epoch 150/350


Snapshot weight 3 shuffle 2 at epoch 150
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1991 - accuracy: 0.9446 - val_loss: 0.4178 - val_accuracy: 0.8955
Epoch 151/350
391/391 - 25s - loss: 0.1945 - accuracy: 0.9448 - val_loss: 0.4280 - val_accuracy: 0.8972
Epoch 152/350
391/391 - 24s - loss: 0.1986 - accuracy: 0.9453 - val_loss: 0.4768 - val_accuracy: 0.8877
Epoch 153/350
391/391 - 25s - loss: 0.1999 - accuracy: 0.9438 - val_loss: 0.4292 - val_accuracy: 0.8932
Epoch 154/350
391/391 - 24s - loss: 0.2021 - accuracy: 0.9429 - val_loss: 0.4350 - val_accuracy: 0.8935
Epoch 155/350
391/391 - 24s - loss: 0.1936 - accuracy: 0.9457 - val_loss: 0.4635 - val_accuracy: 0.8896
Epoch 156/350
391/391 - 24s - loss: 0.1980 - accuracy: 0.9450 - val_loss: 0.4604 - val_accuracy: 0.8924
Epoch 157/350
391/391 - 25s - loss: 0.1922 - accuracy: 0.9465 - val_loss: 0.4573 - val_accuracy: 0.8902
Epoch 158/350
391/391 - 24s - loss: 0.1966 - accuracy: 0.9454 - val_loss: 0.4338 - val_accuracy: 0.8925
Epoch 159/350
391/391 - 24s - loss: 0.1972 - accuracy: 0.9445 - val_loss: 0.4389 - val_accuracy: 0.8951
Epoch 160/350
391/391 - 24s - loss: 0.1955 - accuracy: 0.9453 - val_loss: 0.4398 - val_accuracy: 0.8959
Epoch 161/350
391/391 - 25s - loss: 0.1917 - accuracy: 0.9467 - val_loss: 0.4749 - val_accuracy: 0.8873
Epoch 162/350
391/391 - 24s - loss: 0.1899 - accuracy: 0.9479 - val_loss: 0.4657 - val_accuracy: 0.8953
Epoch 163/350
391/391 - 25s - loss: 0.1926 - accuracy: 0.9468 - val_loss: 0.4664 - val_accuracy: 0.8909
Epoch 164/350
391/391 - 24s - loss: 0.1890 - accuracy: 0.9482 - val_loss: 0.4253 - val_accuracy: 0.8953
Epoch 165/350
391/391 - 25s - loss: 0.1862 - accuracy: 0.9495 - val_loss: 0.4569 - val_accuracy: 0.8902
Epoch 166/350
391/391 - 24s - loss: 0.1912 - accuracy: 0.9470 - val_loss: 0.4350 - val_accuracy: 0.8935
Epoch 167/350
391/391 - 24s - loss: 0.1833 - accuracy: 0.9504 - val_loss: 0.4458 - val_accuracy: 0.8951
Epoch 168/350
391/391 - 24s - loss: 0.1849 - accuracy: 0.9497 - val_loss: 0.4807 - val_accuracy: 0.8923
Epoch 169/350
391/391 - 24s - loss: 0.1819 - accuracy: 0.9504 - val_loss: 0.4736 - val_accuracy: 0.8964
Epoch 170/350
391/391 - 24s - loss: 0.1842 - accuracy: 0.9501 - val_loss: 0.4331 - val_accuracy: 0.8957
Epoch 171/350
391/391 - 24s - loss: 0.1857 - accuracy: 0.9498 - val_loss: 0.4496 - val_accuracy: 0.8954
Epoch 172/350
391/391 - 24s - loss: 0.1860 - accuracy: 0.9493 - val_loss: 0.4526 - val_accuracy: 0.8976
Epoch 173/350
391/391 - 24s - loss: 0.1824 - accuracy: 0.9501 - val_loss: 0.4523 - val_accuracy: 0.8939
Epoch 174/350
391/391 - 24s - loss: 0.1835 - accuracy: 0.9499 - val_loss: 0.4412 - val_accuracy: 0.8895
Epoch 175/350
391/391 - 25s - loss: 0.1816 - accuracy: 0.9511 - val_loss: 0.4390 - val_accuracy: 0.8968
Epoch 176/350
391/391 - 24s - loss: 0.1787 - accuracy: 0.9526 - val_loss: 0.5002 - val_accuracy: 0.8912
Epoch 177/350
391/391 - 24s - loss: 0.1829 - accuracy: 0.9522 - val_loss: 0.4330 - val_accuracy: 0.8957
Epoch 178/350
391/391 - 25s - loss: 0.1796 - accuracy: 0.9521 - val_loss: 0.4576 - val_accuracy: 0.8976
Epoch 179/350
391/391 - 24s - loss: 0.1820 - accuracy: 0.9512 - val_loss: 0.4420 - val_accuracy: 0.8990
Epoch 180/350
391/391 - 24s - loss: 0.1799 - accuracy: 0.9528 - val_loss: 0.4442 - val_accuracy: 0.8995
Epoch 181/350
391/391 - 24s - loss: 0.1795 - accuracy: 0.9512 - val_loss: 0.4511 - val_accuracy: 0.8955
Epoch 182/350
391/391 - 24s - loss: 0.1817 - accuracy: 0.9518 - val_loss: 0.4642 - val_accuracy: 0.8964
Epoch 183/350
391/391 - 24s - loss: 0.1762 - accuracy: 0.9524 - val_loss: 0.4773 - val_accuracy: 0.8970
Epoch 184/350
391/391 - 24s - loss: 0.1772 - accuracy: 0.9535 - val_loss: 0.4779 - val_accuracy: 0.8929
Epoch 185/350
391/391 - 24s - loss: 0.1725 - accuracy: 0.9551 - val_loss: 0.4771 - val_accuracy: 0.8921
Epoch 186/350
391/391 - 25s - loss: 0.1755 - accuracy: 0.9530 - val_loss: 0.4738 - val_accuracy: 0.8945
Epoch 187/350
391/391 - 25s - loss: 0.1779 - accuracy: 0.9534 - val_loss: 0.4822 - val_accuracy: 0.8881
Epoch 188/350
391/391 - 24s - loss: 0.1763 - accuracy: 0.9533 - val_loss: 0.4614 - val_accuracy: 0.8980
Epoch 189/350
391/391 - 24s - loss: 0.1754 - accuracy: 0.9540 - val_loss: 0.4716 - val_accuracy: 0.8953
Epoch 190/350
391/391 - 24s - loss: 0.1748 - accuracy: 0.9552 - val_loss: 0.4617 - val_accuracy: 0.8950
Epoch 191/350
391/391 - 25s - loss: 0.1732 - accuracy: 0.9562 - val_loss: 0.4860 - val_accuracy: 0.8915
Epoch 192/350
391/391 - 24s - loss: 0.1700 - accuracy: 0.9552 - val_loss: 0.4553 - val_accuracy: 0.8923
Epoch 193/350
391/391 - 25s - loss: 0.1737 - accuracy: 0.9541 - val_loss: 0.5147 - val_accuracy: 0.8885
Epoch 194/350
391/391 - 24s - loss: 0.1714 - accuracy: 0.9555 - val_loss: 0.4898 - val_accuracy: 0.8924
Epoch 195/350
391/391 - 25s - loss: 0.1704 - accuracy: 0.9563 - val_loss: 0.4708 - val_accuracy: 0.8938
Epoch 196/350
391/391 - 24s - loss: 0.1734 - accuracy: 0.9541 - val_loss: 0.4549 - val_accuracy: 0.8930
Epoch 197/350
391/391 - 24s - loss: 0.1681 - accuracy: 0.9570 - val_loss: 0.4919 - val_accuracy: 0.8878
Epoch 198/350
391/391 - 24s - loss: 0.1696 - accuracy: 0.9551 - val_loss: 0.4818 - val_accuracy: 0.8934
Epoch 199/350
391/391 - 25s - loss: 0.1691 - accuracy: 0.9564 - val_loss: 0.4979 - val_accuracy: 0.8915
Epoch 200/350


Snapshot weight 3 shuffle 2 at epoch 200
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1675 - accuracy: 0.9575 - val_loss: 0.4690 - val_accuracy: 0.8942
Epoch 201/350
391/391 - 24s - loss: 0.1417 - accuracy: 0.9669 - val_loss: 0.4567 - val_accuracy: 0.9009
Epoch 202/350
391/391 - 24s - loss: 0.1297 - accuracy: 0.9707 - val_loss: 0.4614 - val_accuracy: 0.9030
Epoch 203/350
391/391 - 24s - loss: 0.1278 - accuracy: 0.9713 - val_loss: 0.4659 - val_accuracy: 0.9015
Epoch 204/350
391/391 - 24s - loss: 0.1241 - accuracy: 0.9722 - val_loss: 0.4674 - val_accuracy: 0.9047
Epoch 205/350
391/391 - 24s - loss: 0.1245 - accuracy: 0.9723 - val_loss: 0.4574 - val_accuracy: 0.9034
Epoch 206/350
391/391 - 24s - loss: 0.1206 - accuracy: 0.9733 - val_loss: 0.4761 - val_accuracy: 0.9031
Epoch 207/350
391/391 - 24s - loss: 0.1195 - accuracy: 0.9737 - val_loss: 0.4610 - val_accuracy: 0.9055
Epoch 208/350
391/391 - 24s - loss: 0.1217 - accuracy: 0.9727 - val_loss: 0.4742 - val_accuracy: 0.9038
Epoch 209/350
391/391 - 24s - loss: 0.1180 - accuracy: 0.9738 - val_loss: 0.4760 - val_accuracy: 0.9027
Epoch 210/350
391/391 - 24s - loss: 0.1163 - accuracy: 0.9749 - val_loss: 0.4694 - val_accuracy: 0.9053
Epoch 211/350
391/391 - 24s - loss: 0.1161 - accuracy: 0.9754 - val_loss: 0.4788 - val_accuracy: 0.9043
Epoch 212/350
391/391 - 25s - loss: 0.1175 - accuracy: 0.9741 - val_loss: 0.4809 - val_accuracy: 0.9038
Epoch 213/350
391/391 - 24s - loss: 0.1149 - accuracy: 0.9757 - val_loss: 0.4810 - val_accuracy: 0.9040
Epoch 214/350
391/391 - 24s - loss: 0.1180 - accuracy: 0.9748 - val_loss: 0.4701 - val_accuracy: 0.9045
Epoch 215/350
391/391 - 24s - loss: 0.1136 - accuracy: 0.9760 - val_loss: 0.4735 - val_accuracy: 0.9035
Epoch 216/350
391/391 - 24s - loss: 0.1138 - accuracy: 0.9757 - val_loss: 0.4854 - val_accuracy: 0.9033
Epoch 217/350
391/391 - 24s - loss: 0.1148 - accuracy: 0.9758 - val_loss: 0.4811 - val_accuracy: 0.9042
Epoch 218/350
391/391 - 24s - loss: 0.1157 - accuracy: 0.9750 - val_loss: 0.4851 - val_accuracy: 0.9049
Epoch 219/350
391/391 - 24s - loss: 0.1120 - accuracy: 0.9766 - val_loss: 0.4857 - val_accuracy: 0.9053
Epoch 220/350
391/391 - 24s - loss: 0.1092 - accuracy: 0.9787 - val_loss: 0.4811 - val_accuracy: 0.9043
Epoch 221/350
391/391 - 24s - loss: 0.1124 - accuracy: 0.9770 - val_loss: 0.4909 - val_accuracy: 0.9062
Epoch 222/350
391/391 - 24s - loss: 0.1141 - accuracy: 0.9759 - val_loss: 0.4818 - val_accuracy: 0.9054
Epoch 223/350
391/391 - 24s - loss: 0.1145 - accuracy: 0.9757 - val_loss: 0.4765 - val_accuracy: 0.9050
Epoch 224/350
391/391 - 24s - loss: 0.1156 - accuracy: 0.9757 - val_loss: 0.4759 - val_accuracy: 0.9041
Epoch 225/350
391/391 - 24s - loss: 0.1112 - accuracy: 0.9770 - val_loss: 0.4735 - val_accuracy: 0.9063
Epoch 226/350
391/391 - 24s - loss: 0.1140 - accuracy: 0.9758 - val_loss: 0.4753 - val_accuracy: 0.9047
Epoch 227/350
391/391 - 24s - loss: 0.1095 - accuracy: 0.9777 - val_loss: 0.4794 - val_accuracy: 0.9056
Epoch 228/350
391/391 - 24s - loss: 0.1106 - accuracy: 0.9772 - val_loss: 0.4831 - val_accuracy: 0.9062
Epoch 229/350
391/391 - 24s - loss: 0.1098 - accuracy: 0.9765 - val_loss: 0.4819 - val_accuracy: 0.9062
Epoch 230/350
391/391 - 24s - loss: 0.1102 - accuracy: 0.9766 - val_loss: 0.4874 - val_accuracy: 0.9042
Epoch 231/350
391/391 - 24s - loss: 0.1072 - accuracy: 0.9779 - val_loss: 0.4914 - val_accuracy: 0.9042
Epoch 232/350
391/391 - 24s - loss: 0.1093 - accuracy: 0.9773 - val_loss: 0.4884 - val_accuracy: 0.9064
Epoch 233/350
391/391 - 24s - loss: 0.1132 - accuracy: 0.9763 - val_loss: 0.4839 - val_accuracy: 0.9062
Epoch 234/350
391/391 - 25s - loss: 0.1115 - accuracy: 0.9767 - val_loss: 0.4951 - val_accuracy: 0.9052
Epoch 235/350
391/391 - 24s - loss: 0.1087 - accuracy: 0.9770 - val_loss: 0.4899 - val_accuracy: 0.9048
Epoch 236/350
391/391 - 24s - loss: 0.1088 - accuracy: 0.9780 - val_loss: 0.4946 - val_accuracy: 0.9057
Epoch 237/350
391/391 - 25s - loss: 0.1084 - accuracy: 0.9780 - val_loss: 0.4833 - val_accuracy: 0.9049
Epoch 238/350
391/391 - 24s - loss: 0.1107 - accuracy: 0.9767 - val_loss: 0.4863 - val_accuracy: 0.9055
Epoch 239/350
391/391 - 24s - loss: 0.1113 - accuracy: 0.9771 - val_loss: 0.4848 - val_accuracy: 0.9056
Epoch 240/350
391/391 - 24s - loss: 0.1085 - accuracy: 0.9768 - val_loss: 0.4902 - val_accuracy: 0.9059
Epoch 241/350
391/391 - 24s - loss: 0.1086 - accuracy: 0.9779 - val_loss: 0.4978 - val_accuracy: 0.9064
Epoch 242/350
391/391 - 24s - loss: 0.1065 - accuracy: 0.9785 - val_loss: 0.4905 - val_accuracy: 0.9061
Epoch 243/350
391/391 - 25s - loss: 0.1070 - accuracy: 0.9785 - val_loss: 0.4937 - val_accuracy: 0.9053
Epoch 244/350
391/391 - 24s - loss: 0.1057 - accuracy: 0.9793 - val_loss: 0.4975 - val_accuracy: 0.9064
Epoch 245/350
391/391 - 24s - loss: 0.1086 - accuracy: 0.9778 - val_loss: 0.4955 - val_accuracy: 0.9049
Epoch 246/350
391/391 - 25s - loss: 0.1061 - accuracy: 0.9785 - val_loss: 0.4910 - val_accuracy: 0.9054
Epoch 247/350
391/391 - 25s - loss: 0.1072 - accuracy: 0.9777 - val_loss: 0.4979 - val_accuracy: 0.9058
Epoch 248/350
391/391 - 24s - loss: 0.1063 - accuracy: 0.9787 - val_loss: 0.5025 - val_accuracy: 0.9038
Epoch 249/350
391/391 - 24s - loss: 0.1049 - accuracy: 0.9791 - val_loss: 0.5026 - val_accuracy: 0.9062
Epoch 250/350


Snapshot weight 3 shuffle 2 at epoch 250
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1072 - accuracy: 0.9784 - val_loss: 0.4981 - val_accuracy: 0.9050
Epoch 251/350
391/391 - 24s - loss: 0.1053 - accuracy: 0.9792 - val_loss: 0.4952 - val_accuracy: 0.9051
Epoch 252/350
391/391 - 25s - loss: 0.1031 - accuracy: 0.9805 - val_loss: 0.4938 - val_accuracy: 0.9053
Epoch 253/350
391/391 - 24s - loss: 0.1060 - accuracy: 0.9787 - val_loss: 0.4964 - val_accuracy: 0.9056
Epoch 254/350
391/391 - 24s - loss: 0.1049 - accuracy: 0.9792 - val_loss: 0.4944 - val_accuracy: 0.9048
Epoch 255/350
391/391 - 24s - loss: 0.1015 - accuracy: 0.9809 - val_loss: 0.4952 - val_accuracy: 0.9054
Epoch 256/350
391/391 - 24s - loss: 0.1039 - accuracy: 0.9795 - val_loss: 0.4929 - val_accuracy: 0.9049
Epoch 257/350
391/391 - 24s - loss: 0.1027 - accuracy: 0.9795 - val_loss: 0.4950 - val_accuracy: 0.9049
Epoch 258/350
391/391 - 25s - loss: 0.1047 - accuracy: 0.9792 - val_loss: 0.4952 - val_accuracy: 0.9056
Epoch 259/350
391/391 - 24s - loss: 0.1027 - accuracy: 0.9795 - val_loss: 0.4950 - val_accuracy: 0.9055
Epoch 260/350
391/391 - 24s - loss: 0.1016 - accuracy: 0.9798 - val_loss: 0.4956 - val_accuracy: 0.9053
Epoch 261/350
391/391 - 24s - loss: 0.1029 - accuracy: 0.9800 - val_loss: 0.4955 - val_accuracy: 0.9056
Epoch 262/350
391/391 - 24s - loss: 0.1026 - accuracy: 0.9807 - val_loss: 0.4958 - val_accuracy: 0.9051
Epoch 263/350
391/391 - 24s - loss: 0.1027 - accuracy: 0.9794 - val_loss: 0.4975 - val_accuracy: 0.9059
Epoch 264/350
391/391 - 24s - loss: 0.1021 - accuracy: 0.9800 - val_loss: 0.4978 - val_accuracy: 0.9053
Epoch 265/350
391/391 - 24s - loss: 0.1020 - accuracy: 0.9798 - val_loss: 0.4982 - val_accuracy: 0.9054
Epoch 266/350
391/391 - 24s - loss: 0.1026 - accuracy: 0.9804 - val_loss: 0.4976 - val_accuracy: 0.9060
Epoch 267/350
391/391 - 24s - loss: 0.1023 - accuracy: 0.9794 - val_loss: 0.4963 - val_accuracy: 0.9053
Epoch 268/350
391/391 - 24s - loss: 0.1030 - accuracy: 0.9800 - val_loss: 0.4984 - val_accuracy: 0.9049
Epoch 269/350
391/391 - 24s - loss: 0.1018 - accuracy: 0.9801 - val_loss: 0.4978 - val_accuracy: 0.9057
Epoch 270/350
391/391 - 24s - loss: 0.1012 - accuracy: 0.9802 - val_loss: 0.4981 - val_accuracy: 0.9051
Epoch 271/350
391/391 - 24s - loss: 0.1018 - accuracy: 0.9797 - val_loss: 0.4968 - val_accuracy: 0.9051
Epoch 272/350
391/391 - 24s - loss: 0.1022 - accuracy: 0.9800 - val_loss: 0.4980 - val_accuracy: 0.9052
Epoch 273/350
391/391 - 24s - loss: 0.1008 - accuracy: 0.9806 - val_loss: 0.4997 - val_accuracy: 0.9047
Epoch 274/350
391/391 - 24s - loss: 0.1012 - accuracy: 0.9807 - val_loss: 0.4982 - val_accuracy: 0.9049
Epoch 275/350
391/391 - 24s - loss: 0.1037 - accuracy: 0.9797 - val_loss: 0.4982 - val_accuracy: 0.9059
Epoch 276/350
391/391 - 24s - loss: 0.1027 - accuracy: 0.9797 - val_loss: 0.4988 - val_accuracy: 0.9053
Epoch 277/350
391/391 - 24s - loss: 0.1031 - accuracy: 0.9795 - val_loss: 0.4988 - val_accuracy: 0.9047
Epoch 278/350
391/391 - 24s - loss: 0.1008 - accuracy: 0.9803 - val_loss: 0.4994 - val_accuracy: 0.9054
Epoch 279/350
391/391 - 24s - loss: 0.1019 - accuracy: 0.9801 - val_loss: 0.5002 - val_accuracy: 0.9051
Epoch 280/350
391/391 - 24s - loss: 0.1016 - accuracy: 0.9801 - val_loss: 0.4995 - val_accuracy: 0.9050
Epoch 281/350
391/391 - 24s - loss: 0.1030 - accuracy: 0.9800 - val_loss: 0.5004 - val_accuracy: 0.9054
Epoch 282/350
391/391 - 25s - loss: 0.1009 - accuracy: 0.9798 - val_loss: 0.4997 - val_accuracy: 0.9059
Epoch 283/350
391/391 - 24s - loss: 0.0980 - accuracy: 0.9822 - val_loss: 0.5023 - val_accuracy: 0.9053
Epoch 284/350
391/391 - 24s - loss: 0.0992 - accuracy: 0.9812 - val_loss: 0.5022 - val_accuracy: 0.9058
Epoch 285/350
391/391 - 24s - loss: 0.1032 - accuracy: 0.9794 - val_loss: 0.5017 - val_accuracy: 0.9060
Epoch 286/350
391/391 - 25s - loss: 0.1015 - accuracy: 0.9796 - val_loss: 0.5014 - val_accuracy: 0.9061
Epoch 287/350
391/391 - 24s - loss: 0.1015 - accuracy: 0.9797 - val_loss: 0.5031 - val_accuracy: 0.9057
Epoch 288/350
391/391 - 25s - loss: 0.1027 - accuracy: 0.9797 - val_loss: 0.5035 - val_accuracy: 0.9056
Epoch 289/350
391/391 - 24s - loss: 0.1016 - accuracy: 0.9809 - val_loss: 0.5011 - val_accuracy: 0.9058
Epoch 290/350
391/391 - 24s - loss: 0.1008 - accuracy: 0.9809 - val_loss: 0.5007 - val_accuracy: 0.9067
Epoch 291/350
391/391 - 24s - loss: 0.1005 - accuracy: 0.9813 - val_loss: 0.5010 - val_accuracy: 0.9061
Epoch 292/350
391/391 - 25s - loss: 0.1037 - accuracy: 0.9796 - val_loss: 0.4996 - val_accuracy: 0.9061
Epoch 293/350
391/391 - 24s - loss: 0.1019 - accuracy: 0.9805 - val_loss: 0.4986 - val_accuracy: 0.9062
Epoch 294/350
391/391 - 25s - loss: 0.1026 - accuracy: 0.9796 - val_loss: 0.5003 - val_accuracy: 0.9056
Epoch 295/350
391/391 - 24s - loss: 0.0999 - accuracy: 0.9813 - val_loss: 0.5024 - val_accuracy: 0.9058
Epoch 296/350
391/391 - 25s - loss: 0.0988 - accuracy: 0.9816 - val_loss: 0.5012 - val_accuracy: 0.9058
Epoch 297/350
391/391 - 24s - loss: 0.1021 - accuracy: 0.9803 - val_loss: 0.5008 - val_accuracy: 0.9056
Epoch 298/350
391/391 - 24s - loss: 0.1008 - accuracy: 0.9803 - val_loss: 0.5002 - val_accuracy: 0.9059
Epoch 299/350
391/391 - 24s - loss: 0.1031 - accuracy: 0.9796 - val_loss: 0.5019 - val_accuracy: 0.9053
Epoch 300/350


Snapshot weight 3 shuffle 2 at epoch 300
Layer 11
Getting activations...


391/391 - 24s - loss: 0.1001 - accuracy: 0.9808 - val_loss: 0.5006 - val_accuracy: 0.9056
Epoch 301/350
391/391 - 25s - loss: 0.1016 - accuracy: 0.9801 - val_loss: 0.5006 - val_accuracy: 0.9055
Epoch 302/350
391/391 - 24s - loss: 0.1015 - accuracy: 0.9804 - val_loss: 0.5006 - val_accuracy: 0.9057
Epoch 303/350
391/391 - 24s - loss: 0.1017 - accuracy: 0.9803 - val_loss: 0.5005 - val_accuracy: 0.9057
Epoch 304/350
391/391 - 24s - loss: 0.1039 - accuracy: 0.9793 - val_loss: 0.5004 - val_accuracy: 0.9056
Epoch 305/350
391/391 - 25s - loss: 0.1006 - accuracy: 0.9805 - val_loss: 0.5003 - val_accuracy: 0.9058
Epoch 306/350
391/391 - 24s - loss: 0.1008 - accuracy: 0.9800 - val_loss: 0.5007 - val_accuracy: 0.9059
Epoch 307/350
391/391 - 24s - loss: 0.1020 - accuracy: 0.9800 - val_loss: 0.5008 - val_accuracy: 0.9059
Epoch 308/350
391/391 - 24s - loss: 0.1018 - accuracy: 0.9802 - val_loss: 0.5006 - val_accuracy: 0.9059
Epoch 309/350
391/391 - 25s - loss: 0.1000 - accuracy: 0.9804 - val_loss: 0.5006 - val_accuracy: 0.9055
Epoch 310/350
391/391 - 24s - loss: 0.1003 - accuracy: 0.9811 - val_loss: 0.5005 - val_accuracy: 0.9057
Epoch 311/350
391/391 - 24s - loss: 0.1006 - accuracy: 0.9805 - val_loss: 0.5006 - val_accuracy: 0.9056
Epoch 312/350
391/391 - 24s - loss: 0.1013 - accuracy: 0.9803 - val_loss: 0.5003 - val_accuracy: 0.9057
Epoch 313/350
391/391 - 24s - loss: 0.1013 - accuracy: 0.9807 - val_loss: 0.5004 - val_accuracy: 0.9057
Epoch 314/350
391/391 - 24s - loss: 0.1022 - accuracy: 0.9796 - val_loss: 0.5001 - val_accuracy: 0.9055
Epoch 315/350
391/391 - 24s - loss: 0.1002 - accuracy: 0.9806 - val_loss: 0.5000 - val_accuracy: 0.9057
Epoch 316/350
391/391 - 25s - loss: 0.0995 - accuracy: 0.9807 - val_loss: 0.5004 - val_accuracy: 0.9058
Epoch 317/350
391/391 - 25s - loss: 0.1024 - accuracy: 0.9798 - val_loss: 0.5005 - val_accuracy: 0.9057
Epoch 318/350
391/391 - 24s - loss: 0.1007 - accuracy: 0.9807 - val_loss: 0.5007 - val_accuracy: 0.9058
Epoch 319/350
391/391 - 24s - loss: 0.1033 - accuracy: 0.9798 - val_loss: 0.5005 - val_accuracy: 0.9058
Epoch 320/350
391/391 - 25s - loss: 0.1002 - accuracy: 0.9812 - val_loss: 0.5007 - val_accuracy: 0.9056
Epoch 321/350
391/391 - 24s - loss: 0.1013 - accuracy: 0.9810 - val_loss: 0.5005 - val_accuracy: 0.9055
Epoch 322/350
391/391 - 24s - loss: 0.1011 - accuracy: 0.9804 - val_loss: 0.5005 - val_accuracy: 0.9058
Epoch 323/350
391/391 - 24s - loss: 0.1003 - accuracy: 0.9808 - val_loss: 0.5008 - val_accuracy: 0.9058
Epoch 324/350
391/391 - 25s - loss: 0.1026 - accuracy: 0.9797 - val_loss: 0.5007 - val_accuracy: 0.9057
Epoch 325/350
391/391 - 24s - loss: 0.1029 - accuracy: 0.9808 - val_loss: 0.5008 - val_accuracy: 0.9056
Epoch 326/350
391/391 - 24s - loss: 0.1007 - accuracy: 0.9807 - val_loss: 0.5009 - val_accuracy: 0.9057
Epoch 327/350
391/391 - 24s - loss: 0.1022 - accuracy: 0.9804 - val_loss: 0.5010 - val_accuracy: 0.9059
Epoch 328/350
391/391 - 24s - loss: 0.1005 - accuracy: 0.9804 - val_loss: 0.5009 - val_accuracy: 0.9054
Epoch 329/350
391/391 - 25s - loss: 0.1008 - accuracy: 0.9802 - val_loss: 0.5010 - val_accuracy: 0.9056
Epoch 330/350
391/391 - 24s - loss: 0.0967 - accuracy: 0.9831 - val_loss: 0.5014 - val_accuracy: 0.9055
Epoch 331/350
391/391 - 24s - loss: 0.1021 - accuracy: 0.9800 - val_loss: 0.5012 - val_accuracy: 0.9056
Epoch 332/350
391/391 - 24s - loss: 0.1003 - accuracy: 0.9801 - val_loss: 0.5013 - val_accuracy: 0.9055
Epoch 333/350
391/391 - 24s - loss: 0.1043 - accuracy: 0.9792 - val_loss: 0.5014 - val_accuracy: 0.9056
Epoch 334/350
391/391 - 24s - loss: 0.1003 - accuracy: 0.9809 - val_loss: 0.5015 - val_accuracy: 0.9057
Epoch 335/350
391/391 - 24s - loss: 0.1012 - accuracy: 0.9801 - val_loss: 0.5010 - val_accuracy: 0.9058
Epoch 336/350
391/391 - 24s - loss: 0.1017 - accuracy: 0.9804 - val_loss: 0.5008 - val_accuracy: 0.9057
Epoch 337/350
391/391 - 24s - loss: 0.1004 - accuracy: 0.9805 - val_loss: 0.5010 - val_accuracy: 0.9056
Epoch 338/350
391/391 - 24s - loss: 0.1008 - accuracy: 0.9798 - val_loss: 0.5014 - val_accuracy: 0.9054
Epoch 339/350
391/391 - 25s - loss: 0.1012 - accuracy: 0.9805 - val_loss: 0.5012 - val_accuracy: 0.9054
Epoch 340/350
391/391 - 24s - loss: 0.1036 - accuracy: 0.9794 - val_loss: 0.5012 - val_accuracy: 0.9057
Epoch 341/350
391/391 - 24s - loss: 0.1002 - accuracy: 0.9809 - val_loss: 0.5012 - val_accuracy: 0.9056
Epoch 342/350
391/391 - 24s - loss: 0.1019 - accuracy: 0.9803 - val_loss: 0.5013 - val_accuracy: 0.9059
Epoch 343/350
391/391 - 24s - loss: 0.1029 - accuracy: 0.9797 - val_loss: 0.5014 - val_accuracy: 0.9058
Epoch 344/350
391/391 - 24s - loss: 0.1018 - accuracy: 0.9803 - val_loss: 0.5015 - val_accuracy: 0.9057
Epoch 345/350
391/391 - 24s - loss: 0.1015 - accuracy: 0.9803 - val_loss: 0.5014 - val_accuracy: 0.9059
Epoch 346/350
391/391 - 24s - loss: 0.1007 - accuracy: 0.9801 - val_loss: 0.5015 - val_accuracy: 0.9058
Epoch 347/350
391/391 - 24s - loss: 0.1035 - accuracy: 0.9796 - val_loss: 0.5014 - val_accuracy: 0.9057
Epoch 348/350
391/391 - 24s - loss: 0.1034 - accuracy: 0.9794 - val_loss: 0.5011 - val_accuracy: 0.9058
Epoch 349/350
391/391 - 24s - loss: 0.1015 - accuracy: 0.9801 - val_loss: 0.5009 - val_accuracy: 0.9063
Epoch 350/350


Snapshot weight 3 shuffle 2 at epoch 350
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1018 - accuracy: 0.9799 - val_loss: 0.5008 - val_accuracy: 0.9062
/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:493: UserWarning: fill_value is not supported and is always 0 for TensorFlow < 2.4.0.
  return py_builtins.overload_of(f)(*args)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-07-01 23:47:21.442772: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
Saving, final validation acc: 0.9061999917030334
