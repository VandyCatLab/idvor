2021-07-02 07:14:23.540520: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 07:15:50.604209: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-07-02 07:15:50.623573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2021-07-02 07:15:50.623655: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 07:15:50.663701: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-02 07:15:50.683593: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-02 07:15:50.691683: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-02 07:15:50.732976: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-02 07:15:50.741258: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-02 07:15:50.815229: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 07:15:50.817681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-02 07:15:50.821255: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-02 07:15:50.836442: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600090000 Hz
2021-07-02 07:15:50.836552: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4ac6c80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-07-02 07:15:50.836571: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-07-02 07:15:50.942758: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4aa7d70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-07-02 07:15:50.942834: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN Xp, Compute Capability 6.1
2021-07-02 07:15:50.945182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2021-07-02 07:15:50.945223: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 07:15:50.945259: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-02 07:15:50.945279: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-02 07:15:50.945298: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-02 07:15:50.945323: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-02 07:15:50.945345: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-02 07:15:50.945364: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 07:15:50.953164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-02 07:15:50.954814: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 07:15:52.647636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-02 07:15:52.647724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-07-02 07:15:52.647737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-07-02 07:15:52.653538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11218 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
2021-07-02 07:15:58.303685: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 07:16:00.705615: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
Using model index: 54
Making train data...
GCN...
ZCA...
Done!
Making test data...
Done!
Epoch 1/350


Snapshot weight 4 shuffle 5 at epoch 1
Layer 11
Getting activations...


391/391 - 23s - loss: 2.3251 - accuracy: 0.1026 - val_loss: 2.3198 - val_accuracy: 0.1037
Epoch 2/350


Snapshot weight 4 shuffle 5 at epoch 2
Layer 11
Getting activations...


391/391 - 22s - loss: 2.2930 - accuracy: 0.1281 - val_loss: 2.2298 - val_accuracy: 0.1771
Epoch 3/350


Snapshot weight 4 shuffle 5 at epoch 3
Layer 11
Getting activations...


391/391 - 23s - loss: 2.1006 - accuracy: 0.2314 - val_loss: 2.2045 - val_accuracy: 0.2374
Epoch 4/350


Snapshot weight 4 shuffle 5 at epoch 4
Layer 11
Getting activations...


391/391 - 23s - loss: 1.7202 - accuracy: 0.3723 - val_loss: 1.4735 - val_accuracy: 0.4847
Epoch 5/350


Snapshot weight 4 shuffle 5 at epoch 5
Layer 11
Getting activations...


391/391 - 23s - loss: 1.5091 - accuracy: 0.4629 - val_loss: 1.3516 - val_accuracy: 0.5268
Epoch 6/350


Snapshot weight 4 shuffle 5 at epoch 6
Layer 11
Getting activations...


391/391 - 23s - loss: 1.3723 - accuracy: 0.5168 - val_loss: 1.2152 - val_accuracy: 0.5727
Epoch 7/350


Snapshot weight 4 shuffle 5 at epoch 7
Layer 11
Getting activations...


391/391 - 24s - loss: 1.2812 - accuracy: 0.5500 - val_loss: 1.2183 - val_accuracy: 0.5769
Epoch 8/350


Snapshot weight 4 shuffle 5 at epoch 8
Layer 11
Getting activations...


391/391 - 23s - loss: 1.1845 - accuracy: 0.5880 - val_loss: 1.0351 - val_accuracy: 0.6361
Epoch 9/350


Snapshot weight 4 shuffle 5 at epoch 9
Layer 11
Getting activations...


391/391 - 24s - loss: 1.1164 - accuracy: 0.6104 - val_loss: 1.0249 - val_accuracy: 0.6499
Epoch 10/350


Snapshot weight 4 shuffle 5 at epoch 10
Layer 11
Getting activations...


391/391 - 24s - loss: 1.0454 - accuracy: 0.6365 - val_loss: 1.1892 - val_accuracy: 0.6142
Epoch 11/350
391/391 - 23s - loss: 1.0088 - accuracy: 0.6498 - val_loss: 0.9295 - val_accuracy: 0.6882
Epoch 12/350
391/391 - 23s - loss: 0.9585 - accuracy: 0.6696 - val_loss: 0.9599 - val_accuracy: 0.6738
Epoch 13/350
391/391 - 23s - loss: 0.9214 - accuracy: 0.6845 - val_loss: 0.8299 - val_accuracy: 0.7175
Epoch 14/350
391/391 - 23s - loss: 0.8803 - accuracy: 0.6985 - val_loss: 0.8596 - val_accuracy: 0.7134
Epoch 15/350
391/391 - 23s - loss: 0.8415 - accuracy: 0.7137 - val_loss: 0.8234 - val_accuracy: 0.7223
Epoch 16/350
391/391 - 23s - loss: 0.8069 - accuracy: 0.7269 - val_loss: 0.7145 - val_accuracy: 0.7509
Epoch 17/350
391/391 - 23s - loss: 0.7805 - accuracy: 0.7341 - val_loss: 0.7420 - val_accuracy: 0.7494
Epoch 18/350
391/391 - 23s - loss: 0.7430 - accuracy: 0.7488 - val_loss: 0.7545 - val_accuracy: 0.7507
Epoch 19/350
391/391 - 23s - loss: 0.7213 - accuracy: 0.7590 - val_loss: 0.7251 - val_accuracy: 0.7649
Epoch 20/350
391/391 - 23s - loss: 0.7066 - accuracy: 0.7629 - val_loss: 0.6514 - val_accuracy: 0.7805
Epoch 21/350
391/391 - 23s - loss: 0.6866 - accuracy: 0.7702 - val_loss: 0.7630 - val_accuracy: 0.7623
Epoch 22/350
391/391 - 23s - loss: 0.6673 - accuracy: 0.7782 - val_loss: 0.6572 - val_accuracy: 0.7831
Epoch 23/350
391/391 - 23s - loss: 0.6495 - accuracy: 0.7845 - val_loss: 0.6074 - val_accuracy: 0.7984
Epoch 24/350
391/391 - 23s - loss: 0.6275 - accuracy: 0.7919 - val_loss: 0.5917 - val_accuracy: 0.8094
Epoch 25/350
391/391 - 23s - loss: 0.6197 - accuracy: 0.7950 - val_loss: 0.5852 - val_accuracy: 0.8161
Epoch 26/350
391/391 - 23s - loss: 0.6015 - accuracy: 0.8003 - val_loss: 0.5918 - val_accuracy: 0.8087
Epoch 27/350
391/391 - 23s - loss: 0.5867 - accuracy: 0.8045 - val_loss: 0.6118 - val_accuracy: 0.8081
Epoch 28/350
391/391 - 23s - loss: 0.5727 - accuracy: 0.8110 - val_loss: 0.5471 - val_accuracy: 0.8200
Epoch 29/350
391/391 - 23s - loss: 0.5603 - accuracy: 0.8141 - val_loss: 0.5358 - val_accuracy: 0.8253
Epoch 30/350
391/391 - 23s - loss: 0.5503 - accuracy: 0.8163 - val_loss: 0.5688 - val_accuracy: 0.8182
Epoch 31/350
391/391 - 23s - loss: 0.5494 - accuracy: 0.8209 - val_loss: 0.5307 - val_accuracy: 0.8249
Epoch 32/350
391/391 - 23s - loss: 0.5370 - accuracy: 0.8225 - val_loss: 0.5176 - val_accuracy: 0.8345
Epoch 33/350
391/391 - 23s - loss: 0.5257 - accuracy: 0.8271 - val_loss: 0.5164 - val_accuracy: 0.8376
Epoch 34/350
391/391 - 23s - loss: 0.5157 - accuracy: 0.8314 - val_loss: 0.5159 - val_accuracy: 0.8365
Epoch 35/350
391/391 - 23s - loss: 0.5015 - accuracy: 0.8354 - val_loss: 0.4942 - val_accuracy: 0.8392
Epoch 36/350
391/391 - 23s - loss: 0.4970 - accuracy: 0.8368 - val_loss: 0.4883 - val_accuracy: 0.8483
Epoch 37/350
391/391 - 23s - loss: 0.4821 - accuracy: 0.8430 - val_loss: 0.5052 - val_accuracy: 0.8414
Epoch 38/350
391/391 - 23s - loss: 0.4842 - accuracy: 0.8427 - val_loss: 0.4862 - val_accuracy: 0.8468
Epoch 39/350
391/391 - 23s - loss: 0.4743 - accuracy: 0.8445 - val_loss: 0.4924 - val_accuracy: 0.8419
Epoch 40/350
391/391 - 23s - loss: 0.4608 - accuracy: 0.8494 - val_loss: 0.5187 - val_accuracy: 0.8427
Epoch 41/350
391/391 - 23s - loss: 0.4566 - accuracy: 0.8529 - val_loss: 0.4738 - val_accuracy: 0.8592
Epoch 42/350
391/391 - 23s - loss: 0.4560 - accuracy: 0.8522 - val_loss: 0.4859 - val_accuracy: 0.8467
Epoch 43/350
391/391 - 23s - loss: 0.4497 - accuracy: 0.8536 - val_loss: 0.4913 - val_accuracy: 0.8455
Epoch 44/350
391/391 - 23s - loss: 0.4424 - accuracy: 0.8564 - val_loss: 0.4699 - val_accuracy: 0.8553
Epoch 45/350
391/391 - 23s - loss: 0.4396 - accuracy: 0.8578 - val_loss: 0.4655 - val_accuracy: 0.8574
Epoch 46/350
391/391 - 23s - loss: 0.4279 - accuracy: 0.8616 - val_loss: 0.4472 - val_accuracy: 0.8585
Epoch 47/350
391/391 - 23s - loss: 0.4216 - accuracy: 0.8630 - val_loss: 0.4480 - val_accuracy: 0.8618
Epoch 48/350
391/391 - 23s - loss: 0.4196 - accuracy: 0.8634 - val_loss: 0.4898 - val_accuracy: 0.8533
Epoch 49/350
391/391 - 23s - loss: 0.4210 - accuracy: 0.8635 - val_loss: 0.4944 - val_accuracy: 0.8485
Epoch 50/350


Snapshot weight 4 shuffle 5 at epoch 50
Layer 11
Getting activations...


391/391 - 23s - loss: 0.4109 - accuracy: 0.8662 - val_loss: 0.4603 - val_accuracy: 0.8579
Epoch 51/350
391/391 - 23s - loss: 0.4024 - accuracy: 0.8720 - val_loss: 0.4784 - val_accuracy: 0.8534
Epoch 52/350
391/391 - 23s - loss: 0.3934 - accuracy: 0.8740 - val_loss: 0.5180 - val_accuracy: 0.8522
Epoch 53/350
391/391 - 23s - loss: 0.3954 - accuracy: 0.8731 - val_loss: 0.4681 - val_accuracy: 0.8624
Epoch 54/350
391/391 - 23s - loss: 0.3881 - accuracy: 0.8748 - val_loss: 0.4378 - val_accuracy: 0.8657
Epoch 55/350
391/391 - 23s - loss: 0.3852 - accuracy: 0.8773 - val_loss: 0.4690 - val_accuracy: 0.8603
Epoch 56/350
391/391 - 23s - loss: 0.3800 - accuracy: 0.8788 - val_loss: 0.4634 - val_accuracy: 0.8602
Epoch 57/350
391/391 - 24s - loss: 0.3751 - accuracy: 0.8804 - val_loss: 0.4557 - val_accuracy: 0.8646
Epoch 58/350
391/391 - 23s - loss: 0.3718 - accuracy: 0.8818 - val_loss: 0.4322 - val_accuracy: 0.8708
Epoch 59/350
391/391 - 23s - loss: 0.3667 - accuracy: 0.8831 - val_loss: 0.4859 - val_accuracy: 0.8551
Epoch 60/350
391/391 - 23s - loss: 0.3594 - accuracy: 0.8851 - val_loss: 0.4734 - val_accuracy: 0.8649
Epoch 61/350
391/391 - 23s - loss: 0.3591 - accuracy: 0.8856 - val_loss: 0.4613 - val_accuracy: 0.8670
Epoch 62/350
391/391 - 23s - loss: 0.3582 - accuracy: 0.8853 - val_loss: 0.4178 - val_accuracy: 0.8750
Epoch 63/350
391/391 - 23s - loss: 0.3508 - accuracy: 0.8891 - val_loss: 0.4443 - val_accuracy: 0.8672
Epoch 64/350
391/391 - 23s - loss: 0.3489 - accuracy: 0.8900 - val_loss: 0.4799 - val_accuracy: 0.8615
Epoch 65/350
391/391 - 23s - loss: 0.3472 - accuracy: 0.8905 - val_loss: 0.4228 - val_accuracy: 0.8750
Epoch 66/350
391/391 - 23s - loss: 0.3425 - accuracy: 0.8911 - val_loss: 0.4119 - val_accuracy: 0.8800
Epoch 67/350
391/391 - 23s - loss: 0.3385 - accuracy: 0.8919 - val_loss: 0.4424 - val_accuracy: 0.8728
Epoch 68/350
391/391 - 23s - loss: 0.3334 - accuracy: 0.8944 - val_loss: 0.4747 - val_accuracy: 0.8641
Epoch 69/350
391/391 - 24s - loss: 0.3347 - accuracy: 0.8944 - val_loss: 0.4314 - val_accuracy: 0.8729
Epoch 70/350
391/391 - 23s - loss: 0.3237 - accuracy: 0.8980 - val_loss: 0.4847 - val_accuracy: 0.8649
Epoch 71/350
391/391 - 23s - loss: 0.3220 - accuracy: 0.8992 - val_loss: 0.4613 - val_accuracy: 0.8671
Epoch 72/350
391/391 - 23s - loss: 0.3259 - accuracy: 0.8972 - val_loss: 0.4414 - val_accuracy: 0.8699
Epoch 73/350
391/391 - 23s - loss: 0.3230 - accuracy: 0.8974 - val_loss: 0.4369 - val_accuracy: 0.8737
Epoch 74/350
391/391 - 23s - loss: 0.3120 - accuracy: 0.9027 - val_loss: 0.4359 - val_accuracy: 0.8746
Epoch 75/350
391/391 - 23s - loss: 0.3112 - accuracy: 0.9024 - val_loss: 0.4130 - val_accuracy: 0.8817
Epoch 76/350
391/391 - 23s - loss: 0.3132 - accuracy: 0.9007 - val_loss: 0.4123 - val_accuracy: 0.8760
Epoch 77/350
391/391 - 23s - loss: 0.3060 - accuracy: 0.9036 - val_loss: 0.4338 - val_accuracy: 0.8770
Epoch 78/350
391/391 - 23s - loss: 0.3064 - accuracy: 0.9050 - val_loss: 0.4297 - val_accuracy: 0.8783
Epoch 79/350
391/391 - 23s - loss: 0.3058 - accuracy: 0.9040 - val_loss: 0.4309 - val_accuracy: 0.8766
Epoch 80/350
391/391 - 23s - loss: 0.3065 - accuracy: 0.9057 - val_loss: 0.4244 - val_accuracy: 0.8795
Epoch 81/350
391/391 - 23s - loss: 0.3037 - accuracy: 0.9050 - val_loss: 0.4327 - val_accuracy: 0.8800
Epoch 82/350
391/391 - 23s - loss: 0.2959 - accuracy: 0.9094 - val_loss: 0.4350 - val_accuracy: 0.8841
Epoch 83/350
391/391 - 23s - loss: 0.2904 - accuracy: 0.9097 - val_loss: 0.4304 - val_accuracy: 0.8818
Epoch 84/350
391/391 - 23s - loss: 0.2943 - accuracy: 0.9092 - val_loss: 0.4421 - val_accuracy: 0.8778
Epoch 85/350
391/391 - 23s - loss: 0.2895 - accuracy: 0.9113 - val_loss: 0.4366 - val_accuracy: 0.8791
Epoch 86/350
391/391 - 23s - loss: 0.2892 - accuracy: 0.9116 - val_loss: 0.4469 - val_accuracy: 0.8772
Epoch 87/350
391/391 - 23s - loss: 0.2833 - accuracy: 0.9121 - val_loss: 0.4403 - val_accuracy: 0.8777
Epoch 88/350
391/391 - 23s - loss: 0.2760 - accuracy: 0.9171 - val_loss: 0.4524 - val_accuracy: 0.8770
Epoch 89/350
391/391 - 23s - loss: 0.2838 - accuracy: 0.9114 - val_loss: 0.4063 - val_accuracy: 0.8839
Epoch 90/350
391/391 - 24s - loss: 0.2783 - accuracy: 0.9151 - val_loss: 0.4319 - val_accuracy: 0.8805
Epoch 91/350
391/391 - 23s - loss: 0.2792 - accuracy: 0.9141 - val_loss: 0.4335 - val_accuracy: 0.8860
Epoch 92/350
391/391 - 23s - loss: 0.2791 - accuracy: 0.9146 - val_loss: 0.4301 - val_accuracy: 0.8861
Epoch 93/350
391/391 - 23s - loss: 0.2749 - accuracy: 0.9153 - val_loss: 0.4168 - val_accuracy: 0.8860
Epoch 94/350
391/391 - 23s - loss: 0.2719 - accuracy: 0.9164 - val_loss: 0.4270 - val_accuracy: 0.8870
Epoch 95/350
391/391 - 23s - loss: 0.2647 - accuracy: 0.9204 - val_loss: 0.4331 - val_accuracy: 0.8863
Epoch 96/350
391/391 - 23s - loss: 0.2672 - accuracy: 0.9183 - val_loss: 0.4287 - val_accuracy: 0.8856
Epoch 97/350
391/391 - 23s - loss: 0.2644 - accuracy: 0.9189 - val_loss: 0.3966 - val_accuracy: 0.8905
Epoch 98/350
391/391 - 23s - loss: 0.2666 - accuracy: 0.9189 - val_loss: 0.4324 - val_accuracy: 0.8838
Epoch 99/350
391/391 - 23s - loss: 0.2631 - accuracy: 0.9196 - val_loss: 0.4429 - val_accuracy: 0.8820
Epoch 100/350


Snapshot weight 4 shuffle 5 at epoch 100
Layer 11
Getting activations...


391/391 - 24s - loss: 0.2604 - accuracy: 0.9213 - val_loss: 0.4502 - val_accuracy: 0.8825
Epoch 101/350
391/391 - 23s - loss: 0.2597 - accuracy: 0.9209 - val_loss: 0.4216 - val_accuracy: 0.8881
Epoch 102/350
391/391 - 23s - loss: 0.2571 - accuracy: 0.9227 - val_loss: 0.4287 - val_accuracy: 0.8882
Epoch 103/350
391/391 - 23s - loss: 0.2524 - accuracy: 0.9228 - val_loss: 0.4523 - val_accuracy: 0.8797
Epoch 104/350
391/391 - 23s - loss: 0.2569 - accuracy: 0.9215 - val_loss: 0.4454 - val_accuracy: 0.8818
Epoch 105/350
391/391 - 23s - loss: 0.2536 - accuracy: 0.9235 - val_loss: 0.4828 - val_accuracy: 0.8761
Epoch 106/350
391/391 - 23s - loss: 0.2473 - accuracy: 0.9262 - val_loss: 0.4246 - val_accuracy: 0.8890
Epoch 107/350
391/391 - 23s - loss: 0.2545 - accuracy: 0.9249 - val_loss: 0.4405 - val_accuracy: 0.8876
Epoch 108/350
391/391 - 23s - loss: 0.2452 - accuracy: 0.9260 - val_loss: 0.4083 - val_accuracy: 0.8891
Epoch 109/350
391/391 - 23s - loss: 0.2431 - accuracy: 0.9277 - val_loss: 0.4261 - val_accuracy: 0.8909
Epoch 110/350
391/391 - 23s - loss: 0.2424 - accuracy: 0.9283 - val_loss: 0.4801 - val_accuracy: 0.8764
Epoch 111/350
391/391 - 23s - loss: 0.2417 - accuracy: 0.9282 - val_loss: 0.4070 - val_accuracy: 0.8880
Epoch 112/350
391/391 - 23s - loss: 0.2388 - accuracy: 0.9300 - val_loss: 0.4549 - val_accuracy: 0.8872
Epoch 113/350
391/391 - 23s - loss: 0.2385 - accuracy: 0.9302 - val_loss: 0.4167 - val_accuracy: 0.8930
Epoch 114/350
391/391 - 23s - loss: 0.2332 - accuracy: 0.9311 - val_loss: 0.4299 - val_accuracy: 0.8875
Epoch 115/350
391/391 - 23s - loss: 0.2343 - accuracy: 0.9309 - val_loss: 0.4340 - val_accuracy: 0.8855
Epoch 116/350
391/391 - 23s - loss: 0.2331 - accuracy: 0.9314 - val_loss: 0.4550 - val_accuracy: 0.8846
Epoch 117/350
391/391 - 23s - loss: 0.2317 - accuracy: 0.9317 - val_loss: 0.4216 - val_accuracy: 0.8867
Epoch 118/350
391/391 - 23s - loss: 0.2309 - accuracy: 0.9319 - val_loss: 0.4561 - val_accuracy: 0.8838
Epoch 119/350
391/391 - 23s - loss: 0.2305 - accuracy: 0.9318 - val_loss: 0.4472 - val_accuracy: 0.8887
Epoch 120/350
391/391 - 23s - loss: 0.2268 - accuracy: 0.9332 - val_loss: 0.4735 - val_accuracy: 0.8818
Epoch 121/350
391/391 - 23s - loss: 0.2277 - accuracy: 0.9327 - val_loss: 0.4372 - val_accuracy: 0.8880
Epoch 122/350
391/391 - 23s - loss: 0.2297 - accuracy: 0.9328 - val_loss: 0.4270 - val_accuracy: 0.8877
Epoch 123/350
391/391 - 23s - loss: 0.2250 - accuracy: 0.9346 - val_loss: 0.4616 - val_accuracy: 0.8863
Epoch 124/350
391/391 - 23s - loss: 0.2236 - accuracy: 0.9346 - val_loss: 0.4190 - val_accuracy: 0.8940
Epoch 125/350
391/391 - 23s - loss: 0.2192 - accuracy: 0.9374 - val_loss: 0.4341 - val_accuracy: 0.8884
Epoch 126/350
391/391 - 23s - loss: 0.2211 - accuracy: 0.9354 - val_loss: 0.4442 - val_accuracy: 0.8861
Epoch 127/350
391/391 - 23s - loss: 0.2220 - accuracy: 0.9348 - val_loss: 0.4232 - val_accuracy: 0.8864
Epoch 128/350
391/391 - 23s - loss: 0.2260 - accuracy: 0.9347 - val_loss: 0.4091 - val_accuracy: 0.8939
Epoch 129/350
391/391 - 23s - loss: 0.2172 - accuracy: 0.9367 - val_loss: 0.4509 - val_accuracy: 0.8901
Epoch 130/350
391/391 - 23s - loss: 0.2216 - accuracy: 0.9347 - val_loss: 0.4247 - val_accuracy: 0.8930
Epoch 131/350
391/391 - 23s - loss: 0.2126 - accuracy: 0.9386 - val_loss: 0.4549 - val_accuracy: 0.8841
Epoch 132/350
391/391 - 23s - loss: 0.2160 - accuracy: 0.9377 - val_loss: 0.4332 - val_accuracy: 0.8933
Epoch 133/350
391/391 - 23s - loss: 0.2103 - accuracy: 0.9402 - val_loss: 0.4289 - val_accuracy: 0.8909
Epoch 134/350
391/391 - 23s - loss: 0.2119 - accuracy: 0.9394 - val_loss: 0.4396 - val_accuracy: 0.8944
Epoch 135/350
391/391 - 23s - loss: 0.2100 - accuracy: 0.9391 - val_loss: 0.4525 - val_accuracy: 0.8932
Epoch 136/350
391/391 - 23s - loss: 0.2069 - accuracy: 0.9392 - val_loss: 0.4411 - val_accuracy: 0.8970
Epoch 137/350
391/391 - 23s - loss: 0.2133 - accuracy: 0.9401 - val_loss: 0.4635 - val_accuracy: 0.8909
Epoch 138/350
391/391 - 23s - loss: 0.2051 - accuracy: 0.9415 - val_loss: 0.4511 - val_accuracy: 0.8930
Epoch 139/350
391/391 - 23s - loss: 0.2065 - accuracy: 0.9423 - val_loss: 0.4782 - val_accuracy: 0.8928
Epoch 140/350
391/391 - 23s - loss: 0.2069 - accuracy: 0.9415 - val_loss: 0.4529 - val_accuracy: 0.8919
Epoch 141/350
391/391 - 23s - loss: 0.2026 - accuracy: 0.9427 - val_loss: 0.4870 - val_accuracy: 0.8859
Epoch 142/350
391/391 - 23s - loss: 0.2041 - accuracy: 0.9427 - val_loss: 0.4554 - val_accuracy: 0.8917
Epoch 143/350
391/391 - 23s - loss: 0.2051 - accuracy: 0.9413 - val_loss: 0.4423 - val_accuracy: 0.8945
Epoch 144/350
391/391 - 23s - loss: 0.2057 - accuracy: 0.9425 - val_loss: 0.4607 - val_accuracy: 0.8970
Epoch 145/350
391/391 - 23s - loss: 0.2009 - accuracy: 0.9438 - val_loss: 0.4414 - val_accuracy: 0.8934
Epoch 146/350
391/391 - 23s - loss: 0.2015 - accuracy: 0.9425 - val_loss: 0.4562 - val_accuracy: 0.8881
Epoch 147/350
391/391 - 23s - loss: 0.1941 - accuracy: 0.9454 - val_loss: 0.4614 - val_accuracy: 0.8945
Epoch 148/350
391/391 - 23s - loss: 0.1961 - accuracy: 0.9458 - val_loss: 0.4755 - val_accuracy: 0.8893
Epoch 149/350
391/391 - 23s - loss: 0.1990 - accuracy: 0.9445 - val_loss: 0.4794 - val_accuracy: 0.8888
Epoch 150/350


Snapshot weight 4 shuffle 5 at epoch 150
Layer 11
Getting activations...


391/391 - 24s - loss: 0.1924 - accuracy: 0.9467 - val_loss: 0.4629 - val_accuracy: 0.8948
Epoch 151/350
391/391 - 23s - loss: 0.1977 - accuracy: 0.9452 - val_loss: 0.4602 - val_accuracy: 0.8913
Epoch 152/350
391/391 - 23s - loss: 0.1988 - accuracy: 0.9447 - val_loss: 0.4451 - val_accuracy: 0.8881
Epoch 153/350
391/391 - 23s - loss: 0.1938 - accuracy: 0.9458 - val_loss: 0.4535 - val_accuracy: 0.8946
Epoch 154/350
391/391 - 23s - loss: 0.1967 - accuracy: 0.9459 - val_loss: 0.4452 - val_accuracy: 0.8930
Epoch 155/350
391/391 - 23s - loss: 0.1948 - accuracy: 0.9461 - val_loss: 0.4415 - val_accuracy: 0.8993
Epoch 156/350
391/391 - 23s - loss: 0.1926 - accuracy: 0.9468 - val_loss: 0.4409 - val_accuracy: 0.8990
Epoch 157/350
391/391 - 23s - loss: 0.1904 - accuracy: 0.9479 - val_loss: 0.4694 - val_accuracy: 0.8942
Epoch 158/350
391/391 - 23s - loss: 0.1873 - accuracy: 0.9486 - val_loss: 0.4509 - val_accuracy: 0.8942
Epoch 159/350
391/391 - 23s - loss: 0.1898 - accuracy: 0.9474 - val_loss: 0.4415 - val_accuracy: 0.8984
Epoch 160/350
391/391 - 23s - loss: 0.1887 - accuracy: 0.9486 - val_loss: 0.4593 - val_accuracy: 0.8994
Epoch 161/350
391/391 - 23s - loss: 0.1902 - accuracy: 0.9478 - val_loss: 0.4223 - val_accuracy: 0.9002
Epoch 162/350
391/391 - 23s - loss: 0.1882 - accuracy: 0.9483 - val_loss: 0.4731 - val_accuracy: 0.8962
Epoch 163/350
391/391 - 23s - loss: 0.1907 - accuracy: 0.9476 - val_loss: 0.4912 - val_accuracy: 0.8915
Epoch 164/350
391/391 - 23s - loss: 0.1858 - accuracy: 0.9491 - val_loss: 0.4676 - val_accuracy: 0.8941
Epoch 165/350
391/391 - 23s - loss: 0.1849 - accuracy: 0.9504 - val_loss: 0.4454 - val_accuracy: 0.8994
Epoch 166/350
391/391 - 23s - loss: 0.1848 - accuracy: 0.9499 - val_loss: 0.4442 - val_accuracy: 0.8957
Epoch 167/350
391/391 - 23s - loss: 0.1822 - accuracy: 0.9514 - val_loss: 0.4476 - val_accuracy: 0.8988
Epoch 168/350
391/391 - 23s - loss: 0.1837 - accuracy: 0.9510 - val_loss: 0.4967 - val_accuracy: 0.8929
Epoch 169/350
391/391 - 23s - loss: 0.1834 - accuracy: 0.9495 - val_loss: 0.5169 - val_accuracy: 0.8889
Epoch 170/350
391/391 - 23s - loss: 0.1807 - accuracy: 0.9532 - val_loss: 0.4286 - val_accuracy: 0.8993
Epoch 171/350
391/391 - 23s - loss: 0.1834 - accuracy: 0.9503 - val_loss: 0.4597 - val_accuracy: 0.8916
Epoch 172/350
391/391 - 23s - loss: 0.1813 - accuracy: 0.9507 - val_loss: 0.4714 - val_accuracy: 0.8897
Epoch 173/350
391/391 - 23s - loss: 0.1788 - accuracy: 0.9517 - val_loss: 0.4777 - val_accuracy: 0.8913
Epoch 174/350
391/391 - 23s - loss: 0.1805 - accuracy: 0.9526 - val_loss: 0.4641 - val_accuracy: 0.8968
Epoch 175/350
391/391 - 23s - loss: 0.1801 - accuracy: 0.9519 - val_loss: 0.4389 - val_accuracy: 0.8938
Epoch 176/350
391/391 - 23s - loss: 0.1801 - accuracy: 0.9513 - val_loss: 0.4461 - val_accuracy: 0.9003
Epoch 177/350
391/391 - 23s - loss: 0.1819 - accuracy: 0.9515 - val_loss: 0.4459 - val_accuracy: 0.8962
Epoch 178/350
391/391 - 23s - loss: 0.1761 - accuracy: 0.9529 - val_loss: 0.4408 - val_accuracy: 0.8964
Epoch 179/350
391/391 - 23s - loss: 0.1725 - accuracy: 0.9549 - val_loss: 0.5098 - val_accuracy: 0.8927
Epoch 180/350
391/391 - 23s - loss: 0.1774 - accuracy: 0.9531 - val_loss: 0.4682 - val_accuracy: 0.8919
Epoch 181/350
391/391 - 23s - loss: 0.1769 - accuracy: 0.9536 - val_loss: 0.4959 - val_accuracy: 0.8915
Epoch 182/350
391/391 - 23s - loss: 0.1779 - accuracy: 0.9528 - val_loss: 0.4437 - val_accuracy: 0.8964
Epoch 183/350
391/391 - 23s - loss: 0.1744 - accuracy: 0.9534 - val_loss: 0.5023 - val_accuracy: 0.8915
Epoch 184/350
391/391 - 23s - loss: 0.1740 - accuracy: 0.9550 - val_loss: 0.4398 - val_accuracy: 0.8986
Epoch 185/350
391/391 - 23s - loss: 0.1697 - accuracy: 0.9553 - val_loss: 0.4523 - val_accuracy: 0.9012
Epoch 186/350
391/391 - 23s - loss: 0.1731 - accuracy: 0.9551 - val_loss: 0.4628 - val_accuracy: 0.8964
Epoch 187/350
391/391 - 23s - loss: 0.1702 - accuracy: 0.9567 - val_loss: 0.4625 - val_accuracy: 0.8986
Epoch 188/350
391/391 - 23s - loss: 0.1763 - accuracy: 0.9545 - val_loss: 0.4478 - val_accuracy: 0.8960
Epoch 189/350
391/391 - 23s - loss: 0.1731 - accuracy: 0.9543 - val_loss: 0.4487 - val_accuracy: 0.9002
Epoch 190/350
391/391 - 23s - loss: 0.1742 - accuracy: 0.9546 - val_loss: 0.4558 - val_accuracy: 0.8989
Epoch 191/350
391/391 - 23s - loss: 0.1693 - accuracy: 0.9553 - val_loss: 0.4868 - val_accuracy: 0.8975
Epoch 192/350
391/391 - 23s - loss: 0.1688 - accuracy: 0.9555 - val_loss: 0.4537 - val_accuracy: 0.9005
Epoch 193/350
391/391 - 23s - loss: 0.1710 - accuracy: 0.9557 - val_loss: 0.4474 - val_accuracy: 0.8979
Epoch 194/350
391/391 - 23s - loss: 0.1749 - accuracy: 0.9545 - val_loss: 0.4735 - val_accuracy: 0.8973
Epoch 195/350
391/391 - 23s - loss: 0.1652 - accuracy: 0.9574 - val_loss: 0.5293 - val_accuracy: 0.8872
Epoch 196/350
391/391 - 23s - loss: 0.1671 - accuracy: 0.9570 - val_loss: 0.5043 - val_accuracy: 0.8969
Epoch 197/350
391/391 - 23s - loss: 0.1627 - accuracy: 0.9585 - val_loss: 0.5035 - val_accuracy: 0.8972
Epoch 198/350
391/391 - 23s - loss: 0.1645 - accuracy: 0.9587 - val_loss: 0.4819 - val_accuracy: 0.8990
Epoch 199/350
391/391 - 23s - loss: 0.1654 - accuracy: 0.9578 - val_loss: 0.4649 - val_accuracy: 0.8976
Epoch 200/350


Snapshot weight 4 shuffle 5 at epoch 200
Layer 11
Getting activations...


391/391 - 23s - loss: 0.1657 - accuracy: 0.9585 - val_loss: 0.5057 - val_accuracy: 0.8951
Epoch 201/350
391/391 - 23s - loss: 0.1430 - accuracy: 0.9663 - val_loss: 0.4638 - val_accuracy: 0.9034
Epoch 202/350
391/391 - 23s - loss: 0.1246 - accuracy: 0.9726 - val_loss: 0.4613 - val_accuracy: 0.9044
Epoch 203/350
391/391 - 24s - loss: 0.1202 - accuracy: 0.9747 - val_loss: 0.4720 - val_accuracy: 0.9043
Epoch 204/350
391/391 - 23s - loss: 0.1212 - accuracy: 0.9726 - val_loss: 0.4674 - val_accuracy: 0.9049
Epoch 205/350
391/391 - 23s - loss: 0.1184 - accuracy: 0.9751 - val_loss: 0.4645 - val_accuracy: 0.9065
Epoch 206/350
391/391 - 24s - loss: 0.1138 - accuracy: 0.9763 - val_loss: 0.4730 - val_accuracy: 0.9062
Epoch 207/350
391/391 - 23s - loss: 0.1167 - accuracy: 0.9746 - val_loss: 0.4720 - val_accuracy: 0.9068
Epoch 208/350
391/391 - 23s - loss: 0.1172 - accuracy: 0.9741 - val_loss: 0.4718 - val_accuracy: 0.9069
Epoch 209/350
391/391 - 23s - loss: 0.1142 - accuracy: 0.9756 - val_loss: 0.4733 - val_accuracy: 0.9061
Epoch 210/350
391/391 - 23s - loss: 0.1132 - accuracy: 0.9765 - val_loss: 0.4772 - val_accuracy: 0.9038
Epoch 211/350
391/391 - 23s - loss: 0.1146 - accuracy: 0.9758 - val_loss: 0.4900 - val_accuracy: 0.9043
Epoch 212/350
391/391 - 23s - loss: 0.1126 - accuracy: 0.9765 - val_loss: 0.4898 - val_accuracy: 0.9072
Epoch 213/350
391/391 - 23s - loss: 0.1140 - accuracy: 0.9756 - val_loss: 0.4865 - val_accuracy: 0.9051
Epoch 214/350
391/391 - 23s - loss: 0.1101 - accuracy: 0.9774 - val_loss: 0.4835 - val_accuracy: 0.9049
Epoch 215/350
391/391 - 23s - loss: 0.1107 - accuracy: 0.9777 - val_loss: 0.4975 - val_accuracy: 0.9049
Epoch 216/350
391/391 - 24s - loss: 0.1117 - accuracy: 0.9763 - val_loss: 0.4844 - val_accuracy: 0.9047
Epoch 217/350
391/391 - 23s - loss: 0.1124 - accuracy: 0.9762 - val_loss: 0.4853 - val_accuracy: 0.9066
Epoch 218/350
391/391 - 24s - loss: 0.1126 - accuracy: 0.9767 - val_loss: 0.4780 - val_accuracy: 0.9075
Epoch 219/350
391/391 - 23s - loss: 0.1128 - accuracy: 0.9763 - val_loss: 0.4860 - val_accuracy: 0.9059
Epoch 220/350
391/391 - 23s - loss: 0.1096 - accuracy: 0.9776 - val_loss: 0.4756 - val_accuracy: 0.9082
Epoch 221/350
391/391 - 23s - loss: 0.1106 - accuracy: 0.9766 - val_loss: 0.4861 - val_accuracy: 0.9070
Epoch 222/350
391/391 - 23s - loss: 0.1086 - accuracy: 0.9777 - val_loss: 0.4844 - val_accuracy: 0.9056
Epoch 223/350
391/391 - 24s - loss: 0.1108 - accuracy: 0.9769 - val_loss: 0.4994 - val_accuracy: 0.9083
Epoch 224/350
391/391 - 23s - loss: 0.1101 - accuracy: 0.9769 - val_loss: 0.4744 - val_accuracy: 0.9073
Epoch 225/350
391/391 - 23s - loss: 0.1103 - accuracy: 0.9767 - val_loss: 0.4772 - val_accuracy: 0.9084
Epoch 226/350
391/391 - 23s - loss: 0.1087 - accuracy: 0.9778 - val_loss: 0.4894 - val_accuracy: 0.9073
Epoch 227/350
391/391 - 23s - loss: 0.1078 - accuracy: 0.9782 - val_loss: 0.4836 - val_accuracy: 0.9066
Epoch 228/350
391/391 - 23s - loss: 0.1084 - accuracy: 0.9780 - val_loss: 0.4813 - val_accuracy: 0.9083
Epoch 229/350
391/391 - 23s - loss: 0.1084 - accuracy: 0.9782 - val_loss: 0.5040 - val_accuracy: 0.9069
Epoch 230/350
391/391 - 23s - loss: 0.1071 - accuracy: 0.9782 - val_loss: 0.4860 - val_accuracy: 0.9087
Epoch 231/350
391/391 - 23s - loss: 0.1070 - accuracy: 0.9782 - val_loss: 0.4877 - val_accuracy: 0.9067
Epoch 232/350
391/391 - 24s - loss: 0.1062 - accuracy: 0.9793 - val_loss: 0.4876 - val_accuracy: 0.9059
Epoch 233/350
391/391 - 23s - loss: 0.1061 - accuracy: 0.9789 - val_loss: 0.4918 - val_accuracy: 0.9067
Epoch 234/350
391/391 - 23s - loss: 0.1055 - accuracy: 0.9793 - val_loss: 0.5008 - val_accuracy: 0.9061
Epoch 235/350
391/391 - 23s - loss: 0.1052 - accuracy: 0.9792 - val_loss: 0.4986 - val_accuracy: 0.9071
Epoch 236/350
391/391 - 23s - loss: 0.1065 - accuracy: 0.9789 - val_loss: 0.4901 - val_accuracy: 0.9073
Epoch 237/350
391/391 - 24s - loss: 0.1052 - accuracy: 0.9791 - val_loss: 0.4924 - val_accuracy: 0.9080
Epoch 238/350
391/391 - 23s - loss: 0.1091 - accuracy: 0.9777 - val_loss: 0.5011 - val_accuracy: 0.9076
Epoch 239/350
391/391 - 23s - loss: 0.1062 - accuracy: 0.9791 - val_loss: 0.4968 - val_accuracy: 0.9063
Epoch 240/350
391/391 - 23s - loss: 0.1051 - accuracy: 0.9787 - val_loss: 0.4973 - val_accuracy: 0.9084
Epoch 241/350
391/391 - 23s - loss: 0.1036 - accuracy: 0.9791 - val_loss: 0.4994 - val_accuracy: 0.9080
Epoch 242/350
391/391 - 23s - loss: 0.1026 - accuracy: 0.9801 - val_loss: 0.4991 - val_accuracy: 0.9069
Epoch 243/350
391/391 - 23s - loss: 0.1040 - accuracy: 0.9790 - val_loss: 0.5033 - val_accuracy: 0.9074
Epoch 244/350
391/391 - 23s - loss: 0.1040 - accuracy: 0.9787 - val_loss: 0.4993 - val_accuracy: 0.9082
Epoch 245/350
391/391 - 23s - loss: 0.1029 - accuracy: 0.9793 - val_loss: 0.4978 - val_accuracy: 0.9073
Epoch 246/350
391/391 - 24s - loss: 0.1050 - accuracy: 0.9791 - val_loss: 0.5030 - val_accuracy: 0.9070
Epoch 247/350
391/391 - 23s - loss: 0.1019 - accuracy: 0.9799 - val_loss: 0.5011 - val_accuracy: 0.9074
Epoch 248/350
391/391 - 23s - loss: 0.1035 - accuracy: 0.9804 - val_loss: 0.5017 - val_accuracy: 0.9073
Epoch 249/350
391/391 - 23s - loss: 0.1029 - accuracy: 0.9801 - val_loss: 0.4965 - val_accuracy: 0.9071
Epoch 250/350


Snapshot weight 4 shuffle 5 at epoch 250
Layer 11
Getting activations...


391/391 - 23s - loss: 0.1031 - accuracy: 0.9799 - val_loss: 0.5057 - val_accuracy: 0.9078
Epoch 251/350
391/391 - 23s - loss: 0.1057 - accuracy: 0.9787 - val_loss: 0.5037 - val_accuracy: 0.9061
Epoch 252/350
391/391 - 23s - loss: 0.1012 - accuracy: 0.9811 - val_loss: 0.5026 - val_accuracy: 0.9068
Epoch 253/350
391/391 - 23s - loss: 0.0997 - accuracy: 0.9813 - val_loss: 0.5012 - val_accuracy: 0.9082
Epoch 254/350
391/391 - 24s - loss: 0.0997 - accuracy: 0.9819 - val_loss: 0.5031 - val_accuracy: 0.9074
Epoch 255/350
391/391 - 23s - loss: 0.1012 - accuracy: 0.9807 - val_loss: 0.5011 - val_accuracy: 0.9083
Epoch 256/350
391/391 - 23s - loss: 0.0975 - accuracy: 0.9821 - val_loss: 0.5057 - val_accuracy: 0.9073
Epoch 257/350
391/391 - 23s - loss: 0.1014 - accuracy: 0.9808 - val_loss: 0.5040 - val_accuracy: 0.9084
Epoch 258/350
391/391 - 23s - loss: 0.0982 - accuracy: 0.9815 - val_loss: 0.5034 - val_accuracy: 0.9078
Epoch 259/350
391/391 - 23s - loss: 0.1013 - accuracy: 0.9804 - val_loss: 0.4998 - val_accuracy: 0.9077
Epoch 260/350
391/391 - 23s - loss: 0.1019 - accuracy: 0.9798 - val_loss: 0.5018 - val_accuracy: 0.9076
Epoch 261/350
391/391 - 23s - loss: 0.1005 - accuracy: 0.9810 - val_loss: 0.5001 - val_accuracy: 0.9072
Epoch 262/350
391/391 - 23s - loss: 0.0994 - accuracy: 0.9814 - val_loss: 0.5002 - val_accuracy: 0.9072
Epoch 263/350
391/391 - 23s - loss: 0.1021 - accuracy: 0.9808 - val_loss: 0.5005 - val_accuracy: 0.9080
Epoch 264/350
391/391 - 23s - loss: 0.1004 - accuracy: 0.9808 - val_loss: 0.5000 - val_accuracy: 0.9081
Epoch 265/350
391/391 - 23s - loss: 0.0990 - accuracy: 0.9810 - val_loss: 0.5053 - val_accuracy: 0.9086
Epoch 266/350
391/391 - 23s - loss: 0.1017 - accuracy: 0.9806 - val_loss: 0.5046 - val_accuracy: 0.9075
Epoch 267/350
391/391 - 24s - loss: 0.0999 - accuracy: 0.9807 - val_loss: 0.5043 - val_accuracy: 0.9077
Epoch 268/350
391/391 - 23s - loss: 0.1002 - accuracy: 0.9808 - val_loss: 0.5061 - val_accuracy: 0.9076
Epoch 269/350
391/391 - 23s - loss: 0.1011 - accuracy: 0.9804 - val_loss: 0.5042 - val_accuracy: 0.9080
Epoch 270/350
391/391 - 23s - loss: 0.0980 - accuracy: 0.9823 - val_loss: 0.5042 - val_accuracy: 0.9078
Epoch 271/350
391/391 - 23s - loss: 0.1005 - accuracy: 0.9800 - val_loss: 0.5049 - val_accuracy: 0.9081
Epoch 272/350
391/391 - 23s - loss: 0.0988 - accuracy: 0.9813 - val_loss: 0.5047 - val_accuracy: 0.9085
Epoch 273/350
391/391 - 23s - loss: 0.1010 - accuracy: 0.9803 - val_loss: 0.5047 - val_accuracy: 0.9073
Epoch 274/350
391/391 - 23s - loss: 0.0991 - accuracy: 0.9807 - val_loss: 0.5052 - val_accuracy: 0.9086
Epoch 275/350
391/391 - 24s - loss: 0.1014 - accuracy: 0.9803 - val_loss: 0.5021 - val_accuracy: 0.9078
Epoch 276/350
391/391 - 23s - loss: 0.1006 - accuracy: 0.9808 - val_loss: 0.5059 - val_accuracy: 0.9067
Epoch 277/350
391/391 - 23s - loss: 0.0996 - accuracy: 0.9812 - val_loss: 0.5042 - val_accuracy: 0.9074
Epoch 278/350
391/391 - 23s - loss: 0.1024 - accuracy: 0.9801 - val_loss: 0.5031 - val_accuracy: 0.9080
Epoch 279/350
391/391 - 23s - loss: 0.1010 - accuracy: 0.9811 - val_loss: 0.5006 - val_accuracy: 0.9084
Epoch 280/350
391/391 - 23s - loss: 0.0965 - accuracy: 0.9820 - val_loss: 0.5046 - val_accuracy: 0.9079
Epoch 281/350
391/391 - 23s - loss: 0.1009 - accuracy: 0.9808 - val_loss: 0.5035 - val_accuracy: 0.9074
Epoch 282/350
391/391 - 23s - loss: 0.0993 - accuracy: 0.9813 - val_loss: 0.5028 - val_accuracy: 0.9076
Epoch 283/350
391/391 - 23s - loss: 0.0997 - accuracy: 0.9813 - val_loss: 0.5031 - val_accuracy: 0.9068
Epoch 284/350
391/391 - 23s - loss: 0.1005 - accuracy: 0.9805 - val_loss: 0.5024 - val_accuracy: 0.9070
Epoch 285/350
391/391 - 23s - loss: 0.0982 - accuracy: 0.9815 - val_loss: 0.5045 - val_accuracy: 0.9075
Epoch 286/350
391/391 - 23s - loss: 0.0989 - accuracy: 0.9818 - val_loss: 0.5030 - val_accuracy: 0.9074
Epoch 287/350
391/391 - 23s - loss: 0.1013 - accuracy: 0.9804 - val_loss: 0.5036 - val_accuracy: 0.9078
Epoch 288/350
391/391 - 23s - loss: 0.1012 - accuracy: 0.9804 - val_loss: 0.5057 - val_accuracy: 0.9078
Epoch 289/350
391/391 - 24s - loss: 0.1006 - accuracy: 0.9805 - val_loss: 0.5028 - val_accuracy: 0.9082
Epoch 290/350
391/391 - 23s - loss: 0.0980 - accuracy: 0.9826 - val_loss: 0.5035 - val_accuracy: 0.9079
Epoch 291/350
391/391 - 23s - loss: 0.1008 - accuracy: 0.9805 - val_loss: 0.5057 - val_accuracy: 0.9074
Epoch 292/350
391/391 - 23s - loss: 0.1009 - accuracy: 0.9809 - val_loss: 0.5037 - val_accuracy: 0.9082
Epoch 293/350
391/391 - 23s - loss: 0.1001 - accuracy: 0.9809 - val_loss: 0.5044 - val_accuracy: 0.9075
Epoch 294/350
391/391 - 23s - loss: 0.0988 - accuracy: 0.9815 - val_loss: 0.5041 - val_accuracy: 0.9073
Epoch 295/350
391/391 - 23s - loss: 0.0983 - accuracy: 0.9808 - val_loss: 0.5035 - val_accuracy: 0.9080
Epoch 296/350
391/391 - 23s - loss: 0.0993 - accuracy: 0.9805 - val_loss: 0.5051 - val_accuracy: 0.9076
Epoch 297/350
391/391 - 23s - loss: 0.0996 - accuracy: 0.9807 - val_loss: 0.5035 - val_accuracy: 0.9074
Epoch 298/350
391/391 - 23s - loss: 0.0994 - accuracy: 0.9817 - val_loss: 0.5049 - val_accuracy: 0.9069
Epoch 299/350
391/391 - 23s - loss: 0.0984 - accuracy: 0.9817 - val_loss: 0.5030 - val_accuracy: 0.9078
Epoch 300/350


Snapshot weight 4 shuffle 5 at epoch 300
Layer 11
Getting activations...


391/391 - 23s - loss: 0.0981 - accuracy: 0.9817 - val_loss: 0.5045 - val_accuracy: 0.9071
Epoch 301/350
391/391 - 23s - loss: 0.0995 - accuracy: 0.9813 - val_loss: 0.5048 - val_accuracy: 0.9070
Epoch 302/350
391/391 - 23s - loss: 0.0985 - accuracy: 0.9813 - val_loss: 0.5047 - val_accuracy: 0.9070
Epoch 303/350
391/391 - 23s - loss: 0.0986 - accuracy: 0.9817 - val_loss: 0.5055 - val_accuracy: 0.9070
Epoch 304/350
391/391 - 24s - loss: 0.0986 - accuracy: 0.9820 - val_loss: 0.5052 - val_accuracy: 0.9072
Epoch 305/350
391/391 - 23s - loss: 0.0982 - accuracy: 0.9810 - val_loss: 0.5055 - val_accuracy: 0.9070
Epoch 306/350
391/391 - 23s - loss: 0.0984 - accuracy: 0.9815 - val_loss: 0.5054 - val_accuracy: 0.9066
Epoch 307/350
391/391 - 23s - loss: 0.0992 - accuracy: 0.9817 - val_loss: 0.5052 - val_accuracy: 0.9073
Epoch 308/350
391/391 - 23s - loss: 0.1006 - accuracy: 0.9808 - val_loss: 0.5050 - val_accuracy: 0.9073
Epoch 309/350
391/391 - 23s - loss: 0.0988 - accuracy: 0.9820 - val_loss: 0.5048 - val_accuracy: 0.9069
Epoch 310/350
391/391 - 23s - loss: 0.0978 - accuracy: 0.9819 - val_loss: 0.5045 - val_accuracy: 0.9071
Epoch 311/350
391/391 - 23s - loss: 0.1003 - accuracy: 0.9806 - val_loss: 0.5043 - val_accuracy: 0.9073
Epoch 312/350
391/391 - 23s - loss: 0.0983 - accuracy: 0.9818 - val_loss: 0.5046 - val_accuracy: 0.9074
Epoch 313/350
391/391 - 23s - loss: 0.0986 - accuracy: 0.9814 - val_loss: 0.5050 - val_accuracy: 0.9072
Epoch 314/350
391/391 - 23s - loss: 0.0985 - accuracy: 0.9813 - val_loss: 0.5050 - val_accuracy: 0.9074
Epoch 315/350
391/391 - 23s - loss: 0.0987 - accuracy: 0.9819 - val_loss: 0.5046 - val_accuracy: 0.9075
Epoch 316/350
391/391 - 23s - loss: 0.0981 - accuracy: 0.9820 - val_loss: 0.5046 - val_accuracy: 0.9075
Epoch 317/350
391/391 - 24s - loss: 0.0990 - accuracy: 0.9813 - val_loss: 0.5050 - val_accuracy: 0.9077
Epoch 318/350
391/391 - 23s - loss: 0.1003 - accuracy: 0.9808 - val_loss: 0.5052 - val_accuracy: 0.9074
Epoch 319/350
391/391 - 23s - loss: 0.0985 - accuracy: 0.9806 - val_loss: 0.5056 - val_accuracy: 0.9073
Epoch 320/350
391/391 - 23s - loss: 0.0994 - accuracy: 0.9810 - val_loss: 0.5053 - val_accuracy: 0.9073
Epoch 321/350
391/391 - 24s - loss: 0.0987 - accuracy: 0.9815 - val_loss: 0.5053 - val_accuracy: 0.9074
Epoch 322/350
391/391 - 23s - loss: 0.0976 - accuracy: 0.9812 - val_loss: 0.5050 - val_accuracy: 0.9071
Epoch 323/350
391/391 - 23s - loss: 0.0976 - accuracy: 0.9812 - val_loss: 0.5047 - val_accuracy: 0.9075
Epoch 324/350
391/391 - 23s - loss: 0.1004 - accuracy: 0.9805 - val_loss: 0.5049 - val_accuracy: 0.9074
Epoch 325/350
391/391 - 23s - loss: 0.0977 - accuracy: 0.9820 - val_loss: 0.5048 - val_accuracy: 0.9074
Epoch 326/350
391/391 - 23s - loss: 0.0986 - accuracy: 0.9815 - val_loss: 0.5053 - val_accuracy: 0.9072
Epoch 327/350
391/391 - 23s - loss: 0.0965 - accuracy: 0.9819 - val_loss: 0.5056 - val_accuracy: 0.9074
Epoch 328/350
391/391 - 23s - loss: 0.0984 - accuracy: 0.9814 - val_loss: 0.5054 - val_accuracy: 0.9074
Epoch 329/350
391/391 - 23s - loss: 0.0991 - accuracy: 0.9814 - val_loss: 0.5056 - val_accuracy: 0.9072
Epoch 330/350
391/391 - 23s - loss: 0.0983 - accuracy: 0.9818 - val_loss: 0.5055 - val_accuracy: 0.9071
Epoch 331/350
391/391 - 23s - loss: 0.0986 - accuracy: 0.9818 - val_loss: 0.5053 - val_accuracy: 0.9072
Epoch 332/350
391/391 - 23s - loss: 0.1011 - accuracy: 0.9812 - val_loss: 0.5051 - val_accuracy: 0.9073
Epoch 333/350
391/391 - 23s - loss: 0.0968 - accuracy: 0.9821 - val_loss: 0.5048 - val_accuracy: 0.9074
Epoch 334/350
391/391 - 23s - loss: 0.0983 - accuracy: 0.9815 - val_loss: 0.5051 - val_accuracy: 0.9073
Epoch 335/350
391/391 - 23s - loss: 0.0996 - accuracy: 0.9806 - val_loss: 0.5052 - val_accuracy: 0.9075
Epoch 336/350
391/391 - 23s - loss: 0.0969 - accuracy: 0.9818 - val_loss: 0.5056 - val_accuracy: 0.9074
Epoch 337/350
391/391 - 23s - loss: 0.0988 - accuracy: 0.9817 - val_loss: 0.5057 - val_accuracy: 0.9075
Epoch 338/350
391/391 - 23s - loss: 0.0989 - accuracy: 0.9816 - val_loss: 0.5053 - val_accuracy: 0.9073
Epoch 339/350
391/391 - 23s - loss: 0.0984 - accuracy: 0.9815 - val_loss: 0.5050 - val_accuracy: 0.9073
Epoch 340/350
391/391 - 23s - loss: 0.0959 - accuracy: 0.9823 - val_loss: 0.5054 - val_accuracy: 0.9072
Epoch 341/350
391/391 - 23s - loss: 0.1010 - accuracy: 0.9809 - val_loss: 0.5051 - val_accuracy: 0.9075
Epoch 342/350
391/391 - 23s - loss: 0.0986 - accuracy: 0.9811 - val_loss: 0.5050 - val_accuracy: 0.9070
Epoch 343/350
391/391 - 23s - loss: 0.1018 - accuracy: 0.9804 - val_loss: 0.5051 - val_accuracy: 0.9070
Epoch 344/350
391/391 - 23s - loss: 0.1003 - accuracy: 0.9810 - val_loss: 0.5043 - val_accuracy: 0.9072
Epoch 345/350
391/391 - 23s - loss: 0.0978 - accuracy: 0.9818 - val_loss: 0.5046 - val_accuracy: 0.9072
Epoch 346/350
391/391 - 23s - loss: 0.0981 - accuracy: 0.9821 - val_loss: 0.5047 - val_accuracy: 0.9072
Epoch 347/350
391/391 - 23s - loss: 0.0971 - accuracy: 0.9818 - val_loss: 0.5047 - val_accuracy: 0.9072
Epoch 348/350
391/391 - 23s - loss: 0.1004 - accuracy: 0.9804 - val_loss: 0.5049 - val_accuracy: 0.9070
Epoch 349/350
391/391 - 23s - loss: 0.0991 - accuracy: 0.9818 - val_loss: 0.5052 - val_accuracy: 0.9071
Epoch 350/350


Snapshot weight 4 shuffle 5 at epoch 350
Layer 11
Getting activations...


391/391 - 23s - loss: 0.0985 - accuracy: 0.9817 - val_loss: 0.5051 - val_accuracy: 0.9071
/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:493: UserWarning: fill_value is not supported and is always 0 for TensorFlow < 2.4.0.
  return py_builtins.overload_of(f)(*args)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-07-02 09:38:13.838793: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
Saving, final validation acc: 0.9071000218391418
