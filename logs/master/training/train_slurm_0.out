2021-07-01 16:11:51.710022: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 16:13:17.026666: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-07-01 16:13:17.060350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:82:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2021-07-01 16:13:17.060431: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 16:13:17.103637: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-01 16:13:17.125854: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-01 16:13:17.135265: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-01 16:13:17.181275: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-01 16:13:17.189996: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-01 16:13:17.268739: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-01 16:13:17.277055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-01 16:13:17.280802: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-01 16:13:17.296884: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600265000 Hz
2021-07-01 16:13:17.297011: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3fdfc80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-07-01 16:13:17.297033: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-07-01 16:13:17.470536: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3f85e60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-07-01 16:13:17.470605: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN Xp, Compute Capability 6.1
2021-07-01 16:13:17.474197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:82:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2021-07-01 16:13:17.474242: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 16:13:17.474276: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-01 16:13:17.474298: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-01 16:13:17.474318: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-01 16:13:17.474337: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-01 16:13:17.474356: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-01 16:13:17.474376: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-01 16:13:17.477217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-01 16:13:17.478957: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 16:13:19.297671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-01 16:13:19.297753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-07-01 16:13:19.297767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-07-01 16:13:19.303771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11218 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:82:00.0, compute capability: 6.1)
2021-07-01 16:13:25.207146: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-01 16:13:27.705585: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
Using model index: 0
Making train data...
GCN...
ZCA...
Done!
Making test data...
Done!
Epoch 1/350


Snapshot weight 0 shuffle 0 at epoch 1
Layer 11
Getting activations...


391/391 - 24s - loss: 2.3226 - accuracy: 0.1030 - val_loss: 2.3158 - val_accuracy: 0.1083
Epoch 2/350


Snapshot weight 0 shuffle 0 at epoch 2
Layer 11
Getting activations...


391/391 - 23s - loss: 2.3103 - accuracy: 0.1285 - val_loss: 2.2966 - val_accuracy: 0.1621
Epoch 3/350


Snapshot weight 0 shuffle 0 at epoch 3
Layer 11
Getting activations...


391/391 - 24s - loss: 2.2823 - accuracy: 0.1675 - val_loss: 2.3112 - val_accuracy: 0.1636
Epoch 4/350


Snapshot weight 0 shuffle 0 at epoch 4
Layer 11
Getting activations...


391/391 - 24s - loss: 2.1944 - accuracy: 0.2158 - val_loss: 1.9682 - val_accuracy: 0.2921
Epoch 5/350


Snapshot weight 0 shuffle 0 at epoch 5
Layer 11
Getting activations...


391/391 - 24s - loss: 1.8608 - accuracy: 0.3510 - val_loss: 1.6966 - val_accuracy: 0.4208
Epoch 6/350


Snapshot weight 0 shuffle 0 at epoch 6
Layer 11
Getting activations...


391/391 - 24s - loss: 1.6832 - accuracy: 0.4238 - val_loss: 1.5132 - val_accuracy: 0.4913
Epoch 7/350


Snapshot weight 0 shuffle 0 at epoch 7
Layer 11
Getting activations...


391/391 - 24s - loss: 1.4256 - accuracy: 0.4933 - val_loss: 1.2502 - val_accuracy: 0.5627
Epoch 8/350


Snapshot weight 0 shuffle 0 at epoch 8
Layer 11
Getting activations...


391/391 - 24s - loss: 1.3128 - accuracy: 0.5344 - val_loss: 1.2738 - val_accuracy: 0.5562
Epoch 9/350


Snapshot weight 0 shuffle 0 at epoch 9
Layer 11
Getting activations...


391/391 - 24s - loss: 1.2306 - accuracy: 0.5665 - val_loss: 1.2307 - val_accuracy: 0.5874
Epoch 10/350


Snapshot weight 0 shuffle 0 at epoch 10
Layer 11
Getting activations...


391/391 - 24s - loss: 1.1578 - accuracy: 0.5954 - val_loss: 1.0902 - val_accuracy: 0.6310
Epoch 11/350
391/391 - 24s - loss: 1.0842 - accuracy: 0.6227 - val_loss: 0.9925 - val_accuracy: 0.6589
Epoch 12/350
391/391 - 24s - loss: 1.0364 - accuracy: 0.6407 - val_loss: 1.0265 - val_accuracy: 0.6602
Epoch 13/350
391/391 - 24s - loss: 0.9973 - accuracy: 0.6530 - val_loss: 0.9598 - val_accuracy: 0.6701
Epoch 14/350
391/391 - 24s - loss: 0.9555 - accuracy: 0.6699 - val_loss: 0.8680 - val_accuracy: 0.7024
Epoch 15/350
391/391 - 24s - loss: 0.9192 - accuracy: 0.6839 - val_loss: 0.9330 - val_accuracy: 0.6900
Epoch 16/350
391/391 - 24s - loss: 0.8848 - accuracy: 0.6991 - val_loss: 0.8124 - val_accuracy: 0.7223
Epoch 17/350
391/391 - 24s - loss: 0.8451 - accuracy: 0.7095 - val_loss: 0.8506 - val_accuracy: 0.7178
Epoch 18/350
391/391 - 24s - loss: 0.8206 - accuracy: 0.7221 - val_loss: 0.8141 - val_accuracy: 0.7245
Epoch 19/350
391/391 - 24s - loss: 0.8020 - accuracy: 0.7267 - val_loss: 0.7702 - val_accuracy: 0.7420
Epoch 20/350
391/391 - 24s - loss: 0.7665 - accuracy: 0.7386 - val_loss: 0.7746 - val_accuracy: 0.7467
Epoch 21/350
391/391 - 24s - loss: 0.7478 - accuracy: 0.7479 - val_loss: 0.8555 - val_accuracy: 0.7297
Epoch 22/350
391/391 - 24s - loss: 0.7176 - accuracy: 0.7603 - val_loss: 0.7208 - val_accuracy: 0.7648
Epoch 23/350
391/391 - 24s - loss: 0.6973 - accuracy: 0.7666 - val_loss: 0.7194 - val_accuracy: 0.7652
Epoch 24/350
391/391 - 24s - loss: 0.6799 - accuracy: 0.7725 - val_loss: 0.6428 - val_accuracy: 0.7900
Epoch 25/350
391/391 - 24s - loss: 0.6621 - accuracy: 0.7788 - val_loss: 0.6402 - val_accuracy: 0.7918
Epoch 26/350
391/391 - 24s - loss: 0.6502 - accuracy: 0.7824 - val_loss: 0.6131 - val_accuracy: 0.7994
Epoch 27/350
391/391 - 24s - loss: 0.6296 - accuracy: 0.7902 - val_loss: 0.5871 - val_accuracy: 0.8081
Epoch 28/350
391/391 - 24s - loss: 0.6203 - accuracy: 0.7936 - val_loss: 0.6265 - val_accuracy: 0.7961
Epoch 29/350
391/391 - 24s - loss: 0.6074 - accuracy: 0.7982 - val_loss: 0.5540 - val_accuracy: 0.8234
Epoch 30/350
391/391 - 24s - loss: 0.5948 - accuracy: 0.8036 - val_loss: 0.5981 - val_accuracy: 0.8101
Epoch 31/350
391/391 - 24s - loss: 0.5775 - accuracy: 0.8093 - val_loss: 0.5479 - val_accuracy: 0.8208
Epoch 32/350
391/391 - 24s - loss: 0.5628 - accuracy: 0.8163 - val_loss: 0.5774 - val_accuracy: 0.8133
Epoch 33/350
391/391 - 24s - loss: 0.5626 - accuracy: 0.8149 - val_loss: 0.5864 - val_accuracy: 0.8103
Epoch 34/350
391/391 - 24s - loss: 0.5484 - accuracy: 0.8208 - val_loss: 0.5420 - val_accuracy: 0.8259
Epoch 35/350
391/391 - 24s - loss: 0.5341 - accuracy: 0.8260 - val_loss: 0.5382 - val_accuracy: 0.8328
Epoch 36/350
391/391 - 24s - loss: 0.5180 - accuracy: 0.8311 - val_loss: 0.5444 - val_accuracy: 0.8254
Epoch 37/350
391/391 - 24s - loss: 0.5081 - accuracy: 0.8336 - val_loss: 0.5180 - val_accuracy: 0.8337
Epoch 38/350
391/391 - 24s - loss: 0.5107 - accuracy: 0.8335 - val_loss: 0.5179 - val_accuracy: 0.8361
Epoch 39/350
391/391 - 24s - loss: 0.4979 - accuracy: 0.8357 - val_loss: 0.5002 - val_accuracy: 0.8434
Epoch 40/350
391/391 - 24s - loss: 0.4901 - accuracy: 0.8404 - val_loss: 0.4818 - val_accuracy: 0.8479
Epoch 41/350
391/391 - 24s - loss: 0.4832 - accuracy: 0.8411 - val_loss: 0.4864 - val_accuracy: 0.8467
Epoch 42/350
391/391 - 24s - loss: 0.4737 - accuracy: 0.8463 - val_loss: 0.5349 - val_accuracy: 0.8338
Epoch 43/350
391/391 - 24s - loss: 0.4626 - accuracy: 0.8487 - val_loss: 0.5211 - val_accuracy: 0.8353
Epoch 44/350
391/391 - 24s - loss: 0.4610 - accuracy: 0.8494 - val_loss: 0.4993 - val_accuracy: 0.8480
Epoch 45/350
391/391 - 24s - loss: 0.4585 - accuracy: 0.8527 - val_loss: 0.5276 - val_accuracy: 0.8382
Epoch 46/350
391/391 - 24s - loss: 0.4419 - accuracy: 0.8577 - val_loss: 0.4703 - val_accuracy: 0.8534
Epoch 47/350
391/391 - 24s - loss: 0.4391 - accuracy: 0.8577 - val_loss: 0.4433 - val_accuracy: 0.8590
Epoch 48/350
391/391 - 24s - loss: 0.4310 - accuracy: 0.8602 - val_loss: 0.4771 - val_accuracy: 0.8555
Epoch 49/350
391/391 - 24s - loss: 0.4295 - accuracy: 0.8616 - val_loss: 0.5033 - val_accuracy: 0.8498
Epoch 50/350


Snapshot weight 0 shuffle 0 at epoch 50
Layer 11
Getting activations...


391/391 - 24s - loss: 0.4252 - accuracy: 0.8625 - val_loss: 0.4934 - val_accuracy: 0.8506
Epoch 51/350
391/391 - 24s - loss: 0.4169 - accuracy: 0.8658 - val_loss: 0.4663 - val_accuracy: 0.8570
Epoch 52/350
391/391 - 24s - loss: 0.4089 - accuracy: 0.8682 - val_loss: 0.4860 - val_accuracy: 0.8488
Epoch 53/350
391/391 - 24s - loss: 0.4085 - accuracy: 0.8704 - val_loss: 0.4761 - val_accuracy: 0.8589
Epoch 54/350
391/391 - 24s - loss: 0.4048 - accuracy: 0.8706 - val_loss: 0.4453 - val_accuracy: 0.8612
Epoch 55/350
391/391 - 24s - loss: 0.3959 - accuracy: 0.8731 - val_loss: 0.4563 - val_accuracy: 0.8642
Epoch 56/350
391/391 - 24s - loss: 0.3944 - accuracy: 0.8730 - val_loss: 0.4706 - val_accuracy: 0.8568
Epoch 57/350
391/391 - 24s - loss: 0.3913 - accuracy: 0.8751 - val_loss: 0.4559 - val_accuracy: 0.8637
Epoch 58/350
391/391 - 24s - loss: 0.3865 - accuracy: 0.8740 - val_loss: 0.4342 - val_accuracy: 0.8682
Epoch 59/350
391/391 - 24s - loss: 0.3812 - accuracy: 0.8798 - val_loss: 0.4599 - val_accuracy: 0.8588
Epoch 60/350
391/391 - 24s - loss: 0.3745 - accuracy: 0.8807 - val_loss: 0.4510 - val_accuracy: 0.8675
Epoch 61/350
391/391 - 24s - loss: 0.3733 - accuracy: 0.8785 - val_loss: 0.4360 - val_accuracy: 0.8728
Epoch 62/350
391/391 - 24s - loss: 0.3674 - accuracy: 0.8827 - val_loss: 0.4258 - val_accuracy: 0.8705
Epoch 63/350
391/391 - 24s - loss: 0.3591 - accuracy: 0.8842 - val_loss: 0.4734 - val_accuracy: 0.8641
Epoch 64/350
391/391 - 24s - loss: 0.3582 - accuracy: 0.8853 - val_loss: 0.4320 - val_accuracy: 0.8736
Epoch 65/350
391/391 - 24s - loss: 0.3559 - accuracy: 0.8868 - val_loss: 0.4357 - val_accuracy: 0.8714
Epoch 66/350
391/391 - 24s - loss: 0.3498 - accuracy: 0.8899 - val_loss: 0.4994 - val_accuracy: 0.8517
Epoch 67/350
391/391 - 24s - loss: 0.3526 - accuracy: 0.8880 - val_loss: 0.4329 - val_accuracy: 0.8738
Epoch 68/350
391/391 - 24s - loss: 0.3462 - accuracy: 0.8907 - val_loss: 0.4490 - val_accuracy: 0.8715
Epoch 69/350
391/391 - 24s - loss: 0.3392 - accuracy: 0.8934 - val_loss: 0.4516 - val_accuracy: 0.8706
Epoch 70/350
391/391 - 24s - loss: 0.3374 - accuracy: 0.8926 - val_loss: 0.4291 - val_accuracy: 0.8770
Epoch 71/350
391/391 - 24s - loss: 0.3347 - accuracy: 0.8940 - val_loss: 0.4095 - val_accuracy: 0.8815
Epoch 72/350
391/391 - 24s - loss: 0.3309 - accuracy: 0.8961 - val_loss: 0.4346 - val_accuracy: 0.8736
Epoch 73/350
391/391 - 24s - loss: 0.3271 - accuracy: 0.8971 - val_loss: 0.4172 - val_accuracy: 0.8786
Epoch 74/350
391/391 - 24s - loss: 0.3254 - accuracy: 0.8978 - val_loss: 0.4308 - val_accuracy: 0.8769
Epoch 75/350
391/391 - 24s - loss: 0.3228 - accuracy: 0.8984 - val_loss: 0.4113 - val_accuracy: 0.8785
Epoch 76/350
391/391 - 24s - loss: 0.3202 - accuracy: 0.8996 - val_loss: 0.4290 - val_accuracy: 0.8767
Epoch 77/350
391/391 - 24s - loss: 0.3152 - accuracy: 0.8999 - val_loss: 0.4296 - val_accuracy: 0.8785
Epoch 78/350
391/391 - 24s - loss: 0.3141 - accuracy: 0.9004 - val_loss: 0.4211 - val_accuracy: 0.8799
Epoch 79/350
391/391 - 24s - loss: 0.3100 - accuracy: 0.9028 - val_loss: 0.4335 - val_accuracy: 0.8757
Epoch 80/350
391/391 - 24s - loss: 0.3054 - accuracy: 0.9057 - val_loss: 0.4265 - val_accuracy: 0.8791
Epoch 81/350
391/391 - 24s - loss: 0.3038 - accuracy: 0.9046 - val_loss: 0.4279 - val_accuracy: 0.8763
Epoch 82/350
391/391 - 24s - loss: 0.3082 - accuracy: 0.9028 - val_loss: 0.4322 - val_accuracy: 0.8754
Epoch 83/350
391/391 - 24s - loss: 0.3032 - accuracy: 0.9043 - val_loss: 0.3977 - val_accuracy: 0.8827
Epoch 84/350
391/391 - 24s - loss: 0.3006 - accuracy: 0.9062 - val_loss: 0.4173 - val_accuracy: 0.8809
Epoch 85/350
391/391 - 24s - loss: 0.2959 - accuracy: 0.9079 - val_loss: 0.4088 - val_accuracy: 0.8820
Epoch 86/350
391/391 - 24s - loss: 0.2948 - accuracy: 0.9079 - val_loss: 0.4287 - val_accuracy: 0.8800
Epoch 87/350
391/391 - 24s - loss: 0.2957 - accuracy: 0.9084 - val_loss: 0.3959 - val_accuracy: 0.8818
Epoch 88/350
391/391 - 24s - loss: 0.2881 - accuracy: 0.9115 - val_loss: 0.4140 - val_accuracy: 0.8824
Epoch 89/350
391/391 - 24s - loss: 0.2859 - accuracy: 0.9113 - val_loss: 0.4139 - val_accuracy: 0.8812
Epoch 90/350
391/391 - 24s - loss: 0.2846 - accuracy: 0.9130 - val_loss: 0.4009 - val_accuracy: 0.8866
Epoch 91/350
391/391 - 24s - loss: 0.2837 - accuracy: 0.9137 - val_loss: 0.4191 - val_accuracy: 0.8819
Epoch 92/350
391/391 - 24s - loss: 0.2832 - accuracy: 0.9139 - val_loss: 0.3989 - val_accuracy: 0.8859
Epoch 93/350
391/391 - 24s - loss: 0.2756 - accuracy: 0.9154 - val_loss: 0.4254 - val_accuracy: 0.8817
Epoch 94/350
391/391 - 24s - loss: 0.2763 - accuracy: 0.9160 - val_loss: 0.4341 - val_accuracy: 0.8778
Epoch 95/350
391/391 - 24s - loss: 0.2766 - accuracy: 0.9140 - val_loss: 0.4582 - val_accuracy: 0.8758
Epoch 96/350
391/391 - 24s - loss: 0.2740 - accuracy: 0.9175 - val_loss: 0.4265 - val_accuracy: 0.8820
Epoch 97/350
391/391 - 24s - loss: 0.2727 - accuracy: 0.9144 - val_loss: 0.4241 - val_accuracy: 0.8835
Epoch 98/350
391/391 - 24s - loss: 0.2632 - accuracy: 0.9204 - val_loss: 0.4196 - val_accuracy: 0.8828
Epoch 99/350
391/391 - 24s - loss: 0.2624 - accuracy: 0.9195 - val_loss: 0.4189 - val_accuracy: 0.8825
Epoch 100/350


Snapshot weight 0 shuffle 0 at epoch 100
Layer 11
Getting activations...


391/391 - 24s - loss: 0.2587 - accuracy: 0.9206 - val_loss: 0.4024 - val_accuracy: 0.8872
Epoch 101/350
391/391 - 24s - loss: 0.2604 - accuracy: 0.9214 - val_loss: 0.4296 - val_accuracy: 0.8817
Epoch 102/350
391/391 - 24s - loss: 0.2585 - accuracy: 0.9224 - val_loss: 0.4283 - val_accuracy: 0.8824
Epoch 103/350
391/391 - 24s - loss: 0.2610 - accuracy: 0.9221 - val_loss: 0.4195 - val_accuracy: 0.8835
Epoch 104/350
391/391 - 24s - loss: 0.2546 - accuracy: 0.9225 - val_loss: 0.4361 - val_accuracy: 0.8828
Epoch 105/350
391/391 - 24s - loss: 0.2624 - accuracy: 0.9194 - val_loss: 0.4060 - val_accuracy: 0.8920
Epoch 106/350
391/391 - 24s - loss: 0.2536 - accuracy: 0.9231 - val_loss: 0.4275 - val_accuracy: 0.8826
Epoch 107/350
391/391 - 24s - loss: 0.2518 - accuracy: 0.9251 - val_loss: 0.4295 - val_accuracy: 0.8877
Epoch 108/350
391/391 - 24s - loss: 0.2516 - accuracy: 0.9243 - val_loss: 0.4195 - val_accuracy: 0.8858
Epoch 109/350
391/391 - 24s - loss: 0.2488 - accuracy: 0.9252 - val_loss: 0.4261 - val_accuracy: 0.8912
Epoch 110/350
391/391 - 24s - loss: 0.2481 - accuracy: 0.9256 - val_loss: 0.4862 - val_accuracy: 0.8767
Epoch 111/350
391/391 - 24s - loss: 0.2485 - accuracy: 0.9258 - val_loss: 0.4522 - val_accuracy: 0.8816
Epoch 112/350
391/391 - 24s - loss: 0.2442 - accuracy: 0.9271 - val_loss: 0.4399 - val_accuracy: 0.8860
Epoch 113/350
391/391 - 24s - loss: 0.2460 - accuracy: 0.9271 - val_loss: 0.4719 - val_accuracy: 0.8779
Epoch 114/350
391/391 - 24s - loss: 0.2409 - accuracy: 0.9290 - val_loss: 0.4195 - val_accuracy: 0.8873
Epoch 115/350
391/391 - 24s - loss: 0.2405 - accuracy: 0.9288 - val_loss: 0.4479 - val_accuracy: 0.8874
Epoch 116/350
391/391 - 24s - loss: 0.2403 - accuracy: 0.9274 - val_loss: 0.4314 - val_accuracy: 0.8916
Epoch 117/350
391/391 - 24s - loss: 0.2377 - accuracy: 0.9292 - val_loss: 0.4279 - val_accuracy: 0.8921
Epoch 118/350
391/391 - 24s - loss: 0.2380 - accuracy: 0.9295 - val_loss: 0.3968 - val_accuracy: 0.8948
Epoch 119/350
391/391 - 24s - loss: 0.2334 - accuracy: 0.9312 - val_loss: 0.4098 - val_accuracy: 0.8934
Epoch 120/350
391/391 - 24s - loss: 0.2364 - accuracy: 0.9297 - val_loss: 0.4146 - val_accuracy: 0.8925
Epoch 121/350
391/391 - 24s - loss: 0.2297 - accuracy: 0.9326 - val_loss: 0.4080 - val_accuracy: 0.8953
Epoch 122/350
391/391 - 24s - loss: 0.2333 - accuracy: 0.9321 - val_loss: 0.4253 - val_accuracy: 0.8935
Epoch 123/350
391/391 - 24s - loss: 0.2299 - accuracy: 0.9332 - val_loss: 0.4328 - val_accuracy: 0.8871
Epoch 124/350
391/391 - 24s - loss: 0.2299 - accuracy: 0.9309 - val_loss: 0.4578 - val_accuracy: 0.8895
Epoch 125/350
391/391 - 24s - loss: 0.2257 - accuracy: 0.9333 - val_loss: 0.4242 - val_accuracy: 0.8926
Epoch 126/350
391/391 - 24s - loss: 0.2257 - accuracy: 0.9342 - val_loss: 0.4379 - val_accuracy: 0.8889
Epoch 127/350
391/391 - 24s - loss: 0.2255 - accuracy: 0.9337 - val_loss: 0.4116 - val_accuracy: 0.8957
Epoch 128/350
391/391 - 24s - loss: 0.2235 - accuracy: 0.9339 - val_loss: 0.4372 - val_accuracy: 0.8835
Epoch 129/350
391/391 - 24s - loss: 0.2257 - accuracy: 0.9349 - val_loss: 0.4461 - val_accuracy: 0.8889
Epoch 130/350
391/391 - 24s - loss: 0.2250 - accuracy: 0.9344 - val_loss: 0.4198 - val_accuracy: 0.8966
Epoch 131/350
391/391 - 24s - loss: 0.2192 - accuracy: 0.9364 - val_loss: 0.4256 - val_accuracy: 0.8899
Epoch 132/350
391/391 - 24s - loss: 0.2176 - accuracy: 0.9365 - val_loss: 0.4207 - val_accuracy: 0.8971
Epoch 133/350
391/391 - 24s - loss: 0.2195 - accuracy: 0.9362 - val_loss: 0.4169 - val_accuracy: 0.8940
Epoch 134/350
391/391 - 24s - loss: 0.2158 - accuracy: 0.9378 - val_loss: 0.4234 - val_accuracy: 0.8956
Epoch 135/350
391/391 - 24s - loss: 0.2153 - accuracy: 0.9379 - val_loss: 0.4575 - val_accuracy: 0.8889
Epoch 136/350
391/391 - 24s - loss: 0.2151 - accuracy: 0.9378 - val_loss: 0.4226 - val_accuracy: 0.8964
Epoch 137/350
391/391 - 24s - loss: 0.2143 - accuracy: 0.9386 - val_loss: 0.4011 - val_accuracy: 0.8976
Epoch 138/350
391/391 - 24s - loss: 0.2128 - accuracy: 0.9394 - val_loss: 0.4179 - val_accuracy: 0.8946
Epoch 139/350
391/391 - 24s - loss: 0.2099 - accuracy: 0.9395 - val_loss: 0.4311 - val_accuracy: 0.8930
Epoch 140/350
391/391 - 24s - loss: 0.2055 - accuracy: 0.9418 - val_loss: 0.4377 - val_accuracy: 0.8949
Epoch 141/350
391/391 - 24s - loss: 0.2078 - accuracy: 0.9419 - val_loss: 0.4348 - val_accuracy: 0.8935
Epoch 142/350
391/391 - 24s - loss: 0.2073 - accuracy: 0.9415 - val_loss: 0.4419 - val_accuracy: 0.8945
Epoch 143/350
391/391 - 24s - loss: 0.2044 - accuracy: 0.9424 - val_loss: 0.4461 - val_accuracy: 0.8926
Epoch 144/350
391/391 - 24s - loss: 0.2078 - accuracy: 0.9412 - val_loss: 0.4566 - val_accuracy: 0.8925
Epoch 145/350
391/391 - 24s - loss: 0.2046 - accuracy: 0.9423 - val_loss: 0.4493 - val_accuracy: 0.8900
Epoch 146/350
391/391 - 24s - loss: 0.2027 - accuracy: 0.9422 - val_loss: 0.4319 - val_accuracy: 0.8942
Epoch 147/350
391/391 - 24s - loss: 0.2040 - accuracy: 0.9416 - val_loss: 0.4284 - val_accuracy: 0.8962
Epoch 148/350
391/391 - 24s - loss: 0.2016 - accuracy: 0.9430 - val_loss: 0.4319 - val_accuracy: 0.8906
Epoch 149/350
391/391 - 24s - loss: 0.2014 - accuracy: 0.9431 - val_loss: 0.4123 - val_accuracy: 0.8974
Epoch 150/350


Snapshot weight 0 shuffle 0 at epoch 150
Layer 11
Getting activations...


391/391 - 24s - loss: 0.1996 - accuracy: 0.9447 - val_loss: 0.4355 - val_accuracy: 0.8962
Epoch 151/350
391/391 - 24s - loss: 0.1967 - accuracy: 0.9448 - val_loss: 0.4774 - val_accuracy: 0.8866
Epoch 152/350
391/391 - 24s - loss: 0.1957 - accuracy: 0.9457 - val_loss: 0.4844 - val_accuracy: 0.8915
Epoch 153/350
391/391 - 24s - loss: 0.1989 - accuracy: 0.9450 - val_loss: 0.4098 - val_accuracy: 0.8981
Epoch 154/350
391/391 - 24s - loss: 0.2021 - accuracy: 0.9425 - val_loss: 0.4141 - val_accuracy: 0.8946
Epoch 155/350
391/391 - 24s - loss: 0.1935 - accuracy: 0.9468 - val_loss: 0.4213 - val_accuracy: 0.8997
Epoch 156/350
391/391 - 24s - loss: 0.1948 - accuracy: 0.9453 - val_loss: 0.4550 - val_accuracy: 0.8938
Epoch 157/350
391/391 - 24s - loss: 0.1965 - accuracy: 0.9458 - val_loss: 0.4491 - val_accuracy: 0.8948
Epoch 158/350
391/391 - 24s - loss: 0.1942 - accuracy: 0.9463 - val_loss: 0.4751 - val_accuracy: 0.8937
Epoch 159/350
391/391 - 24s - loss: 0.1934 - accuracy: 0.9462 - val_loss: 0.4297 - val_accuracy: 0.8960
Epoch 160/350
391/391 - 24s - loss: 0.1900 - accuracy: 0.9476 - val_loss: 0.4520 - val_accuracy: 0.8955
Epoch 161/350
391/391 - 24s - loss: 0.1880 - accuracy: 0.9485 - val_loss: 0.4269 - val_accuracy: 0.8973
Epoch 162/350
391/391 - 24s - loss: 0.1912 - accuracy: 0.9476 - val_loss: 0.4283 - val_accuracy: 0.9011
Epoch 163/350
391/391 - 24s - loss: 0.1864 - accuracy: 0.9494 - val_loss: 0.4671 - val_accuracy: 0.8942
Epoch 164/350
391/391 - 24s - loss: 0.1886 - accuracy: 0.9494 - val_loss: 0.4473 - val_accuracy: 0.8944
Epoch 165/350
391/391 - 24s - loss: 0.1901 - accuracy: 0.9471 - val_loss: 0.4495 - val_accuracy: 0.8979
Epoch 166/350
391/391 - 24s - loss: 0.1919 - accuracy: 0.9472 - val_loss: 0.4401 - val_accuracy: 0.8942
Epoch 167/350
391/391 - 24s - loss: 0.1855 - accuracy: 0.9497 - val_loss: 0.4714 - val_accuracy: 0.8946
Epoch 168/350
391/391 - 24s - loss: 0.1831 - accuracy: 0.9509 - val_loss: 0.4448 - val_accuracy: 0.8970
Epoch 169/350
391/391 - 23s - loss: 0.1808 - accuracy: 0.9503 - val_loss: 0.4388 - val_accuracy: 0.8938
Epoch 170/350
391/391 - 24s - loss: 0.1834 - accuracy: 0.9500 - val_loss: 0.4650 - val_accuracy: 0.8934
Epoch 171/350
391/391 - 24s - loss: 0.1823 - accuracy: 0.9495 - val_loss: 0.4735 - val_accuracy: 0.8928
Epoch 172/350
391/391 - 24s - loss: 0.1854 - accuracy: 0.9502 - val_loss: 0.4394 - val_accuracy: 0.8973
Epoch 173/350
391/391 - 24s - loss: 0.1814 - accuracy: 0.9521 - val_loss: 0.4629 - val_accuracy: 0.8948
Epoch 174/350
391/391 - 24s - loss: 0.1816 - accuracy: 0.9513 - val_loss: 0.4203 - val_accuracy: 0.8992
Epoch 175/350
391/391 - 24s - loss: 0.1775 - accuracy: 0.9528 - val_loss: 0.4894 - val_accuracy: 0.8949
Epoch 176/350
391/391 - 24s - loss: 0.1830 - accuracy: 0.9502 - val_loss: 0.4460 - val_accuracy: 0.8992
Epoch 177/350
391/391 - 24s - loss: 0.1789 - accuracy: 0.9523 - val_loss: 0.4345 - val_accuracy: 0.9021
Epoch 178/350
391/391 - 24s - loss: 0.1754 - accuracy: 0.9542 - val_loss: 0.4397 - val_accuracy: 0.8987
Epoch 179/350
391/391 - 24s - loss: 0.1771 - accuracy: 0.9531 - val_loss: 0.4957 - val_accuracy: 0.8919
Epoch 180/350
391/391 - 24s - loss: 0.1769 - accuracy: 0.9529 - val_loss: 0.4649 - val_accuracy: 0.8951
Epoch 181/350
391/391 - 24s - loss: 0.1800 - accuracy: 0.9526 - val_loss: 0.4545 - val_accuracy: 0.8964
Epoch 182/350
391/391 - 24s - loss: 0.1739 - accuracy: 0.9543 - val_loss: 0.4404 - val_accuracy: 0.9013
Epoch 183/350
391/391 - 24s - loss: 0.1749 - accuracy: 0.9535 - val_loss: 0.4378 - val_accuracy: 0.8968
Epoch 184/350
391/391 - 24s - loss: 0.1783 - accuracy: 0.9533 - val_loss: 0.4464 - val_accuracy: 0.8974
Epoch 185/350
391/391 - 24s - loss: 0.1692 - accuracy: 0.9557 - val_loss: 0.4687 - val_accuracy: 0.8982
Epoch 186/350
391/391 - 24s - loss: 0.1777 - accuracy: 0.9526 - val_loss: 0.4570 - val_accuracy: 0.8964
Epoch 187/350
391/391 - 24s - loss: 0.1716 - accuracy: 0.9545 - val_loss: 0.4290 - val_accuracy: 0.9015
Epoch 188/350
391/391 - 24s - loss: 0.1754 - accuracy: 0.9538 - val_loss: 0.4657 - val_accuracy: 0.8974
Epoch 189/350
391/391 - 24s - loss: 0.1720 - accuracy: 0.9548 - val_loss: 0.4511 - val_accuracy: 0.9010
Epoch 190/350
391/391 - 24s - loss: 0.1727 - accuracy: 0.9548 - val_loss: 0.4532 - val_accuracy: 0.8980
Epoch 191/350
391/391 - 24s - loss: 0.1735 - accuracy: 0.9551 - val_loss: 0.4529 - val_accuracy: 0.8972
Epoch 192/350
391/391 - 24s - loss: 0.1677 - accuracy: 0.9570 - val_loss: 0.4757 - val_accuracy: 0.8950
Epoch 193/350
391/391 - 24s - loss: 0.1655 - accuracy: 0.9575 - val_loss: 0.4891 - val_accuracy: 0.8972
Epoch 194/350
391/391 - 24s - loss: 0.1694 - accuracy: 0.9563 - val_loss: 0.4723 - val_accuracy: 0.8934
Epoch 195/350
391/391 - 24s - loss: 0.1683 - accuracy: 0.9564 - val_loss: 0.4477 - val_accuracy: 0.8981
Epoch 196/350
391/391 - 24s - loss: 0.1698 - accuracy: 0.9555 - val_loss: 0.4328 - val_accuracy: 0.9020
Epoch 197/350
391/391 - 24s - loss: 0.1608 - accuracy: 0.9592 - val_loss: 0.4672 - val_accuracy: 0.8996
Epoch 198/350
391/391 - 24s - loss: 0.1698 - accuracy: 0.9556 - val_loss: 0.4499 - val_accuracy: 0.9018
Epoch 199/350
391/391 - 24s - loss: 0.1660 - accuracy: 0.9581 - val_loss: 0.4585 - val_accuracy: 0.9013
Epoch 200/350


Snapshot weight 0 shuffle 0 at epoch 200
Layer 11
Getting activations...


391/391 - 24s - loss: 0.1614 - accuracy: 0.9593 - val_loss: 0.4497 - val_accuracy: 0.9040
Epoch 201/350
391/391 - 24s - loss: 0.1369 - accuracy: 0.9684 - val_loss: 0.4482 - val_accuracy: 0.9083
Epoch 202/350
391/391 - 24s - loss: 0.1303 - accuracy: 0.9701 - val_loss: 0.4553 - val_accuracy: 0.9087
Epoch 203/350
391/391 - 24s - loss: 0.1278 - accuracy: 0.9706 - val_loss: 0.4506 - val_accuracy: 0.9100
Epoch 204/350
391/391 - 24s - loss: 0.1252 - accuracy: 0.9717 - val_loss: 0.4525 - val_accuracy: 0.9092
Epoch 205/350
391/391 - 24s - loss: 0.1219 - accuracy: 0.9735 - val_loss: 0.4652 - val_accuracy: 0.9093
Epoch 206/350
391/391 - 24s - loss: 0.1217 - accuracy: 0.9728 - val_loss: 0.4668 - val_accuracy: 0.9079
Epoch 207/350
391/391 - 24s - loss: 0.1199 - accuracy: 0.9736 - val_loss: 0.4681 - val_accuracy: 0.9077
Epoch 208/350
391/391 - 24s - loss: 0.1170 - accuracy: 0.9753 - val_loss: 0.4625 - val_accuracy: 0.9099
Epoch 209/350
391/391 - 24s - loss: 0.1161 - accuracy: 0.9750 - val_loss: 0.4611 - val_accuracy: 0.9103
Epoch 210/350
391/391 - 24s - loss: 0.1192 - accuracy: 0.9742 - val_loss: 0.4616 - val_accuracy: 0.9106
Epoch 211/350
391/391 - 24s - loss: 0.1171 - accuracy: 0.9749 - val_loss: 0.4626 - val_accuracy: 0.9088
Epoch 212/350
391/391 - 24s - loss: 0.1168 - accuracy: 0.9750 - val_loss: 0.4724 - val_accuracy: 0.9084
Epoch 213/350
391/391 - 24s - loss: 0.1158 - accuracy: 0.9752 - val_loss: 0.4734 - val_accuracy: 0.9087
Epoch 214/350
391/391 - 24s - loss: 0.1125 - accuracy: 0.9767 - val_loss: 0.4697 - val_accuracy: 0.9086
Epoch 215/350
391/391 - 24s - loss: 0.1140 - accuracy: 0.9758 - val_loss: 0.4705 - val_accuracy: 0.9113
Epoch 216/350
391/391 - 24s - loss: 0.1146 - accuracy: 0.9756 - val_loss: 0.4763 - val_accuracy: 0.9106
Epoch 217/350
391/391 - 24s - loss: 0.1144 - accuracy: 0.9758 - val_loss: 0.4883 - val_accuracy: 0.9073
Epoch 218/350
391/391 - 24s - loss: 0.1128 - accuracy: 0.9768 - val_loss: 0.4735 - val_accuracy: 0.9106
Epoch 219/350
391/391 - 24s - loss: 0.1132 - accuracy: 0.9760 - val_loss: 0.4712 - val_accuracy: 0.9106
Epoch 220/350
391/391 - 24s - loss: 0.1124 - accuracy: 0.9757 - val_loss: 0.4838 - val_accuracy: 0.9099
Epoch 221/350
391/391 - 24s - loss: 0.1095 - accuracy: 0.9772 - val_loss: 0.4753 - val_accuracy: 0.9098
Epoch 222/350
391/391 - 24s - loss: 0.1120 - accuracy: 0.9760 - val_loss: 0.4811 - val_accuracy: 0.9085
Epoch 223/350
391/391 - 24s - loss: 0.1111 - accuracy: 0.9767 - val_loss: 0.4723 - val_accuracy: 0.9107
Epoch 224/350
391/391 - 24s - loss: 0.1099 - accuracy: 0.9768 - val_loss: 0.4834 - val_accuracy: 0.9103
Epoch 225/350
391/391 - 24s - loss: 0.1093 - accuracy: 0.9776 - val_loss: 0.4909 - val_accuracy: 0.9091
Epoch 226/350
391/391 - 24s - loss: 0.1120 - accuracy: 0.9769 - val_loss: 0.4867 - val_accuracy: 0.9088
Epoch 227/350
391/391 - 24s - loss: 0.1125 - accuracy: 0.9769 - val_loss: 0.4892 - val_accuracy: 0.9098
Epoch 228/350
391/391 - 24s - loss: 0.1078 - accuracy: 0.9787 - val_loss: 0.4873 - val_accuracy: 0.9098
Epoch 229/350
391/391 - 24s - loss: 0.1079 - accuracy: 0.9784 - val_loss: 0.4835 - val_accuracy: 0.9088
Epoch 230/350
391/391 - 24s - loss: 0.1099 - accuracy: 0.9770 - val_loss: 0.4812 - val_accuracy: 0.9098
Epoch 231/350
391/391 - 24s - loss: 0.1092 - accuracy: 0.9772 - val_loss: 0.4737 - val_accuracy: 0.9103
Epoch 232/350
391/391 - 24s - loss: 0.1104 - accuracy: 0.9774 - val_loss: 0.4825 - val_accuracy: 0.9096
Epoch 233/350
391/391 - 24s - loss: 0.1081 - accuracy: 0.9765 - val_loss: 0.4841 - val_accuracy: 0.9111
Epoch 234/350
391/391 - 24s - loss: 0.1092 - accuracy: 0.9776 - val_loss: 0.4785 - val_accuracy: 0.9088
Epoch 235/350
391/391 - 24s - loss: 0.1087 - accuracy: 0.9777 - val_loss: 0.4851 - val_accuracy: 0.9105
Epoch 236/350
391/391 - 24s - loss: 0.1072 - accuracy: 0.9776 - val_loss: 0.4745 - val_accuracy: 0.9121
Epoch 237/350
391/391 - 24s - loss: 0.1088 - accuracy: 0.9782 - val_loss: 0.4896 - val_accuracy: 0.9108
Epoch 238/350
391/391 - 24s - loss: 0.1093 - accuracy: 0.9780 - val_loss: 0.4748 - val_accuracy: 0.9112
Epoch 239/350
391/391 - 24s - loss: 0.1072 - accuracy: 0.9781 - val_loss: 0.4855 - val_accuracy: 0.9106
Epoch 240/350
391/391 - 24s - loss: 0.1042 - accuracy: 0.9797 - val_loss: 0.4786 - val_accuracy: 0.9112
Epoch 241/350
391/391 - 24s - loss: 0.1093 - accuracy: 0.9770 - val_loss: 0.4821 - val_accuracy: 0.9100
Epoch 242/350
391/391 - 24s - loss: 0.1084 - accuracy: 0.9785 - val_loss: 0.4842 - val_accuracy: 0.9094
Epoch 243/350
391/391 - 24s - loss: 0.1070 - accuracy: 0.9780 - val_loss: 0.4891 - val_accuracy: 0.9095
Epoch 244/350
391/391 - 24s - loss: 0.1081 - accuracy: 0.9790 - val_loss: 0.4817 - val_accuracy: 0.9099
Epoch 245/350
391/391 - 24s - loss: 0.1045 - accuracy: 0.9796 - val_loss: 0.4906 - val_accuracy: 0.9103
Epoch 246/350
391/391 - 24s - loss: 0.1061 - accuracy: 0.9782 - val_loss: 0.4880 - val_accuracy: 0.9099
Epoch 247/350
391/391 - 24s - loss: 0.1043 - accuracy: 0.9799 - val_loss: 0.4847 - val_accuracy: 0.9107
Epoch 248/350
391/391 - 24s - loss: 0.1074 - accuracy: 0.9786 - val_loss: 0.4822 - val_accuracy: 0.9128
Epoch 249/350
391/391 - 24s - loss: 0.1042 - accuracy: 0.9791 - val_loss: 0.4839 - val_accuracy: 0.9124
Epoch 250/350


Snapshot weight 0 shuffle 0 at epoch 250
Layer 11
Getting activations...


391/391 - 24s - loss: 0.1053 - accuracy: 0.9791 - val_loss: 0.4869 - val_accuracy: 0.9124
Epoch 251/350
391/391 - 24s - loss: 0.1022 - accuracy: 0.9807 - val_loss: 0.4849 - val_accuracy: 0.9119
Epoch 252/350
391/391 - 24s - loss: 0.1038 - accuracy: 0.9800 - val_loss: 0.4835 - val_accuracy: 0.9120
Epoch 253/350
391/391 - 24s - loss: 0.1015 - accuracy: 0.9804 - val_loss: 0.4813 - val_accuracy: 0.9116
Epoch 254/350
391/391 - 24s - loss: 0.1025 - accuracy: 0.9806 - val_loss: 0.4808 - val_accuracy: 0.9115
Epoch 255/350
391/391 - 24s - loss: 0.1037 - accuracy: 0.9792 - val_loss: 0.4825 - val_accuracy: 0.9119
Epoch 256/350
391/391 - 24s - loss: 0.1016 - accuracy: 0.9802 - val_loss: 0.4821 - val_accuracy: 0.9123
Epoch 257/350
391/391 - 24s - loss: 0.1020 - accuracy: 0.9802 - val_loss: 0.4845 - val_accuracy: 0.9123
Epoch 258/350
391/391 - 24s - loss: 0.1016 - accuracy: 0.9804 - val_loss: 0.4862 - val_accuracy: 0.9125
Epoch 259/350
391/391 - 24s - loss: 0.0992 - accuracy: 0.9803 - val_loss: 0.4844 - val_accuracy: 0.9126
Epoch 260/350
391/391 - 24s - loss: 0.1038 - accuracy: 0.9792 - val_loss: 0.4836 - val_accuracy: 0.9119
Epoch 261/350
391/391 - 24s - loss: 0.1036 - accuracy: 0.9800 - val_loss: 0.4819 - val_accuracy: 0.9128
Epoch 262/350
391/391 - 24s - loss: 0.0998 - accuracy: 0.9808 - val_loss: 0.4813 - val_accuracy: 0.9130
Epoch 263/350
391/391 - 24s - loss: 0.1031 - accuracy: 0.9801 - val_loss: 0.4842 - val_accuracy: 0.9127
Epoch 264/350
391/391 - 24s - loss: 0.1008 - accuracy: 0.9806 - val_loss: 0.4840 - val_accuracy: 0.9124
Epoch 265/350
391/391 - 24s - loss: 0.1004 - accuracy: 0.9810 - val_loss: 0.4838 - val_accuracy: 0.9123
Epoch 266/350
391/391 - 24s - loss: 0.1008 - accuracy: 0.9809 - val_loss: 0.4843 - val_accuracy: 0.9130
Epoch 267/350
391/391 - 24s - loss: 0.1015 - accuracy: 0.9808 - val_loss: 0.4833 - val_accuracy: 0.9123
Epoch 268/350
391/391 - 24s - loss: 0.1003 - accuracy: 0.9812 - val_loss: 0.4812 - val_accuracy: 0.9128
Epoch 269/350
391/391 - 24s - loss: 0.1031 - accuracy: 0.9793 - val_loss: 0.4838 - val_accuracy: 0.9130
Epoch 270/350
391/391 - 24s - loss: 0.1016 - accuracy: 0.9801 - val_loss: 0.4796 - val_accuracy: 0.9129
Epoch 271/350
391/391 - 24s - loss: 0.0992 - accuracy: 0.9818 - val_loss: 0.4834 - val_accuracy: 0.9128
Epoch 272/350
391/391 - 24s - loss: 0.1000 - accuracy: 0.9806 - val_loss: 0.4825 - val_accuracy: 0.9130
Epoch 273/350
391/391 - 24s - loss: 0.1015 - accuracy: 0.9806 - val_loss: 0.4808 - val_accuracy: 0.9134
Epoch 274/350
391/391 - 24s - loss: 0.1011 - accuracy: 0.9809 - val_loss: 0.4842 - val_accuracy: 0.9126
Epoch 275/350
391/391 - 24s - loss: 0.1023 - accuracy: 0.9801 - val_loss: 0.4819 - val_accuracy: 0.9120
Epoch 276/350
391/391 - 24s - loss: 0.1013 - accuracy: 0.9805 - val_loss: 0.4812 - val_accuracy: 0.9123
Epoch 277/350
391/391 - 24s - loss: 0.0993 - accuracy: 0.9813 - val_loss: 0.4846 - val_accuracy: 0.9127
Epoch 278/350
391/391 - 24s - loss: 0.1001 - accuracy: 0.9807 - val_loss: 0.4851 - val_accuracy: 0.9130
Epoch 279/350
391/391 - 24s - loss: 0.0996 - accuracy: 0.9813 - val_loss: 0.4858 - val_accuracy: 0.9126
Epoch 280/350
391/391 - 24s - loss: 0.1009 - accuracy: 0.9807 - val_loss: 0.4857 - val_accuracy: 0.9118
Epoch 281/350
391/391 - 24s - loss: 0.1015 - accuracy: 0.9803 - val_loss: 0.4853 - val_accuracy: 0.9112
Epoch 282/350
391/391 - 24s - loss: 0.0991 - accuracy: 0.9806 - val_loss: 0.4850 - val_accuracy: 0.9112
Epoch 283/350
391/391 - 24s - loss: 0.0978 - accuracy: 0.9815 - val_loss: 0.4865 - val_accuracy: 0.9116
Epoch 284/350
391/391 - 24s - loss: 0.1023 - accuracy: 0.9799 - val_loss: 0.4870 - val_accuracy: 0.9120
Epoch 285/350
391/391 - 24s - loss: 0.1030 - accuracy: 0.9799 - val_loss: 0.4868 - val_accuracy: 0.9120
Epoch 286/350
391/391 - 24s - loss: 0.1009 - accuracy: 0.9804 - val_loss: 0.4863 - val_accuracy: 0.9121
Epoch 287/350
391/391 - 24s - loss: 0.0992 - accuracy: 0.9804 - val_loss: 0.4863 - val_accuracy: 0.9126
Epoch 288/350
391/391 - 24s - loss: 0.0999 - accuracy: 0.9806 - val_loss: 0.4871 - val_accuracy: 0.9118
Epoch 289/350
391/391 - 24s - loss: 0.1026 - accuracy: 0.9799 - val_loss: 0.4852 - val_accuracy: 0.9116
Epoch 290/350
391/391 - 24s - loss: 0.1016 - accuracy: 0.9798 - val_loss: 0.4862 - val_accuracy: 0.9108
Epoch 291/350
391/391 - 24s - loss: 0.1007 - accuracy: 0.9806 - val_loss: 0.4870 - val_accuracy: 0.9118
Epoch 292/350
391/391 - 24s - loss: 0.0993 - accuracy: 0.9816 - val_loss: 0.4868 - val_accuracy: 0.9118
Epoch 293/350
391/391 - 24s - loss: 0.1020 - accuracy: 0.9799 - val_loss: 0.4875 - val_accuracy: 0.9116
Epoch 294/350
391/391 - 24s - loss: 0.1011 - accuracy: 0.9799 - val_loss: 0.4850 - val_accuracy: 0.9119
Epoch 295/350
391/391 - 24s - loss: 0.0999 - accuracy: 0.9804 - val_loss: 0.4869 - val_accuracy: 0.9121
Epoch 296/350
391/391 - 24s - loss: 0.1023 - accuracy: 0.9802 - val_loss: 0.4867 - val_accuracy: 0.9121
Epoch 297/350
391/391 - 24s - loss: 0.0985 - accuracy: 0.9810 - val_loss: 0.4851 - val_accuracy: 0.9122
Epoch 298/350
391/391 - 24s - loss: 0.1008 - accuracy: 0.9810 - val_loss: 0.4858 - val_accuracy: 0.9119
Epoch 299/350
391/391 - 24s - loss: 0.1005 - accuracy: 0.9801 - val_loss: 0.4866 - val_accuracy: 0.9122
Epoch 300/350


Snapshot weight 0 shuffle 0 at epoch 300
Layer 11
Getting activations...


391/391 - 24s - loss: 0.1019 - accuracy: 0.9800 - val_loss: 0.4877 - val_accuracy: 0.9113
Epoch 301/350
391/391 - 24s - loss: 0.1005 - accuracy: 0.9809 - val_loss: 0.4875 - val_accuracy: 0.9116
Epoch 302/350
391/391 - 24s - loss: 0.1021 - accuracy: 0.9802 - val_loss: 0.4870 - val_accuracy: 0.9119
Epoch 303/350
391/391 - 24s - loss: 0.1014 - accuracy: 0.9806 - val_loss: 0.4872 - val_accuracy: 0.9120
Epoch 304/350
391/391 - 24s - loss: 0.0983 - accuracy: 0.9814 - val_loss: 0.4871 - val_accuracy: 0.9119
Epoch 305/350
391/391 - 24s - loss: 0.1006 - accuracy: 0.9798 - val_loss: 0.4870 - val_accuracy: 0.9121
Epoch 306/350
391/391 - 24s - loss: 0.0987 - accuracy: 0.9809 - val_loss: 0.4870 - val_accuracy: 0.9120
Epoch 307/350
391/391 - 24s - loss: 0.1002 - accuracy: 0.9811 - val_loss: 0.4867 - val_accuracy: 0.9122
Epoch 308/350
391/391 - 24s - loss: 0.1005 - accuracy: 0.9811 - val_loss: 0.4868 - val_accuracy: 0.9122
Epoch 309/350
391/391 - 24s - loss: 0.1001 - accuracy: 0.9814 - val_loss: 0.4867 - val_accuracy: 0.9122
Epoch 310/350
391/391 - 24s - loss: 0.0998 - accuracy: 0.9813 - val_loss: 0.4868 - val_accuracy: 0.9120
Epoch 311/350
391/391 - 24s - loss: 0.0990 - accuracy: 0.9811 - val_loss: 0.4868 - val_accuracy: 0.9123
Epoch 312/350
391/391 - 24s - loss: 0.0992 - accuracy: 0.9818 - val_loss: 0.4868 - val_accuracy: 0.9122
Epoch 313/350
391/391 - 24s - loss: 0.1008 - accuracy: 0.9803 - val_loss: 0.4871 - val_accuracy: 0.9123
Epoch 314/350
391/391 - 24s - loss: 0.1005 - accuracy: 0.9811 - val_loss: 0.4869 - val_accuracy: 0.9120
Epoch 315/350
391/391 - 24s - loss: 0.0988 - accuracy: 0.9814 - val_loss: 0.4869 - val_accuracy: 0.9122
Epoch 316/350
391/391 - 24s - loss: 0.1010 - accuracy: 0.9801 - val_loss: 0.4867 - val_accuracy: 0.9122
Epoch 317/350
391/391 - 24s - loss: 0.1008 - accuracy: 0.9804 - val_loss: 0.4867 - val_accuracy: 0.9122
Epoch 318/350
391/391 - 24s - loss: 0.0995 - accuracy: 0.9811 - val_loss: 0.4870 - val_accuracy: 0.9122
Epoch 319/350
391/391 - 24s - loss: 0.0992 - accuracy: 0.9819 - val_loss: 0.4865 - val_accuracy: 0.9121
Epoch 320/350
391/391 - 24s - loss: 0.0993 - accuracy: 0.9808 - val_loss: 0.4867 - val_accuracy: 0.9123
Epoch 321/350
391/391 - 24s - loss: 0.0985 - accuracy: 0.9817 - val_loss: 0.4866 - val_accuracy: 0.9123
Epoch 322/350
391/391 - 24s - loss: 0.1020 - accuracy: 0.9799 - val_loss: 0.4868 - val_accuracy: 0.9121
Epoch 323/350
391/391 - 24s - loss: 0.0989 - accuracy: 0.9814 - val_loss: 0.4865 - val_accuracy: 0.9121
Epoch 324/350
391/391 - 24s - loss: 0.0978 - accuracy: 0.9814 - val_loss: 0.4865 - val_accuracy: 0.9122
Epoch 325/350
391/391 - 24s - loss: 0.0989 - accuracy: 0.9810 - val_loss: 0.4868 - val_accuracy: 0.9123
Epoch 326/350
391/391 - 24s - loss: 0.1008 - accuracy: 0.9810 - val_loss: 0.4870 - val_accuracy: 0.9123
Epoch 327/350
391/391 - 24s - loss: 0.0984 - accuracy: 0.9820 - val_loss: 0.4872 - val_accuracy: 0.9122
Epoch 328/350
391/391 - 24s - loss: 0.0976 - accuracy: 0.9811 - val_loss: 0.4872 - val_accuracy: 0.9122
Epoch 329/350
391/391 - 24s - loss: 0.0999 - accuracy: 0.9807 - val_loss: 0.4870 - val_accuracy: 0.9119
Epoch 330/350
391/391 - 24s - loss: 0.1006 - accuracy: 0.9810 - val_loss: 0.4868 - val_accuracy: 0.9121
Epoch 331/350
391/391 - 24s - loss: 0.1015 - accuracy: 0.9805 - val_loss: 0.4868 - val_accuracy: 0.9119
Epoch 332/350
391/391 - 24s - loss: 0.1007 - accuracy: 0.9811 - val_loss: 0.4869 - val_accuracy: 0.9120
Epoch 333/350
391/391 - 24s - loss: 0.1029 - accuracy: 0.9799 - val_loss: 0.4870 - val_accuracy: 0.9119
Epoch 334/350
391/391 - 24s - loss: 0.0996 - accuracy: 0.9807 - val_loss: 0.4868 - val_accuracy: 0.9120
Epoch 335/350
391/391 - 24s - loss: 0.0974 - accuracy: 0.9826 - val_loss: 0.4870 - val_accuracy: 0.9120
Epoch 336/350
391/391 - 24s - loss: 0.1020 - accuracy: 0.9806 - val_loss: 0.4875 - val_accuracy: 0.9123
Epoch 337/350
391/391 - 24s - loss: 0.1004 - accuracy: 0.9807 - val_loss: 0.4873 - val_accuracy: 0.9125
Epoch 338/350
391/391 - 24s - loss: 0.0979 - accuracy: 0.9814 - val_loss: 0.4872 - val_accuracy: 0.9123
Epoch 339/350
391/391 - 24s - loss: 0.0999 - accuracy: 0.9811 - val_loss: 0.4868 - val_accuracy: 0.9126
Epoch 340/350
391/391 - 24s - loss: 0.0978 - accuracy: 0.9815 - val_loss: 0.4869 - val_accuracy: 0.9119
Epoch 341/350
391/391 - 24s - loss: 0.0999 - accuracy: 0.9811 - val_loss: 0.4866 - val_accuracy: 0.9121
Epoch 342/350
391/391 - 24s - loss: 0.0991 - accuracy: 0.9808 - val_loss: 0.4871 - val_accuracy: 0.9119
Epoch 343/350
391/391 - 24s - loss: 0.0993 - accuracy: 0.9813 - val_loss: 0.4872 - val_accuracy: 0.9120
Epoch 344/350
391/391 - 24s - loss: 0.1004 - accuracy: 0.9806 - val_loss: 0.4867 - val_accuracy: 0.9120
Epoch 345/350
391/391 - 24s - loss: 0.0971 - accuracy: 0.9817 - val_loss: 0.4870 - val_accuracy: 0.9122
Epoch 346/350
391/391 - 24s - loss: 0.0990 - accuracy: 0.9816 - val_loss: 0.4871 - val_accuracy: 0.9121
Epoch 347/350
391/391 - 24s - loss: 0.0992 - accuracy: 0.9816 - val_loss: 0.4874 - val_accuracy: 0.9121
Epoch 348/350
391/391 - 24s - loss: 0.1004 - accuracy: 0.9799 - val_loss: 0.4874 - val_accuracy: 0.9121
Epoch 349/350
391/391 - 24s - loss: 0.0975 - accuracy: 0.9818 - val_loss: 0.4876 - val_accuracy: 0.9121
Epoch 350/350


Snapshot weight 0 shuffle 0 at epoch 350
Layer 11
Getting activations...


391/391 - 24s - loss: 0.1004 - accuracy: 0.9809 - val_loss: 0.4872 - val_accuracy: 0.9120
/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:493: UserWarning: fill_value is not supported and is always 0 for TensorFlow < 2.4.0.
  return py_builtins.overload_of(f)(*args)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-07-01 18:38:40.940453: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
Saving, final validation acc: 0.9120000004768372
