2021-07-05 01:02:28.489254: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
Loading dataset
dataset shape: (1000, 32, 32, 3)
2021-07-05 01:02:30.984540: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-07-05 01:02:31.015899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:82:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2021-07-05 01:02:31.016000: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-05 01:02:31.057934: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-05 01:02:31.079382: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-05 01:02:31.088182: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-05 01:02:31.133133: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-05 01:02:31.142025: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-05 01:02:31.219109: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-05 01:02:31.221600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-05 01:02:31.221981: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-05 01:02:31.237639: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600075000 Hz
2021-07-05 01:02:31.237817: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x62b7c50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-07-05 01:02:31.237840: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-07-05 01:02:31.361702: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x632faf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-07-05 01:02:31.361785: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN Xp, Compute Capability 6.1
2021-07-05 01:02:31.364393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:82:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2021-07-05 01:02:31.364482: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-05 01:02:31.364521: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-05 01:02:31.364546: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-05 01:02:31.364570: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-05 01:02:31.364594: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-05 01:02:31.364617: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-05 01:02:31.365412: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-05 01:02:31.367107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-05 01:02:31.368877: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-05 01:02:33.118000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-05 01:02:33.118107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-07-05 01:02:33.118123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-07-05 01:02:33.122381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11218 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:82:00.0, compute capability: 6.1)
Model loaded: w0s0.pb
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 32, 32, 96)        2688      
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 32, 32, 96)        83040     
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 16, 16, 96)        83040     
_________________________________________________________________
dropout (Dropout)            (None, 16, 16, 96)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 16, 16, 192)       166080    
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 16, 16, 192)       331968    
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 8, 8, 192)         331968    
_________________________________________________________________
dropout_1 (Dropout)          (None, 8, 8, 192)         0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 6, 6, 192)         331968    
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 6, 6, 192)         37056     
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 6, 6, 10)          1930      
_________________________________________________________________
global_average_pooling2d (Gl (None, 10)                0         
_________________________________________________________________
activation (Activation)      (None, 10)                0         
=================================================================
Total params: 1,369,738
Trainable params: 1,369,738
Non-trainable params: 0
_________________________________________________________________
Performing correspondence analysis.
Working on model: w0s5.pb
2021-07-05 01:02:36.307051: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-05 01:02:38.707932: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
Layer 0 winners {'do_rsa': [0, 0.9915349354310014], 'do_pwcca': [0, 0.985531704608886], 'do_linearCKA': [0, 0.9991137986612718]}
Layer 1 winners {'do_rsa': [1, 0.8475171628672828], 'do_pwcca': [1, 0.9054650182593817], 'do_linearCKA': [1, 0.9891006142063892]}
Layer 2 winners {'do_rsa': [2, 0.8789471971117561], 'do_pwcca': [3, 0.9252096744526965], 'do_linearCKA': [2, 0.9766714539494328]}
Layer 3 winners {'do_rsa': [3, 0.8529935884922226], 'do_pwcca': [0, 0.941378061908523], 'do_linearCKA': [3, 0.9682641390834812]}
Layer 4 winners {'do_rsa': [4, 0.8326570996411566], 'do_pwcca': [0, 0.9254570302760148], 'do_linearCKA': [4, 0.9568667556462406]}
Layer 5 winners {'do_rsa': [5, 0.774051602399571], 'do_pwcca': [0, 0.9002841623308885], 'do_linearCKA': [5, 0.9331589665527115]}
Layer 6 winners {'do_rsa': [6, 0.7259024189800941], 'do_pwcca': [9, 0.9441813793727323], 'do_linearCKA': [6, 0.9202967543875804]}
Layer 7 winners {'do_rsa': [7, 0.6403408556022991], 'do_pwcca': [9, 0.9610191111971782], 'do_linearCKA': [7, 0.9173248956967076]}
Layer 8 winners {'do_rsa': [8, 0.7993702173101381], 'do_pwcca': [7, 0.9585401155186319], 'do_linearCKA': [8, 0.9232670270844953]}
Layer 9 winners {'do_rsa': [9, 0.9013267132701956], 'do_pwcca': [7, 0.9585401174807663], 'do_linearCKA': [9, 0.9454248584378887]}
Layer 10 winners {'do_rsa': [10, 0.5697924324540725], 'do_pwcca': [10, 0.8282502055218665], 'do_linearCKA': [10, 0.8666561365474728]}
--- 1307.2570679187775 seconds ---
Working on model: w2s2.pb
Layer 0 winners {'do_rsa': [0, 0.9807437856920894], 'do_pwcca': [0, 0.9740904573425813], 'do_linearCKA': [0, 0.998284703547887]}
Layer 1 winners {'do_rsa': [1, 0.824857849716862], 'do_pwcca': [3, 0.9077592571556927], 'do_linearCKA': [1, 0.9876867375295141]}
Layer 2 winners {'do_rsa': [2, 0.8610731190034919], 'do_pwcca': [3, 0.9255878202791394], 'do_linearCKA': [2, 0.9718009002058623]}
Layer 3 winners {'do_rsa': [3, 0.8445408543888702], 'do_pwcca': [0, 0.937270651441332], 'do_linearCKA': [3, 0.9686313610371957]}
Layer 4 winners {'do_rsa': [4, 0.8237340850359343], 'do_pwcca': [0, 0.9185507404308718], 'do_linearCKA': [4, 0.9569187593424976]}
Layer 5 winners {'do_rsa': [5, 0.7658237085299492], 'do_pwcca': [0, 0.9030457252235043], 'do_linearCKA': [5, 0.9347015807083008]}
Layer 6 winners {'do_rsa': [6, 0.7238975639146747], 'do_pwcca': [9, 0.9491596914890302], 'do_linearCKA': [6, 0.9208085125414105]}
Layer 7 winners {'do_rsa': [7, 0.6369178909707817], 'do_pwcca': [9, 0.9592730675542572], 'do_linearCKA': [7, 0.9189458732985312]}
Layer 8 winners {'do_rsa': [8, 0.7890278899271972], 'do_pwcca': [7, 0.9582474678606908], 'do_linearCKA': [8, 0.9181102416983731]}
Layer 9 winners {'do_rsa': [9, 0.8980843254808039], 'do_pwcca': [7, 0.9582474681830341], 'do_linearCKA': [9, 0.9411009704088513]}
Layer 10 winners {'do_rsa': [10, 0.5660962266461699], 'do_pwcca': [10, 0.8449599051697001], 'do_linearCKA': [10, 0.8939578588043684]}
--- 1302.1818125247955 seconds ---
Working on model: w2s7.pb
Layer 0 winners {'do_rsa': [0, 0.9800159582569589], 'do_pwcca': [0, 0.9734784629624625], 'do_linearCKA': [0, 0.9985396233080476]}
Layer 1 winners {'do_rsa': [1, 0.8394418337297486], 'do_pwcca': [3, 0.9071883534813685], 'do_linearCKA': [1, 0.9863386782605743]}
Layer 2 winners {'do_rsa': [2, 0.8701209662603915], 'do_pwcca': [3, 0.924933267469123], 'do_linearCKA': [2, 0.9739593509788477]}
Layer 3 winners {'do_rsa': [3, 0.8457871584157238], 'do_pwcca': [0, 0.9369462829048316], 'do_linearCKA': [3, 0.9653771338833489]}
Layer 4 winners {'do_rsa': [4, 0.8164864574197178], 'do_pwcca': [0, 0.9192890342202372], 'do_linearCKA': [4, 0.9534858525998262]}
Layer 5 winners {'do_rsa': [5, 0.7646604780406068], 'do_pwcca': [0, 0.9049838238890439], 'do_linearCKA': [5, 0.9335044368780091]}
Layer 6 winners {'do_rsa': [6, 0.7108327577761547], 'do_pwcca': [9, 0.949162896169046], 'do_linearCKA': [6, 0.9174657966628698]}
Layer 7 winners {'do_rsa': [7, 0.6168516365558464], 'do_pwcca': [9, 0.9620805262743263], 'do_linearCKA': [7, 0.9166801871445255]}
Layer 8 winners {'do_rsa': [8, 0.7857218130614624], 'do_pwcca': [7, 0.959255018390166], 'do_linearCKA': [8, 0.9170990305608504]}
Layer 9 winners {'do_rsa': [9, 0.8857100651192908], 'do_pwcca': [7, 0.9592550178843833], 'do_linearCKA': [9, 0.9368301720535115]}
Layer 10 winners {'do_rsa': [10, 0.57743753491363], 'do_pwcca': [10, 0.8440836040226294], 'do_linearCKA': [10, 0.8934074868490743]}
--- 1305.3959937095642 seconds ---
Working on model: w4s4.pb
Layer 0 winners {'do_rsa': [0, 0.9812955551782904], 'do_pwcca': [0, 0.9738020437161476], 'do_linearCKA': [0, 0.9984032857731193]}
Layer 1 winners {'do_rsa': [1, 0.8208419555996217], 'do_pwcca': [3, 0.909355588978647], 'do_linearCKA': [1, 0.9866673267569336]}
Layer 2 winners {'do_rsa': [2, 0.8733896038915215], 'do_pwcca': [3, 0.9262592047023348], 'do_linearCKA': [2, 0.9727343493511653]}
Layer 3 winners {'do_rsa': [3, 0.8439303694620408], 'do_pwcca': [0, 0.9391906884894731], 'do_linearCKA': [3, 0.9674279258003325]}
Layer 4 winners {'do_rsa': [4, 0.8321401594373149], 'do_pwcca': [0, 0.9242640964883209], 'do_linearCKA': [4, 0.9556456832054511]}
Layer 5 winners {'do_rsa': [5, 0.7806900475988492], 'do_pwcca': [0, 0.8962480069425438], 'do_linearCKA': [5, 0.9346119036627202]}
Layer 6 winners {'do_rsa': [6, 0.7157843363033706], 'do_pwcca': [9, 0.9499189397705883], 'do_linearCKA': [6, 0.9128761101429881]}
Layer 7 winners {'do_rsa': [7, 0.6240790994592699], 'do_pwcca': [9, 0.9607199209878471], 'do_linearCKA': [7, 0.9121230812784104]}
Layer 8 winners {'do_rsa': [8, 0.7829299902503799], 'do_pwcca': [7, 0.9561947040004428], 'do_linearCKA': [8, 0.9003940129463975]}
Layer 9 winners {'do_rsa': [9, 0.8985046777895178], 'do_pwcca': [7, 0.9561947066101553], 'do_linearCKA': [9, 0.9356406557473532]}
Layer 10 winners {'do_rsa': [10, 0.563364608646842], 'do_pwcca': [10, 0.8449176214592976], 'do_linearCKA': [10, 0.8924141138352694]}
--- 1311.3016374111176 seconds ---
Working on model: w6s1.pb
Layer 0 winners {'do_rsa': [0, 0.9732117957984592], 'do_pwcca': [0, 0.973389893390171], 'do_linearCKA': [0, 0.9976862153901418]}
Layer 1 winners {'do_rsa': [1, 0.8383068068620865], 'do_pwcca': [3, 0.9041915805700176], 'do_linearCKA': [1, 0.9841263282448657]}
Layer 2 winners {'do_rsa': [2, 0.8625691910630707], 'do_pwcca': [3, 0.9228235015952554], 'do_linearCKA': [2, 0.9707668670334473]}
Layer 3 winners {'do_rsa': [3, 0.8361076679694569], 'do_pwcca': [0, 0.9414124217960119], 'do_linearCKA': [3, 0.962231664699954]}
Layer 4 winners {'do_rsa': [4, 0.7870773871827695], 'do_pwcca': [0, 0.9236113429296493], 'do_linearCKA': [4, 0.9491302166939685]}
Layer 5 winners {'do_rsa': [5, 0.7316117558024209], 'do_pwcca': [0, 0.9089406925581034], 'do_linearCKA': [5, 0.9230037383545927]}
Layer 6 winners {'do_rsa': [6, 0.688275078937592], 'do_pwcca': [9, 0.9405040892461889], 'do_linearCKA': [6, 0.8992210869324433]}
Layer 7 winners {'do_rsa': [7, 0.6038318968406775], 'do_pwcca': [8, 0.9589140390758408], 'do_linearCKA': [7, 0.9073795713642175]}
Layer 8 winners {'do_rsa': [8, 0.7939772959118683], 'do_pwcca': [7, 0.9583076478163051], 'do_linearCKA': [8, 0.916825824882833]}
Layer 9 winners {'do_rsa': [9, 0.8995580385119784], 'do_pwcca': [7, 0.9583076475338331], 'do_linearCKA': [9, 0.9380228401834675]}
Layer 10 winners {'do_rsa': [10, 0.5875323506257875], 'do_pwcca': [10, 0.8444347941013477], 'do_linearCKA': [10, 0.8807439115799031]}
--- 1308.6077318191528 seconds ---
Working on model: w4s9.pb
Layer 0 winners {'do_rsa': [0, 0.9816017779665888], 'do_pwcca': [0, 0.9732602939712153], 'do_linearCKA': [0, 0.9984658580761346]}
Layer 1 winners {'do_rsa': [1, 0.7817392156429211], 'do_pwcca': [3, 0.9039585898248976], 'do_linearCKA': [1, 0.9839220311531617]}
Layer 2 winners {'do_rsa': [2, 0.8714519409648835], 'do_pwcca': [3, 0.9248093389474813], 'do_linearCKA': [2, 0.9724730535668322]}
Layer 3 winners {'do_rsa': [3, 0.8515288995978987], 'do_pwcca': [0, 0.9399163820046542], 'do_linearCKA': [3, 0.9667587021198729]}
Layer 4 winners {'do_rsa': [4, 0.8370794596896536], 'do_pwcca': [0, 0.9252098187662819], 'do_linearCKA': [4, 0.9554304847727478]}
Layer 5 winners {'do_rsa': [5, 0.7802624247742065], 'do_pwcca': [0, 0.9042413102112066], 'do_linearCKA': [5, 0.9328406391525541]}
Layer 6 winners {'do_rsa': [6, 0.7258233811531366], 'do_pwcca': [8, 0.9503009342036061], 'do_linearCKA': [6, 0.9204734651887938]}
Layer 7 winners {'do_rsa': [7, 0.6176946465609143], 'do_pwcca': [9, 0.9627261271488816], 'do_linearCKA': [7, 0.9146030488864431]}
Layer 8 winners {'do_rsa': [8, 0.7963905218424004], 'do_pwcca': [7, 0.9590053275947948], 'do_linearCKA': [8, 0.9201641772000801]}
Layer 9 winners {'do_rsa': [9, 0.894432235610832], 'do_pwcca': [7, 0.959005324691925], 'do_linearCKA': [9, 0.9420797943026837]}
Layer 10 winners {'do_rsa': [10, 0.5810121774762276], 'do_pwcca': [10, 0.8398855888053128], 'do_linearCKA': [10, 0.8853730432059427]}
--- 1306.4297244548798 seconds ---
Working on model: w6s6.pb
Layer 0 winners {'do_rsa': [0, 0.977767258410664], 'do_pwcca': [0, 0.9733092595394733], 'do_linearCKA': [0, 0.9979310408611404]}
Layer 1 winners {'do_rsa': [1, 0.8034504292656448], 'do_pwcca': [3, 0.9065060333552266], 'do_linearCKA': [1, 0.9864682650559758]}
Layer 2 winners {'do_rsa': [2, 0.8643267201779671], 'do_pwcca': [3, 0.9250939822064632], 'do_linearCKA': [2, 0.9715658075223648]}
Layer 3 winners {'do_rsa': [3, 0.8377928093093817], 'do_pwcca': [0, 0.9376517826645275], 'do_linearCKA': [3, 0.9674222154696089]}
Layer 4 winners {'do_rsa': [4, 0.8200253694366274], 'do_pwcca': [0, 0.9185007036596375], 'do_linearCKA': [4, 0.9534924952547463]}
Layer 5 winners {'do_rsa': [5, 0.7718317952641184], 'do_pwcca': [0, 0.9023643291065292], 'do_linearCKA': [5, 0.930618347378143]}
Layer 6 winners {'do_rsa': [6, 0.7155588039128752], 'do_pwcca': [9, 0.9481621288412213], 'do_linearCKA': [6, 0.9147282032141983]}
Layer 7 winners {'do_rsa': [7, 0.6158178819428148], 'do_pwcca': [9, 0.9602995262272592], 'do_linearCKA': [7, 0.9102959723284811]}
Layer 8 winners {'do_rsa': [8, 0.7938001600500022], 'do_pwcca': [7, 0.9616366044149689], 'do_linearCKA': [8, 0.9170842592554584]}
Layer 9 winners {'do_rsa': [9, 0.8939690063060892], 'do_pwcca': [7, 0.9616366055799477], 'do_linearCKA': [9, 0.940397447513797]}
Layer 10 winners {'do_rsa': [10, 0.5489254776236877], 'do_pwcca': [10, 0.8441436121026161], 'do_linearCKA': [10, 0.8750159029091882]}
--- 1304.9060838222504 seconds ---
Working on model: w8s3.pb
Layer 0 winners {'do_rsa': [0, 0.9818509217414786], 'do_pwcca': [0, 0.9735472815131312], 'do_linearCKA': [0, 0.9985031543554215]}
Layer 1 winners {'do_rsa': [1, 0.8075128806147701], 'do_pwcca': [3, 0.9069749523893068], 'do_linearCKA': [1, 0.9859712497966683]}
Layer 2 winners {'do_rsa': [2, 0.8535425884353375], 'do_pwcca': [3, 0.9227800951354447], 'do_linearCKA': [2, 0.9704444129588523]}
Layer 3 winners {'do_rsa': [3, 0.8316853942789407], 'do_pwcca': [0, 0.9406540020759877], 'do_linearCKA': [3, 0.9667796993548647]}
Layer 4 winners {'do_rsa': [4, 0.8296342046730024], 'do_pwcca': [0, 0.920123596181067], 'do_linearCKA': [4, 0.955768365476782]}
Layer 5 winners {'do_rsa': [5, 0.7760351704219773], 'do_pwcca': [0, 0.8988955272829234], 'do_linearCKA': [5, 0.9331125162002737]}
Layer 6 winners {'do_rsa': [6, 0.7217474751820125], 'do_pwcca': [8, 0.9447683417354116], 'do_linearCKA': [6, 0.9057452208618163]}
Layer 7 winners {'do_rsa': [7, 0.61441739858649], 'do_pwcca': [8, 0.9553439402106946], 'do_linearCKA': [7, 0.9089547003727803]}
Layer 8 winners {'do_rsa': [8, 0.7913243831412181], 'do_pwcca': [7, 0.9563189766060288], 'do_linearCKA': [8, 0.9117099152872614]}
Layer 9 winners {'do_rsa': [9, 0.8926363312522944], 'do_pwcca': [7, 0.9563189773868267], 'do_linearCKA': [9, 0.9367452439611312]}
Layer 10 winners {'do_rsa': [10, 0.5553241212808614], 'do_pwcca': [10, 0.83660211306908], 'do_linearCKA': [10, 0.8822058244516849]}
--- 1307.445494890213 seconds ---
Working on model: w8s8.pb
Layer 0 winners {'do_rsa': [0, 0.9789542620978792], 'do_pwcca': [0, 0.9740228842097272], 'do_linearCKA': [0, 0.9985545721176716]}
Layer 1 winners {'do_rsa': [1, 0.7922804547752235], 'do_pwcca': [3, 0.9046831069001884], 'do_linearCKA': [1, 0.985797750202371]}
Layer 2 winners {'do_rsa': [2, 0.858088152170476], 'do_pwcca': [3, 0.925460965567418], 'do_linearCKA': [2, 0.9715085993229222]}
Layer 3 winners {'do_rsa': [3, 0.8192612767981294], 'do_pwcca': [0, 0.94228761526714], 'do_linearCKA': [3, 0.9641505898166276]}
Layer 4 winners {'do_rsa': [4, 0.8203015839482392], 'do_pwcca': [0, 0.9199382510150524], 'do_linearCKA': [4, 0.954549580032754]}
Layer 5 winners {'do_rsa': [5, 0.7761947727612586], 'do_pwcca': [8, 0.9051354665069904], 'do_linearCKA': [5, 0.9345650801176763]}
Layer 6 winners {'do_rsa': [6, 0.7026908739607998], 'do_pwcca': [8, 0.9498642286515466], 'do_linearCKA': [6, 0.9125767365606611]}
Layer 7 winners {'do_rsa': [7, 0.620964497869063], 'do_pwcca': [9, 0.9572526023993784], 'do_linearCKA': [7, 0.9111587254473219]}
Layer 8 winners {'do_rsa': [8, 0.7872905532982961], 'do_pwcca': [7, 0.9561203053824029], 'do_linearCKA': [8, 0.9133842523176826]}
Layer 9 winners {'do_rsa': [9, 0.8882002086085349], 'do_pwcca': [7, 0.956120306370789], 'do_linearCKA': [9, 0.9403175244078501]}
Layer 10 winners {'do_rsa': [10, 0.5499347818834819], 'do_pwcca': [10, 0.846307933457511], 'do_linearCKA': [10, 0.8922748730189531]}
--- 1302.3414056301117 seconds ---
Working on model: w1s4.pb
Layer 0 winners {'do_rsa': [0, 0.9722289756339985], 'do_pwcca': [0, 0.9733411917463561], 'do_linearCKA': [0, 0.9983701866510933]}
Layer 1 winners {'do_rsa': [1, 0.8107775439914112], 'do_pwcca': [3, 0.9035646440347407], 'do_linearCKA': [1, 0.9820510772334422]}
Layer 2 winners {'do_rsa': [2, 0.8664622499847238], 'do_pwcca': [3, 0.9225333599120126], 'do_linearCKA': [2, 0.9717059370484648]}
Layer 3 winners {'do_rsa': [3, 0.8182571416143399], 'do_pwcca': [0, 0.941281057580809], 'do_linearCKA': [3, 0.965342782340449]}
Layer 4 winners {'do_rsa': [4, 0.8017956534510507], 'do_pwcca': [0, 0.9262122246680433], 'do_linearCKA': [4, 0.9492514762383095]}
Layer 5 winners {'do_rsa': [5, 0.7316577443682935], 'do_pwcca': [0, 0.8999685688345342], 'do_linearCKA': [5, 0.9279169193280078]}
Layer 6 winners {'do_rsa': [6, 0.6852380246579785], 'do_pwcca': [9, 0.9486247096611958], 'do_linearCKA': [6, 0.9082596165622387]}
Layer 7 winners {'do_rsa': [7, 0.6011524812187333], 'do_pwcca': [9, 0.9582747048520025], 'do_linearCKA': [7, 0.9141217002383693]}
Layer 8 winners {'do_rsa': [8, 0.778650326907501], 'do_pwcca': [7, 0.9572085751542186], 'do_linearCKA': [8, 0.9202291160762022]}
Layer 9 winners {'do_rsa': [9, 0.889563326161845], 'do_pwcca': [7, 0.9572085752520797], 'do_linearCKA': [9, 0.9395979893984846]}
Layer 10 winners {'do_rsa': [10, 0.5707355586760412], 'do_pwcca': [10, 0.831737187346833], 'do_linearCKA': [10, 0.8743054191712317]}
--- 1308.28346824646 seconds ---
Working on model: w3s1.pb
Layer 0 winners {'do_rsa': [0, 0.9792346741087117], 'do_pwcca': [0, 0.9740718565036852], 'do_linearCKA': [0, 0.9985612119284312]}
Layer 1 winners {'do_rsa': [1, 0.8159525127322838], 'do_pwcca': [3, 0.9043015564458841], 'do_linearCKA': [1, 0.9867946797316893]}
Layer 2 winners {'do_rsa': [2, 0.8653060678347191], 'do_pwcca': [3, 0.9246085370462526], 'do_linearCKA': [2, 0.9719716771992386]}
Layer 3 winners {'do_rsa': [3, 0.8510793865583496], 'do_pwcca': [0, 0.9409058369389206], 'do_linearCKA': [3, 0.9658939110297224]}
Layer 4 winners {'do_rsa': [4, 0.8262478893293548], 'do_pwcca': [0, 0.9260481680086265], 'do_linearCKA': [4, 0.9568427953570445]}
Layer 5 winners {'do_rsa': [5, 0.7728771521005905], 'do_pwcca': [0, 0.9003003113730552], 'do_linearCKA': [5, 0.9341350954538201]}
Layer 6 winners {'do_rsa': [6, 0.7153636175990985], 'do_pwcca': [8, 0.9489501961092055], 'do_linearCKA': [6, 0.9152623174709296]}
Layer 7 winners {'do_rsa': [7, 0.6289049992337946], 'do_pwcca': [8, 0.9547146482456264], 'do_linearCKA': [7, 0.9177065727226075]}
Layer 8 winners {'do_rsa': [8, 0.795077478596739], 'do_pwcca': [7, 0.9604323726749749], 'do_linearCKA': [8, 0.922035274828549]}
Layer 9 winners {'do_rsa': [9, 0.8964394552318317], 'do_pwcca': [7, 0.9604323719766321], 'do_linearCKA': [9, 0.9397239605444399]}
Layer 10 winners {'do_rsa': [10, 0.5547872739478326], 'do_pwcca': [10, 0.8436243284548509], 'do_linearCKA': [10, 0.882899803295629]}
--- 1303.208610534668 seconds ---
Working on model: w1s9.pb
Layer 0 winners {'do_rsa': [0, 0.9761351861231925], 'do_pwcca': [0, 0.9738759162552302], 'do_linearCKA': [0, 0.9980956495653592]}
Layer 1 winners {'do_rsa': [1, 0.801407491651357], 'do_pwcca': [3, 0.8991957063550314], 'do_linearCKA': [1, 0.9772414634157164]}
Layer 2 winners {'do_rsa': [2, 0.841453215074283], 'do_pwcca': [3, 0.9190500417730323], 'do_linearCKA': [2, 0.9601194661389149]}
Layer 3 winners {'do_rsa': [2, 0.8075407245880267], 'do_pwcca': [0, 0.9420762343795123], 'do_linearCKA': [3, 0.953809393856642]}
Layer 4 winners {'do_rsa': [4, 0.7756297592941775], 'do_pwcca': [0, 0.9202688581543012], 'do_linearCKA': [4, 0.9393290414110674]}
Layer 5 winners {'do_rsa': [4, 0.6995993979019696], 'do_pwcca': [0, 0.9064125549494311], 'do_linearCKA': [5, 0.9120460029682862]}
Layer 6 winners {'do_rsa': [6, 0.644914168157042], 'do_pwcca': [8, 0.938289128982688], 'do_linearCKA': [6, 0.878950080881974]}
Layer 7 winners {'do_rsa': [7, 0.5922682752789713], 'do_pwcca': [8, 0.9534616431423018], 'do_linearCKA': [7, 0.9010525883108392]}
Layer 8 winners {'do_rsa': [8, 0.7847084195486953], 'do_pwcca': [7, 0.951296921475345], 'do_linearCKA': [8, 0.9147927215006657]}
Layer 9 winners {'do_rsa': [9, 0.8901763958262774], 'do_pwcca': [7, 0.9512969203251744], 'do_linearCKA': [9, 0.9341200371036514]}
Layer 10 winners {'do_rsa': [10, 0.5520201349473558], 'do_pwcca': [10, 0.8384312470792374], 'do_linearCKA': [10, 0.8834461257397659]}
--- 1294.267077445984 seconds ---
Working on model: w3s6.pb
Layer 0 winners {'do_rsa': [0, 0.979916739820597], 'do_pwcca': [0, 0.9735397110980475], 'do_linearCKA': [0, 0.9985319627240143]}
Layer 1 winners {'do_rsa': [1, 0.8315326273461899], 'do_pwcca': [3, 0.9043525676470858], 'do_linearCKA': [1, 0.9876202532284227]}
Layer 2 winners {'do_rsa': [2, 0.8777145012141424], 'do_pwcca': [3, 0.9232921191969545], 'do_linearCKA': [2, 0.97454863821204]}
Layer 3 winners {'do_rsa': [3, 0.8396243894995156], 'do_pwcca': [0, 0.941260846040782], 'do_linearCKA': [3, 0.9676953098844678]}
Layer 4 winners {'do_rsa': [4, 0.8208503830364818], 'do_pwcca': [0, 0.9190062649242406], 'do_linearCKA': [4, 0.9554997516633887]}
Layer 5 winners {'do_rsa': [5, 0.77744827909969], 'do_pwcca': [0, 0.9038861994036101], 'do_linearCKA': [5, 0.9356667698223039]}
Layer 6 winners {'do_rsa': [6, 0.7211857874338949], 'do_pwcca': [9, 0.9519788467645087], 'do_linearCKA': [6, 0.9149268536434525]}
Layer 7 winners {'do_rsa': [7, 0.624481237980124], 'do_pwcca': [8, 0.9604890332967296], 'do_linearCKA': [7, 0.9177688072774429]}
Layer 8 winners {'do_rsa': [8, 0.7929872843822314], 'do_pwcca': [7, 0.9562333078303735], 'do_linearCKA': [8, 0.920848651958332]}
Layer 9 winners {'do_rsa': [9, 0.8961889182727285], 'do_pwcca': [7, 0.9562333097151423], 'do_linearCKA': [9, 0.9443540679827275]}
Layer 10 winners {'do_rsa': [10, 0.5830885057926153], 'do_pwcca': [10, 0.8424356226871771], 'do_linearCKA': [10, 0.8875085698873203]}
--- 1260.0058014392853 seconds ---
Working on model: w5s3.pb
Layer 0 winners {'do_rsa': [0, 0.9710471140542998], 'do_pwcca': [0, 0.9740585925545379], 'do_linearCKA': [0, 0.9980246957398674]}
Layer 1 winners {'do_rsa': [1, 0.8219409841695734], 'do_pwcca': [3, 0.9048324260976798], 'do_linearCKA': [1, 0.9867075531060929]}
Layer 2 winners {'do_rsa': [2, 0.8569816416837427], 'do_pwcca': [3, 0.9257608504987277], 'do_linearCKA': [2, 0.9688714644175191]}
Layer 3 winners {'do_rsa': [3, 0.8317368407127701], 'do_pwcca': [0, 0.940876644933704], 'do_linearCKA': [3, 0.9686529351943738]}
Layer 4 winners {'do_rsa': [4, 0.8259986641982056], 'do_pwcca': [0, 0.9236415767342963], 'do_linearCKA': [4, 0.9554492897909138]}
Layer 5 winners {'do_rsa': [5, 0.7742403971869833], 'do_pwcca': [0, 0.900537870491843], 'do_linearCKA': [5, 0.932720673679219]}
Layer 6 winners {'do_rsa': [6, 0.716187310027635], 'do_pwcca': [9, 0.9476118458340491], 'do_linearCKA': [6, 0.9169388577587734]}
Layer 7 winners {'do_rsa': [7, 0.6218684242892245], 'do_pwcca': [8, 0.9609530875101131], 'do_linearCKA': [7, 0.9084870412118938]}
Layer 8 winners {'do_rsa': [8, 0.7915207163208747], 'do_pwcca': [7, 0.9566593543252894], 'do_linearCKA': [8, 0.9105804321958962]}
Layer 9 winners {'do_rsa': [9, 0.8944300308431431], 'do_pwcca': [7, 0.9566593551463033], 'do_linearCKA': [9, 0.9394572726046087]}
Layer 10 winners {'do_rsa': [10, 0.5591378281079058], 'do_pwcca': [10, 0.8433665393329806], 'do_linearCKA': [10, 0.8926733770111899]}
--- 1258.8463747501373 seconds ---
Working on model: w7s0.pb
Layer 0 winners {'do_rsa': [0, 0.9731774499167589], 'do_pwcca': [0, 0.9729324269188161], 'do_linearCKA': [0, 0.9980199522351181]}
Layer 1 winners {'do_rsa': [1, 0.7971558755071548], 'do_pwcca': [3, 0.9065384490250961], 'do_linearCKA': [1, 0.9863623747218312]}
Layer 2 winners {'do_rsa': [2, 0.8542462649965731], 'do_pwcca': [3, 0.9247380737887402], 'do_linearCKA': [2, 0.9745192043832461]}
Layer 3 winners {'do_rsa': [3, 0.8463662994528168], 'do_pwcca': [0, 0.9418774788605114], 'do_linearCKA': [3, 0.9693736261466865]}
Layer 4 winners {'do_rsa': [4, 0.8222053270888392], 'do_pwcca': [0, 0.921832474409662], 'do_linearCKA': [4, 0.9554536269377851]}
Layer 5 winners {'do_rsa': [5, 0.7699755647341797], 'do_pwcca': [0, 0.9073282624902583], 'do_linearCKA': [5, 0.9340067055655513]}
Layer 6 winners {'do_rsa': [6, 0.7294824533816734], 'do_pwcca': [8, 0.9483607106443643], 'do_linearCKA': [6, 0.9198615665882273]}
Layer 7 winners {'do_rsa': [7, 0.6346712481780177], 'do_pwcca': [8, 0.9618276770966232], 'do_linearCKA': [7, 0.9202004817682785]}
Layer 8 winners {'do_rsa': [8, 0.8004914746281075], 'do_pwcca': [7, 0.954917176723709], 'do_linearCKA': [8, 0.9220182617736418]}
Layer 9 winners {'do_rsa': [9, 0.8943272333047698], 'do_pwcca': [7, 0.9549171780805944], 'do_linearCKA': [9, 0.9397417906288849]}
Layer 10 winners {'do_rsa': [10, 0.5789860217111505], 'do_pwcca': [10, 0.836703250865352], 'do_linearCKA': [10, 0.8916516450749867]}
--- 1263.5245554447174 seconds ---
Working on model: w5s8.pb
Layer 0 winners {'do_rsa': [0, 0.9752019287391155], 'do_pwcca': [0, 0.9748507435833981], 'do_linearCKA': [0, 0.9979856056957928]}
Layer 1 winners {'do_rsa': [1, 0.7823689476154483], 'do_pwcca': [3, 0.9039740166445432], 'do_linearCKA': [1, 0.9846262077452902]}
Layer 2 winners {'do_rsa': [2, 0.8619705825652271], 'do_pwcca': [3, 0.922500104594581], 'do_linearCKA': [2, 0.9717471861017174]}
Layer 3 winners {'do_rsa': [3, 0.8538575961931166], 'do_pwcca': [0, 0.9367154367001786], 'do_linearCKA': [3, 0.9676851007471865]}
Layer 4 winners {'do_rsa': [4, 0.8326863685168087], 'do_pwcca': [0, 0.9195141879335711], 'do_linearCKA': [4, 0.9570634445388922]}
Layer 5 winners {'do_rsa': [5, 0.7738382867298027], 'do_pwcca': [0, 0.9002430093013563], 'do_linearCKA': [5, 0.93549487147743]}
Layer 6 winners {'do_rsa': [6, 0.7142269908074946], 'do_pwcca': [8, 0.9445978021576495], 'do_linearCKA': [6, 0.9186310306427234]}
Layer 7 winners {'do_rsa': [7, 0.6304336835230953], 'do_pwcca': [9, 0.9554105133921047], 'do_linearCKA': [7, 0.910931937995335]}
Layer 8 winners {'do_rsa': [8, 0.7931015602634202], 'do_pwcca': [7, 0.9619267632325866], 'do_linearCKA': [8, 0.9155481296531424]}
Layer 9 winners {'do_rsa': [9, 0.8993515112609184], 'do_pwcca': [7, 0.9619267636314536], 'do_linearCKA': [9, 0.9399870024645779]}
Layer 10 winners {'do_rsa': [10, 0.5926587891748875], 'do_pwcca': [10, 0.8313462651301058], 'do_linearCKA': [10, 0.8815118682846564]}
--- 1263.5046048164368 seconds ---
Working on model: w7s5.pb
Layer 0 winners {'do_rsa': [0, 0.9802707045381142], 'do_pwcca': [0, 0.9733528278774997], 'do_linearCKA': [0, 0.9985480302817572]}
Layer 1 winners {'do_rsa': [1, 0.8101364400177331], 'do_pwcca': [3, 0.905836784246153], 'do_linearCKA': [1, 0.9867626058086182]}
Layer 2 winners {'do_rsa': [2, 0.8771089160103285], 'do_pwcca': [3, 0.9244881082152873], 'do_linearCKA': [2, 0.9742802679472704]}
Layer 3 winners {'do_rsa': [3, 0.8507315770475679], 'do_pwcca': [0, 0.9424950860959662], 'do_linearCKA': [3, 0.9705544380227715]}
Layer 4 winners {'do_rsa': [4, 0.8281953410571575], 'do_pwcca': [0, 0.9236603538444779], 'do_linearCKA': [4, 0.9563140367747464]}
Layer 5 winners {'do_rsa': [5, 0.7800131160855435], 'do_pwcca': [0, 0.9045491602523712], 'do_linearCKA': [5, 0.9382001734601767]}
Layer 6 winners {'do_rsa': [6, 0.722641181948402], 'do_pwcca': [8, 0.9460871001919491], 'do_linearCKA': [6, 0.9192455049719741]}
Layer 7 winners {'do_rsa': [7, 0.6262551073580186], 'do_pwcca': [8, 0.9588235818211688], 'do_linearCKA': [7, 0.9142459161119247]}
Layer 8 winners {'do_rsa': [8, 0.7876709546579026], 'do_pwcca': [7, 0.9565110312351631], 'do_linearCKA': [8, 0.9175033733259703]}
Layer 9 winners {'do_rsa': [9, 0.8890958007923413], 'do_pwcca': [7, 0.9565110314761294], 'do_linearCKA': [9, 0.9369180756852706]}
Layer 10 winners {'do_rsa': [10, 0.571057531327503], 'do_pwcca': [10, 0.8481338609586333], 'do_linearCKA': [10, 0.8910735533185004]}
--- 1262.4276988506317 seconds ---
Working on model: w9s2.pb
Layer 0 winners {'do_rsa': [0, 0.9796143527545422], 'do_pwcca': [0, 0.9734339940462967], 'do_linearCKA': [0, 0.9986722319397333]}
Layer 1 winners {'do_rsa': [1, 0.8467642127488829], 'do_pwcca': [3, 0.9077761369291638], 'do_linearCKA': [1, 0.9845492264149185]}
Layer 2 winners {'do_rsa': [2, 0.8462358859996957], 'do_pwcca': [3, 0.9250959115254949], 'do_linearCKA': [2, 0.9678754946486301]}
Layer 3 winners {'do_rsa': [3, 0.8276900865636566], 'do_pwcca': [0, 0.9426379114353218], 'do_linearCKA': [3, 0.964939872990264]}
Layer 4 winners {'do_rsa': [4, 0.8125657832454838], 'do_pwcca': [0, 0.921065627453219], 'do_linearCKA': [4, 0.9521707418130985]}
Layer 5 winners {'do_rsa': [5, 0.7579110447456944], 'do_pwcca': [8, 0.8968192616257108], 'do_linearCKA': [5, 0.9304186711680065]}
Layer 6 winners {'do_rsa': [6, 0.6982353080073851], 'do_pwcca': [8, 0.95293222404213], 'do_linearCKA': [6, 0.9074859569627614]}
Layer 7 winners {'do_rsa': [7, 0.6205993376415443], 'do_pwcca': [8, 0.9581762430014655], 'do_linearCKA': [7, 0.916532684576853]}
Layer 8 winners {'do_rsa': [8, 0.8001673493461018], 'do_pwcca': [7, 0.9584586695308651], 'do_linearCKA': [8, 0.92006170646429]}
Layer 9 winners {'do_rsa': [9, 0.8950185777394548], 'do_pwcca': [7, 0.9584586700194131], 'do_linearCKA': [9, 0.9420794025375843]}
Layer 10 winners {'do_rsa': [10, 0.5584993307151399], 'do_pwcca': [10, 0.8290893703622644], 'do_linearCKA': [10, 0.8795092102277201]}
--- 1264.933165550232 seconds ---
Working on model: w0s1.pb
Layer 0 winners {'do_rsa': [0, 0.9930170666831147], 'do_pwcca': [0, 0.9866125952946101], 'do_linearCKA': [0, 0.9995655141025305]}
Layer 1 winners {'do_rsa': [1, 0.8631741183719938], 'do_pwcca': [1, 0.9137119634759987], 'do_linearCKA': [1, 0.9851670196890957]}
Layer 2 winners {'do_rsa': [2, 0.8852297593590237], 'do_pwcca': [3, 0.9257016728593769], 'do_linearCKA': [2, 0.9769756862674595]}
Layer 3 winners {'do_rsa': [3, 0.8559826847845031], 'do_pwcca': [0, 0.9402721190821046], 'do_linearCKA': [3, 0.9673922289603756]}
Layer 4 winners {'do_rsa': [4, 0.8137475847257487], 'do_pwcca': [0, 0.923320376551067], 'do_linearCKA': [4, 0.9549505772464831]}
Layer 5 winners {'do_rsa': [5, 0.7674712084589073], 'do_pwcca': [0, 0.8996746391596289], 'do_linearCKA': [5, 0.9340077530787259]}
Layer 6 winners {'do_rsa': [6, 0.7115680134045349], 'do_pwcca': [9, 0.9450850699115151], 'do_linearCKA': [6, 0.9078778631840467]}
Layer 7 winners {'do_rsa': [7, 0.6384327628821409], 'do_pwcca': [9, 0.9602170177121904], 'do_linearCKA': [7, 0.9136073035652468]}
Layer 8 winners {'do_rsa': [8, 0.7994383549379418], 'do_pwcca': [7, 0.9565864193041596], 'do_linearCKA': [8, 0.9257105391456523]}
Layer 9 winners {'do_rsa': [9, 0.8989052443374398], 'do_pwcca': [7, 0.9565864190710076], 'do_linearCKA': [9, 0.9452078882267462]}
Layer 10 winners {'do_rsa': [10, 0.5734504783141265], 'do_pwcca': [10, 0.8357374640836991], 'do_linearCKA': [10, 0.8778642694412586]}
--- 1259.7786962985992 seconds ---
Working on model: w0s6.pb
Layer 0 winners {'do_rsa': [0, 0.9924925553928932], 'do_pwcca': [0, 0.9869700813762794], 'do_linearCKA': [0, 0.9993256018162106]}
Layer 1 winners {'do_rsa': [1, 0.849860913737074], 'do_pwcca': [3, 0.9099625173727046], 'do_linearCKA': [1, 0.9885505137700797]}
Layer 2 winners {'do_rsa': [2, 0.8732588167378428], 'do_pwcca': [3, 0.9282568653283831], 'do_linearCKA': [2, 0.9734629224843362]}
Layer 3 winners {'do_rsa': [3, 0.8556495816314525], 'do_pwcca': [0, 0.94216064504963], 'do_linearCKA': [3, 0.9693970154030914]}
Layer 4 winners {'do_rsa': [4, 0.8408853802697531], 'do_pwcca': [0, 0.9259053073970395], 'do_linearCKA': [4, 0.9589453150236721]}
Layer 5 winners {'do_rsa': [5, 0.7761680677670801], 'do_pwcca': [0, 0.9063215502905146], 'do_linearCKA': [5, 0.939932513127645]}
Layer 6 winners {'do_rsa': [6, 0.7273958876505277], 'do_pwcca': [9, 0.9450376638686251], 'do_linearCKA': [6, 0.9233477006410464]}
Layer 7 winners {'do_rsa': [7, 0.63650261266054], 'do_pwcca': [8, 0.9581283712098744], 'do_linearCKA': [7, 0.9171544957999839]}
Layer 8 winners {'do_rsa': [8, 0.7998038978555694], 'do_pwcca': [7, 0.9608368228085674], 'do_linearCKA': [8, 0.9260283248965094]}
Layer 9 winners {'do_rsa': [9, 0.8941215500346926], 'do_pwcca': [7, 0.9608368248658058], 'do_linearCKA': [9, 0.9458366165539736]}
Layer 10 winners {'do_rsa': [10, 0.5882835059921862], 'do_pwcca': [10, 0.8432414664478882], 'do_linearCKA': [10, 0.9074633887088024]}
--- 1263.009440422058 seconds ---
Working on model: w2s3.pb
Layer 0 winners {'do_rsa': [0, 0.9805398018986523], 'do_pwcca': [0, 0.9737287342419589], 'do_linearCKA': [0, 0.9980238693664154]}
Layer 1 winners {'do_rsa': [1, 0.8328122845149233], 'do_pwcca': [3, 0.9049571460676109], 'do_linearCKA': [1, 0.9852258241342325]}
Layer 2 winners {'do_rsa': [2, 0.8582469934629616], 'do_pwcca': [3, 0.9249574145091959], 'do_linearCKA': [2, 0.9698944338072139]}
Layer 3 winners {'do_rsa': [3, 0.8265201568693396], 'do_pwcca': [0, 0.9407666072053525], 'do_linearCKA': [3, 0.9664150911317044]}
Layer 4 winners {'do_rsa': [4, 0.8298507313011176], 'do_pwcca': [0, 0.9202310200870427], 'do_linearCKA': [4, 0.9553091676030836]}
Layer 5 winners {'do_rsa': [5, 0.7623196616486132], 'do_pwcca': [0, 0.9042091713274673], 'do_linearCKA': [5, 0.9328349201820694]}
Layer 6 winners {'do_rsa': [6, 0.7103910089050556], 'do_pwcca': [9, 0.9436853359540244], 'do_linearCKA': [6, 0.9138545134941642]}
Layer 7 winners {'do_rsa': [7, 0.6212267081334776], 'do_pwcca': [9, 0.9609812364552089], 'do_linearCKA': [7, 0.9114713421465703]}
Layer 8 winners {'do_rsa': [8, 0.7898041553740732], 'do_pwcca': [7, 0.9600935734721335], 'do_linearCKA': [8, 0.910526543940529]}
Layer 9 winners {'do_rsa': [9, 0.8902926138883065], 'do_pwcca': [7, 0.960093574388322], 'do_linearCKA': [9, 0.9357880149981834]}
Layer 10 winners {'do_rsa': [10, 0.570041849756324], 'do_pwcca': [10, 0.8407450353384758], 'do_linearCKA': [10, 0.8881326028732646]}
--- 1258.612274646759 seconds ---
Working on model: w4s0.pb
Layer 0 winners {'do_rsa': [0, 0.9812171263160324], 'do_pwcca': [0, 0.9737670210791123], 'do_linearCKA': [0, 0.9984423109709106]}
Layer 1 winners {'do_rsa': [1, 0.8216144774689363], 'do_pwcca': [3, 0.9046490458604478], 'do_linearCKA': [1, 0.9875337548490094]}
Layer 2 winners {'do_rsa': [2, 0.8656985363764124], 'do_pwcca': [3, 0.9258292302225749], 'do_linearCKA': [2, 0.9719656972798301]}
Layer 3 winners {'do_rsa': [3, 0.836515785264076], 'do_pwcca': [0, 0.9401417249623801], 'do_linearCKA': [3, 0.9633225067168537]}
Layer 4 winners {'do_rsa': [4, 0.8224960126371657], 'do_pwcca': [0, 0.9194046122467451], 'do_linearCKA': [4, 0.9516651272953109]}
Layer 5 winners {'do_rsa': [5, 0.7801437438936861], 'do_pwcca': [0, 0.9027041668435088], 'do_linearCKA': [5, 0.9321588871402863]}
Layer 6 winners {'do_rsa': [6, 0.7134925844693204], 'do_pwcca': [8, 0.9456906718331581], 'do_linearCKA': [6, 0.915200147118179]}
Layer 7 winners {'do_rsa': [7, 0.6303383981205413], 'do_pwcca': [8, 0.9585550926235917], 'do_linearCKA': [7, 0.9143792951011872]}
Layer 8 winners {'do_rsa': [8, 0.8005940568677515], 'do_pwcca': [7, 0.9539319832124455], 'do_linearCKA': [8, 0.9111557856392046]}
Layer 9 winners {'do_rsa': [9, 0.8998387140613048], 'do_pwcca': [7, 0.9539319851584142], 'do_linearCKA': [9, 0.9358533766043746]}
Layer 10 winners {'do_rsa': [10, 0.5814590106892175], 'do_pwcca': [10, 0.8428739952876468], 'do_linearCKA': [10, 0.8845808572307512]}
--- 1261.3845658302307 seconds ---
Working on model: w2s8.pb
Layer 0 winners {'do_rsa': [0, 0.9786166643054807], 'do_pwcca': [0, 0.9735670653182964], 'do_linearCKA': [0, 0.998151708723511]}
Layer 1 winners {'do_rsa': [1, 0.8032188218428636], 'do_pwcca': [3, 0.9062435617272685], 'do_linearCKA': [1, 0.9849064792427638]}
Layer 2 winners {'do_rsa': [2, 0.8642047496729568], 'do_pwcca': [3, 0.9257507173232202], 'do_linearCKA': [2, 0.9714448141849789]}
Layer 3 winners {'do_rsa': [3, 0.8520094403187073], 'do_pwcca': [0, 0.9391136321881363], 'do_linearCKA': [3, 0.9683737847617407]}
Layer 4 winners {'do_rsa': [4, 0.8163179076403623], 'do_pwcca': [0, 0.9207774373104453], 'do_linearCKA': [4, 0.9557954589255769]}
Layer 5 winners {'do_rsa': [5, 0.7641149094671764], 'do_pwcca': [0, 0.9016037451342458], 'do_linearCKA': [5, 0.9325029104890401]}
Layer 6 winners {'do_rsa': [6, 0.7241815454258279], 'do_pwcca': [9, 0.9446559658275773], 'do_linearCKA': [6, 0.9177694441053103]}
Layer 7 winners {'do_rsa': [7, 0.6281605885541492], 'do_pwcca': [8, 0.9597107524828254], 'do_linearCKA': [7, 0.9183449787943306]}
Layer 8 winners {'do_rsa': [8, 0.7981253862037693], 'do_pwcca': [7, 0.9564932923999077], 'do_linearCKA': [8, 0.9185940522989955]}
ERROR:smemwatch:This job has exceeded its memory quota and will be terminated
ERROR:smemwatch:Killing process 24794 cgroup RSS size 8237.19921875 MB > 8217.0 MB
