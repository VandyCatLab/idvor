2021-07-02 12:18:39.966080: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 12:20:08.542213: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-07-02 12:20:08.576745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:82:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-02 12:20:08.576832: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 12:20:08.618923: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-02 12:20:08.639706: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-02 12:20:08.647983: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-02 12:20:08.689703: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-02 12:20:08.698046: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-02 12:20:08.772756: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 12:20:08.776081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-02 12:20:08.779652: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-02 12:20:08.795524: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599990000 Hz
2021-07-02 12:20:08.795643: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4a97320 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-07-02 12:20:08.795664: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-07-02 12:20:08.929175: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4a8f2b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-07-02 12:20:08.929259: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN X (Pascal), Compute Capability 6.1
2021-07-02 12:20:08.943078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:82:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-02 12:20:08.943134: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 12:20:08.943188: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-02 12:20:08.943213: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-02 12:20:08.943235: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-02 12:20:08.943257: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-02 12:20:08.943279: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-02 12:20:08.943850: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 12:20:08.948730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-02 12:20:08.950592: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 12:20:10.736322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-02 12:20:10.736401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-07-02 12:20:10.736416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-07-02 12:20:10.742454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11228 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:82:00.0, compute capability: 6.1)
2021-07-02 12:20:16.658838: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 12:20:19.167507: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
Using model index: 70
Making train data...
GCN...
ZCA...
Done!
Making test data...
Done!
Epoch 1/350


Snapshot weight 0 shuffle 7 at epoch 1
Layer 11
Getting activations...


391/391 - 25s - loss: 2.3280 - accuracy: 0.1003 - val_loss: 2.3267 - val_accuracy: 0.0996
Epoch 2/350


Snapshot weight 0 shuffle 7 at epoch 2
Layer 11
Getting activations...


391/391 - 25s - loss: 2.3267 - accuracy: 0.0967 - val_loss: 2.3267 - val_accuracy: 0.0999
Epoch 3/350


Snapshot weight 0 shuffle 7 at epoch 3
Layer 11
Getting activations...


391/391 - 26s - loss: 2.3254 - accuracy: 0.0986 - val_loss: 2.3245 - val_accuracy: 0.1154
Epoch 4/350


Snapshot weight 0 shuffle 7 at epoch 4
Layer 11
Getting activations...


391/391 - 26s - loss: 2.3108 - accuracy: 0.1249 - val_loss: 2.2997 - val_accuracy: 0.1597
Epoch 5/350


Snapshot weight 0 shuffle 7 at epoch 5
Layer 11
Getting activations...


391/391 - 26s - loss: 2.2443 - accuracy: 0.1959 - val_loss: 2.4819 - val_accuracy: 0.1745
Epoch 6/350


Snapshot weight 0 shuffle 7 at epoch 6
Layer 11
Getting activations...


391/391 - 26s - loss: 2.1663 - accuracy: 0.2487 - val_loss: 2.1758 - val_accuracy: 0.2641
Epoch 7/350


Snapshot weight 0 shuffle 7 at epoch 7
Layer 11
Getting activations...


391/391 - 26s - loss: 1.9816 - accuracy: 0.3342 - val_loss: 1.8290 - val_accuracy: 0.3957
Epoch 8/350


Snapshot weight 0 shuffle 7 at epoch 8
Layer 11
Getting activations...


391/391 - 26s - loss: 1.6437 - accuracy: 0.4125 - val_loss: 1.4827 - val_accuracy: 0.4737
Epoch 9/350


Snapshot weight 0 shuffle 7 at epoch 9
Layer 11
Getting activations...


391/391 - 26s - loss: 1.4330 - accuracy: 0.4928 - val_loss: 1.2860 - val_accuracy: 0.5485
Epoch 10/350


Snapshot weight 0 shuffle 7 at epoch 10
Layer 11
Getting activations...


391/391 - 25s - loss: 1.3294 - accuracy: 0.5309 - val_loss: 1.3685 - val_accuracy: 0.5189
Epoch 11/350
391/391 - 25s - loss: 1.2413 - accuracy: 0.5627 - val_loss: 1.1642 - val_accuracy: 0.6021
Epoch 12/350
391/391 - 25s - loss: 1.1525 - accuracy: 0.5972 - val_loss: 1.1388 - val_accuracy: 0.6097
Epoch 13/350
391/391 - 25s - loss: 1.0900 - accuracy: 0.6204 - val_loss: 0.9659 - val_accuracy: 0.6641
Epoch 14/350
391/391 - 25s - loss: 1.0313 - accuracy: 0.6433 - val_loss: 0.9711 - val_accuracy: 0.6704
Epoch 15/350
391/391 - 26s - loss: 0.9962 - accuracy: 0.6547 - val_loss: 0.9264 - val_accuracy: 0.6820
Epoch 16/350
391/391 - 25s - loss: 0.9552 - accuracy: 0.6727 - val_loss: 0.9928 - val_accuracy: 0.6589
Epoch 17/350
391/391 - 25s - loss: 0.9152 - accuracy: 0.6854 - val_loss: 0.8139 - val_accuracy: 0.7213
Epoch 18/350
391/391 - 25s - loss: 0.8700 - accuracy: 0.7035 - val_loss: 0.7656 - val_accuracy: 0.7387
Epoch 19/350
391/391 - 25s - loss: 0.8367 - accuracy: 0.7139 - val_loss: 0.8121 - val_accuracy: 0.7253
Epoch 20/350
391/391 - 26s - loss: 0.8119 - accuracy: 0.7250 - val_loss: 0.7472 - val_accuracy: 0.7424
Epoch 21/350
391/391 - 25s - loss: 0.7751 - accuracy: 0.7380 - val_loss: 0.7591 - val_accuracy: 0.7502
Epoch 22/350
391/391 - 25s - loss: 0.7514 - accuracy: 0.7452 - val_loss: 0.6620 - val_accuracy: 0.7761
Epoch 23/350
391/391 - 25s - loss: 0.7300 - accuracy: 0.7545 - val_loss: 0.6691 - val_accuracy: 0.7750
Epoch 24/350
391/391 - 25s - loss: 0.7059 - accuracy: 0.7603 - val_loss: 0.6730 - val_accuracy: 0.7800
Epoch 25/350
391/391 - 25s - loss: 0.6913 - accuracy: 0.7679 - val_loss: 0.6490 - val_accuracy: 0.7867
Epoch 26/350
391/391 - 25s - loss: 0.6678 - accuracy: 0.7795 - val_loss: 0.6409 - val_accuracy: 0.7928
Epoch 27/350
391/391 - 25s - loss: 0.6458 - accuracy: 0.7863 - val_loss: 0.6487 - val_accuracy: 0.7845
Epoch 28/350
391/391 - 25s - loss: 0.6380 - accuracy: 0.7874 - val_loss: 0.6510 - val_accuracy: 0.7873
Epoch 29/350
391/391 - 25s - loss: 0.6181 - accuracy: 0.7938 - val_loss: 0.6018 - val_accuracy: 0.8091
Epoch 30/350
391/391 - 25s - loss: 0.6052 - accuracy: 0.7991 - val_loss: 0.5789 - val_accuracy: 0.8130
Epoch 31/350
391/391 - 25s - loss: 0.5895 - accuracy: 0.8044 - val_loss: 0.6236 - val_accuracy: 0.7999
Epoch 32/350
391/391 - 25s - loss: 0.5808 - accuracy: 0.8078 - val_loss: 0.6164 - val_accuracy: 0.8037
Epoch 33/350
391/391 - 25s - loss: 0.5742 - accuracy: 0.8114 - val_loss: 0.5349 - val_accuracy: 0.8250
Epoch 34/350
391/391 - 25s - loss: 0.5623 - accuracy: 0.8149 - val_loss: 0.5767 - val_accuracy: 0.8155
Epoch 35/350
391/391 - 25s - loss: 0.5477 - accuracy: 0.8215 - val_loss: 0.5422 - val_accuracy: 0.8238
Epoch 36/350
391/391 - 25s - loss: 0.5373 - accuracy: 0.8255 - val_loss: 0.5143 - val_accuracy: 0.8286
Epoch 37/350
391/391 - 25s - loss: 0.5313 - accuracy: 0.8268 - val_loss: 0.5358 - val_accuracy: 0.8314
Epoch 38/350
391/391 - 25s - loss: 0.5198 - accuracy: 0.8314 - val_loss: 0.5160 - val_accuracy: 0.8353
Epoch 39/350
391/391 - 25s - loss: 0.5080 - accuracy: 0.8346 - val_loss: 0.5324 - val_accuracy: 0.8292
Epoch 40/350
391/391 - 25s - loss: 0.4932 - accuracy: 0.8408 - val_loss: 0.5201 - val_accuracy: 0.8342
Epoch 41/350
391/391 - 26s - loss: 0.4947 - accuracy: 0.8389 - val_loss: 0.5074 - val_accuracy: 0.8397
Epoch 42/350
391/391 - 25s - loss: 0.4821 - accuracy: 0.8440 - val_loss: 0.5020 - val_accuracy: 0.8447
Epoch 43/350
391/391 - 25s - loss: 0.4770 - accuracy: 0.8467 - val_loss: 0.5032 - val_accuracy: 0.8422
Epoch 44/350
391/391 - 25s - loss: 0.4699 - accuracy: 0.8478 - val_loss: 0.4582 - val_accuracy: 0.8569
Epoch 45/350
391/391 - 25s - loss: 0.4629 - accuracy: 0.8498 - val_loss: 0.5015 - val_accuracy: 0.8430
Epoch 46/350
391/391 - 25s - loss: 0.4577 - accuracy: 0.8523 - val_loss: 0.4889 - val_accuracy: 0.8527
Epoch 47/350
391/391 - 25s - loss: 0.4429 - accuracy: 0.8550 - val_loss: 0.4850 - val_accuracy: 0.8499
Epoch 48/350
391/391 - 25s - loss: 0.4454 - accuracy: 0.8556 - val_loss: 0.4684 - val_accuracy: 0.8559
Epoch 49/350
391/391 - 25s - loss: 0.4406 - accuracy: 0.8560 - val_loss: 0.4751 - val_accuracy: 0.8509
Epoch 50/350


Snapshot weight 0 shuffle 7 at epoch 50
Layer 11
Getting activations...


391/391 - 26s - loss: 0.4266 - accuracy: 0.8629 - val_loss: 0.4587 - val_accuracy: 0.8594
Epoch 51/350
391/391 - 25s - loss: 0.4238 - accuracy: 0.8643 - val_loss: 0.4582 - val_accuracy: 0.8608
Epoch 52/350
391/391 - 25s - loss: 0.4190 - accuracy: 0.8648 - val_loss: 0.4585 - val_accuracy: 0.8621
Epoch 53/350
391/391 - 26s - loss: 0.4172 - accuracy: 0.8669 - val_loss: 0.4613 - val_accuracy: 0.8611
Epoch 54/350
391/391 - 25s - loss: 0.4085 - accuracy: 0.8681 - val_loss: 0.4434 - val_accuracy: 0.8593
Epoch 55/350
391/391 - 25s - loss: 0.4069 - accuracy: 0.8681 - val_loss: 0.4245 - val_accuracy: 0.8659
Epoch 56/350
391/391 - 25s - loss: 0.3953 - accuracy: 0.8746 - val_loss: 0.4278 - val_accuracy: 0.8676
Epoch 57/350
391/391 - 25s - loss: 0.3952 - accuracy: 0.8732 - val_loss: 0.4784 - val_accuracy: 0.8572
Epoch 58/350
391/391 - 25s - loss: 0.3931 - accuracy: 0.8746 - val_loss: 0.4478 - val_accuracy: 0.8614
Epoch 59/350
391/391 - 25s - loss: 0.3874 - accuracy: 0.8754 - val_loss: 0.5069 - val_accuracy: 0.8521
Epoch 60/350
391/391 - 25s - loss: 0.3832 - accuracy: 0.8781 - val_loss: 0.4469 - val_accuracy: 0.8631
Epoch 61/350
391/391 - 25s - loss: 0.3797 - accuracy: 0.8785 - val_loss: 0.4352 - val_accuracy: 0.8677
Epoch 62/350
391/391 - 25s - loss: 0.3719 - accuracy: 0.8799 - val_loss: 0.4232 - val_accuracy: 0.8733
Epoch 63/350
391/391 - 25s - loss: 0.3692 - accuracy: 0.8816 - val_loss: 0.4457 - val_accuracy: 0.8691
Epoch 64/350
391/391 - 26s - loss: 0.3658 - accuracy: 0.8846 - val_loss: 0.4626 - val_accuracy: 0.8596
Epoch 65/350
391/391 - 26s - loss: 0.3627 - accuracy: 0.8835 - val_loss: 0.5081 - val_accuracy: 0.8519
Epoch 66/350
391/391 - 25s - loss: 0.3546 - accuracy: 0.8871 - val_loss: 0.4374 - val_accuracy: 0.8727
Epoch 67/350
391/391 - 25s - loss: 0.3528 - accuracy: 0.8881 - val_loss: 0.4223 - val_accuracy: 0.8704
Epoch 68/350
391/391 - 25s - loss: 0.3537 - accuracy: 0.8882 - val_loss: 0.4585 - val_accuracy: 0.8644
Epoch 69/350
391/391 - 25s - loss: 0.3483 - accuracy: 0.8890 - val_loss: 0.4511 - val_accuracy: 0.8725
Epoch 70/350
391/391 - 25s - loss: 0.3435 - accuracy: 0.8919 - val_loss: 0.4487 - val_accuracy: 0.8730
Epoch 71/350
391/391 - 25s - loss: 0.3410 - accuracy: 0.8924 - val_loss: 0.4135 - val_accuracy: 0.8766
Epoch 72/350
391/391 - 25s - loss: 0.3371 - accuracy: 0.8936 - val_loss: 0.4518 - val_accuracy: 0.8667
Epoch 73/350
391/391 - 25s - loss: 0.3329 - accuracy: 0.8953 - val_loss: 0.4404 - val_accuracy: 0.8722
Epoch 74/350
391/391 - 25s - loss: 0.3238 - accuracy: 0.8985 - val_loss: 0.4352 - val_accuracy: 0.8715
Epoch 75/350
391/391 - 26s - loss: 0.3263 - accuracy: 0.8971 - val_loss: 0.4670 - val_accuracy: 0.8687
Epoch 76/350
391/391 - 25s - loss: 0.3187 - accuracy: 0.9000 - val_loss: 0.4168 - val_accuracy: 0.8796
Epoch 77/350
391/391 - 25s - loss: 0.3214 - accuracy: 0.9006 - val_loss: 0.4532 - val_accuracy: 0.8691
Epoch 78/350
391/391 - 25s - loss: 0.3157 - accuracy: 0.8999 - val_loss: 0.4094 - val_accuracy: 0.8804
Epoch 79/350
391/391 - 26s - loss: 0.3181 - accuracy: 0.8999 - val_loss: 0.4532 - val_accuracy: 0.8718
Epoch 80/350
391/391 - 25s - loss: 0.3110 - accuracy: 0.9033 - val_loss: 0.4199 - val_accuracy: 0.8797
Epoch 81/350
391/391 - 25s - loss: 0.3058 - accuracy: 0.9045 - val_loss: 0.4388 - val_accuracy: 0.8751
Epoch 82/350
391/391 - 25s - loss: 0.3079 - accuracy: 0.9034 - val_loss: 0.4411 - val_accuracy: 0.8729
Epoch 83/350
391/391 - 25s - loss: 0.3084 - accuracy: 0.9043 - val_loss: 0.4053 - val_accuracy: 0.8818
Epoch 84/350
391/391 - 25s - loss: 0.3027 - accuracy: 0.9059 - val_loss: 0.4153 - val_accuracy: 0.8835
Epoch 85/350
391/391 - 25s - loss: 0.3013 - accuracy: 0.9057 - val_loss: 0.4355 - val_accuracy: 0.8751
Epoch 86/350
391/391 - 25s - loss: 0.2991 - accuracy: 0.9074 - val_loss: 0.4396 - val_accuracy: 0.8745
Epoch 87/350
391/391 - 25s - loss: 0.2931 - accuracy: 0.9097 - val_loss: 0.4317 - val_accuracy: 0.8807
Epoch 88/350
391/391 - 25s - loss: 0.2934 - accuracy: 0.9088 - val_loss: 0.4229 - val_accuracy: 0.8795
Epoch 89/350
391/391 - 25s - loss: 0.2877 - accuracy: 0.9103 - val_loss: 0.4455 - val_accuracy: 0.8771
Epoch 90/350
391/391 - 25s - loss: 0.2809 - accuracy: 0.9137 - val_loss: 0.4333 - val_accuracy: 0.8798
Epoch 91/350
391/391 - 25s - loss: 0.2886 - accuracy: 0.9116 - val_loss: 0.4230 - val_accuracy: 0.8838
Epoch 92/350
391/391 - 25s - loss: 0.2807 - accuracy: 0.9133 - val_loss: 0.4124 - val_accuracy: 0.8859
Epoch 93/350
391/391 - 25s - loss: 0.2801 - accuracy: 0.9139 - val_loss: 0.4287 - val_accuracy: 0.8800
Epoch 94/350
391/391 - 25s - loss: 0.2823 - accuracy: 0.9135 - val_loss: 0.4066 - val_accuracy: 0.8872
Epoch 95/350
391/391 - 26s - loss: 0.2788 - accuracy: 0.9147 - val_loss: 0.4177 - val_accuracy: 0.8814
Epoch 96/350
391/391 - 25s - loss: 0.2727 - accuracy: 0.9174 - val_loss: 0.4147 - val_accuracy: 0.8850
Epoch 97/350
391/391 - 25s - loss: 0.2767 - accuracy: 0.9152 - val_loss: 0.4367 - val_accuracy: 0.8854
Epoch 98/350
391/391 - 25s - loss: 0.2759 - accuracy: 0.9149 - val_loss: 0.4342 - val_accuracy: 0.8851
Epoch 99/350
391/391 - 25s - loss: 0.2705 - accuracy: 0.9179 - val_loss: 0.4060 - val_accuracy: 0.8866
Epoch 100/350


Snapshot weight 0 shuffle 7 at epoch 100
Layer 11
Getting activations...


391/391 - 26s - loss: 0.2733 - accuracy: 0.9171 - val_loss: 0.4441 - val_accuracy: 0.8784
Epoch 101/350
391/391 - 26s - loss: 0.2674 - accuracy: 0.9188 - val_loss: 0.4161 - val_accuracy: 0.8899
Epoch 102/350
391/391 - 25s - loss: 0.2638 - accuracy: 0.9214 - val_loss: 0.4238 - val_accuracy: 0.8850
Epoch 103/350
391/391 - 25s - loss: 0.2599 - accuracy: 0.9205 - val_loss: 0.4506 - val_accuracy: 0.8840
Epoch 104/350
391/391 - 25s - loss: 0.2609 - accuracy: 0.9209 - val_loss: 0.4158 - val_accuracy: 0.8891
Epoch 105/350
391/391 - 25s - loss: 0.2602 - accuracy: 0.9218 - val_loss: 0.4331 - val_accuracy: 0.8861
Epoch 106/350
391/391 - 25s - loss: 0.2538 - accuracy: 0.9225 - val_loss: 0.4369 - val_accuracy: 0.8837
Epoch 107/350
391/391 - 25s - loss: 0.2572 - accuracy: 0.9228 - val_loss: 0.4172 - val_accuracy: 0.8864
Epoch 108/350
391/391 - 25s - loss: 0.2509 - accuracy: 0.9252 - val_loss: 0.4663 - val_accuracy: 0.8767
Epoch 109/350
391/391 - 25s - loss: 0.2500 - accuracy: 0.9241 - val_loss: 0.4192 - val_accuracy: 0.8856
Epoch 110/350
391/391 - 25s - loss: 0.2504 - accuracy: 0.9237 - val_loss: 0.4157 - val_accuracy: 0.8888
Epoch 111/350
391/391 - 25s - loss: 0.2463 - accuracy: 0.9258 - val_loss: 0.4445 - val_accuracy: 0.8824
Epoch 112/350
391/391 - 25s - loss: 0.2506 - accuracy: 0.9249 - val_loss: 0.4059 - val_accuracy: 0.8920
Epoch 113/350
391/391 - 25s - loss: 0.2461 - accuracy: 0.9252 - val_loss: 0.4286 - val_accuracy: 0.8895
Epoch 114/350
391/391 - 25s - loss: 0.2411 - accuracy: 0.9291 - val_loss: 0.4101 - val_accuracy: 0.8896
Epoch 115/350
391/391 - 25s - loss: 0.2412 - accuracy: 0.9283 - val_loss: 0.4406 - val_accuracy: 0.8868
Epoch 116/350
391/391 - 25s - loss: 0.2411 - accuracy: 0.9278 - val_loss: 0.4531 - val_accuracy: 0.8809
Epoch 117/350
391/391 - 26s - loss: 0.2365 - accuracy: 0.9302 - val_loss: 0.4294 - val_accuracy: 0.8905
Epoch 118/350
391/391 - 25s - loss: 0.2405 - accuracy: 0.9279 - val_loss: 0.4302 - val_accuracy: 0.8881
Epoch 119/350
391/391 - 25s - loss: 0.2380 - accuracy: 0.9290 - val_loss: 0.4519 - val_accuracy: 0.8882
Epoch 120/350
391/391 - 25s - loss: 0.2365 - accuracy: 0.9306 - val_loss: 0.4144 - val_accuracy: 0.8890
Epoch 121/350
391/391 - 26s - loss: 0.2356 - accuracy: 0.9298 - val_loss: 0.4262 - val_accuracy: 0.8919
Epoch 122/350
391/391 - 25s - loss: 0.2316 - accuracy: 0.9309 - val_loss: 0.4470 - val_accuracy: 0.8851
Epoch 123/350
391/391 - 25s - loss: 0.2311 - accuracy: 0.9307 - val_loss: 0.4467 - val_accuracy: 0.8876
Epoch 124/350
391/391 - 25s - loss: 0.2277 - accuracy: 0.9332 - val_loss: 0.4498 - val_accuracy: 0.8839
Epoch 125/350
391/391 - 25s - loss: 0.2249 - accuracy: 0.9354 - val_loss: 0.4300 - val_accuracy: 0.8896
Epoch 126/350
391/391 - 25s - loss: 0.2279 - accuracy: 0.9327 - val_loss: 0.4333 - val_accuracy: 0.8907
Epoch 127/350
391/391 - 25s - loss: 0.2295 - accuracy: 0.9334 - val_loss: 0.4313 - val_accuracy: 0.8901
Epoch 128/350
391/391 - 25s - loss: 0.2257 - accuracy: 0.9345 - val_loss: 0.4369 - val_accuracy: 0.8886
Epoch 129/350
391/391 - 25s - loss: 0.2215 - accuracy: 0.9360 - val_loss: 0.4075 - val_accuracy: 0.8939
Epoch 130/350
391/391 - 25s - loss: 0.2229 - accuracy: 0.9349 - val_loss: 0.4863 - val_accuracy: 0.8777
Epoch 131/350
391/391 - 25s - loss: 0.2229 - accuracy: 0.9347 - val_loss: 0.4369 - val_accuracy: 0.8901
Epoch 132/350
391/391 - 25s - loss: 0.2206 - accuracy: 0.9356 - val_loss: 0.4457 - val_accuracy: 0.8874
Epoch 133/350
391/391 - 25s - loss: 0.2200 - accuracy: 0.9351 - val_loss: 0.4152 - val_accuracy: 0.8910
Epoch 134/350
391/391 - 25s - loss: 0.2168 - accuracy: 0.9377 - val_loss: 0.4290 - val_accuracy: 0.8923
Epoch 135/350
391/391 - 25s - loss: 0.2160 - accuracy: 0.9389 - val_loss: 0.4854 - val_accuracy: 0.8845
Epoch 136/350
391/391 - 25s - loss: 0.2161 - accuracy: 0.9375 - val_loss: 0.4549 - val_accuracy: 0.8819
Epoch 137/350
391/391 - 25s - loss: 0.2092 - accuracy: 0.9402 - val_loss: 0.4525 - val_accuracy: 0.8912
Epoch 138/350
391/391 - 25s - loss: 0.2150 - accuracy: 0.9384 - val_loss: 0.4530 - val_accuracy: 0.8934
Epoch 139/350
391/391 - 25s - loss: 0.2115 - accuracy: 0.9401 - val_loss: 0.4435 - val_accuracy: 0.8874
Epoch 140/350
391/391 - 25s - loss: 0.2086 - accuracy: 0.9400 - val_loss: 0.4331 - val_accuracy: 0.8951
Epoch 141/350
391/391 - 25s - loss: 0.2121 - accuracy: 0.9397 - val_loss: 0.4421 - val_accuracy: 0.8892
Epoch 142/350
391/391 - 25s - loss: 0.2090 - accuracy: 0.9415 - val_loss: 0.4371 - val_accuracy: 0.8923
Epoch 143/350
391/391 - 25s - loss: 0.2097 - accuracy: 0.9401 - val_loss: 0.4726 - val_accuracy: 0.8847
Epoch 144/350
391/391 - 25s - loss: 0.2053 - accuracy: 0.9424 - val_loss: 0.4758 - val_accuracy: 0.8866
Epoch 145/350
391/391 - 25s - loss: 0.2061 - accuracy: 0.9423 - val_loss: 0.4474 - val_accuracy: 0.8942
Epoch 146/350
391/391 - 25s - loss: 0.2033 - accuracy: 0.9434 - val_loss: 0.3974 - val_accuracy: 0.9011
Epoch 147/350
391/391 - 25s - loss: 0.2068 - accuracy: 0.9416 - val_loss: 0.4268 - val_accuracy: 0.8972
Epoch 148/350
391/391 - 26s - loss: 0.2025 - accuracy: 0.9434 - val_loss: 0.4790 - val_accuracy: 0.8877
Epoch 149/350
391/391 - 25s - loss: 0.2014 - accuracy: 0.9434 - val_loss: 0.4314 - val_accuracy: 0.8935
Epoch 150/350


Snapshot weight 0 shuffle 7 at epoch 150
Layer 11
Getting activations...


391/391 - 25s - loss: 0.2022 - accuracy: 0.9438 - val_loss: 0.4482 - val_accuracy: 0.8912
Epoch 151/350
391/391 - 25s - loss: 0.1999 - accuracy: 0.9429 - val_loss: 0.4290 - val_accuracy: 0.8947
Epoch 152/350
391/391 - 25s - loss: 0.2013 - accuracy: 0.9428 - val_loss: 0.4396 - val_accuracy: 0.8912
Epoch 153/350
391/391 - 25s - loss: 0.1960 - accuracy: 0.9453 - val_loss: 0.4628 - val_accuracy: 0.8920
Epoch 154/350
391/391 - 26s - loss: 0.1925 - accuracy: 0.9464 - val_loss: 0.4457 - val_accuracy: 0.8954
Epoch 155/350
391/391 - 25s - loss: 0.1964 - accuracy: 0.9457 - val_loss: 0.4371 - val_accuracy: 0.8975
Epoch 156/350
391/391 - 25s - loss: 0.1983 - accuracy: 0.9448 - val_loss: 0.4316 - val_accuracy: 0.8938
Epoch 157/350
391/391 - 25s - loss: 0.2007 - accuracy: 0.9438 - val_loss: 0.4578 - val_accuracy: 0.8946
Epoch 158/350
391/391 - 25s - loss: 0.1928 - accuracy: 0.9470 - val_loss: 0.4528 - val_accuracy: 0.8901
Epoch 159/350
391/391 - 25s - loss: 0.1956 - accuracy: 0.9450 - val_loss: 0.4702 - val_accuracy: 0.8945
Epoch 160/350
391/391 - 26s - loss: 0.1933 - accuracy: 0.9461 - val_loss: 0.4330 - val_accuracy: 0.8982
Epoch 161/350
391/391 - 25s - loss: 0.1908 - accuracy: 0.9478 - val_loss: 0.4384 - val_accuracy: 0.8961
Epoch 162/350
391/391 - 25s - loss: 0.1939 - accuracy: 0.9453 - val_loss: 0.4668 - val_accuracy: 0.8962
Epoch 163/350
391/391 - 25s - loss: 0.1859 - accuracy: 0.9489 - val_loss: 0.4629 - val_accuracy: 0.8953
Epoch 164/350
391/391 - 25s - loss: 0.1924 - accuracy: 0.9469 - val_loss: 0.4350 - val_accuracy: 0.8934
Epoch 165/350
391/391 - 25s - loss: 0.1909 - accuracy: 0.9483 - val_loss: 0.4447 - val_accuracy: 0.8903
Epoch 166/350
391/391 - 25s - loss: 0.1894 - accuracy: 0.9480 - val_loss: 0.4501 - val_accuracy: 0.8931
Epoch 167/350
391/391 - 25s - loss: 0.1890 - accuracy: 0.9482 - val_loss: 0.4718 - val_accuracy: 0.8901
Epoch 168/350
391/391 - 25s - loss: 0.1848 - accuracy: 0.9500 - val_loss: 0.4525 - val_accuracy: 0.8984
Epoch 169/350
391/391 - 25s - loss: 0.1843 - accuracy: 0.9503 - val_loss: 0.4546 - val_accuracy: 0.8937
Epoch 170/350
391/391 - 25s - loss: 0.1826 - accuracy: 0.9503 - val_loss: 0.4952 - val_accuracy: 0.8917
Epoch 171/350
391/391 - 25s - loss: 0.1844 - accuracy: 0.9500 - val_loss: 0.4245 - val_accuracy: 0.8994
Epoch 172/350
391/391 - 25s - loss: 0.1840 - accuracy: 0.9496 - val_loss: 0.4577 - val_accuracy: 0.8953
Epoch 173/350
391/391 - 25s - loss: 0.1864 - accuracy: 0.9494 - val_loss: 0.4565 - val_accuracy: 0.8933
Epoch 174/350
391/391 - 25s - loss: 0.1798 - accuracy: 0.9525 - val_loss: 0.4342 - val_accuracy: 0.8988
Epoch 175/350
391/391 - 25s - loss: 0.1779 - accuracy: 0.9524 - val_loss: 0.4271 - val_accuracy: 0.8972
Epoch 176/350
391/391 - 25s - loss: 0.1773 - accuracy: 0.9529 - val_loss: 0.4423 - val_accuracy: 0.8975
Epoch 177/350
391/391 - 25s - loss: 0.1819 - accuracy: 0.9514 - val_loss: 0.4488 - val_accuracy: 0.8931
Epoch 178/350
391/391 - 25s - loss: 0.1820 - accuracy: 0.9502 - val_loss: 0.4546 - val_accuracy: 0.8972
Epoch 179/350
391/391 - 25s - loss: 0.1769 - accuracy: 0.9531 - val_loss: 0.4376 - val_accuracy: 0.8992
Epoch 180/350
391/391 - 25s - loss: 0.1742 - accuracy: 0.9533 - val_loss: 0.4513 - val_accuracy: 0.8980
Epoch 181/350
391/391 - 26s - loss: 0.1779 - accuracy: 0.9523 - val_loss: 0.4590 - val_accuracy: 0.8965
Epoch 182/350
391/391 - 25s - loss: 0.1749 - accuracy: 0.9543 - val_loss: 0.4604 - val_accuracy: 0.8972
Epoch 183/350
391/391 - 25s - loss: 0.1763 - accuracy: 0.9542 - val_loss: 0.4337 - val_accuracy: 0.8992
Epoch 184/350
391/391 - 25s - loss: 0.1743 - accuracy: 0.9549 - val_loss: 0.4574 - val_accuracy: 0.8974
Epoch 185/350
391/391 - 25s - loss: 0.1793 - accuracy: 0.9524 - val_loss: 0.4815 - val_accuracy: 0.8917
Epoch 186/350
391/391 - 25s - loss: 0.1738 - accuracy: 0.9541 - val_loss: 0.5093 - val_accuracy: 0.8909
Epoch 187/350
391/391 - 25s - loss: 0.1736 - accuracy: 0.9547 - val_loss: 0.4501 - val_accuracy: 0.9004
Epoch 188/350
391/391 - 25s - loss: 0.1717 - accuracy: 0.9541 - val_loss: 0.4619 - val_accuracy: 0.8985
Epoch 189/350
391/391 - 25s - loss: 0.1751 - accuracy: 0.9529 - val_loss: 0.4812 - val_accuracy: 0.8945
Epoch 190/350
391/391 - 25s - loss: 0.1711 - accuracy: 0.9558 - val_loss: 0.4641 - val_accuracy: 0.8954
Epoch 191/350
391/391 - 25s - loss: 0.1700 - accuracy: 0.9558 - val_loss: 0.4638 - val_accuracy: 0.8978
Epoch 192/350
391/391 - 25s - loss: 0.1701 - accuracy: 0.9560 - val_loss: 0.4480 - val_accuracy: 0.8975
Epoch 193/350
391/391 - 25s - loss: 0.1751 - accuracy: 0.9539 - val_loss: 0.5290 - val_accuracy: 0.8904
Epoch 194/350
391/391 - 25s - loss: 0.1730 - accuracy: 0.9546 - val_loss: 0.4563 - val_accuracy: 0.8991
Epoch 195/350
391/391 - 25s - loss: 0.1651 - accuracy: 0.9578 - val_loss: 0.4757 - val_accuracy: 0.8924
Epoch 196/350
391/391 - 25s - loss: 0.1720 - accuracy: 0.9567 - val_loss: 0.4973 - val_accuracy: 0.8925
Epoch 197/350
391/391 - 25s - loss: 0.1656 - accuracy: 0.9566 - val_loss: 0.4779 - val_accuracy: 0.8963
Epoch 198/350
391/391 - 25s - loss: 0.1664 - accuracy: 0.9576 - val_loss: 0.4624 - val_accuracy: 0.8967
Epoch 199/350
391/391 - 25s - loss: 0.1693 - accuracy: 0.9572 - val_loss: 0.4509 - val_accuracy: 0.9007
Epoch 200/350


Snapshot weight 0 shuffle 7 at epoch 200
Layer 11
Getting activations...


391/391 - 26s - loss: 0.1655 - accuracy: 0.9579 - val_loss: 0.4712 - val_accuracy: 0.8949
Epoch 201/350
391/391 - 25s - loss: 0.1417 - accuracy: 0.9659 - val_loss: 0.4529 - val_accuracy: 0.9034
Epoch 202/350
391/391 - 25s - loss: 0.1294 - accuracy: 0.9702 - val_loss: 0.4610 - val_accuracy: 0.9044
Epoch 203/350
391/391 - 26s - loss: 0.1249 - accuracy: 0.9728 - val_loss: 0.4583 - val_accuracy: 0.9051
Epoch 204/350
391/391 - 25s - loss: 0.1229 - accuracy: 0.9724 - val_loss: 0.4609 - val_accuracy: 0.9064
Epoch 205/350
391/391 - 25s - loss: 0.1211 - accuracy: 0.9739 - val_loss: 0.4609 - val_accuracy: 0.9064
Epoch 206/350
391/391 - 25s - loss: 0.1190 - accuracy: 0.9745 - val_loss: 0.4592 - val_accuracy: 0.9068
Epoch 207/350
391/391 - 25s - loss: 0.1204 - accuracy: 0.9735 - val_loss: 0.4686 - val_accuracy: 0.9047
Epoch 208/350
391/391 - 25s - loss: 0.1191 - accuracy: 0.9740 - val_loss: 0.4656 - val_accuracy: 0.9087
Epoch 209/350
391/391 - 25s - loss: 0.1158 - accuracy: 0.9751 - val_loss: 0.4692 - val_accuracy: 0.9072
Epoch 210/350
391/391 - 25s - loss: 0.1173 - accuracy: 0.9746 - val_loss: 0.4706 - val_accuracy: 0.9078
Epoch 211/350
391/391 - 25s - loss: 0.1161 - accuracy: 0.9754 - val_loss: 0.4758 - val_accuracy: 0.9071
Epoch 212/350
391/391 - 25s - loss: 0.1122 - accuracy: 0.9762 - val_loss: 0.4753 - val_accuracy: 0.9072
Epoch 213/350
391/391 - 25s - loss: 0.1132 - accuracy: 0.9756 - val_loss: 0.4777 - val_accuracy: 0.9081
Epoch 214/350
391/391 - 25s - loss: 0.1138 - accuracy: 0.9764 - val_loss: 0.4781 - val_accuracy: 0.9076
Epoch 215/350
391/391 - 25s - loss: 0.1136 - accuracy: 0.9753 - val_loss: 0.4774 - val_accuracy: 0.9095
Epoch 216/350
391/391 - 25s - loss: 0.1141 - accuracy: 0.9759 - val_loss: 0.4767 - val_accuracy: 0.9075
Epoch 217/350
391/391 - 25s - loss: 0.1139 - accuracy: 0.9753 - val_loss: 0.4722 - val_accuracy: 0.9091
Epoch 218/350
391/391 - 25s - loss: 0.1127 - accuracy: 0.9763 - val_loss: 0.4851 - val_accuracy: 0.9077
Epoch 219/350
391/391 - 25s - loss: 0.1112 - accuracy: 0.9768 - val_loss: 0.4816 - val_accuracy: 0.9088
Epoch 220/350
391/391 - 25s - loss: 0.1100 - accuracy: 0.9766 - val_loss: 0.4881 - val_accuracy: 0.9086
Epoch 221/350
391/391 - 25s - loss: 0.1129 - accuracy: 0.9762 - val_loss: 0.4786 - val_accuracy: 0.9096
Epoch 222/350
391/391 - 25s - loss: 0.1112 - accuracy: 0.9762 - val_loss: 0.4841 - val_accuracy: 0.9085
Epoch 223/350
391/391 - 25s - loss: 0.1095 - accuracy: 0.9773 - val_loss: 0.4950 - val_accuracy: 0.9076
Epoch 224/350
391/391 - 25s - loss: 0.1101 - accuracy: 0.9777 - val_loss: 0.4968 - val_accuracy: 0.9054
Epoch 225/350
391/391 - 25s - loss: 0.1106 - accuracy: 0.9770 - val_loss: 0.4810 - val_accuracy: 0.9088
Epoch 226/350
391/391 - 25s - loss: 0.1082 - accuracy: 0.9776 - val_loss: 0.4882 - val_accuracy: 0.9076
Epoch 227/350
391/391 - 25s - loss: 0.1080 - accuracy: 0.9779 - val_loss: 0.4890 - val_accuracy: 0.9082
Epoch 228/350
391/391 - 25s - loss: 0.1112 - accuracy: 0.9770 - val_loss: 0.4886 - val_accuracy: 0.9064
Epoch 229/350
391/391 - 25s - loss: 0.1086 - accuracy: 0.9778 - val_loss: 0.4884 - val_accuracy: 0.9091
Epoch 230/350
391/391 - 25s - loss: 0.1114 - accuracy: 0.9767 - val_loss: 0.4782 - val_accuracy: 0.9094
Epoch 231/350
391/391 - 25s - loss: 0.1090 - accuracy: 0.9776 - val_loss: 0.4899 - val_accuracy: 0.9080
Epoch 232/350
391/391 - 25s - loss: 0.1088 - accuracy: 0.9779 - val_loss: 0.4920 - val_accuracy: 0.9062
Epoch 233/350
391/391 - 25s - loss: 0.1090 - accuracy: 0.9772 - val_loss: 0.4856 - val_accuracy: 0.9091
Epoch 234/350
391/391 - 25s - loss: 0.1078 - accuracy: 0.9781 - val_loss: 0.5021 - val_accuracy: 0.9077
Epoch 235/350
391/391 - 25s - loss: 0.1095 - accuracy: 0.9770 - val_loss: 0.4881 - val_accuracy: 0.9080
Epoch 236/350
391/391 - 26s - loss: 0.1071 - accuracy: 0.9778 - val_loss: 0.4917 - val_accuracy: 0.9092
Epoch 237/350
391/391 - 25s - loss: 0.1081 - accuracy: 0.9779 - val_loss: 0.4959 - val_accuracy: 0.9090
Epoch 238/350
391/391 - 25s - loss: 0.1084 - accuracy: 0.9780 - val_loss: 0.4967 - val_accuracy: 0.9082
Epoch 239/350
391/391 - 25s - loss: 0.1095 - accuracy: 0.9771 - val_loss: 0.4910 - val_accuracy: 0.9084
Epoch 240/350
391/391 - 25s - loss: 0.1064 - accuracy: 0.9783 - val_loss: 0.4973 - val_accuracy: 0.9082
Epoch 241/350
391/391 - 25s - loss: 0.1067 - accuracy: 0.9785 - val_loss: 0.4909 - val_accuracy: 0.9084
Epoch 242/350
391/391 - 25s - loss: 0.1059 - accuracy: 0.9793 - val_loss: 0.4893 - val_accuracy: 0.9074
Epoch 243/350
391/391 - 25s - loss: 0.1093 - accuracy: 0.9778 - val_loss: 0.4953 - val_accuracy: 0.9070
Epoch 244/350
391/391 - 25s - loss: 0.1091 - accuracy: 0.9776 - val_loss: 0.4948 - val_accuracy: 0.9089
Epoch 245/350
391/391 - 25s - loss: 0.1056 - accuracy: 0.9796 - val_loss: 0.4986 - val_accuracy: 0.9082
Epoch 246/350
391/391 - 25s - loss: 0.1049 - accuracy: 0.9795 - val_loss: 0.5032 - val_accuracy: 0.9059
Epoch 247/350
391/391 - 25s - loss: 0.1041 - accuracy: 0.9792 - val_loss: 0.5116 - val_accuracy: 0.9059
Epoch 248/350
391/391 - 25s - loss: 0.1049 - accuracy: 0.9789 - val_loss: 0.4987 - val_accuracy: 0.9075
Epoch 249/350
391/391 - 25s - loss: 0.1063 - accuracy: 0.9790 - val_loss: 0.5007 - val_accuracy: 0.9071
Epoch 250/350


Snapshot weight 0 shuffle 7 at epoch 250
Layer 11
Getting activations...


391/391 - 26s - loss: 0.1048 - accuracy: 0.9790 - val_loss: 0.5111 - val_accuracy: 0.9066
Epoch 251/350
391/391 - 25s - loss: 0.1040 - accuracy: 0.9796 - val_loss: 0.5009 - val_accuracy: 0.9080
Epoch 252/350
391/391 - 25s - loss: 0.1040 - accuracy: 0.9791 - val_loss: 0.5001 - val_accuracy: 0.9079
Epoch 253/350
391/391 - 25s - loss: 0.1024 - accuracy: 0.9796 - val_loss: 0.4992 - val_accuracy: 0.9078
Epoch 254/350
391/391 - 25s - loss: 0.1015 - accuracy: 0.9805 - val_loss: 0.4996 - val_accuracy: 0.9075
Epoch 255/350
391/391 - 25s - loss: 0.1011 - accuracy: 0.9803 - val_loss: 0.5006 - val_accuracy: 0.9072
Epoch 256/350
391/391 - 26s - loss: 0.1023 - accuracy: 0.9802 - val_loss: 0.4989 - val_accuracy: 0.9079
Epoch 257/350
391/391 - 25s - loss: 0.1040 - accuracy: 0.9798 - val_loss: 0.4990 - val_accuracy: 0.9086
Epoch 258/350
391/391 - 25s - loss: 0.1024 - accuracy: 0.9796 - val_loss: 0.4997 - val_accuracy: 0.9076
Epoch 259/350
391/391 - 25s - loss: 0.1031 - accuracy: 0.9790 - val_loss: 0.4997 - val_accuracy: 0.9070
Epoch 260/350
391/391 - 25s - loss: 0.1024 - accuracy: 0.9802 - val_loss: 0.4976 - val_accuracy: 0.9079
Epoch 261/350
391/391 - 25s - loss: 0.1024 - accuracy: 0.9797 - val_loss: 0.4984 - val_accuracy: 0.9082
Epoch 262/350
391/391 - 25s - loss: 0.1003 - accuracy: 0.9804 - val_loss: 0.4984 - val_accuracy: 0.9081
Epoch 263/350
391/391 - 25s - loss: 0.1030 - accuracy: 0.9799 - val_loss: 0.4963 - val_accuracy: 0.9083
Epoch 264/350
391/391 - 25s - loss: 0.1007 - accuracy: 0.9811 - val_loss: 0.5010 - val_accuracy: 0.9075
Epoch 265/350
391/391 - 25s - loss: 0.1042 - accuracy: 0.9789 - val_loss: 0.5007 - val_accuracy: 0.9078
Epoch 266/350
391/391 - 25s - loss: 0.0992 - accuracy: 0.9816 - val_loss: 0.5016 - val_accuracy: 0.9083
Epoch 267/350
391/391 - 25s - loss: 0.1027 - accuracy: 0.9799 - val_loss: 0.5013 - val_accuracy: 0.9080
Epoch 268/350
391/391 - 25s - loss: 0.0996 - accuracy: 0.9808 - val_loss: 0.5029 - val_accuracy: 0.9078
Epoch 269/350
391/391 - 25s - loss: 0.1001 - accuracy: 0.9806 - val_loss: 0.5015 - val_accuracy: 0.9081
Epoch 270/350
391/391 - 25s - loss: 0.1011 - accuracy: 0.9811 - val_loss: 0.5008 - val_accuracy: 0.9081
Epoch 271/350
391/391 - 25s - loss: 0.1031 - accuracy: 0.9791 - val_loss: 0.5004 - val_accuracy: 0.9085
Epoch 272/350
391/391 - 25s - loss: 0.0996 - accuracy: 0.9815 - val_loss: 0.5018 - val_accuracy: 0.9075
Epoch 273/350
391/391 - 25s - loss: 0.1004 - accuracy: 0.9808 - val_loss: 0.5009 - val_accuracy: 0.9080
Epoch 274/350
391/391 - 25s - loss: 0.1027 - accuracy: 0.9791 - val_loss: 0.5007 - val_accuracy: 0.9085
Epoch 275/350
391/391 - 25s - loss: 0.0986 - accuracy: 0.9817 - val_loss: 0.5023 - val_accuracy: 0.9075
Epoch 276/350
391/391 - 25s - loss: 0.1024 - accuracy: 0.9794 - val_loss: 0.5029 - val_accuracy: 0.9073
Epoch 277/350
391/391 - 26s - loss: 0.1004 - accuracy: 0.9804 - val_loss: 0.5032 - val_accuracy: 0.9080
Epoch 278/350
391/391 - 25s - loss: 0.1009 - accuracy: 0.9807 - val_loss: 0.5022 - val_accuracy: 0.9083
Epoch 279/350
391/391 - 25s - loss: 0.1022 - accuracy: 0.9795 - val_loss: 0.5022 - val_accuracy: 0.9080
Epoch 280/350
391/391 - 25s - loss: 0.1013 - accuracy: 0.9802 - val_loss: 0.5020 - val_accuracy: 0.9078
Epoch 281/350
391/391 - 25s - loss: 0.1022 - accuracy: 0.9799 - val_loss: 0.5021 - val_accuracy: 0.9075
Epoch 282/350
391/391 - 25s - loss: 0.1017 - accuracy: 0.9796 - val_loss: 0.5009 - val_accuracy: 0.9075
Epoch 283/350
391/391 - 25s - loss: 0.1012 - accuracy: 0.9804 - val_loss: 0.5019 - val_accuracy: 0.9080
Epoch 284/350
391/391 - 25s - loss: 0.1014 - accuracy: 0.9801 - val_loss: 0.5032 - val_accuracy: 0.9072
Epoch 285/350
391/391 - 26s - loss: 0.1000 - accuracy: 0.9810 - val_loss: 0.5012 - val_accuracy: 0.9081
Epoch 286/350
391/391 - 25s - loss: 0.1016 - accuracy: 0.9804 - val_loss: 0.5017 - val_accuracy: 0.9081
Epoch 287/350
391/391 - 25s - loss: 0.0989 - accuracy: 0.9810 - val_loss: 0.5041 - val_accuracy: 0.9076
Epoch 288/350
391/391 - 25s - loss: 0.1006 - accuracy: 0.9808 - val_loss: 0.5048 - val_accuracy: 0.9077
Epoch 289/350
391/391 - 25s - loss: 0.1018 - accuracy: 0.9802 - val_loss: 0.5037 - val_accuracy: 0.9080
Epoch 290/350
391/391 - 25s - loss: 0.0997 - accuracy: 0.9815 - val_loss: 0.5046 - val_accuracy: 0.9078
Epoch 291/350
391/391 - 25s - loss: 0.1002 - accuracy: 0.9804 - val_loss: 0.5025 - val_accuracy: 0.9079
Epoch 292/350
391/391 - 26s - loss: 0.0994 - accuracy: 0.9809 - val_loss: 0.5042 - val_accuracy: 0.9076
Epoch 293/350
391/391 - 25s - loss: 0.1017 - accuracy: 0.9802 - val_loss: 0.5016 - val_accuracy: 0.9085
Epoch 294/350
391/391 - 25s - loss: 0.1012 - accuracy: 0.9797 - val_loss: 0.5011 - val_accuracy: 0.9082
Epoch 295/350
391/391 - 25s - loss: 0.0992 - accuracy: 0.9807 - val_loss: 0.5024 - val_accuracy: 0.9077
Epoch 296/350
391/391 - 25s - loss: 0.1004 - accuracy: 0.9809 - val_loss: 0.5019 - val_accuracy: 0.9084
Epoch 297/350
391/391 - 25s - loss: 0.1017 - accuracy: 0.9802 - val_loss: 0.5024 - val_accuracy: 0.9086
Epoch 298/350
391/391 - 25s - loss: 0.1026 - accuracy: 0.9795 - val_loss: 0.5033 - val_accuracy: 0.9082
Epoch 299/350
391/391 - 25s - loss: 0.1005 - accuracy: 0.9803 - val_loss: 0.5030 - val_accuracy: 0.9084
Epoch 300/350


Snapshot weight 0 shuffle 7 at epoch 300
Layer 11
Getting activations...


391/391 - 26s - loss: 0.1006 - accuracy: 0.9806 - val_loss: 0.5026 - val_accuracy: 0.9077
Epoch 301/350
391/391 - 25s - loss: 0.1013 - accuracy: 0.9805 - val_loss: 0.5024 - val_accuracy: 0.9079
Epoch 302/350
391/391 - 25s - loss: 0.1007 - accuracy: 0.9805 - val_loss: 0.5030 - val_accuracy: 0.9078
Epoch 303/350
391/391 - 26s - loss: 0.1008 - accuracy: 0.9809 - val_loss: 0.5030 - val_accuracy: 0.9078
Epoch 304/350
391/391 - 25s - loss: 0.0985 - accuracy: 0.9803 - val_loss: 0.5030 - val_accuracy: 0.9083
Epoch 305/350
391/391 - 25s - loss: 0.0998 - accuracy: 0.9811 - val_loss: 0.5031 - val_accuracy: 0.9084
Epoch 306/350
391/391 - 25s - loss: 0.0997 - accuracy: 0.9808 - val_loss: 0.5033 - val_accuracy: 0.9081
Epoch 307/350
391/391 - 25s - loss: 0.1008 - accuracy: 0.9811 - val_loss: 0.5032 - val_accuracy: 0.9082
Epoch 308/350
391/391 - 25s - loss: 0.1004 - accuracy: 0.9801 - val_loss: 0.5034 - val_accuracy: 0.9079
Epoch 309/350
391/391 - 25s - loss: 0.0994 - accuracy: 0.9802 - val_loss: 0.5034 - val_accuracy: 0.9079
Epoch 310/350
391/391 - 26s - loss: 0.0989 - accuracy: 0.9812 - val_loss: 0.5036 - val_accuracy: 0.9077
Epoch 311/350
391/391 - 25s - loss: 0.0992 - accuracy: 0.9808 - val_loss: 0.5040 - val_accuracy: 0.9082
Epoch 312/350
391/391 - 25s - loss: 0.1013 - accuracy: 0.9804 - val_loss: 0.5038 - val_accuracy: 0.9081
Epoch 313/350
391/391 - 25s - loss: 0.0998 - accuracy: 0.9809 - val_loss: 0.5040 - val_accuracy: 0.9077
Epoch 314/350
391/391 - 25s - loss: 0.0997 - accuracy: 0.9811 - val_loss: 0.5042 - val_accuracy: 0.9077
Epoch 315/350
391/391 - 25s - loss: 0.1017 - accuracy: 0.9803 - val_loss: 0.5044 - val_accuracy: 0.9076
Epoch 316/350
391/391 - 25s - loss: 0.1024 - accuracy: 0.9797 - val_loss: 0.5045 - val_accuracy: 0.9078
Epoch 317/350
391/391 - 25s - loss: 0.1011 - accuracy: 0.9804 - val_loss: 0.5047 - val_accuracy: 0.9079
Epoch 318/350
391/391 - 25s - loss: 0.0995 - accuracy: 0.9806 - val_loss: 0.5048 - val_accuracy: 0.9078
Epoch 319/350
391/391 - 26s - loss: 0.1006 - accuracy: 0.9804 - val_loss: 0.5046 - val_accuracy: 0.9080
Epoch 320/350
391/391 - 25s - loss: 0.1005 - accuracy: 0.9812 - val_loss: 0.5043 - val_accuracy: 0.9081
Epoch 321/350
391/391 - 25s - loss: 0.0990 - accuracy: 0.9809 - val_loss: 0.5041 - val_accuracy: 0.9083
Epoch 322/350
391/391 - 26s - loss: 0.0994 - accuracy: 0.9816 - val_loss: 0.5043 - val_accuracy: 0.9080
Epoch 323/350
391/391 - 25s - loss: 0.0992 - accuracy: 0.9805 - val_loss: 0.5045 - val_accuracy: 0.9082
Epoch 324/350
391/391 - 25s - loss: 0.0988 - accuracy: 0.9815 - val_loss: 0.5044 - val_accuracy: 0.9082
Epoch 325/350
391/391 - 25s - loss: 0.1007 - accuracy: 0.9802 - val_loss: 0.5046 - val_accuracy: 0.9079
Epoch 326/350
391/391 - 25s - loss: 0.0985 - accuracy: 0.9813 - val_loss: 0.5044 - val_accuracy: 0.9081
Epoch 327/350
391/391 - 25s - loss: 0.1016 - accuracy: 0.9796 - val_loss: 0.5045 - val_accuracy: 0.9081
Epoch 328/350
391/391 - 25s - loss: 0.0969 - accuracy: 0.9818 - val_loss: 0.5048 - val_accuracy: 0.9081
Epoch 329/350
391/391 - 25s - loss: 0.1004 - accuracy: 0.9809 - val_loss: 0.5046 - val_accuracy: 0.9082
Epoch 330/350
391/391 - 25s - loss: 0.0995 - accuracy: 0.9809 - val_loss: 0.5047 - val_accuracy: 0.9080
Epoch 331/350
391/391 - 25s - loss: 0.0992 - accuracy: 0.9809 - val_loss: 0.5050 - val_accuracy: 0.9082
Epoch 332/350
391/391 - 26s - loss: 0.1017 - accuracy: 0.9804 - val_loss: 0.5048 - val_accuracy: 0.9080
Epoch 333/350
391/391 - 25s - loss: 0.0995 - accuracy: 0.9808 - val_loss: 0.5048 - val_accuracy: 0.9081
Epoch 334/350
391/391 - 25s - loss: 0.0984 - accuracy: 0.9816 - val_loss: 0.5049 - val_accuracy: 0.9081
Epoch 335/350
391/391 - 25s - loss: 0.1009 - accuracy: 0.9802 - val_loss: 0.5045 - val_accuracy: 0.9081
Epoch 336/350
391/391 - 26s - loss: 0.1020 - accuracy: 0.9795 - val_loss: 0.5048 - val_accuracy: 0.9077
Epoch 337/350
391/391 - 25s - loss: 0.1007 - accuracy: 0.9811 - val_loss: 0.5050 - val_accuracy: 0.9078
Epoch 338/350
391/391 - 26s - loss: 0.1017 - accuracy: 0.9801 - val_loss: 0.5048 - val_accuracy: 0.9078
Epoch 339/350
391/391 - 25s - loss: 0.0993 - accuracy: 0.9810 - val_loss: 0.5046 - val_accuracy: 0.9079
Epoch 340/350
391/391 - 26s - loss: 0.0971 - accuracy: 0.9822 - val_loss: 0.5047 - val_accuracy: 0.9078
Epoch 341/350
391/391 - 25s - loss: 0.1013 - accuracy: 0.9804 - val_loss: 0.5047 - val_accuracy: 0.9078
Epoch 342/350
391/391 - 25s - loss: 0.0984 - accuracy: 0.9813 - val_loss: 0.5048 - val_accuracy: 0.9078
Epoch 343/350
391/391 - 25s - loss: 0.1011 - accuracy: 0.9803 - val_loss: 0.5049 - val_accuracy: 0.9077
Epoch 344/350
391/391 - 25s - loss: 0.1016 - accuracy: 0.9802 - val_loss: 0.5047 - val_accuracy: 0.9082
Epoch 345/350
391/391 - 25s - loss: 0.0991 - accuracy: 0.9810 - val_loss: 0.5047 - val_accuracy: 0.9079
Epoch 346/350
391/391 - 25s - loss: 0.0983 - accuracy: 0.9815 - val_loss: 0.5047 - val_accuracy: 0.9081
Epoch 347/350
391/391 - 25s - loss: 0.1002 - accuracy: 0.9802 - val_loss: 0.5046 - val_accuracy: 0.9082
Epoch 348/350
391/391 - 25s - loss: 0.0979 - accuracy: 0.9816 - val_loss: 0.5048 - val_accuracy: 0.9078
Epoch 349/350
391/391 - 26s - loss: 0.1000 - accuracy: 0.9803 - val_loss: 0.5048 - val_accuracy: 0.9083
Epoch 350/350


Snapshot weight 0 shuffle 7 at epoch 350
Layer 11
Getting activations...


391/391 - 26s - loss: 0.1019 - accuracy: 0.9802 - val_loss: 0.5047 - val_accuracy: 0.9081
/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:493: UserWarning: fill_value is not supported and is always 0 for TensorFlow < 2.4.0.
  return py_builtins.overload_of(f)(*args)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-07-02 14:54:49.064388: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
Saving, final validation acc: 0.9081000089645386
