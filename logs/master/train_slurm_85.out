2021-07-02 17:16:41.390061: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 17:18:04.531392: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-07-02 17:18:04.575860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-02 17:18:04.575943: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 17:18:04.620828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-02 17:18:04.642616: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-02 17:18:04.651036: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-02 17:18:04.695414: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-02 17:18:04.703945: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-02 17:18:04.783862: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 17:18:04.787358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-02 17:18:04.791222: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-02 17:18:04.807743: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599865000 Hz
2021-07-02 17:18:04.807912: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5b9cc60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-07-02 17:18:04.807933: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-07-02 17:18:04.980268: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5b7e580 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-07-02 17:18:04.980342: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN X (Pascal), Compute Capability 6.1
2021-07-02 17:18:04.982915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-02 17:18:04.982971: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 17:18:04.983006: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-02 17:18:04.983025: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-02 17:18:04.983043: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-02 17:18:04.983061: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-02 17:18:04.983078: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-02 17:18:04.983785: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 17:18:04.987770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-02 17:18:04.989635: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 17:18:06.829976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-02 17:18:06.830057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-07-02 17:18:06.830071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-07-02 17:18:06.839238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11228 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
2021-07-02 17:18:12.851732: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 17:18:15.441717: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
Using model index: 85
Making train data...
GCN...
ZCA...
Done!
Making test data...
Done!
Epoch 1/350


Snapshot weight 5 shuffle 8 at epoch 1
Layer 11
Getting activations...


391/391 - 25s - loss: 2.3023 - accuracy: 0.1245 - val_loss: 2.2596 - val_accuracy: 0.1644
Epoch 2/350


Snapshot weight 5 shuffle 8 at epoch 2
Layer 11
Getting activations...


391/391 - 25s - loss: 2.1864 - accuracy: 0.1940 - val_loss: 2.0710 - val_accuracy: 0.2459
Epoch 3/350


Snapshot weight 5 shuffle 8 at epoch 3
Layer 11
Getting activations...


391/391 - 26s - loss: 1.9524 - accuracy: 0.2974 - val_loss: 1.8208 - val_accuracy: 0.3516
Epoch 4/350


Snapshot weight 5 shuffle 8 at epoch 4
Layer 11
Getting activations...


391/391 - 25s - loss: 1.7495 - accuracy: 0.3798 - val_loss: 1.5697 - val_accuracy: 0.4603
Epoch 5/350


Snapshot weight 5 shuffle 8 at epoch 5
Layer 11
Getting activations...


391/391 - 25s - loss: 1.5472 - accuracy: 0.4578 - val_loss: 1.3199 - val_accuracy: 0.5533
Epoch 6/350


Snapshot weight 5 shuffle 8 at epoch 6
Layer 11
Getting activations...


391/391 - 25s - loss: 1.3269 - accuracy: 0.5334 - val_loss: 1.1769 - val_accuracy: 0.5949
Epoch 7/350


Snapshot weight 5 shuffle 8 at epoch 7
Layer 11
Getting activations...


391/391 - 25s - loss: 1.2200 - accuracy: 0.5727 - val_loss: 1.1389 - val_accuracy: 0.6065
Epoch 8/350


Snapshot weight 5 shuffle 8 at epoch 8
Layer 11
Getting activations...


391/391 - 26s - loss: 1.1473 - accuracy: 0.6019 - val_loss: 1.0714 - val_accuracy: 0.6276
Epoch 9/350


Snapshot weight 5 shuffle 8 at epoch 9
Layer 11
Getting activations...


391/391 - 25s - loss: 1.1067 - accuracy: 0.6157 - val_loss: 1.0781 - val_accuracy: 0.6220
Epoch 10/350


Snapshot weight 5 shuffle 8 at epoch 10
Layer 11
Getting activations...


391/391 - 25s - loss: 1.0268 - accuracy: 0.6456 - val_loss: 0.9018 - val_accuracy: 0.6854
Epoch 11/350
391/391 - 25s - loss: 0.9842 - accuracy: 0.6615 - val_loss: 0.9112 - val_accuracy: 0.6848
Epoch 12/350
391/391 - 25s - loss: 0.9435 - accuracy: 0.6744 - val_loss: 0.8388 - val_accuracy: 0.7122
Epoch 13/350
391/391 - 25s - loss: 0.9074 - accuracy: 0.6882 - val_loss: 0.8406 - val_accuracy: 0.7135
Epoch 14/350
391/391 - 25s - loss: 0.8674 - accuracy: 0.7039 - val_loss: 0.8072 - val_accuracy: 0.7302
Epoch 15/350
391/391 - 25s - loss: 0.8286 - accuracy: 0.7186 - val_loss: 0.7598 - val_accuracy: 0.7429
Epoch 16/350
391/391 - 25s - loss: 0.8102 - accuracy: 0.7250 - val_loss: 0.7485 - val_accuracy: 0.7494
Epoch 17/350
391/391 - 25s - loss: 0.7680 - accuracy: 0.7423 - val_loss: 0.7089 - val_accuracy: 0.7652
Epoch 18/350
391/391 - 25s - loss: 0.7446 - accuracy: 0.7501 - val_loss: 0.7145 - val_accuracy: 0.7619
Epoch 19/350
391/391 - 25s - loss: 0.7247 - accuracy: 0.7570 - val_loss: 0.6975 - val_accuracy: 0.7686
Epoch 20/350
391/391 - 25s - loss: 0.6983 - accuracy: 0.7676 - val_loss: 0.6349 - val_accuracy: 0.7909
Epoch 21/350
391/391 - 25s - loss: 0.6778 - accuracy: 0.7733 - val_loss: 0.6948 - val_accuracy: 0.7713
Epoch 22/350
391/391 - 25s - loss: 0.6628 - accuracy: 0.7783 - val_loss: 0.6268 - val_accuracy: 0.7957
Epoch 23/350
391/391 - 25s - loss: 0.6529 - accuracy: 0.7833 - val_loss: 0.6736 - val_accuracy: 0.7706
Epoch 24/350
391/391 - 25s - loss: 0.6266 - accuracy: 0.7927 - val_loss: 0.5603 - val_accuracy: 0.8168
Epoch 25/350
391/391 - 25s - loss: 0.6116 - accuracy: 0.7978 - val_loss: 0.5795 - val_accuracy: 0.8100
Epoch 26/350
391/391 - 25s - loss: 0.5978 - accuracy: 0.8026 - val_loss: 0.5686 - val_accuracy: 0.8215
Epoch 27/350
391/391 - 25s - loss: 0.5888 - accuracy: 0.8072 - val_loss: 0.5600 - val_accuracy: 0.8181
Epoch 28/350
391/391 - 25s - loss: 0.5738 - accuracy: 0.8103 - val_loss: 0.5365 - val_accuracy: 0.8272
Epoch 29/350
391/391 - 25s - loss: 0.5641 - accuracy: 0.8148 - val_loss: 0.5724 - val_accuracy: 0.8207
Epoch 30/350
391/391 - 25s - loss: 0.5503 - accuracy: 0.8200 - val_loss: 0.5402 - val_accuracy: 0.8261
Epoch 31/350
391/391 - 25s - loss: 0.5401 - accuracy: 0.8226 - val_loss: 0.5131 - val_accuracy: 0.8314
Epoch 32/350
391/391 - 25s - loss: 0.5308 - accuracy: 0.8264 - val_loss: 0.5220 - val_accuracy: 0.8351
Epoch 33/350
391/391 - 25s - loss: 0.5279 - accuracy: 0.8272 - val_loss: 0.5484 - val_accuracy: 0.8178
Epoch 34/350
391/391 - 25s - loss: 0.5127 - accuracy: 0.8334 - val_loss: 0.4864 - val_accuracy: 0.8461
Epoch 35/350
391/391 - 25s - loss: 0.5035 - accuracy: 0.8345 - val_loss: 0.5294 - val_accuracy: 0.8323
Epoch 36/350
391/391 - 25s - loss: 0.4980 - accuracy: 0.8364 - val_loss: 0.4987 - val_accuracy: 0.8421
Epoch 37/350
391/391 - 25s - loss: 0.4903 - accuracy: 0.8401 - val_loss: 0.4883 - val_accuracy: 0.8435
Epoch 38/350
391/391 - 25s - loss: 0.4826 - accuracy: 0.8427 - val_loss: 0.4780 - val_accuracy: 0.8447
Epoch 39/350
391/391 - 25s - loss: 0.4755 - accuracy: 0.8434 - val_loss: 0.5087 - val_accuracy: 0.8415
Epoch 40/350
391/391 - 25s - loss: 0.4725 - accuracy: 0.8450 - val_loss: 0.4765 - val_accuracy: 0.8482
Epoch 41/350
391/391 - 25s - loss: 0.4609 - accuracy: 0.8506 - val_loss: 0.4779 - val_accuracy: 0.8500
Epoch 42/350
391/391 - 25s - loss: 0.4466 - accuracy: 0.8561 - val_loss: 0.4727 - val_accuracy: 0.8518
Epoch 43/350
391/391 - 25s - loss: 0.4487 - accuracy: 0.8548 - val_loss: 0.4727 - val_accuracy: 0.8544
Epoch 44/350
391/391 - 25s - loss: 0.4448 - accuracy: 0.8561 - val_loss: 0.4775 - val_accuracy: 0.8517
Epoch 45/350
391/391 - 25s - loss: 0.4318 - accuracy: 0.8601 - val_loss: 0.4790 - val_accuracy: 0.8502
Epoch 46/350
391/391 - 25s - loss: 0.4311 - accuracy: 0.8611 - val_loss: 0.5165 - val_accuracy: 0.8416
Epoch 47/350
391/391 - 25s - loss: 0.4236 - accuracy: 0.8632 - val_loss: 0.4411 - val_accuracy: 0.8583
Epoch 48/350
391/391 - 25s - loss: 0.4224 - accuracy: 0.8643 - val_loss: 0.4948 - val_accuracy: 0.8484
Epoch 49/350
391/391 - 25s - loss: 0.4106 - accuracy: 0.8670 - val_loss: 0.4517 - val_accuracy: 0.8606
Epoch 50/350


Snapshot weight 5 shuffle 8 at epoch 50
Layer 11
Getting activations...


391/391 - 25s - loss: 0.4061 - accuracy: 0.8697 - val_loss: 0.4430 - val_accuracy: 0.8612
Epoch 51/350
391/391 - 25s - loss: 0.4037 - accuracy: 0.8702 - val_loss: 0.4386 - val_accuracy: 0.8639
Epoch 52/350
391/391 - 25s - loss: 0.4004 - accuracy: 0.8709 - val_loss: 0.4367 - val_accuracy: 0.8665
Epoch 53/350
391/391 - 25s - loss: 0.3910 - accuracy: 0.8759 - val_loss: 0.4277 - val_accuracy: 0.8675
Epoch 54/350
391/391 - 25s - loss: 0.3871 - accuracy: 0.8773 - val_loss: 0.4501 - val_accuracy: 0.8611
Epoch 55/350
391/391 - 25s - loss: 0.3853 - accuracy: 0.8767 - val_loss: 0.4263 - val_accuracy: 0.8697
Epoch 56/350
391/391 - 25s - loss: 0.3791 - accuracy: 0.8789 - val_loss: 0.4509 - val_accuracy: 0.8582
Epoch 57/350
391/391 - 25s - loss: 0.3794 - accuracy: 0.8788 - val_loss: 0.4980 - val_accuracy: 0.8532
Epoch 58/350
391/391 - 25s - loss: 0.3721 - accuracy: 0.8809 - val_loss: 0.4437 - val_accuracy: 0.8678
Epoch 59/350
391/391 - 25s - loss: 0.3709 - accuracy: 0.8822 - val_loss: 0.4484 - val_accuracy: 0.8603
Epoch 60/350
391/391 - 25s - loss: 0.3635 - accuracy: 0.8859 - val_loss: 0.4409 - val_accuracy: 0.8643
Epoch 61/350
391/391 - 25s - loss: 0.3633 - accuracy: 0.8846 - val_loss: 0.4400 - val_accuracy: 0.8673
Epoch 62/350
391/391 - 25s - loss: 0.3569 - accuracy: 0.8854 - val_loss: 0.4470 - val_accuracy: 0.8648
Epoch 63/350
391/391 - 25s - loss: 0.3593 - accuracy: 0.8863 - val_loss: 0.4199 - val_accuracy: 0.8693
Epoch 64/350
391/391 - 25s - loss: 0.3500 - accuracy: 0.8903 - val_loss: 0.4254 - val_accuracy: 0.8697
Epoch 65/350
391/391 - 25s - loss: 0.3440 - accuracy: 0.8910 - val_loss: 0.4596 - val_accuracy: 0.8683
Epoch 66/350
391/391 - 25s - loss: 0.3424 - accuracy: 0.8910 - val_loss: 0.4503 - val_accuracy: 0.8643
Epoch 67/350
391/391 - 25s - loss: 0.3387 - accuracy: 0.8919 - val_loss: 0.4147 - val_accuracy: 0.8764
Epoch 68/350
391/391 - 25s - loss: 0.3338 - accuracy: 0.8935 - val_loss: 0.4122 - val_accuracy: 0.8756
Epoch 69/350
391/391 - 25s - loss: 0.3344 - accuracy: 0.8937 - val_loss: 0.4300 - val_accuracy: 0.8750
Epoch 70/350
391/391 - 25s - loss: 0.3350 - accuracy: 0.8945 - val_loss: 0.4294 - val_accuracy: 0.8728
Epoch 71/350
391/391 - 25s - loss: 0.3259 - accuracy: 0.8967 - val_loss: 0.4249 - val_accuracy: 0.8785
Epoch 72/350
391/391 - 25s - loss: 0.3226 - accuracy: 0.8992 - val_loss: 0.4282 - val_accuracy: 0.8742
Epoch 73/350
391/391 - 25s - loss: 0.3233 - accuracy: 0.8993 - val_loss: 0.4129 - val_accuracy: 0.8795
Epoch 74/350
391/391 - 25s - loss: 0.3202 - accuracy: 0.9002 - val_loss: 0.4295 - val_accuracy: 0.8717
Epoch 75/350
391/391 - 25s - loss: 0.3145 - accuracy: 0.9003 - val_loss: 0.4038 - val_accuracy: 0.8806
Epoch 76/350
391/391 - 25s - loss: 0.3136 - accuracy: 0.9004 - val_loss: 0.4059 - val_accuracy: 0.8799
Epoch 77/350
391/391 - 25s - loss: 0.3136 - accuracy: 0.9028 - val_loss: 0.4167 - val_accuracy: 0.8780
Epoch 78/350
391/391 - 25s - loss: 0.3080 - accuracy: 0.9030 - val_loss: 0.4682 - val_accuracy: 0.8708
Epoch 79/350
391/391 - 25s - loss: 0.3076 - accuracy: 0.9026 - val_loss: 0.4285 - val_accuracy: 0.8752
Epoch 80/350
391/391 - 25s - loss: 0.2996 - accuracy: 0.9060 - val_loss: 0.4189 - val_accuracy: 0.8792
Epoch 81/350
391/391 - 25s - loss: 0.3032 - accuracy: 0.9053 - val_loss: 0.4548 - val_accuracy: 0.8701
Epoch 82/350
391/391 - 25s - loss: 0.2977 - accuracy: 0.9064 - val_loss: 0.4158 - val_accuracy: 0.8796
Epoch 83/350
391/391 - 25s - loss: 0.3008 - accuracy: 0.9050 - val_loss: 0.4021 - val_accuracy: 0.8833
Epoch 84/350
391/391 - 25s - loss: 0.2910 - accuracy: 0.9104 - val_loss: 0.4110 - val_accuracy: 0.8780
Epoch 85/350
391/391 - 25s - loss: 0.2884 - accuracy: 0.9109 - val_loss: 0.4254 - val_accuracy: 0.8773
Epoch 86/350
391/391 - 25s - loss: 0.2862 - accuracy: 0.9119 - val_loss: 0.4092 - val_accuracy: 0.8814
Epoch 87/350
391/391 - 25s - loss: 0.2819 - accuracy: 0.9129 - val_loss: 0.3997 - val_accuracy: 0.8815
Epoch 88/350
391/391 - 25s - loss: 0.2850 - accuracy: 0.9123 - val_loss: 0.4085 - val_accuracy: 0.8859
Epoch 89/350
391/391 - 25s - loss: 0.2857 - accuracy: 0.9123 - val_loss: 0.4206 - val_accuracy: 0.8798
Epoch 90/350
391/391 - 25s - loss: 0.2793 - accuracy: 0.9148 - val_loss: 0.4233 - val_accuracy: 0.8852
Epoch 91/350
391/391 - 25s - loss: 0.2767 - accuracy: 0.9150 - val_loss: 0.4309 - val_accuracy: 0.8769
Epoch 92/350
391/391 - 25s - loss: 0.2742 - accuracy: 0.9164 - val_loss: 0.4048 - val_accuracy: 0.8846
Epoch 93/350
391/391 - 25s - loss: 0.2683 - accuracy: 0.9184 - val_loss: 0.4160 - val_accuracy: 0.8813
Epoch 94/350
391/391 - 25s - loss: 0.2772 - accuracy: 0.9151 - val_loss: 0.4263 - val_accuracy: 0.8793
Epoch 95/350
391/391 - 25s - loss: 0.2732 - accuracy: 0.9153 - val_loss: 0.4334 - val_accuracy: 0.8766
Epoch 96/350
391/391 - 25s - loss: 0.2733 - accuracy: 0.9157 - val_loss: 0.4018 - val_accuracy: 0.8895
Epoch 97/350
391/391 - 25s - loss: 0.2636 - accuracy: 0.9189 - val_loss: 0.4181 - val_accuracy: 0.8804
Epoch 98/350
391/391 - 25s - loss: 0.2651 - accuracy: 0.9186 - val_loss: 0.4408 - val_accuracy: 0.8778
Epoch 99/350
391/391 - 25s - loss: 0.2630 - accuracy: 0.9203 - val_loss: 0.4245 - val_accuracy: 0.8816
Epoch 100/350


Snapshot weight 5 shuffle 8 at epoch 100
Layer 11
Getting activations...


391/391 - 25s - loss: 0.2601 - accuracy: 0.9205 - val_loss: 0.3936 - val_accuracy: 0.8903
Epoch 101/350
391/391 - 25s - loss: 0.2563 - accuracy: 0.9221 - val_loss: 0.4400 - val_accuracy: 0.8795
Epoch 102/350
391/391 - 25s - loss: 0.2610 - accuracy: 0.9206 - val_loss: 0.4182 - val_accuracy: 0.8854
Epoch 103/350
391/391 - 25s - loss: 0.2528 - accuracy: 0.9252 - val_loss: 0.3990 - val_accuracy: 0.8902
Epoch 104/350
391/391 - 25s - loss: 0.2540 - accuracy: 0.9236 - val_loss: 0.4153 - val_accuracy: 0.8811
Epoch 105/350
391/391 - 25s - loss: 0.2491 - accuracy: 0.9245 - val_loss: 0.4725 - val_accuracy: 0.8713
Epoch 106/350
391/391 - 25s - loss: 0.2544 - accuracy: 0.9228 - val_loss: 0.4050 - val_accuracy: 0.8920
Epoch 107/350
391/391 - 25s - loss: 0.2530 - accuracy: 0.9246 - val_loss: 0.4398 - val_accuracy: 0.8801
Epoch 108/350
391/391 - 25s - loss: 0.2466 - accuracy: 0.9265 - val_loss: 0.4142 - val_accuracy: 0.8930
Epoch 109/350
391/391 - 25s - loss: 0.2461 - accuracy: 0.9271 - val_loss: 0.4403 - val_accuracy: 0.8834
Epoch 110/350
391/391 - 25s - loss: 0.2432 - accuracy: 0.9267 - val_loss: 0.4484 - val_accuracy: 0.8853
Epoch 111/350
391/391 - 25s - loss: 0.2436 - accuracy: 0.9271 - val_loss: 0.4256 - val_accuracy: 0.8912
Epoch 112/350
391/391 - 25s - loss: 0.2392 - accuracy: 0.9290 - val_loss: 0.4225 - val_accuracy: 0.8886
Epoch 113/350
391/391 - 25s - loss: 0.2368 - accuracy: 0.9306 - val_loss: 0.4180 - val_accuracy: 0.8842
Epoch 114/350
391/391 - 25s - loss: 0.2331 - accuracy: 0.9321 - val_loss: 0.4192 - val_accuracy: 0.8901
Epoch 115/350
391/391 - 25s - loss: 0.2402 - accuracy: 0.9296 - val_loss: 0.4227 - val_accuracy: 0.8885
Epoch 116/350
391/391 - 25s - loss: 0.2327 - accuracy: 0.9313 - val_loss: 0.4430 - val_accuracy: 0.8873
Epoch 117/350
391/391 - 25s - loss: 0.2341 - accuracy: 0.9296 - val_loss: 0.4202 - val_accuracy: 0.8880
Epoch 118/350
391/391 - 25s - loss: 0.2341 - accuracy: 0.9307 - val_loss: 0.4275 - val_accuracy: 0.8920
Epoch 119/350
391/391 - 25s - loss: 0.2280 - accuracy: 0.9343 - val_loss: 0.4388 - val_accuracy: 0.8894
Epoch 120/350
391/391 - 25s - loss: 0.2282 - accuracy: 0.9333 - val_loss: 0.4344 - val_accuracy: 0.8881
Epoch 121/350
391/391 - 25s - loss: 0.2321 - accuracy: 0.9312 - val_loss: 0.4454 - val_accuracy: 0.8849
Epoch 122/350
391/391 - 25s - loss: 0.2283 - accuracy: 0.9332 - val_loss: 0.4181 - val_accuracy: 0.8910
Epoch 123/350
391/391 - 25s - loss: 0.2263 - accuracy: 0.9327 - val_loss: 0.4491 - val_accuracy: 0.8859
Epoch 124/350
391/391 - 25s - loss: 0.2248 - accuracy: 0.9339 - val_loss: 0.4272 - val_accuracy: 0.8890
Epoch 125/350
391/391 - 24s - loss: 0.2234 - accuracy: 0.9357 - val_loss: 0.4273 - val_accuracy: 0.8875
Epoch 126/350
391/391 - 25s - loss: 0.2203 - accuracy: 0.9353 - val_loss: 0.4235 - val_accuracy: 0.8934
Epoch 127/350
391/391 - 25s - loss: 0.2237 - accuracy: 0.9341 - val_loss: 0.4237 - val_accuracy: 0.8914
Epoch 128/350
391/391 - 25s - loss: 0.2229 - accuracy: 0.9351 - val_loss: 0.4461 - val_accuracy: 0.8875
Epoch 129/350
391/391 - 25s - loss: 0.2232 - accuracy: 0.9346 - val_loss: 0.4425 - val_accuracy: 0.8859
Epoch 130/350
391/391 - 25s - loss: 0.2172 - accuracy: 0.9376 - val_loss: 0.4146 - val_accuracy: 0.8919
Epoch 131/350
391/391 - 25s - loss: 0.2184 - accuracy: 0.9375 - val_loss: 0.4644 - val_accuracy: 0.8857
Epoch 132/350
391/391 - 25s - loss: 0.2177 - accuracy: 0.9364 - val_loss: 0.4151 - val_accuracy: 0.8894
Epoch 133/350
391/391 - 25s - loss: 0.2148 - accuracy: 0.9373 - val_loss: 0.4543 - val_accuracy: 0.8873
Epoch 134/350
391/391 - 25s - loss: 0.2122 - accuracy: 0.9388 - val_loss: 0.4168 - val_accuracy: 0.8922
Epoch 135/350
391/391 - 25s - loss: 0.2140 - accuracy: 0.9398 - val_loss: 0.4259 - val_accuracy: 0.8886
Epoch 136/350
391/391 - 25s - loss: 0.2141 - accuracy: 0.9378 - val_loss: 0.4568 - val_accuracy: 0.8872
Epoch 137/350
391/391 - 25s - loss: 0.2090 - accuracy: 0.9401 - val_loss: 0.4271 - val_accuracy: 0.8897
Epoch 138/350
391/391 - 25s - loss: 0.2132 - accuracy: 0.9385 - val_loss: 0.4251 - val_accuracy: 0.8935
Epoch 139/350
391/391 - 25s - loss: 0.2084 - accuracy: 0.9408 - val_loss: 0.4594 - val_accuracy: 0.8861
Epoch 140/350
391/391 - 25s - loss: 0.2073 - accuracy: 0.9416 - val_loss: 0.4094 - val_accuracy: 0.8969
Epoch 141/350
391/391 - 25s - loss: 0.2003 - accuracy: 0.9439 - val_loss: 0.4386 - val_accuracy: 0.8923
Epoch 142/350
391/391 - 25s - loss: 0.2025 - accuracy: 0.9431 - val_loss: 0.4615 - val_accuracy: 0.8896
Epoch 143/350
391/391 - 25s - loss: 0.2032 - accuracy: 0.9429 - val_loss: 0.4350 - val_accuracy: 0.8933
Epoch 144/350
391/391 - 25s - loss: 0.1990 - accuracy: 0.9442 - val_loss: 0.4203 - val_accuracy: 0.8957
Epoch 145/350
391/391 - 25s - loss: 0.2053 - accuracy: 0.9425 - val_loss: 0.4239 - val_accuracy: 0.8943
Epoch 146/350
391/391 - 25s - loss: 0.2012 - accuracy: 0.9429 - val_loss: 0.4740 - val_accuracy: 0.8892
Epoch 147/350
391/391 - 25s - loss: 0.2009 - accuracy: 0.9428 - val_loss: 0.4154 - val_accuracy: 0.8946
Epoch 148/350
391/391 - 25s - loss: 0.2006 - accuracy: 0.9442 - val_loss: 0.4603 - val_accuracy: 0.8911
Epoch 149/350
391/391 - 25s - loss: 0.1978 - accuracy: 0.9442 - val_loss: 0.4190 - val_accuracy: 0.8980
Epoch 150/350


Snapshot weight 5 shuffle 8 at epoch 150
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1948 - accuracy: 0.9460 - val_loss: 0.4806 - val_accuracy: 0.8883
Epoch 151/350
391/391 - 25s - loss: 0.2045 - accuracy: 0.9420 - val_loss: 0.4621 - val_accuracy: 0.8878
Epoch 152/350
391/391 - 25s - loss: 0.1954 - accuracy: 0.9463 - val_loss: 0.4806 - val_accuracy: 0.8867
Epoch 153/350
391/391 - 25s - loss: 0.1927 - accuracy: 0.9475 - val_loss: 0.4260 - val_accuracy: 0.8979
Epoch 154/350
391/391 - 25s - loss: 0.1966 - accuracy: 0.9448 - val_loss: 0.4676 - val_accuracy: 0.8881
Epoch 155/350
391/391 - 25s - loss: 0.1979 - accuracy: 0.9441 - val_loss: 0.4321 - val_accuracy: 0.8936
Epoch 156/350
391/391 - 25s - loss: 0.1922 - accuracy: 0.9465 - val_loss: 0.4202 - val_accuracy: 0.8975
Epoch 157/350
391/391 - 25s - loss: 0.1903 - accuracy: 0.9475 - val_loss: 0.4267 - val_accuracy: 0.8930
Epoch 158/350
391/391 - 25s - loss: 0.1885 - accuracy: 0.9474 - val_loss: 0.4742 - val_accuracy: 0.8946
Epoch 159/350
391/391 - 25s - loss: 0.1898 - accuracy: 0.9486 - val_loss: 0.4406 - val_accuracy: 0.8933
Epoch 160/350
391/391 - 25s - loss: 0.1882 - accuracy: 0.9479 - val_loss: 0.4932 - val_accuracy: 0.8862
Epoch 161/350
391/391 - 25s - loss: 0.1877 - accuracy: 0.9491 - val_loss: 0.4386 - val_accuracy: 0.8935
Epoch 162/350
391/391 - 25s - loss: 0.1892 - accuracy: 0.9489 - val_loss: 0.4678 - val_accuracy: 0.8953
Epoch 163/350
391/391 - 25s - loss: 0.1904 - accuracy: 0.9469 - val_loss: 0.4805 - val_accuracy: 0.8894
Epoch 164/350
391/391 - 25s - loss: 0.1889 - accuracy: 0.9481 - val_loss: 0.4664 - val_accuracy: 0.8906
Epoch 165/350
391/391 - 25s - loss: 0.1874 - accuracy: 0.9479 - val_loss: 0.4532 - val_accuracy: 0.8907
Epoch 166/350
391/391 - 25s - loss: 0.1822 - accuracy: 0.9505 - val_loss: 0.4399 - val_accuracy: 0.8953
Epoch 167/350
391/391 - 25s - loss: 0.1858 - accuracy: 0.9492 - val_loss: 0.4763 - val_accuracy: 0.8956
Epoch 168/350
391/391 - 25s - loss: 0.1877 - accuracy: 0.9488 - val_loss: 0.4432 - val_accuracy: 0.8969
Epoch 169/350
391/391 - 25s - loss: 0.1889 - accuracy: 0.9491 - val_loss: 0.4517 - val_accuracy: 0.8981
Epoch 170/350
391/391 - 25s - loss: 0.1828 - accuracy: 0.9489 - val_loss: 0.4622 - val_accuracy: 0.8923
Epoch 171/350
391/391 - 25s - loss: 0.1838 - accuracy: 0.9508 - val_loss: 0.4924 - val_accuracy: 0.8927
Epoch 172/350
391/391 - 25s - loss: 0.1851 - accuracy: 0.9494 - val_loss: 0.4727 - val_accuracy: 0.8957
Epoch 173/350
391/391 - 25s - loss: 0.1832 - accuracy: 0.9500 - val_loss: 0.4456 - val_accuracy: 0.8931
Epoch 174/350
391/391 - 25s - loss: 0.1780 - accuracy: 0.9516 - val_loss: 0.4515 - val_accuracy: 0.8966
Epoch 175/350
391/391 - 25s - loss: 0.1776 - accuracy: 0.9527 - val_loss: 0.4861 - val_accuracy: 0.8893
Epoch 176/350
391/391 - 25s - loss: 0.1741 - accuracy: 0.9540 - val_loss: 0.4803 - val_accuracy: 0.8894
Epoch 177/350
391/391 - 25s - loss: 0.1790 - accuracy: 0.9520 - val_loss: 0.4369 - val_accuracy: 0.8979
Epoch 178/350
391/391 - 25s - loss: 0.1763 - accuracy: 0.9538 - val_loss: 0.4190 - val_accuracy: 0.9012
Epoch 179/350
391/391 - 25s - loss: 0.1740 - accuracy: 0.9541 - val_loss: 0.4871 - val_accuracy: 0.8871
Epoch 180/350
391/391 - 25s - loss: 0.1770 - accuracy: 0.9531 - val_loss: 0.4386 - val_accuracy: 0.8934
Epoch 181/350
391/391 - 25s - loss: 0.1739 - accuracy: 0.9533 - val_loss: 0.4835 - val_accuracy: 0.8932
Epoch 182/350
391/391 - 25s - loss: 0.1790 - accuracy: 0.9519 - val_loss: 0.4904 - val_accuracy: 0.8895
Epoch 183/350
391/391 - 25s - loss: 0.1771 - accuracy: 0.9537 - val_loss: 0.4934 - val_accuracy: 0.8923
Epoch 184/350
391/391 - 25s - loss: 0.1781 - accuracy: 0.9522 - val_loss: 0.4558 - val_accuracy: 0.8969
Epoch 185/350
391/391 - 25s - loss: 0.1749 - accuracy: 0.9536 - val_loss: 0.4829 - val_accuracy: 0.8961
Epoch 186/350
391/391 - 25s - loss: 0.1728 - accuracy: 0.9549 - val_loss: 0.4514 - val_accuracy: 0.8960
Epoch 187/350
391/391 - 25s - loss: 0.1741 - accuracy: 0.9544 - val_loss: 0.4746 - val_accuracy: 0.8957
Epoch 188/350
391/391 - 25s - loss: 0.1707 - accuracy: 0.9561 - val_loss: 0.4729 - val_accuracy: 0.8964
Epoch 189/350
391/391 - 25s - loss: 0.1690 - accuracy: 0.9562 - val_loss: 0.4352 - val_accuracy: 0.8990
Epoch 190/350
391/391 - 25s - loss: 0.1675 - accuracy: 0.9563 - val_loss: 0.4590 - val_accuracy: 0.8977
Epoch 191/350
391/391 - 25s - loss: 0.1775 - accuracy: 0.9539 - val_loss: 0.4638 - val_accuracy: 0.9010
Epoch 192/350
391/391 - 25s - loss: 0.1674 - accuracy: 0.9567 - val_loss: 0.4765 - val_accuracy: 0.8929
Epoch 193/350
391/391 - 25s - loss: 0.1676 - accuracy: 0.9568 - val_loss: 0.4677 - val_accuracy: 0.8964
Epoch 194/350
391/391 - 25s - loss: 0.1691 - accuracy: 0.9560 - val_loss: 0.4624 - val_accuracy: 0.8974
Epoch 195/350
391/391 - 25s - loss: 0.1674 - accuracy: 0.9564 - val_loss: 0.4739 - val_accuracy: 0.8964
Epoch 196/350
391/391 - 25s - loss: 0.1671 - accuracy: 0.9565 - val_loss: 0.4524 - val_accuracy: 0.8991
Epoch 197/350
391/391 - 25s - loss: 0.1662 - accuracy: 0.9578 - val_loss: 0.4519 - val_accuracy: 0.8927
Epoch 198/350
391/391 - 25s - loss: 0.1644 - accuracy: 0.9586 - val_loss: 0.4963 - val_accuracy: 0.8934
Epoch 199/350
391/391 - 25s - loss: 0.1637 - accuracy: 0.9592 - val_loss: 0.4574 - val_accuracy: 0.9004
Epoch 200/350


Snapshot weight 5 shuffle 8 at epoch 200
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1669 - accuracy: 0.9569 - val_loss: 0.4394 - val_accuracy: 0.8991
Epoch 201/350
391/391 - 25s - loss: 0.1398 - accuracy: 0.9670 - val_loss: 0.4344 - val_accuracy: 0.9065
Epoch 202/350
391/391 - 25s - loss: 0.1262 - accuracy: 0.9722 - val_loss: 0.4540 - val_accuracy: 0.9077
Epoch 203/350
391/391 - 25s - loss: 0.1233 - accuracy: 0.9730 - val_loss: 0.4512 - val_accuracy: 0.9060
Epoch 204/350
391/391 - 25s - loss: 0.1229 - accuracy: 0.9732 - val_loss: 0.4574 - val_accuracy: 0.9086
Epoch 205/350
391/391 - 25s - loss: 0.1236 - accuracy: 0.9723 - val_loss: 0.4643 - val_accuracy: 0.9074
Epoch 206/350
391/391 - 25s - loss: 0.1191 - accuracy: 0.9743 - val_loss: 0.4591 - val_accuracy: 0.9071
Epoch 207/350
391/391 - 25s - loss: 0.1214 - accuracy: 0.9737 - val_loss: 0.4680 - val_accuracy: 0.9078
Epoch 208/350
391/391 - 25s - loss: 0.1179 - accuracy: 0.9750 - val_loss: 0.4639 - val_accuracy: 0.9074
Epoch 209/350
391/391 - 25s - loss: 0.1190 - accuracy: 0.9735 - val_loss: 0.4682 - val_accuracy: 0.9064
Epoch 210/350
391/391 - 25s - loss: 0.1172 - accuracy: 0.9747 - val_loss: 0.4705 - val_accuracy: 0.9078
Epoch 211/350
391/391 - 25s - loss: 0.1175 - accuracy: 0.9744 - val_loss: 0.4777 - val_accuracy: 0.9066
Epoch 212/350
391/391 - 25s - loss: 0.1137 - accuracy: 0.9762 - val_loss: 0.4723 - val_accuracy: 0.9070
Epoch 213/350
391/391 - 25s - loss: 0.1173 - accuracy: 0.9741 - val_loss: 0.4642 - val_accuracy: 0.9084
Epoch 214/350
391/391 - 25s - loss: 0.1166 - accuracy: 0.9749 - val_loss: 0.4670 - val_accuracy: 0.9095
Epoch 215/350
391/391 - 25s - loss: 0.1135 - accuracy: 0.9764 - val_loss: 0.4680 - val_accuracy: 0.9079
Epoch 216/350
391/391 - 25s - loss: 0.1135 - accuracy: 0.9764 - val_loss: 0.4740 - val_accuracy: 0.9084
Epoch 217/350
391/391 - 25s - loss: 0.1114 - accuracy: 0.9775 - val_loss: 0.4790 - val_accuracy: 0.9076
Epoch 218/350
391/391 - 25s - loss: 0.1135 - accuracy: 0.9757 - val_loss: 0.4727 - val_accuracy: 0.9078
Epoch 219/350
391/391 - 25s - loss: 0.1113 - accuracy: 0.9769 - val_loss: 0.4830 - val_accuracy: 0.9073
Epoch 220/350
391/391 - 25s - loss: 0.1130 - accuracy: 0.9757 - val_loss: 0.4733 - val_accuracy: 0.9063
Epoch 221/350
391/391 - 25s - loss: 0.1145 - accuracy: 0.9752 - val_loss: 0.4713 - val_accuracy: 0.9073
Epoch 222/350
391/391 - 25s - loss: 0.1117 - accuracy: 0.9767 - val_loss: 0.4725 - val_accuracy: 0.9062
Epoch 223/350
391/391 - 25s - loss: 0.1106 - accuracy: 0.9771 - val_loss: 0.4781 - val_accuracy: 0.9063
Epoch 224/350
391/391 - 25s - loss: 0.1121 - accuracy: 0.9763 - val_loss: 0.4752 - val_accuracy: 0.9075
Epoch 225/350
391/391 - 25s - loss: 0.1104 - accuracy: 0.9778 - val_loss: 0.4811 - val_accuracy: 0.9079
Epoch 226/350
391/391 - 25s - loss: 0.1081 - accuracy: 0.9779 - val_loss: 0.4824 - val_accuracy: 0.9079
Epoch 227/350
391/391 - 25s - loss: 0.1084 - accuracy: 0.9776 - val_loss: 0.4807 - val_accuracy: 0.9076
Epoch 228/350
391/391 - 25s - loss: 0.1108 - accuracy: 0.9776 - val_loss: 0.4804 - val_accuracy: 0.9092
Epoch 229/350
391/391 - 25s - loss: 0.1106 - accuracy: 0.9765 - val_loss: 0.4830 - val_accuracy: 0.9070
Epoch 230/350
391/391 - 25s - loss: 0.1088 - accuracy: 0.9775 - val_loss: 0.4792 - val_accuracy: 0.9071
Epoch 231/350
391/391 - 25s - loss: 0.1085 - accuracy: 0.9776 - val_loss: 0.4888 - val_accuracy: 0.9056
Epoch 232/350
391/391 - 25s - loss: 0.1082 - accuracy: 0.9780 - val_loss: 0.4823 - val_accuracy: 0.9071
Epoch 233/350
391/391 - 25s - loss: 0.1083 - accuracy: 0.9780 - val_loss: 0.4769 - val_accuracy: 0.9081
Epoch 234/350
391/391 - 25s - loss: 0.1072 - accuracy: 0.9782 - val_loss: 0.4854 - val_accuracy: 0.9064
Epoch 235/350
391/391 - 25s - loss: 0.1114 - accuracy: 0.9772 - val_loss: 0.4837 - val_accuracy: 0.9079
Epoch 236/350
391/391 - 25s - loss: 0.1069 - accuracy: 0.9787 - val_loss: 0.4831 - val_accuracy: 0.9071
Epoch 237/350
391/391 - 25s - loss: 0.1072 - accuracy: 0.9788 - val_loss: 0.4797 - val_accuracy: 0.9080
Epoch 238/350
391/391 - 25s - loss: 0.1050 - accuracy: 0.9794 - val_loss: 0.4860 - val_accuracy: 0.9066
Epoch 239/350
391/391 - 25s - loss: 0.1072 - accuracy: 0.9779 - val_loss: 0.4815 - val_accuracy: 0.9087
Epoch 240/350
391/391 - 25s - loss: 0.1050 - accuracy: 0.9791 - val_loss: 0.4895 - val_accuracy: 0.9071
Epoch 241/350
391/391 - 25s - loss: 0.1066 - accuracy: 0.9784 - val_loss: 0.4805 - val_accuracy: 0.9082
Epoch 242/350
391/391 - 25s - loss: 0.1063 - accuracy: 0.9785 - val_loss: 0.4821 - val_accuracy: 0.9083
Epoch 243/350
391/391 - 25s - loss: 0.1054 - accuracy: 0.9787 - val_loss: 0.4970 - val_accuracy: 0.9067
Epoch 244/350
391/391 - 25s - loss: 0.1056 - accuracy: 0.9785 - val_loss: 0.4876 - val_accuracy: 0.9069
Epoch 245/350
391/391 - 25s - loss: 0.1059 - accuracy: 0.9795 - val_loss: 0.4940 - val_accuracy: 0.9081
Epoch 246/350
391/391 - 25s - loss: 0.1068 - accuracy: 0.9780 - val_loss: 0.4947 - val_accuracy: 0.9058
Epoch 247/350
391/391 - 25s - loss: 0.1042 - accuracy: 0.9793 - val_loss: 0.4919 - val_accuracy: 0.9083
Epoch 248/350
391/391 - 25s - loss: 0.1055 - accuracy: 0.9780 - val_loss: 0.4840 - val_accuracy: 0.9082
Epoch 249/350
391/391 - 25s - loss: 0.1030 - accuracy: 0.9793 - val_loss: 0.5010 - val_accuracy: 0.9082
Epoch 250/350


Snapshot weight 5 shuffle 8 at epoch 250
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1057 - accuracy: 0.9789 - val_loss: 0.5055 - val_accuracy: 0.9074
Epoch 251/350
391/391 - 25s - loss: 0.1043 - accuracy: 0.9798 - val_loss: 0.4986 - val_accuracy: 0.9066
Epoch 252/350
391/391 - 25s - loss: 0.1018 - accuracy: 0.9795 - val_loss: 0.4988 - val_accuracy: 0.9061
Epoch 253/350
391/391 - 25s - loss: 0.1025 - accuracy: 0.9805 - val_loss: 0.4985 - val_accuracy: 0.9066
Epoch 254/350
391/391 - 25s - loss: 0.1012 - accuracy: 0.9800 - val_loss: 0.5004 - val_accuracy: 0.9064
Epoch 255/350
391/391 - 25s - loss: 0.1034 - accuracy: 0.9800 - val_loss: 0.4975 - val_accuracy: 0.9064
Epoch 256/350
391/391 - 25s - loss: 0.1043 - accuracy: 0.9799 - val_loss: 0.4954 - val_accuracy: 0.9066
Epoch 257/350
391/391 - 25s - loss: 0.1023 - accuracy: 0.9802 - val_loss: 0.4966 - val_accuracy: 0.9072
Epoch 258/350
391/391 - 25s - loss: 0.1014 - accuracy: 0.9806 - val_loss: 0.4960 - val_accuracy: 0.9073
Epoch 259/350
391/391 - 25s - loss: 0.0999 - accuracy: 0.9810 - val_loss: 0.4958 - val_accuracy: 0.9072
Epoch 260/350
391/391 - 25s - loss: 0.1021 - accuracy: 0.9802 - val_loss: 0.4951 - val_accuracy: 0.9077
Epoch 261/350
391/391 - 25s - loss: 0.1031 - accuracy: 0.9794 - val_loss: 0.4934 - val_accuracy: 0.9073
Epoch 262/350
391/391 - 25s - loss: 0.1027 - accuracy: 0.9795 - val_loss: 0.4928 - val_accuracy: 0.9074
Epoch 263/350
391/391 - 25s - loss: 0.1026 - accuracy: 0.9809 - val_loss: 0.4952 - val_accuracy: 0.9066
Epoch 264/350
391/391 - 25s - loss: 0.1030 - accuracy: 0.9794 - val_loss: 0.4931 - val_accuracy: 0.9078
Epoch 265/350
391/391 - 25s - loss: 0.1010 - accuracy: 0.9816 - val_loss: 0.4913 - val_accuracy: 0.9081
Epoch 266/350
391/391 - 25s - loss: 0.1013 - accuracy: 0.9803 - val_loss: 0.4935 - val_accuracy: 0.9070
Epoch 267/350
391/391 - 25s - loss: 0.1007 - accuracy: 0.9804 - val_loss: 0.4937 - val_accuracy: 0.9074
Epoch 268/350
391/391 - 25s - loss: 0.1003 - accuracy: 0.9810 - val_loss: 0.4938 - val_accuracy: 0.9084
Epoch 269/350
391/391 - 25s - loss: 0.0991 - accuracy: 0.9810 - val_loss: 0.4939 - val_accuracy: 0.9075
Epoch 270/350
391/391 - 25s - loss: 0.1005 - accuracy: 0.9801 - val_loss: 0.4958 - val_accuracy: 0.9072
Epoch 271/350
391/391 - 25s - loss: 0.0983 - accuracy: 0.9814 - val_loss: 0.4973 - val_accuracy: 0.9081
Epoch 272/350
391/391 - 25s - loss: 0.1002 - accuracy: 0.9809 - val_loss: 0.4976 - val_accuracy: 0.9074
Epoch 273/350
391/391 - 25s - loss: 0.1038 - accuracy: 0.9795 - val_loss: 0.4964 - val_accuracy: 0.9074
Epoch 274/350
391/391 - 25s - loss: 0.1001 - accuracy: 0.9804 - val_loss: 0.4953 - val_accuracy: 0.9078
Epoch 275/350
391/391 - 25s - loss: 0.1014 - accuracy: 0.9799 - val_loss: 0.4970 - val_accuracy: 0.9076
Epoch 276/350
391/391 - 25s - loss: 0.1005 - accuracy: 0.9807 - val_loss: 0.4938 - val_accuracy: 0.9073
Epoch 277/350
391/391 - 25s - loss: 0.1005 - accuracy: 0.9807 - val_loss: 0.4969 - val_accuracy: 0.9087
Epoch 278/350
391/391 - 25s - loss: 0.0996 - accuracy: 0.9813 - val_loss: 0.4979 - val_accuracy: 0.9080
Epoch 279/350
391/391 - 25s - loss: 0.1001 - accuracy: 0.9812 - val_loss: 0.4964 - val_accuracy: 0.9077
Epoch 280/350
391/391 - 25s - loss: 0.1024 - accuracy: 0.9795 - val_loss: 0.4972 - val_accuracy: 0.9076
Epoch 281/350
391/391 - 25s - loss: 0.1002 - accuracy: 0.9803 - val_loss: 0.4972 - val_accuracy: 0.9081
Epoch 282/350
391/391 - 25s - loss: 0.0998 - accuracy: 0.9805 - val_loss: 0.4986 - val_accuracy: 0.9084
Epoch 283/350
391/391 - 25s - loss: 0.1005 - accuracy: 0.9811 - val_loss: 0.4965 - val_accuracy: 0.9082
Epoch 284/350
391/391 - 25s - loss: 0.0991 - accuracy: 0.9814 - val_loss: 0.4981 - val_accuracy: 0.9081
Epoch 285/350
391/391 - 25s - loss: 0.0994 - accuracy: 0.9810 - val_loss: 0.4985 - val_accuracy: 0.9084
Epoch 286/350
391/391 - 25s - loss: 0.1011 - accuracy: 0.9803 - val_loss: 0.4986 - val_accuracy: 0.9080
Epoch 287/350
391/391 - 25s - loss: 0.1017 - accuracy: 0.9808 - val_loss: 0.4958 - val_accuracy: 0.9083
Epoch 288/350
391/391 - 25s - loss: 0.1009 - accuracy: 0.9812 - val_loss: 0.4942 - val_accuracy: 0.9094
Epoch 289/350
391/391 - 25s - loss: 0.0986 - accuracy: 0.9816 - val_loss: 0.4929 - val_accuracy: 0.9090
Epoch 290/350
391/391 - 25s - loss: 0.1031 - accuracy: 0.9805 - val_loss: 0.4951 - val_accuracy: 0.9087
Epoch 291/350
391/391 - 25s - loss: 0.1014 - accuracy: 0.9801 - val_loss: 0.4976 - val_accuracy: 0.9083
Epoch 292/350
391/391 - 25s - loss: 0.1007 - accuracy: 0.9802 - val_loss: 0.4959 - val_accuracy: 0.9089
Epoch 293/350
391/391 - 25s - loss: 0.1006 - accuracy: 0.9805 - val_loss: 0.5009 - val_accuracy: 0.9080
Epoch 294/350
391/391 - 25s - loss: 0.0997 - accuracy: 0.9817 - val_loss: 0.4999 - val_accuracy: 0.9073
Epoch 295/350
391/391 - 25s - loss: 0.1028 - accuracy: 0.9796 - val_loss: 0.4985 - val_accuracy: 0.9077
Epoch 296/350
391/391 - 25s - loss: 0.0994 - accuracy: 0.9812 - val_loss: 0.4998 - val_accuracy: 0.9080
Epoch 297/350
391/391 - 25s - loss: 0.1020 - accuracy: 0.9805 - val_loss: 0.4969 - val_accuracy: 0.9080
Epoch 298/350
391/391 - 25s - loss: 0.1027 - accuracy: 0.9797 - val_loss: 0.4987 - val_accuracy: 0.9077
Epoch 299/350
391/391 - 25s - loss: 0.1014 - accuracy: 0.9799 - val_loss: 0.4990 - val_accuracy: 0.9076
Epoch 300/350


Snapshot weight 5 shuffle 8 at epoch 300
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1001 - accuracy: 0.9812 - val_loss: 0.4965 - val_accuracy: 0.9077
Epoch 301/350
391/391 - 25s - loss: 0.0992 - accuracy: 0.9807 - val_loss: 0.4968 - val_accuracy: 0.9083
Epoch 302/350
391/391 - 25s - loss: 0.1020 - accuracy: 0.9804 - val_loss: 0.4971 - val_accuracy: 0.9083
Epoch 303/350
391/391 - 25s - loss: 0.0999 - accuracy: 0.9811 - val_loss: 0.4973 - val_accuracy: 0.9081
Epoch 304/350
391/391 - 25s - loss: 0.1009 - accuracy: 0.9804 - val_loss: 0.4975 - val_accuracy: 0.9080
Epoch 305/350
391/391 - 25s - loss: 0.0999 - accuracy: 0.9813 - val_loss: 0.4979 - val_accuracy: 0.9080
Epoch 306/350
391/391 - 25s - loss: 0.0998 - accuracy: 0.9811 - val_loss: 0.4979 - val_accuracy: 0.9083
Epoch 307/350
391/391 - 25s - loss: 0.1002 - accuracy: 0.9818 - val_loss: 0.4974 - val_accuracy: 0.9082
Epoch 308/350
391/391 - 25s - loss: 0.1011 - accuracy: 0.9808 - val_loss: 0.4973 - val_accuracy: 0.9082
Epoch 309/350
391/391 - 25s - loss: 0.1006 - accuracy: 0.9808 - val_loss: 0.4975 - val_accuracy: 0.9084
Epoch 310/350
391/391 - 25s - loss: 0.1022 - accuracy: 0.9798 - val_loss: 0.4975 - val_accuracy: 0.9079
Epoch 311/350
391/391 - 25s - loss: 0.1013 - accuracy: 0.9804 - val_loss: 0.4972 - val_accuracy: 0.9081
Epoch 312/350
391/391 - 25s - loss: 0.1003 - accuracy: 0.9808 - val_loss: 0.4972 - val_accuracy: 0.9081
Epoch 313/350
391/391 - 25s - loss: 0.1011 - accuracy: 0.9801 - val_loss: 0.4975 - val_accuracy: 0.9082
Epoch 314/350
391/391 - 25s - loss: 0.1002 - accuracy: 0.9810 - val_loss: 0.4975 - val_accuracy: 0.9077
Epoch 315/350
391/391 - 25s - loss: 0.1015 - accuracy: 0.9806 - val_loss: 0.4977 - val_accuracy: 0.9081
Epoch 316/350
391/391 - 25s - loss: 0.1012 - accuracy: 0.9806 - val_loss: 0.4977 - val_accuracy: 0.9080
Epoch 317/350
391/391 - 25s - loss: 0.1001 - accuracy: 0.9808 - val_loss: 0.4976 - val_accuracy: 0.9084
Epoch 318/350
391/391 - 25s - loss: 0.0986 - accuracy: 0.9813 - val_loss: 0.4976 - val_accuracy: 0.9082
Epoch 319/350
391/391 - 25s - loss: 0.1005 - accuracy: 0.9804 - val_loss: 0.4976 - val_accuracy: 0.9077
Epoch 320/350
391/391 - 25s - loss: 0.1016 - accuracy: 0.9804 - val_loss: 0.4975 - val_accuracy: 0.9081
Epoch 321/350
391/391 - 25s - loss: 0.0979 - accuracy: 0.9823 - val_loss: 0.4977 - val_accuracy: 0.9082
Epoch 322/350
391/391 - 25s - loss: 0.1001 - accuracy: 0.9804 - val_loss: 0.4976 - val_accuracy: 0.9080
Epoch 323/350
391/391 - 25s - loss: 0.1006 - accuracy: 0.9809 - val_loss: 0.4975 - val_accuracy: 0.9082
Epoch 324/350
391/391 - 25s - loss: 0.1010 - accuracy: 0.9803 - val_loss: 0.4973 - val_accuracy: 0.9081
Epoch 325/350
391/391 - 25s - loss: 0.0997 - accuracy: 0.9806 - val_loss: 0.4974 - val_accuracy: 0.9082
Epoch 326/350
391/391 - 25s - loss: 0.1002 - accuracy: 0.9811 - val_loss: 0.4977 - val_accuracy: 0.9080
Epoch 327/350
391/391 - 25s - loss: 0.1002 - accuracy: 0.9801 - val_loss: 0.4979 - val_accuracy: 0.9084
Epoch 328/350
391/391 - 25s - loss: 0.0998 - accuracy: 0.9811 - val_loss: 0.4980 - val_accuracy: 0.9082
Epoch 329/350
391/391 - 25s - loss: 0.1000 - accuracy: 0.9813 - val_loss: 0.4981 - val_accuracy: 0.9081
Epoch 330/350
391/391 - 25s - loss: 0.1016 - accuracy: 0.9804 - val_loss: 0.4979 - val_accuracy: 0.9082
Epoch 331/350
391/391 - 25s - loss: 0.1004 - accuracy: 0.9798 - val_loss: 0.4981 - val_accuracy: 0.9081
Epoch 332/350
391/391 - 25s - loss: 0.1000 - accuracy: 0.9806 - val_loss: 0.4982 - val_accuracy: 0.9083
Epoch 333/350
391/391 - 25s - loss: 0.1014 - accuracy: 0.9805 - val_loss: 0.4982 - val_accuracy: 0.9083
Epoch 334/350
391/391 - 25s - loss: 0.1024 - accuracy: 0.9805 - val_loss: 0.4979 - val_accuracy: 0.9082
Epoch 335/350
391/391 - 25s - loss: 0.0995 - accuracy: 0.9813 - val_loss: 0.4977 - val_accuracy: 0.9081
Epoch 336/350
391/391 - 25s - loss: 0.0992 - accuracy: 0.9816 - val_loss: 0.4981 - val_accuracy: 0.9085
Epoch 337/350
391/391 - 25s - loss: 0.1007 - accuracy: 0.9805 - val_loss: 0.4983 - val_accuracy: 0.9083
Epoch 338/350
391/391 - 25s - loss: 0.1009 - accuracy: 0.9804 - val_loss: 0.4981 - val_accuracy: 0.9077
Epoch 339/350
391/391 - 25s - loss: 0.1005 - accuracy: 0.9803 - val_loss: 0.4981 - val_accuracy: 0.9078
Epoch 340/350
391/391 - 25s - loss: 0.1004 - accuracy: 0.9810 - val_loss: 0.4978 - val_accuracy: 0.9076
Epoch 341/350
391/391 - 25s - loss: 0.1008 - accuracy: 0.9809 - val_loss: 0.4977 - val_accuracy: 0.9081
Epoch 342/350
391/391 - 25s - loss: 0.0999 - accuracy: 0.9815 - val_loss: 0.4975 - val_accuracy: 0.9082
Epoch 343/350
391/391 - 25s - loss: 0.1001 - accuracy: 0.9804 - val_loss: 0.4978 - val_accuracy: 0.9082
Epoch 344/350
391/391 - 25s - loss: 0.1012 - accuracy: 0.9806 - val_loss: 0.4981 - val_accuracy: 0.9077
Epoch 345/350
391/391 - 25s - loss: 0.1008 - accuracy: 0.9805 - val_loss: 0.4978 - val_accuracy: 0.9076
Epoch 346/350
391/391 - 25s - loss: 0.0991 - accuracy: 0.9814 - val_loss: 0.4977 - val_accuracy: 0.9079
Epoch 347/350
391/391 - 25s - loss: 0.0999 - accuracy: 0.9809 - val_loss: 0.4979 - val_accuracy: 0.9073
Epoch 348/350
391/391 - 25s - loss: 0.0997 - accuracy: 0.9826 - val_loss: 0.4984 - val_accuracy: 0.9077
Epoch 349/350
391/391 - 25s - loss: 0.1015 - accuracy: 0.9807 - val_loss: 0.4982 - val_accuracy: 0.9079
Epoch 350/350


Snapshot weight 5 shuffle 8 at epoch 350
Layer 11
Getting activations...


391/391 - 25s - loss: 0.0978 - accuracy: 0.9812 - val_loss: 0.4981 - val_accuracy: 0.9075
/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:493: UserWarning: fill_value is not supported and is always 0 for TensorFlow < 2.4.0.
  return py_builtins.overload_of(f)(*args)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-07-02 19:50:17.307299: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
Saving, final validation acc: 0.9075000286102295
