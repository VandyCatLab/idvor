2021-07-02 07:54:23.112395: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 07:55:49.593293: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-07-02 07:55:49.625739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-02 07:55:49.625814: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 07:55:49.672180: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-02 07:55:49.693978: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-02 07:55:49.702721: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-02 07:55:49.747957: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-02 07:55:49.756719: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-02 07:55:49.837124: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 07:55:49.839478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-02 07:55:49.843230: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-02 07:55:49.858771: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600150000 Hz
2021-07-02 07:55:49.858883: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5875ab0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-07-02 07:55:49.858903: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-07-02 07:55:49.998921: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5873cb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-07-02 07:55:49.998980: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN X (Pascal), Compute Capability 6.1
2021-07-02 07:55:50.001370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-02 07:55:50.001407: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 07:55:50.001435: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-02 07:55:50.001453: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-02 07:55:50.001470: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-02 07:55:50.001487: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-02 07:55:50.001503: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-02 07:55:50.004473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 07:55:50.006126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-02 07:55:50.008014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 07:55:51.848570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-02 07:55:51.848641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-07-02 07:55:51.848655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-07-02 07:55:51.854790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11228 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
2021-07-02 07:55:57.659520: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 07:56:00.267214: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
Using model index: 56
Making train data...
GCN...
ZCA...
Done!
Making test data...
Done!
Epoch 1/350


Snapshot weight 6 shuffle 5 at epoch 1
Layer 11
Getting activations...


391/391 - 25s - loss: 2.3149 - accuracy: 0.1161 - val_loss: 2.3156 - val_accuracy: 0.1896
Epoch 2/350


Snapshot weight 6 shuffle 5 at epoch 2
Layer 11
Getting activations...


391/391 - 24s - loss: 2.1312 - accuracy: 0.2152 - val_loss: 1.9395 - val_accuracy: 0.3034
Epoch 3/350


Snapshot weight 6 shuffle 5 at epoch 3
Layer 11
Getting activations...


391/391 - 25s - loss: 1.8147 - accuracy: 0.3459 - val_loss: 1.6269 - val_accuracy: 0.4304
Epoch 4/350


Snapshot weight 6 shuffle 5 at epoch 4
Layer 11
Getting activations...


391/391 - 25s - loss: 1.5201 - accuracy: 0.4568 - val_loss: 1.5160 - val_accuracy: 0.4722
Epoch 5/350


Snapshot weight 6 shuffle 5 at epoch 5
Layer 11
Getting activations...


391/391 - 25s - loss: 1.3919 - accuracy: 0.5063 - val_loss: 1.2987 - val_accuracy: 0.5452
Epoch 6/350


Snapshot weight 6 shuffle 5 at epoch 6
Layer 11
Getting activations...


391/391 - 25s - loss: 1.2783 - accuracy: 0.5508 - val_loss: 1.1642 - val_accuracy: 0.5912
Epoch 7/350


Snapshot weight 6 shuffle 5 at epoch 7
Layer 11
Getting activations...


391/391 - 25s - loss: 1.1932 - accuracy: 0.5796 - val_loss: 1.1610 - val_accuracy: 0.5983
Epoch 8/350


Snapshot weight 6 shuffle 5 at epoch 8
Layer 11
Getting activations...


391/391 - 25s - loss: 1.1270 - accuracy: 0.6085 - val_loss: 1.0154 - val_accuracy: 0.6467
Epoch 9/350


Snapshot weight 6 shuffle 5 at epoch 9
Layer 11
Getting activations...


391/391 - 25s - loss: 1.0624 - accuracy: 0.6291 - val_loss: 0.9490 - val_accuracy: 0.6722
Epoch 10/350


Snapshot weight 6 shuffle 5 at epoch 10
Layer 11
Getting activations...


391/391 - 25s - loss: 1.0170 - accuracy: 0.6476 - val_loss: 1.0514 - val_accuracy: 0.6491
Epoch 11/350
391/391 - 24s - loss: 0.9694 - accuracy: 0.6655 - val_loss: 0.9139 - val_accuracy: 0.6965
Epoch 12/350
391/391 - 25s - loss: 0.9278 - accuracy: 0.6825 - val_loss: 0.9348 - val_accuracy: 0.6789
Epoch 13/350
391/391 - 25s - loss: 0.8953 - accuracy: 0.6958 - val_loss: 0.8111 - val_accuracy: 0.7166
Epoch 14/350
391/391 - 25s - loss: 0.8637 - accuracy: 0.7019 - val_loss: 0.8078 - val_accuracy: 0.7297
Epoch 15/350
391/391 - 24s - loss: 0.8204 - accuracy: 0.7199 - val_loss: 0.8133 - val_accuracy: 0.7252
Epoch 16/350
391/391 - 24s - loss: 0.7938 - accuracy: 0.7315 - val_loss: 0.7381 - val_accuracy: 0.7482
Epoch 17/350
391/391 - 25s - loss: 0.7692 - accuracy: 0.7391 - val_loss: 0.7519 - val_accuracy: 0.7553
Epoch 18/350
391/391 - 24s - loss: 0.7294 - accuracy: 0.7563 - val_loss: 0.6803 - val_accuracy: 0.7722
Epoch 19/350
391/391 - 24s - loss: 0.7092 - accuracy: 0.7609 - val_loss: 0.6391 - val_accuracy: 0.7913
Epoch 20/350
391/391 - 24s - loss: 0.6881 - accuracy: 0.7706 - val_loss: 0.6555 - val_accuracy: 0.7849
Epoch 21/350
391/391 - 24s - loss: 0.6777 - accuracy: 0.7731 - val_loss: 0.7085 - val_accuracy: 0.7721
Epoch 22/350
391/391 - 25s - loss: 0.6505 - accuracy: 0.7834 - val_loss: 0.6154 - val_accuracy: 0.8010
Epoch 23/350
391/391 - 24s - loss: 0.6400 - accuracy: 0.7862 - val_loss: 0.6061 - val_accuracy: 0.8024
Epoch 24/350
391/391 - 24s - loss: 0.6154 - accuracy: 0.7956 - val_loss: 0.5960 - val_accuracy: 0.8068
Epoch 25/350
391/391 - 24s - loss: 0.6131 - accuracy: 0.7956 - val_loss: 0.5916 - val_accuracy: 0.8134
Epoch 26/350
391/391 - 25s - loss: 0.5930 - accuracy: 0.8039 - val_loss: 0.5793 - val_accuracy: 0.8068
Epoch 27/350
391/391 - 25s - loss: 0.5797 - accuracy: 0.8092 - val_loss: 0.5842 - val_accuracy: 0.8149
Epoch 28/350
391/391 - 24s - loss: 0.5719 - accuracy: 0.8109 - val_loss: 0.5407 - val_accuracy: 0.8267
Epoch 29/350
391/391 - 24s - loss: 0.5585 - accuracy: 0.8156 - val_loss: 0.5569 - val_accuracy: 0.8173
Epoch 30/350
391/391 - 24s - loss: 0.5468 - accuracy: 0.8199 - val_loss: 0.5162 - val_accuracy: 0.8358
Epoch 31/350
391/391 - 24s - loss: 0.5366 - accuracy: 0.8229 - val_loss: 0.5190 - val_accuracy: 0.8304
Epoch 32/350
391/391 - 24s - loss: 0.5261 - accuracy: 0.8281 - val_loss: 0.5051 - val_accuracy: 0.8379
Epoch 33/350
391/391 - 24s - loss: 0.5239 - accuracy: 0.8265 - val_loss: 0.5199 - val_accuracy: 0.8372
Epoch 34/350
391/391 - 25s - loss: 0.5077 - accuracy: 0.8336 - val_loss: 0.5158 - val_accuracy: 0.8367
Epoch 35/350
391/391 - 24s - loss: 0.5057 - accuracy: 0.8346 - val_loss: 0.5074 - val_accuracy: 0.8317
Epoch 36/350
391/391 - 25s - loss: 0.4939 - accuracy: 0.8393 - val_loss: 0.4932 - val_accuracy: 0.8469
Epoch 37/350
391/391 - 24s - loss: 0.4815 - accuracy: 0.8432 - val_loss: 0.4974 - val_accuracy: 0.8430
Epoch 38/350
391/391 - 25s - loss: 0.4756 - accuracy: 0.8457 - val_loss: 0.4731 - val_accuracy: 0.8521
Epoch 39/350
391/391 - 24s - loss: 0.4721 - accuracy: 0.8455 - val_loss: 0.4877 - val_accuracy: 0.8438
Epoch 40/350
391/391 - 24s - loss: 0.4633 - accuracy: 0.8497 - val_loss: 0.5121 - val_accuracy: 0.8389
Epoch 41/350
391/391 - 24s - loss: 0.4582 - accuracy: 0.8516 - val_loss: 0.4720 - val_accuracy: 0.8554
Epoch 42/350
391/391 - 24s - loss: 0.4541 - accuracy: 0.8536 - val_loss: 0.5022 - val_accuracy: 0.8418
Epoch 43/350
391/391 - 24s - loss: 0.4471 - accuracy: 0.8552 - val_loss: 0.4881 - val_accuracy: 0.8466
Epoch 44/350
391/391 - 24s - loss: 0.4407 - accuracy: 0.8562 - val_loss: 0.4646 - val_accuracy: 0.8541
Epoch 45/350
391/391 - 25s - loss: 0.4355 - accuracy: 0.8602 - val_loss: 0.4475 - val_accuracy: 0.8588
Epoch 46/350
391/391 - 24s - loss: 0.4259 - accuracy: 0.8613 - val_loss: 0.4400 - val_accuracy: 0.8612
Epoch 47/350
391/391 - 24s - loss: 0.4168 - accuracy: 0.8664 - val_loss: 0.4434 - val_accuracy: 0.8636
Epoch 48/350
391/391 - 25s - loss: 0.4188 - accuracy: 0.8663 - val_loss: 0.4587 - val_accuracy: 0.8612
Epoch 49/350
391/391 - 24s - loss: 0.4154 - accuracy: 0.8665 - val_loss: 0.4395 - val_accuracy: 0.8642
Epoch 50/350


Snapshot weight 6 shuffle 5 at epoch 50
Layer 11
Getting activations...


391/391 - 25s - loss: 0.4095 - accuracy: 0.8687 - val_loss: 0.4717 - val_accuracy: 0.8571
Epoch 51/350
391/391 - 24s - loss: 0.4022 - accuracy: 0.8701 - val_loss: 0.4596 - val_accuracy: 0.8573
Epoch 52/350
391/391 - 24s - loss: 0.4017 - accuracy: 0.8716 - val_loss: 0.4978 - val_accuracy: 0.8526
Epoch 53/350
391/391 - 25s - loss: 0.3916 - accuracy: 0.8738 - val_loss: 0.4461 - val_accuracy: 0.8641
Epoch 54/350
391/391 - 25s - loss: 0.3844 - accuracy: 0.8780 - val_loss: 0.4433 - val_accuracy: 0.8629
Epoch 55/350
391/391 - 24s - loss: 0.3828 - accuracy: 0.8772 - val_loss: 0.4454 - val_accuracy: 0.8634
Epoch 56/350
391/391 - 24s - loss: 0.3752 - accuracy: 0.8797 - val_loss: 0.4735 - val_accuracy: 0.8595
Epoch 57/350
391/391 - 24s - loss: 0.3779 - accuracy: 0.8792 - val_loss: 0.4264 - val_accuracy: 0.8696
Epoch 58/350
391/391 - 24s - loss: 0.3685 - accuracy: 0.8812 - val_loss: 0.4358 - val_accuracy: 0.8695
Epoch 59/350
391/391 - 25s - loss: 0.3653 - accuracy: 0.8838 - val_loss: 0.4744 - val_accuracy: 0.8597
Epoch 60/350
391/391 - 24s - loss: 0.3607 - accuracy: 0.8841 - val_loss: 0.4769 - val_accuracy: 0.8602
Epoch 61/350
391/391 - 24s - loss: 0.3588 - accuracy: 0.8853 - val_loss: 0.4535 - val_accuracy: 0.8642
Epoch 62/350
391/391 - 24s - loss: 0.3564 - accuracy: 0.8883 - val_loss: 0.4191 - val_accuracy: 0.8730
Epoch 63/350
391/391 - 24s - loss: 0.3501 - accuracy: 0.8884 - val_loss: 0.4194 - val_accuracy: 0.8758
Epoch 64/350
391/391 - 24s - loss: 0.3472 - accuracy: 0.8910 - val_loss: 0.4346 - val_accuracy: 0.8678
Epoch 65/350
391/391 - 24s - loss: 0.3473 - accuracy: 0.8893 - val_loss: 0.4229 - val_accuracy: 0.8728
Epoch 66/350
391/391 - 24s - loss: 0.3443 - accuracy: 0.8926 - val_loss: 0.4198 - val_accuracy: 0.8745
Epoch 67/350
391/391 - 24s - loss: 0.3381 - accuracy: 0.8930 - val_loss: 0.4347 - val_accuracy: 0.8754
Epoch 68/350
391/391 - 24s - loss: 0.3364 - accuracy: 0.8948 - val_loss: 0.4270 - val_accuracy: 0.8775
Epoch 69/350
391/391 - 24s - loss: 0.3303 - accuracy: 0.8953 - val_loss: 0.4275 - val_accuracy: 0.8723
Epoch 70/350
391/391 - 24s - loss: 0.3288 - accuracy: 0.8961 - val_loss: 0.4147 - val_accuracy: 0.8795
Epoch 71/350
391/391 - 25s - loss: 0.3277 - accuracy: 0.8981 - val_loss: 0.4314 - val_accuracy: 0.8702
Epoch 72/350
391/391 - 24s - loss: 0.3214 - accuracy: 0.8991 - val_loss: 0.4372 - val_accuracy: 0.8759
Epoch 73/350
391/391 - 24s - loss: 0.3229 - accuracy: 0.8988 - val_loss: 0.4361 - val_accuracy: 0.8722
Epoch 74/350
391/391 - 24s - loss: 0.3224 - accuracy: 0.8982 - val_loss: 0.4291 - val_accuracy: 0.8796
Epoch 75/350
391/391 - 24s - loss: 0.3176 - accuracy: 0.9003 - val_loss: 0.4187 - val_accuracy: 0.8763
Epoch 76/350
391/391 - 24s - loss: 0.3096 - accuracy: 0.9018 - val_loss: 0.4138 - val_accuracy: 0.8785
Epoch 77/350
391/391 - 24s - loss: 0.3108 - accuracy: 0.9017 - val_loss: 0.4313 - val_accuracy: 0.8780
Epoch 78/350
391/391 - 24s - loss: 0.3082 - accuracy: 0.9045 - val_loss: 0.4263 - val_accuracy: 0.8766
Epoch 79/350
391/391 - 25s - loss: 0.3030 - accuracy: 0.9071 - val_loss: 0.4184 - val_accuracy: 0.8796
Epoch 80/350
391/391 - 24s - loss: 0.3044 - accuracy: 0.9048 - val_loss: 0.4242 - val_accuracy: 0.8778
Epoch 81/350
391/391 - 24s - loss: 0.3020 - accuracy: 0.9062 - val_loss: 0.4353 - val_accuracy: 0.8769
Epoch 82/350
391/391 - 24s - loss: 0.2957 - accuracy: 0.9080 - val_loss: 0.4163 - val_accuracy: 0.8852
Epoch 83/350
391/391 - 25s - loss: 0.2919 - accuracy: 0.9104 - val_loss: 0.4295 - val_accuracy: 0.8751
Epoch 84/350
391/391 - 24s - loss: 0.2919 - accuracy: 0.9091 - val_loss: 0.4436 - val_accuracy: 0.8787
Epoch 85/350
391/391 - 24s - loss: 0.2887 - accuracy: 0.9107 - val_loss: 0.4091 - val_accuracy: 0.8831
Epoch 86/350
391/391 - 24s - loss: 0.2852 - accuracy: 0.9113 - val_loss: 0.4150 - val_accuracy: 0.8832
Epoch 87/350
391/391 - 24s - loss: 0.2845 - accuracy: 0.9120 - val_loss: 0.4211 - val_accuracy: 0.8858
Epoch 88/350
391/391 - 24s - loss: 0.2806 - accuracy: 0.9124 - val_loss: 0.4494 - val_accuracy: 0.8778
Epoch 89/350
391/391 - 24s - loss: 0.2789 - accuracy: 0.9142 - val_loss: 0.4016 - val_accuracy: 0.8800
Epoch 90/350
391/391 - 24s - loss: 0.2767 - accuracy: 0.9147 - val_loss: 0.4152 - val_accuracy: 0.8817
Epoch 91/350
391/391 - 24s - loss: 0.2755 - accuracy: 0.9149 - val_loss: 0.4433 - val_accuracy: 0.8787
Epoch 92/350
391/391 - 25s - loss: 0.2738 - accuracy: 0.9150 - val_loss: 0.4352 - val_accuracy: 0.8847
Epoch 93/350
391/391 - 24s - loss: 0.2733 - accuracy: 0.9155 - val_loss: 0.4172 - val_accuracy: 0.8846
Epoch 94/350
391/391 - 24s - loss: 0.2743 - accuracy: 0.9160 - val_loss: 0.4094 - val_accuracy: 0.8842
Epoch 95/350
391/391 - 24s - loss: 0.2692 - accuracy: 0.9174 - val_loss: 0.4112 - val_accuracy: 0.8858
Epoch 96/350
391/391 - 24s - loss: 0.2625 - accuracy: 0.9200 - val_loss: 0.4267 - val_accuracy: 0.8837
Epoch 97/350
391/391 - 24s - loss: 0.2651 - accuracy: 0.9192 - val_loss: 0.4079 - val_accuracy: 0.8830
Epoch 98/350
391/391 - 24s - loss: 0.2667 - accuracy: 0.9185 - val_loss: 0.4601 - val_accuracy: 0.8733
Epoch 99/350
391/391 - 24s - loss: 0.2599 - accuracy: 0.9213 - val_loss: 0.4421 - val_accuracy: 0.8830
Epoch 100/350


Snapshot weight 6 shuffle 5 at epoch 100
Layer 11
Getting activations...


391/391 - 25s - loss: 0.2550 - accuracy: 0.9236 - val_loss: 0.4123 - val_accuracy: 0.8901
Epoch 101/350
391/391 - 24s - loss: 0.2571 - accuracy: 0.9219 - val_loss: 0.4404 - val_accuracy: 0.8843
Epoch 102/350
391/391 - 24s - loss: 0.2549 - accuracy: 0.9225 - val_loss: 0.4234 - val_accuracy: 0.8860
Epoch 103/350
391/391 - 24s - loss: 0.2566 - accuracy: 0.9240 - val_loss: 0.4149 - val_accuracy: 0.8819
Epoch 104/350
391/391 - 24s - loss: 0.2523 - accuracy: 0.9245 - val_loss: 0.4287 - val_accuracy: 0.8876
Epoch 105/350
391/391 - 24s - loss: 0.2528 - accuracy: 0.9224 - val_loss: 0.4297 - val_accuracy: 0.8862
Epoch 106/350
391/391 - 24s - loss: 0.2475 - accuracy: 0.9246 - val_loss: 0.4410 - val_accuracy: 0.8836
Epoch 107/350
391/391 - 24s - loss: 0.2463 - accuracy: 0.9265 - val_loss: 0.4048 - val_accuracy: 0.8899
Epoch 108/350
391/391 - 25s - loss: 0.2474 - accuracy: 0.9258 - val_loss: 0.4487 - val_accuracy: 0.8824
Epoch 109/350
391/391 - 24s - loss: 0.2453 - accuracy: 0.9266 - val_loss: 0.4257 - val_accuracy: 0.8901
Epoch 110/350
391/391 - 24s - loss: 0.2462 - accuracy: 0.9275 - val_loss: 0.4122 - val_accuracy: 0.8872
Epoch 111/350
391/391 - 24s - loss: 0.2451 - accuracy: 0.9286 - val_loss: 0.4236 - val_accuracy: 0.8864
Epoch 112/350
391/391 - 24s - loss: 0.2388 - accuracy: 0.9290 - val_loss: 0.4367 - val_accuracy: 0.8860
Epoch 113/350
391/391 - 25s - loss: 0.2367 - accuracy: 0.9306 - val_loss: 0.4030 - val_accuracy: 0.8931
Epoch 114/350
391/391 - 24s - loss: 0.2358 - accuracy: 0.9296 - val_loss: 0.4443 - val_accuracy: 0.8866
Epoch 115/350
391/391 - 24s - loss: 0.2393 - accuracy: 0.9289 - val_loss: 0.4393 - val_accuracy: 0.8835
Epoch 116/350
391/391 - 24s - loss: 0.2320 - accuracy: 0.9321 - val_loss: 0.4346 - val_accuracy: 0.8895
Epoch 117/350
391/391 - 24s - loss: 0.2330 - accuracy: 0.9307 - val_loss: 0.4284 - val_accuracy: 0.8847
Epoch 118/350
391/391 - 24s - loss: 0.2297 - accuracy: 0.9327 - val_loss: 0.4092 - val_accuracy: 0.8896
Epoch 119/350
391/391 - 24s - loss: 0.2277 - accuracy: 0.9334 - val_loss: 0.4259 - val_accuracy: 0.8890
Epoch 120/350
391/391 - 24s - loss: 0.2266 - accuracy: 0.9335 - val_loss: 0.4373 - val_accuracy: 0.8898
Epoch 121/350
391/391 - 24s - loss: 0.2270 - accuracy: 0.9323 - val_loss: 0.4476 - val_accuracy: 0.8837
Epoch 122/350
391/391 - 24s - loss: 0.2273 - accuracy: 0.9341 - val_loss: 0.4664 - val_accuracy: 0.8849
Epoch 123/350
391/391 - 24s - loss: 0.2246 - accuracy: 0.9334 - val_loss: 0.4565 - val_accuracy: 0.8805
Epoch 124/350
391/391 - 24s - loss: 0.2217 - accuracy: 0.9351 - val_loss: 0.4369 - val_accuracy: 0.8905
Epoch 125/350
391/391 - 24s - loss: 0.2206 - accuracy: 0.9372 - val_loss: 0.4303 - val_accuracy: 0.8912
Epoch 126/350
391/391 - 24s - loss: 0.2227 - accuracy: 0.9341 - val_loss: 0.4309 - val_accuracy: 0.8915
Epoch 127/350
391/391 - 24s - loss: 0.2210 - accuracy: 0.9348 - val_loss: 0.4386 - val_accuracy: 0.8911
Epoch 128/350
391/391 - 24s - loss: 0.2169 - accuracy: 0.9370 - val_loss: 0.4497 - val_accuracy: 0.8852
Epoch 129/350
391/391 - 24s - loss: 0.2190 - accuracy: 0.9369 - val_loss: 0.4247 - val_accuracy: 0.8935
Epoch 130/350
391/391 - 24s - loss: 0.2170 - accuracy: 0.9378 - val_loss: 0.4288 - val_accuracy: 0.8872
Epoch 131/350
391/391 - 24s - loss: 0.2164 - accuracy: 0.9376 - val_loss: 0.4259 - val_accuracy: 0.8932
Epoch 132/350
391/391 - 25s - loss: 0.2137 - accuracy: 0.9389 - val_loss: 0.4088 - val_accuracy: 0.8952
Epoch 133/350
391/391 - 24s - loss: 0.2140 - accuracy: 0.9381 - val_loss: 0.4224 - val_accuracy: 0.8893
Epoch 134/350
391/391 - 24s - loss: 0.2127 - accuracy: 0.9399 - val_loss: 0.4247 - val_accuracy: 0.8887
Epoch 135/350
391/391 - 24s - loss: 0.2123 - accuracy: 0.9389 - val_loss: 0.4573 - val_accuracy: 0.8890
Epoch 136/350
391/391 - 24s - loss: 0.2103 - accuracy: 0.9383 - val_loss: 0.4283 - val_accuracy: 0.8962
Epoch 137/350
391/391 - 24s - loss: 0.2071 - accuracy: 0.9396 - val_loss: 0.4459 - val_accuracy: 0.8928
Epoch 138/350
391/391 - 24s - loss: 0.2107 - accuracy: 0.9402 - val_loss: 0.4543 - val_accuracy: 0.8897
Epoch 139/350
391/391 - 24s - loss: 0.2051 - accuracy: 0.9410 - val_loss: 0.4362 - val_accuracy: 0.8921
Epoch 140/350
391/391 - 25s - loss: 0.2103 - accuracy: 0.9395 - val_loss: 0.4346 - val_accuracy: 0.8919
Epoch 141/350
391/391 - 24s - loss: 0.2066 - accuracy: 0.9416 - val_loss: 0.4528 - val_accuracy: 0.8945
Epoch 142/350
391/391 - 24s - loss: 0.1997 - accuracy: 0.9442 - val_loss: 0.4788 - val_accuracy: 0.8871
Epoch 143/350
391/391 - 24s - loss: 0.2077 - accuracy: 0.9409 - val_loss: 0.4346 - val_accuracy: 0.8944
Epoch 144/350
391/391 - 25s - loss: 0.2038 - accuracy: 0.9432 - val_loss: 0.4523 - val_accuracy: 0.8933
Epoch 145/350
391/391 - 24s - loss: 0.1992 - accuracy: 0.9448 - val_loss: 0.4331 - val_accuracy: 0.8912
Epoch 146/350
391/391 - 24s - loss: 0.2015 - accuracy: 0.9435 - val_loss: 0.4457 - val_accuracy: 0.8940
Epoch 147/350
391/391 - 24s - loss: 0.1945 - accuracy: 0.9464 - val_loss: 0.4350 - val_accuracy: 0.8947
Epoch 148/350
391/391 - 24s - loss: 0.1977 - accuracy: 0.9447 - val_loss: 0.4472 - val_accuracy: 0.8962
Epoch 149/350
391/391 - 24s - loss: 0.1992 - accuracy: 0.9435 - val_loss: 0.4540 - val_accuracy: 0.8938
Epoch 150/350


Snapshot weight 6 shuffle 5 at epoch 150
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1963 - accuracy: 0.9453 - val_loss: 0.4153 - val_accuracy: 0.8972
Epoch 151/350
391/391 - 24s - loss: 0.1990 - accuracy: 0.9440 - val_loss: 0.4183 - val_accuracy: 0.8952
Epoch 152/350
391/391 - 24s - loss: 0.1935 - accuracy: 0.9461 - val_loss: 0.4705 - val_accuracy: 0.8872
Epoch 153/350
391/391 - 24s - loss: 0.1970 - accuracy: 0.9461 - val_loss: 0.4843 - val_accuracy: 0.8908
Epoch 154/350
391/391 - 24s - loss: 0.1902 - accuracy: 0.9472 - val_loss: 0.4796 - val_accuracy: 0.8903
Epoch 155/350
391/391 - 24s - loss: 0.1951 - accuracy: 0.9454 - val_loss: 0.4729 - val_accuracy: 0.8914
Epoch 156/350
391/391 - 25s - loss: 0.1914 - accuracy: 0.9475 - val_loss: 0.5134 - val_accuracy: 0.8846
Epoch 157/350
391/391 - 24s - loss: 0.1949 - accuracy: 0.9453 - val_loss: 0.4534 - val_accuracy: 0.8959
Epoch 158/350
391/391 - 24s - loss: 0.1909 - accuracy: 0.9480 - val_loss: 0.4679 - val_accuracy: 0.8948
Epoch 159/350
391/391 - 24s - loss: 0.1903 - accuracy: 0.9481 - val_loss: 0.4833 - val_accuracy: 0.8917
Epoch 160/350
391/391 - 24s - loss: 0.1875 - accuracy: 0.9492 - val_loss: 0.4743 - val_accuracy: 0.8904
Epoch 161/350
391/391 - 24s - loss: 0.1869 - accuracy: 0.9487 - val_loss: 0.4332 - val_accuracy: 0.8995
Epoch 162/350
391/391 - 24s - loss: 0.1888 - accuracy: 0.9478 - val_loss: 0.4532 - val_accuracy: 0.8938
Epoch 163/350
391/391 - 24s - loss: 0.1885 - accuracy: 0.9477 - val_loss: 0.4690 - val_accuracy: 0.8903
Epoch 164/350
391/391 - 24s - loss: 0.1809 - accuracy: 0.9507 - val_loss: 0.4528 - val_accuracy: 0.8938
Epoch 165/350
391/391 - 24s - loss: 0.1831 - accuracy: 0.9509 - val_loss: 0.4714 - val_accuracy: 0.8918
Epoch 166/350
391/391 - 24s - loss: 0.1873 - accuracy: 0.9492 - val_loss: 0.4391 - val_accuracy: 0.8927
Epoch 167/350
391/391 - 24s - loss: 0.1854 - accuracy: 0.9499 - val_loss: 0.4584 - val_accuracy: 0.8924
Epoch 168/350
391/391 - 24s - loss: 0.1808 - accuracy: 0.9505 - val_loss: 0.4660 - val_accuracy: 0.8942
Epoch 169/350
391/391 - 24s - loss: 0.1774 - accuracy: 0.9526 - val_loss: 0.4723 - val_accuracy: 0.8925
Epoch 170/350
391/391 - 24s - loss: 0.1851 - accuracy: 0.9499 - val_loss: 0.5112 - val_accuracy: 0.8869
Epoch 171/350
391/391 - 24s - loss: 0.1814 - accuracy: 0.9523 - val_loss: 0.4425 - val_accuracy: 0.8977
Epoch 172/350
391/391 - 24s - loss: 0.1811 - accuracy: 0.9522 - val_loss: 0.4892 - val_accuracy: 0.8893
Epoch 173/350
391/391 - 25s - loss: 0.1771 - accuracy: 0.9527 - val_loss: 0.4864 - val_accuracy: 0.8930
Epoch 174/350
391/391 - 24s - loss: 0.1791 - accuracy: 0.9518 - val_loss: 0.4822 - val_accuracy: 0.8915
Epoch 175/350
391/391 - 24s - loss: 0.1835 - accuracy: 0.9504 - val_loss: 0.4169 - val_accuracy: 0.8991
Epoch 176/350
391/391 - 24s - loss: 0.1731 - accuracy: 0.9545 - val_loss: 0.4472 - val_accuracy: 0.9029
Epoch 177/350
391/391 - 24s - loss: 0.1794 - accuracy: 0.9520 - val_loss: 0.5085 - val_accuracy: 0.8863
Epoch 178/350
391/391 - 25s - loss: 0.1734 - accuracy: 0.9545 - val_loss: 0.4784 - val_accuracy: 0.8953
Epoch 179/350
391/391 - 25s - loss: 0.1762 - accuracy: 0.9530 - val_loss: 0.4709 - val_accuracy: 0.8925
Epoch 180/350
391/391 - 25s - loss: 0.1727 - accuracy: 0.9541 - val_loss: 0.4400 - val_accuracy: 0.8987
Epoch 181/350
391/391 - 24s - loss: 0.1789 - accuracy: 0.9520 - val_loss: 0.4789 - val_accuracy: 0.8953
Epoch 182/350
391/391 - 24s - loss: 0.1696 - accuracy: 0.9557 - val_loss: 0.4518 - val_accuracy: 0.8940
Epoch 183/350
391/391 - 24s - loss: 0.1711 - accuracy: 0.9557 - val_loss: 0.4741 - val_accuracy: 0.8947
Epoch 184/350
391/391 - 24s - loss: 0.1688 - accuracy: 0.9555 - val_loss: 0.4975 - val_accuracy: 0.8935
Epoch 185/350
391/391 - 24s - loss: 0.1700 - accuracy: 0.9557 - val_loss: 0.4980 - val_accuracy: 0.8940
Epoch 186/350
391/391 - 24s - loss: 0.1722 - accuracy: 0.9556 - val_loss: 0.4914 - val_accuracy: 0.8934
Epoch 187/350
391/391 - 25s - loss: 0.1718 - accuracy: 0.9549 - val_loss: 0.5143 - val_accuracy: 0.8875
Epoch 188/350
391/391 - 24s - loss: 0.1689 - accuracy: 0.9561 - val_loss: 0.4912 - val_accuracy: 0.8918
Epoch 189/350
391/391 - 24s - loss: 0.1728 - accuracy: 0.9549 - val_loss: 0.4931 - val_accuracy: 0.8940
Epoch 190/350
391/391 - 24s - loss: 0.1707 - accuracy: 0.9559 - val_loss: 0.4626 - val_accuracy: 0.8971
Epoch 191/350
391/391 - 25s - loss: 0.1698 - accuracy: 0.9564 - val_loss: 0.5102 - val_accuracy: 0.8915
Epoch 192/350
391/391 - 25s - loss: 0.1665 - accuracy: 0.9570 - val_loss: 0.4832 - val_accuracy: 0.8950
Epoch 193/350
391/391 - 24s - loss: 0.1641 - accuracy: 0.9577 - val_loss: 0.4627 - val_accuracy: 0.8968
Epoch 194/350
391/391 - 24s - loss: 0.1681 - accuracy: 0.9561 - val_loss: 0.5132 - val_accuracy: 0.8906
Epoch 195/350
391/391 - 24s - loss: 0.1727 - accuracy: 0.9559 - val_loss: 0.4743 - val_accuracy: 0.8935
Epoch 196/350
391/391 - 24s - loss: 0.1657 - accuracy: 0.9570 - val_loss: 0.4660 - val_accuracy: 0.8948
Epoch 197/350
391/391 - 24s - loss: 0.1664 - accuracy: 0.9568 - val_loss: 0.4636 - val_accuracy: 0.8919
Epoch 198/350
391/391 - 24s - loss: 0.1633 - accuracy: 0.9592 - val_loss: 0.5071 - val_accuracy: 0.8926
Epoch 199/350
391/391 - 24s - loss: 0.1661 - accuracy: 0.9575 - val_loss: 0.4659 - val_accuracy: 0.8971
Epoch 200/350


Snapshot weight 6 shuffle 5 at epoch 200
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1636 - accuracy: 0.9585 - val_loss: 0.4732 - val_accuracy: 0.8966
Epoch 201/350
391/391 - 24s - loss: 0.1388 - accuracy: 0.9678 - val_loss: 0.4637 - val_accuracy: 0.9019
Epoch 202/350
391/391 - 24s - loss: 0.1247 - accuracy: 0.9719 - val_loss: 0.4721 - val_accuracy: 0.9012
Epoch 203/350
391/391 - 25s - loss: 0.1225 - accuracy: 0.9740 - val_loss: 0.4794 - val_accuracy: 0.9005
Epoch 204/350
391/391 - 24s - loss: 0.1199 - accuracy: 0.9741 - val_loss: 0.4797 - val_accuracy: 0.9040
Epoch 205/350
391/391 - 24s - loss: 0.1194 - accuracy: 0.9745 - val_loss: 0.4694 - val_accuracy: 0.9054
Epoch 206/350
391/391 - 24s - loss: 0.1172 - accuracy: 0.9745 - val_loss: 0.4905 - val_accuracy: 0.9020
Epoch 207/350
391/391 - 24s - loss: 0.1150 - accuracy: 0.9751 - val_loss: 0.4770 - val_accuracy: 0.9043
Epoch 208/350
391/391 - 24s - loss: 0.1161 - accuracy: 0.9760 - val_loss: 0.4779 - val_accuracy: 0.9065
Epoch 209/350
391/391 - 24s - loss: 0.1166 - accuracy: 0.9746 - val_loss: 0.4747 - val_accuracy: 0.9070
Epoch 210/350
391/391 - 24s - loss: 0.1158 - accuracy: 0.9759 - val_loss: 0.4792 - val_accuracy: 0.9066
Epoch 211/350
391/391 - 24s - loss: 0.1122 - accuracy: 0.9771 - val_loss: 0.4892 - val_accuracy: 0.9065
Epoch 212/350
391/391 - 24s - loss: 0.1141 - accuracy: 0.9761 - val_loss: 0.4877 - val_accuracy: 0.9065
Epoch 213/350
391/391 - 24s - loss: 0.1146 - accuracy: 0.9754 - val_loss: 0.4893 - val_accuracy: 0.9059
Epoch 214/350
391/391 - 24s - loss: 0.1138 - accuracy: 0.9758 - val_loss: 0.4833 - val_accuracy: 0.9056
Epoch 215/350
391/391 - 25s - loss: 0.1102 - accuracy: 0.9777 - val_loss: 0.4936 - val_accuracy: 0.9057
Epoch 216/350
391/391 - 24s - loss: 0.1143 - accuracy: 0.9760 - val_loss: 0.4830 - val_accuracy: 0.9053
Epoch 217/350
391/391 - 24s - loss: 0.1131 - accuracy: 0.9764 - val_loss: 0.4834 - val_accuracy: 0.9068
Epoch 218/350
391/391 - 24s - loss: 0.1109 - accuracy: 0.9765 - val_loss: 0.4865 - val_accuracy: 0.9068
Epoch 219/350
391/391 - 25s - loss: 0.1105 - accuracy: 0.9772 - val_loss: 0.4849 - val_accuracy: 0.9074
Epoch 220/350
391/391 - 24s - loss: 0.1098 - accuracy: 0.9777 - val_loss: 0.4873 - val_accuracy: 0.9065
Epoch 221/350
391/391 - 24s - loss: 0.1096 - accuracy: 0.9778 - val_loss: 0.4912 - val_accuracy: 0.9070
Epoch 222/350
391/391 - 24s - loss: 0.1080 - accuracy: 0.9779 - val_loss: 0.4962 - val_accuracy: 0.9071
Epoch 223/350
391/391 - 24s - loss: 0.1118 - accuracy: 0.9766 - val_loss: 0.4922 - val_accuracy: 0.9049
Epoch 224/350
391/391 - 24s - loss: 0.1076 - accuracy: 0.9785 - val_loss: 0.4862 - val_accuracy: 0.9075
Epoch 225/350
391/391 - 24s - loss: 0.1090 - accuracy: 0.9779 - val_loss: 0.4943 - val_accuracy: 0.9073
Epoch 226/350
391/391 - 25s - loss: 0.1093 - accuracy: 0.9784 - val_loss: 0.4977 - val_accuracy: 0.9055
Epoch 227/350
391/391 - 24s - loss: 0.1083 - accuracy: 0.9772 - val_loss: 0.5008 - val_accuracy: 0.9059
Epoch 228/350
391/391 - 24s - loss: 0.1083 - accuracy: 0.9783 - val_loss: 0.4945 - val_accuracy: 0.9045
Epoch 229/350
391/391 - 24s - loss: 0.1068 - accuracy: 0.9788 - val_loss: 0.4987 - val_accuracy: 0.9056
Epoch 230/350
391/391 - 24s - loss: 0.1087 - accuracy: 0.9785 - val_loss: 0.5006 - val_accuracy: 0.9056
Epoch 231/350
391/391 - 24s - loss: 0.1079 - accuracy: 0.9781 - val_loss: 0.4981 - val_accuracy: 0.9066
Epoch 232/350
391/391 - 24s - loss: 0.1064 - accuracy: 0.9789 - val_loss: 0.4982 - val_accuracy: 0.9065
Epoch 233/350
391/391 - 24s - loss: 0.1061 - accuracy: 0.9791 - val_loss: 0.4994 - val_accuracy: 0.9078
Epoch 234/350
391/391 - 24s - loss: 0.1047 - accuracy: 0.9781 - val_loss: 0.4967 - val_accuracy: 0.9070
Epoch 235/350
391/391 - 24s - loss: 0.1079 - accuracy: 0.9781 - val_loss: 0.5036 - val_accuracy: 0.9051
Epoch 236/350
391/391 - 24s - loss: 0.1069 - accuracy: 0.9788 - val_loss: 0.5008 - val_accuracy: 0.9075
Epoch 237/350
391/391 - 24s - loss: 0.1047 - accuracy: 0.9795 - val_loss: 0.5030 - val_accuracy: 0.9069
Epoch 238/350
391/391 - 25s - loss: 0.1053 - accuracy: 0.9790 - val_loss: 0.5125 - val_accuracy: 0.9063
Epoch 239/350
391/391 - 24s - loss: 0.1059 - accuracy: 0.9787 - val_loss: 0.5102 - val_accuracy: 0.9065
Epoch 240/350
391/391 - 24s - loss: 0.1048 - accuracy: 0.9789 - val_loss: 0.5089 - val_accuracy: 0.9059
Epoch 241/350
391/391 - 24s - loss: 0.1035 - accuracy: 0.9794 - val_loss: 0.5141 - val_accuracy: 0.9062
Epoch 242/350
391/391 - 25s - loss: 0.1040 - accuracy: 0.9793 - val_loss: 0.5056 - val_accuracy: 0.9066
Epoch 243/350
391/391 - 24s - loss: 0.1070 - accuracy: 0.9785 - val_loss: 0.5069 - val_accuracy: 0.9070
Epoch 244/350
391/391 - 24s - loss: 0.1059 - accuracy: 0.9789 - val_loss: 0.4969 - val_accuracy: 0.9080
Epoch 245/350
391/391 - 24s - loss: 0.1035 - accuracy: 0.9799 - val_loss: 0.5027 - val_accuracy: 0.9072
Epoch 246/350
391/391 - 25s - loss: 0.1058 - accuracy: 0.9786 - val_loss: 0.5114 - val_accuracy: 0.9055
Epoch 247/350
391/391 - 24s - loss: 0.1040 - accuracy: 0.9798 - val_loss: 0.5127 - val_accuracy: 0.9075
Epoch 248/350
391/391 - 24s - loss: 0.1048 - accuracy: 0.9796 - val_loss: 0.5122 - val_accuracy: 0.9078
Epoch 249/350
391/391 - 24s - loss: 0.1023 - accuracy: 0.9802 - val_loss: 0.5123 - val_accuracy: 0.9070
Epoch 250/350


Snapshot weight 6 shuffle 5 at epoch 250
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1030 - accuracy: 0.9793 - val_loss: 0.5077 - val_accuracy: 0.9084
Epoch 251/350
391/391 - 24s - loss: 0.1004 - accuracy: 0.9807 - val_loss: 0.5114 - val_accuracy: 0.9083
Epoch 252/350
391/391 - 24s - loss: 0.1006 - accuracy: 0.9805 - val_loss: 0.5118 - val_accuracy: 0.9079
Epoch 253/350
391/391 - 24s - loss: 0.0993 - accuracy: 0.9810 - val_loss: 0.5128 - val_accuracy: 0.9074
Epoch 254/350
391/391 - 24s - loss: 0.0999 - accuracy: 0.9810 - val_loss: 0.5125 - val_accuracy: 0.9080
Epoch 255/350
391/391 - 24s - loss: 0.1015 - accuracy: 0.9801 - val_loss: 0.5124 - val_accuracy: 0.9075
Epoch 256/350
391/391 - 24s - loss: 0.0988 - accuracy: 0.9810 - val_loss: 0.5161 - val_accuracy: 0.9073
Epoch 257/350
391/391 - 24s - loss: 0.0991 - accuracy: 0.9807 - val_loss: 0.5148 - val_accuracy: 0.9080
Epoch 258/350
391/391 - 24s - loss: 0.1004 - accuracy: 0.9809 - val_loss: 0.5130 - val_accuracy: 0.9068
Epoch 259/350
391/391 - 24s - loss: 0.1008 - accuracy: 0.9803 - val_loss: 0.5122 - val_accuracy: 0.9075
Epoch 260/350
391/391 - 24s - loss: 0.0991 - accuracy: 0.9818 - val_loss: 0.5129 - val_accuracy: 0.9077
Epoch 261/350
391/391 - 25s - loss: 0.0998 - accuracy: 0.9810 - val_loss: 0.5110 - val_accuracy: 0.9069
Epoch 262/350
391/391 - 24s - loss: 0.1003 - accuracy: 0.9809 - val_loss: 0.5122 - val_accuracy: 0.9078
Epoch 263/350
391/391 - 24s - loss: 0.0990 - accuracy: 0.9812 - val_loss: 0.5127 - val_accuracy: 0.9073
Epoch 264/350
391/391 - 24s - loss: 0.1017 - accuracy: 0.9800 - val_loss: 0.5117 - val_accuracy: 0.9082
Epoch 265/350
391/391 - 24s - loss: 0.1013 - accuracy: 0.9805 - val_loss: 0.5110 - val_accuracy: 0.9079
Epoch 266/350
391/391 - 24s - loss: 0.1024 - accuracy: 0.9804 - val_loss: 0.5119 - val_accuracy: 0.9070
Epoch 267/350
391/391 - 24s - loss: 0.0972 - accuracy: 0.9822 - val_loss: 0.5135 - val_accuracy: 0.9072
Epoch 268/350
391/391 - 24s - loss: 0.1004 - accuracy: 0.9808 - val_loss: 0.5132 - val_accuracy: 0.9071
Epoch 269/350
391/391 - 24s - loss: 0.0997 - accuracy: 0.9816 - val_loss: 0.5140 - val_accuracy: 0.9074
Epoch 270/350
391/391 - 24s - loss: 0.1007 - accuracy: 0.9810 - val_loss: 0.5143 - val_accuracy: 0.9069
Epoch 271/350
391/391 - 24s - loss: 0.1011 - accuracy: 0.9809 - val_loss: 0.5114 - val_accuracy: 0.9076
Epoch 272/350
391/391 - 24s - loss: 0.1003 - accuracy: 0.9808 - val_loss: 0.5119 - val_accuracy: 0.9083
Epoch 273/350
391/391 - 25s - loss: 0.0980 - accuracy: 0.9820 - val_loss: 0.5132 - val_accuracy: 0.9080
Epoch 274/350
391/391 - 24s - loss: 0.0983 - accuracy: 0.9818 - val_loss: 0.5107 - val_accuracy: 0.9074
Epoch 275/350
391/391 - 25s - loss: 0.0991 - accuracy: 0.9816 - val_loss: 0.5104 - val_accuracy: 0.9074
Epoch 276/350
391/391 - 24s - loss: 0.1000 - accuracy: 0.9811 - val_loss: 0.5105 - val_accuracy: 0.9080
Epoch 277/350
391/391 - 24s - loss: 0.0985 - accuracy: 0.9819 - val_loss: 0.5105 - val_accuracy: 0.9076
Epoch 278/350
391/391 - 24s - loss: 0.1004 - accuracy: 0.9812 - val_loss: 0.5108 - val_accuracy: 0.9078
Epoch 279/350
391/391 - 24s - loss: 0.1006 - accuracy: 0.9806 - val_loss: 0.5109 - val_accuracy: 0.9073
Epoch 280/350
391/391 - 24s - loss: 0.0989 - accuracy: 0.9817 - val_loss: 0.5124 - val_accuracy: 0.9074
Epoch 281/350
391/391 - 24s - loss: 0.1010 - accuracy: 0.9809 - val_loss: 0.5124 - val_accuracy: 0.9069
Epoch 282/350
391/391 - 24s - loss: 0.0999 - accuracy: 0.9811 - val_loss: 0.5135 - val_accuracy: 0.9075
Epoch 283/350
391/391 - 24s - loss: 0.0983 - accuracy: 0.9818 - val_loss: 0.5142 - val_accuracy: 0.9077
Epoch 284/350
391/391 - 24s - loss: 0.0993 - accuracy: 0.9815 - val_loss: 0.5128 - val_accuracy: 0.9081
Epoch 285/350
391/391 - 24s - loss: 0.0993 - accuracy: 0.9812 - val_loss: 0.5137 - val_accuracy: 0.9083
Epoch 286/350
391/391 - 24s - loss: 0.1005 - accuracy: 0.9804 - val_loss: 0.5132 - val_accuracy: 0.9087
Epoch 287/350
391/391 - 24s - loss: 0.0999 - accuracy: 0.9808 - val_loss: 0.5147 - val_accuracy: 0.9080
Epoch 288/350
391/391 - 24s - loss: 0.0997 - accuracy: 0.9811 - val_loss: 0.5139 - val_accuracy: 0.9093
Epoch 289/350
391/391 - 25s - loss: 0.0992 - accuracy: 0.9807 - val_loss: 0.5128 - val_accuracy: 0.9087
Epoch 290/350
391/391 - 24s - loss: 0.0980 - accuracy: 0.9810 - val_loss: 0.5143 - val_accuracy: 0.9076
Epoch 291/350
391/391 - 24s - loss: 0.0979 - accuracy: 0.9810 - val_loss: 0.5169 - val_accuracy: 0.9078
Epoch 292/350
391/391 - 24s - loss: 0.0985 - accuracy: 0.9819 - val_loss: 0.5133 - val_accuracy: 0.9077
Epoch 293/350
391/391 - 24s - loss: 0.0984 - accuracy: 0.9822 - val_loss: 0.5144 - val_accuracy: 0.9080
Epoch 294/350
391/391 - 25s - loss: 0.0984 - accuracy: 0.9820 - val_loss: 0.5146 - val_accuracy: 0.9081
Epoch 295/350
391/391 - 24s - loss: 0.0976 - accuracy: 0.9815 - val_loss: 0.5141 - val_accuracy: 0.9079
Epoch 296/350
391/391 - 24s - loss: 0.1012 - accuracy: 0.9806 - val_loss: 0.5119 - val_accuracy: 0.9079
Epoch 297/350
391/391 - 25s - loss: 0.0981 - accuracy: 0.9813 - val_loss: 0.5129 - val_accuracy: 0.9089
Epoch 298/350
391/391 - 24s - loss: 0.0978 - accuracy: 0.9818 - val_loss: 0.5131 - val_accuracy: 0.9089
Epoch 299/350
391/391 - 24s - loss: 0.1008 - accuracy: 0.9808 - val_loss: 0.5144 - val_accuracy: 0.9076
Epoch 300/350


Snapshot weight 6 shuffle 5 at epoch 300
Layer 11
Getting activations...


391/391 - 25s - loss: 0.0984 - accuracy: 0.9812 - val_loss: 0.5143 - val_accuracy: 0.9078
Epoch 301/350
391/391 - 24s - loss: 0.1002 - accuracy: 0.9808 - val_loss: 0.5145 - val_accuracy: 0.9079
Epoch 302/350
391/391 - 24s - loss: 0.0990 - accuracy: 0.9811 - val_loss: 0.5143 - val_accuracy: 0.9077
Epoch 303/350
391/391 - 24s - loss: 0.0968 - accuracy: 0.9817 - val_loss: 0.5144 - val_accuracy: 0.9078
Epoch 304/350
391/391 - 24s - loss: 0.0996 - accuracy: 0.9811 - val_loss: 0.5141 - val_accuracy: 0.9081
Epoch 305/350
391/391 - 24s - loss: 0.0990 - accuracy: 0.9811 - val_loss: 0.5144 - val_accuracy: 0.9082
Epoch 306/350
391/391 - 24s - loss: 0.1010 - accuracy: 0.9809 - val_loss: 0.5141 - val_accuracy: 0.9079
Epoch 307/350
391/391 - 24s - loss: 0.0965 - accuracy: 0.9818 - val_loss: 0.5143 - val_accuracy: 0.9078
Epoch 308/350
391/391 - 24s - loss: 0.0996 - accuracy: 0.9816 - val_loss: 0.5141 - val_accuracy: 0.9080
Epoch 309/350
391/391 - 24s - loss: 0.0967 - accuracy: 0.9816 - val_loss: 0.5142 - val_accuracy: 0.9077
Epoch 310/350
391/391 - 25s - loss: 0.1007 - accuracy: 0.9808 - val_loss: 0.5143 - val_accuracy: 0.9078
Epoch 311/350
391/391 - 24s - loss: 0.0973 - accuracy: 0.9820 - val_loss: 0.5143 - val_accuracy: 0.9084
Epoch 312/350
391/391 - 24s - loss: 0.1020 - accuracy: 0.9801 - val_loss: 0.5140 - val_accuracy: 0.9082
Epoch 313/350
391/391 - 24s - loss: 0.1013 - accuracy: 0.9801 - val_loss: 0.5138 - val_accuracy: 0.9081
Epoch 314/350
391/391 - 24s - loss: 0.1005 - accuracy: 0.9807 - val_loss: 0.5132 - val_accuracy: 0.9081
Epoch 315/350
391/391 - 24s - loss: 0.0979 - accuracy: 0.9818 - val_loss: 0.5133 - val_accuracy: 0.9082
Epoch 316/350
391/391 - 24s - loss: 0.0976 - accuracy: 0.9819 - val_loss: 0.5135 - val_accuracy: 0.9083
Epoch 317/350
391/391 - 24s - loss: 0.0978 - accuracy: 0.9819 - val_loss: 0.5135 - val_accuracy: 0.9084
Epoch 318/350
391/391 - 24s - loss: 0.0979 - accuracy: 0.9814 - val_loss: 0.5139 - val_accuracy: 0.9085
Epoch 319/350
391/391 - 24s - loss: 0.1010 - accuracy: 0.9805 - val_loss: 0.5140 - val_accuracy: 0.9088
Epoch 320/350
391/391 - 25s - loss: 0.0978 - accuracy: 0.9818 - val_loss: 0.5142 - val_accuracy: 0.9088
Epoch 321/350
391/391 - 24s - loss: 0.0971 - accuracy: 0.9819 - val_loss: 0.5142 - val_accuracy: 0.9090
Epoch 322/350
391/391 - 24s - loss: 0.0988 - accuracy: 0.9813 - val_loss: 0.5140 - val_accuracy: 0.9087
Epoch 323/350
391/391 - 24s - loss: 0.1004 - accuracy: 0.9804 - val_loss: 0.5137 - val_accuracy: 0.9084
Epoch 324/350
391/391 - 24s - loss: 0.0995 - accuracy: 0.9807 - val_loss: 0.5139 - val_accuracy: 0.9088
Epoch 325/350
391/391 - 24s - loss: 0.0986 - accuracy: 0.9817 - val_loss: 0.5139 - val_accuracy: 0.9088
Epoch 326/350
391/391 - 24s - loss: 0.0977 - accuracy: 0.9813 - val_loss: 0.5143 - val_accuracy: 0.9087
Epoch 327/350
391/391 - 24s - loss: 0.0986 - accuracy: 0.9809 - val_loss: 0.5143 - val_accuracy: 0.9081
Epoch 328/350
391/391 - 24s - loss: 0.0965 - accuracy: 0.9821 - val_loss: 0.5141 - val_accuracy: 0.9087
Epoch 329/350
391/391 - 24s - loss: 0.0988 - accuracy: 0.9814 - val_loss: 0.5138 - val_accuracy: 0.9085
Epoch 330/350
391/391 - 24s - loss: 0.0969 - accuracy: 0.9819 - val_loss: 0.5139 - val_accuracy: 0.9086
Epoch 331/350
391/391 - 25s - loss: 0.0994 - accuracy: 0.9811 - val_loss: 0.5137 - val_accuracy: 0.9090
Epoch 332/350
391/391 - 24s - loss: 0.1007 - accuracy: 0.9811 - val_loss: 0.5141 - val_accuracy: 0.9087
Epoch 333/350
391/391 - 24s - loss: 0.0979 - accuracy: 0.9823 - val_loss: 0.5144 - val_accuracy: 0.9091
Epoch 334/350
391/391 - 24s - loss: 0.0996 - accuracy: 0.9809 - val_loss: 0.5144 - val_accuracy: 0.9089
Epoch 335/350
391/391 - 25s - loss: 0.0967 - accuracy: 0.9823 - val_loss: 0.5146 - val_accuracy: 0.9091
Epoch 336/350
391/391 - 24s - loss: 0.0992 - accuracy: 0.9813 - val_loss: 0.5144 - val_accuracy: 0.9087
Epoch 337/350
391/391 - 24s - loss: 0.0991 - accuracy: 0.9816 - val_loss: 0.5143 - val_accuracy: 0.9085
Epoch 338/350
391/391 - 24s - loss: 0.0982 - accuracy: 0.9821 - val_loss: 0.5145 - val_accuracy: 0.9086
Epoch 339/350
391/391 - 25s - loss: 0.0987 - accuracy: 0.9812 - val_loss: 0.5142 - val_accuracy: 0.9087
Epoch 340/350
391/391 - 24s - loss: 0.0982 - accuracy: 0.9813 - val_loss: 0.5142 - val_accuracy: 0.9084
Epoch 341/350
391/391 - 24s - loss: 0.1005 - accuracy: 0.9811 - val_loss: 0.5144 - val_accuracy: 0.9087
Epoch 342/350
391/391 - 25s - loss: 0.0981 - accuracy: 0.9815 - val_loss: 0.5145 - val_accuracy: 0.9085
Epoch 343/350
391/391 - 24s - loss: 0.1009 - accuracy: 0.9805 - val_loss: 0.5148 - val_accuracy: 0.9086
Epoch 344/350
391/391 - 25s - loss: 0.0989 - accuracy: 0.9815 - val_loss: 0.5147 - val_accuracy: 0.9083
Epoch 345/350
391/391 - 25s - loss: 0.0979 - accuracy: 0.9819 - val_loss: 0.5149 - val_accuracy: 0.9083
Epoch 346/350
391/391 - 24s - loss: 0.0989 - accuracy: 0.9810 - val_loss: 0.5146 - val_accuracy: 0.9085
Epoch 347/350
391/391 - 24s - loss: 0.0958 - accuracy: 0.9828 - val_loss: 0.5146 - val_accuracy: 0.9084
Epoch 348/350
391/391 - 24s - loss: 0.0983 - accuracy: 0.9819 - val_loss: 0.5144 - val_accuracy: 0.9087
Epoch 349/350
391/391 - 24s - loss: 0.0983 - accuracy: 0.9815 - val_loss: 0.5144 - val_accuracy: 0.9086
Epoch 350/350


Snapshot weight 6 shuffle 5 at epoch 350
Layer 11
Getting activations...


391/391 - 25s - loss: 0.0998 - accuracy: 0.9808 - val_loss: 0.5143 - val_accuracy: 0.9085
/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:493: UserWarning: fill_value is not supported and is always 0 for TensorFlow < 2.4.0.
  return py_builtins.overload_of(f)(*args)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-07-02 10:24:47.844827: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
Saving, final validation acc: 0.9085000157356262
