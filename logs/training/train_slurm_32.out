2021-07-02 00:28:45.967452: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 00:30:03.670748: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-07-02 00:30:03.720864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-02 00:30:03.720951: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 00:30:03.763633: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-02 00:30:03.785118: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-02 00:30:03.793400: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-02 00:30:03.838427: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-02 00:30:03.847066: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-02 00:30:03.926772: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 00:30:03.929235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-02 00:30:03.932928: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-02 00:30:03.948979: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599940000 Hz
2021-07-02 00:30:03.949121: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x594cde0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-07-02 00:30:03.949141: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-07-02 00:30:04.126340: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x592cad0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-07-02 00:30:04.126427: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN X (Pascal), Compute Capability 6.1
2021-07-02 00:30:04.133009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-02 00:30:04.133070: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 00:30:04.133102: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-02 00:30:04.133121: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-02 00:30:04.133138: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-02 00:30:04.133155: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-02 00:30:04.133171: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-02 00:30:04.133751: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 00:30:04.135445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-02 00:30:04.137200: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 00:30:05.941879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-02 00:30:05.941965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-07-02 00:30:05.941978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-07-02 00:30:05.947866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11228 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
2021-07-02 00:30:11.704074: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 00:30:14.250710: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
Using model index: 32
Making train data...
GCN...
ZCA...
Done!
Making test data...
Done!
Epoch 1/350


Snapshot weight 2 shuffle 3 at epoch 1
Layer 11
Getting activations...


391/391 - 25s - loss: 2.2858 - accuracy: 0.1379 - val_loss: 2.3802 - val_accuracy: 0.1549
Epoch 2/350


Snapshot weight 2 shuffle 3 at epoch 2
Layer 11
Getting activations...


391/391 - 24s - loss: 2.1988 - accuracy: 0.1827 - val_loss: 2.0937 - val_accuracy: 0.2594
Epoch 3/350


Snapshot weight 2 shuffle 3 at epoch 3
Layer 11
Getting activations...


391/391 - 25s - loss: 1.8436 - accuracy: 0.3468 - val_loss: 1.6736 - val_accuracy: 0.3938
Epoch 4/350


Snapshot weight 2 shuffle 3 at epoch 4
Layer 11
Getting activations...


391/391 - 25s - loss: 1.5456 - accuracy: 0.4524 - val_loss: 1.4906 - val_accuracy: 0.4752
Epoch 5/350


Snapshot weight 2 shuffle 3 at epoch 5
Layer 11
Getting activations...


391/391 - 25s - loss: 1.3614 - accuracy: 0.5186 - val_loss: 1.2889 - val_accuracy: 0.5605
Epoch 6/350


Snapshot weight 2 shuffle 3 at epoch 6
Layer 11
Getting activations...


391/391 - 25s - loss: 1.2373 - accuracy: 0.5652 - val_loss: 1.1824 - val_accuracy: 0.5952
Epoch 7/350


Snapshot weight 2 shuffle 3 at epoch 7
Layer 11
Getting activations...


391/391 - 25s - loss: 1.1529 - accuracy: 0.5990 - val_loss: 1.2162 - val_accuracy: 0.5903
Epoch 8/350


Snapshot weight 2 shuffle 3 at epoch 8
Layer 11
Getting activations...


391/391 - 25s - loss: 1.0961 - accuracy: 0.6194 - val_loss: 1.0400 - val_accuracy: 0.6461
Epoch 9/350


Snapshot weight 2 shuffle 3 at epoch 9
Layer 11
Getting activations...


391/391 - 25s - loss: 1.0567 - accuracy: 0.6324 - val_loss: 1.0359 - val_accuracy: 0.6382
Epoch 10/350


Snapshot weight 2 shuffle 3 at epoch 10
Layer 11
Getting activations...


391/391 - 25s - loss: 0.9978 - accuracy: 0.6534 - val_loss: 0.9086 - val_accuracy: 0.6858
Epoch 11/350
391/391 - 24s - loss: 0.9711 - accuracy: 0.6630 - val_loss: 0.9144 - val_accuracy: 0.6825
Epoch 12/350
391/391 - 25s - loss: 0.9318 - accuracy: 0.6786 - val_loss: 0.8772 - val_accuracy: 0.7014
Epoch 13/350
391/391 - 24s - loss: 0.8834 - accuracy: 0.6953 - val_loss: 0.8547 - val_accuracy: 0.7060
Epoch 14/350
391/391 - 24s - loss: 0.8677 - accuracy: 0.7047 - val_loss: 0.8520 - val_accuracy: 0.7111
Epoch 15/350
391/391 - 24s - loss: 0.8350 - accuracy: 0.7143 - val_loss: 0.7812 - val_accuracy: 0.7442
Epoch 16/350
391/391 - 24s - loss: 0.8132 - accuracy: 0.7205 - val_loss: 0.7577 - val_accuracy: 0.7472
Epoch 17/350
391/391 - 24s - loss: 0.7819 - accuracy: 0.7344 - val_loss: 0.7926 - val_accuracy: 0.7452
Epoch 18/350
391/391 - 24s - loss: 0.7568 - accuracy: 0.7437 - val_loss: 0.7225 - val_accuracy: 0.7605
Epoch 19/350
391/391 - 24s - loss: 0.7399 - accuracy: 0.7493 - val_loss: 0.7222 - val_accuracy: 0.7610
Epoch 20/350
391/391 - 24s - loss: 0.7211 - accuracy: 0.7566 - val_loss: 0.7216 - val_accuracy: 0.7658
Epoch 21/350
391/391 - 24s - loss: 0.6880 - accuracy: 0.7687 - val_loss: 0.7008 - val_accuracy: 0.7751
Epoch 22/350
391/391 - 25s - loss: 0.6726 - accuracy: 0.7732 - val_loss: 0.6509 - val_accuracy: 0.7861
Epoch 23/350
391/391 - 25s - loss: 0.6595 - accuracy: 0.7797 - val_loss: 0.6836 - val_accuracy: 0.7830
Epoch 24/350
391/391 - 24s - loss: 0.6349 - accuracy: 0.7876 - val_loss: 0.6259 - val_accuracy: 0.7933
Epoch 25/350
391/391 - 24s - loss: 0.6240 - accuracy: 0.7923 - val_loss: 0.6150 - val_accuracy: 0.8053
Epoch 26/350
391/391 - 25s - loss: 0.6069 - accuracy: 0.7964 - val_loss: 0.6686 - val_accuracy: 0.7874
Epoch 27/350
391/391 - 25s - loss: 0.5923 - accuracy: 0.8045 - val_loss: 0.5792 - val_accuracy: 0.8154
Epoch 28/350
391/391 - 24s - loss: 0.5807 - accuracy: 0.8070 - val_loss: 0.5296 - val_accuracy: 0.8276
Epoch 29/350
391/391 - 24s - loss: 0.5666 - accuracy: 0.8121 - val_loss: 0.5911 - val_accuracy: 0.8127
Epoch 30/350
391/391 - 25s - loss: 0.5537 - accuracy: 0.8164 - val_loss: 0.6154 - val_accuracy: 0.8125
Epoch 31/350
391/391 - 24s - loss: 0.5395 - accuracy: 0.8212 - val_loss: 0.5138 - val_accuracy: 0.8367
Epoch 32/350
391/391 - 24s - loss: 0.5255 - accuracy: 0.8278 - val_loss: 0.5696 - val_accuracy: 0.8207
Epoch 33/350
391/391 - 25s - loss: 0.5174 - accuracy: 0.8317 - val_loss: 0.5238 - val_accuracy: 0.8291
Epoch 34/350
391/391 - 25s - loss: 0.5124 - accuracy: 0.8317 - val_loss: 0.5044 - val_accuracy: 0.8383
Epoch 35/350
391/391 - 25s - loss: 0.5036 - accuracy: 0.8370 - val_loss: 0.4981 - val_accuracy: 0.8383
Epoch 36/350
391/391 - 24s - loss: 0.4975 - accuracy: 0.8382 - val_loss: 0.4908 - val_accuracy: 0.8440
Epoch 37/350
391/391 - 24s - loss: 0.4893 - accuracy: 0.8403 - val_loss: 0.4932 - val_accuracy: 0.8430
Epoch 38/350
391/391 - 24s - loss: 0.4756 - accuracy: 0.8443 - val_loss: 0.5003 - val_accuracy: 0.8420
Epoch 39/350
391/391 - 24s - loss: 0.4693 - accuracy: 0.8471 - val_loss: 0.4982 - val_accuracy: 0.8461
Epoch 40/350
391/391 - 24s - loss: 0.4637 - accuracy: 0.8493 - val_loss: 0.4888 - val_accuracy: 0.8432
Epoch 41/350
391/391 - 24s - loss: 0.4578 - accuracy: 0.8514 - val_loss: 0.5237 - val_accuracy: 0.8359
Epoch 42/350
391/391 - 24s - loss: 0.4510 - accuracy: 0.8544 - val_loss: 0.4995 - val_accuracy: 0.8463
Epoch 43/350
391/391 - 24s - loss: 0.4439 - accuracy: 0.8571 - val_loss: 0.4810 - val_accuracy: 0.8496
Epoch 44/350
391/391 - 24s - loss: 0.4354 - accuracy: 0.8587 - val_loss: 0.4549 - val_accuracy: 0.8586
Epoch 45/350
391/391 - 25s - loss: 0.4304 - accuracy: 0.8610 - val_loss: 0.4583 - val_accuracy: 0.8556
Epoch 46/350
391/391 - 25s - loss: 0.4268 - accuracy: 0.8625 - val_loss: 0.4774 - val_accuracy: 0.8484
Epoch 47/350
391/391 - 25s - loss: 0.4230 - accuracy: 0.8668 - val_loss: 0.4405 - val_accuracy: 0.8626
Epoch 48/350
391/391 - 24s - loss: 0.4145 - accuracy: 0.8663 - val_loss: 0.4707 - val_accuracy: 0.8568
Epoch 49/350
391/391 - 25s - loss: 0.4085 - accuracy: 0.8683 - val_loss: 0.4636 - val_accuracy: 0.8541
Epoch 50/350


Snapshot weight 2 shuffle 3 at epoch 50
Layer 11
Getting activations...


391/391 - 25s - loss: 0.4066 - accuracy: 0.8705 - val_loss: 0.4597 - val_accuracy: 0.8574
Epoch 51/350
391/391 - 25s - loss: 0.3989 - accuracy: 0.8718 - val_loss: 0.4477 - val_accuracy: 0.8572
Epoch 52/350
391/391 - 24s - loss: 0.3951 - accuracy: 0.8718 - val_loss: 0.4276 - val_accuracy: 0.8675
Epoch 53/350
391/391 - 24s - loss: 0.3897 - accuracy: 0.8743 - val_loss: 0.4831 - val_accuracy: 0.8500
Epoch 54/350
391/391 - 25s - loss: 0.3871 - accuracy: 0.8763 - val_loss: 0.4252 - val_accuracy: 0.8715
Epoch 55/350
391/391 - 24s - loss: 0.3794 - accuracy: 0.8785 - val_loss: 0.4583 - val_accuracy: 0.8589
Epoch 56/350
391/391 - 25s - loss: 0.3754 - accuracy: 0.8804 - val_loss: 0.4384 - val_accuracy: 0.8674
Epoch 57/350
391/391 - 24s - loss: 0.3725 - accuracy: 0.8815 - val_loss: 0.4775 - val_accuracy: 0.8576
Epoch 58/350
391/391 - 25s - loss: 0.3675 - accuracy: 0.8831 - val_loss: 0.4403 - val_accuracy: 0.8687
Epoch 59/350
391/391 - 24s - loss: 0.3654 - accuracy: 0.8846 - val_loss: 0.4596 - val_accuracy: 0.8649
Epoch 60/350
391/391 - 24s - loss: 0.3689 - accuracy: 0.8828 - val_loss: 0.4430 - val_accuracy: 0.8672
Epoch 61/350
391/391 - 24s - loss: 0.3584 - accuracy: 0.8864 - val_loss: 0.4397 - val_accuracy: 0.8719
Epoch 62/350
391/391 - 24s - loss: 0.3547 - accuracy: 0.8862 - val_loss: 0.4122 - val_accuracy: 0.8744
Epoch 63/350
391/391 - 24s - loss: 0.3484 - accuracy: 0.8903 - val_loss: 0.4245 - val_accuracy: 0.8730
Epoch 64/350
391/391 - 24s - loss: 0.3463 - accuracy: 0.8902 - val_loss: 0.4686 - val_accuracy: 0.8657
Epoch 65/350
391/391 - 24s - loss: 0.3384 - accuracy: 0.8930 - val_loss: 0.4269 - val_accuracy: 0.8747
Epoch 66/350
391/391 - 25s - loss: 0.3432 - accuracy: 0.8936 - val_loss: 0.4215 - val_accuracy: 0.8769
Epoch 67/350
391/391 - 24s - loss: 0.3360 - accuracy: 0.8949 - val_loss: 0.4278 - val_accuracy: 0.8720
Epoch 68/350
391/391 - 24s - loss: 0.3259 - accuracy: 0.8964 - val_loss: 0.4112 - val_accuracy: 0.8818
Epoch 69/350
391/391 - 24s - loss: 0.3274 - accuracy: 0.8970 - val_loss: 0.4317 - val_accuracy: 0.8748
Epoch 70/350
391/391 - 25s - loss: 0.3221 - accuracy: 0.8994 - val_loss: 0.4173 - val_accuracy: 0.8752
Epoch 71/350
391/391 - 24s - loss: 0.3234 - accuracy: 0.8993 - val_loss: 0.4469 - val_accuracy: 0.8679
Epoch 72/350
391/391 - 24s - loss: 0.3124 - accuracy: 0.9015 - val_loss: 0.4381 - val_accuracy: 0.8771
Epoch 73/350
391/391 - 24s - loss: 0.3133 - accuracy: 0.9030 - val_loss: 0.4421 - val_accuracy: 0.8728
Epoch 74/350
391/391 - 24s - loss: 0.3179 - accuracy: 0.9001 - val_loss: 0.4345 - val_accuracy: 0.8724
Epoch 75/350
391/391 - 24s - loss: 0.3092 - accuracy: 0.9041 - val_loss: 0.4303 - val_accuracy: 0.8766
Epoch 76/350
391/391 - 25s - loss: 0.3066 - accuracy: 0.9044 - val_loss: 0.4191 - val_accuracy: 0.8799
Epoch 77/350
391/391 - 24s - loss: 0.3086 - accuracy: 0.9040 - val_loss: 0.4398 - val_accuracy: 0.8781
Epoch 78/350
391/391 - 25s - loss: 0.3043 - accuracy: 0.9071 - val_loss: 0.4211 - val_accuracy: 0.8789
Epoch 79/350
391/391 - 25s - loss: 0.3059 - accuracy: 0.9042 - val_loss: 0.4304 - val_accuracy: 0.8739
Epoch 80/350
391/391 - 24s - loss: 0.2947 - accuracy: 0.9089 - val_loss: 0.4020 - val_accuracy: 0.8815
Epoch 81/350
391/391 - 25s - loss: 0.2991 - accuracy: 0.9077 - val_loss: 0.4181 - val_accuracy: 0.8804
Epoch 82/350
391/391 - 24s - loss: 0.2905 - accuracy: 0.9100 - val_loss: 0.4225 - val_accuracy: 0.8778
Epoch 83/350
391/391 - 24s - loss: 0.2920 - accuracy: 0.9097 - val_loss: 0.4308 - val_accuracy: 0.8768
Epoch 84/350
391/391 - 24s - loss: 0.2877 - accuracy: 0.9109 - val_loss: 0.4286 - val_accuracy: 0.8791
Epoch 85/350
391/391 - 24s - loss: 0.2812 - accuracy: 0.9137 - val_loss: 0.4429 - val_accuracy: 0.8789
Epoch 86/350
391/391 - 24s - loss: 0.2865 - accuracy: 0.9107 - val_loss: 0.4844 - val_accuracy: 0.8661
Epoch 87/350
391/391 - 24s - loss: 0.2764 - accuracy: 0.9141 - val_loss: 0.4320 - val_accuracy: 0.8817
Epoch 88/350
391/391 - 24s - loss: 0.2777 - accuracy: 0.9150 - val_loss: 0.4138 - val_accuracy: 0.8876
Epoch 89/350
391/391 - 24s - loss: 0.2766 - accuracy: 0.9137 - val_loss: 0.4139 - val_accuracy: 0.8836
Epoch 90/350
391/391 - 24s - loss: 0.2716 - accuracy: 0.9164 - val_loss: 0.4385 - val_accuracy: 0.8808
Epoch 91/350
391/391 - 24s - loss: 0.2697 - accuracy: 0.9173 - val_loss: 0.4410 - val_accuracy: 0.8819
Epoch 92/350
391/391 - 24s - loss: 0.2749 - accuracy: 0.9164 - val_loss: 0.4486 - val_accuracy: 0.8773
Epoch 93/350
391/391 - 24s - loss: 0.2697 - accuracy: 0.9183 - val_loss: 0.4426 - val_accuracy: 0.8833
Epoch 94/350
391/391 - 24s - loss: 0.2714 - accuracy: 0.9166 - val_loss: 0.4114 - val_accuracy: 0.8856
Epoch 95/350
391/391 - 25s - loss: 0.2675 - accuracy: 0.9180 - val_loss: 0.4460 - val_accuracy: 0.8809
Epoch 96/350
391/391 - 24s - loss: 0.2654 - accuracy: 0.9202 - val_loss: 0.4200 - val_accuracy: 0.8826
Epoch 97/350
391/391 - 24s - loss: 0.2574 - accuracy: 0.9217 - val_loss: 0.4197 - val_accuracy: 0.8871
Epoch 98/350
391/391 - 24s - loss: 0.2526 - accuracy: 0.9232 - val_loss: 0.4407 - val_accuracy: 0.8835
Epoch 99/350
391/391 - 24s - loss: 0.2586 - accuracy: 0.9221 - val_loss: 0.4145 - val_accuracy: 0.8859
Epoch 100/350


Snapshot weight 2 shuffle 3 at epoch 100
Layer 11
Getting activations...


391/391 - 25s - loss: 0.2564 - accuracy: 0.9233 - val_loss: 0.4144 - val_accuracy: 0.8847
Epoch 101/350
391/391 - 24s - loss: 0.2511 - accuracy: 0.9249 - val_loss: 0.4217 - val_accuracy: 0.8852
Epoch 102/350
391/391 - 24s - loss: 0.2547 - accuracy: 0.9229 - val_loss: 0.4510 - val_accuracy: 0.8816
Epoch 103/350
391/391 - 24s - loss: 0.2545 - accuracy: 0.9237 - val_loss: 0.4203 - val_accuracy: 0.8899
Epoch 104/350
391/391 - 24s - loss: 0.2511 - accuracy: 0.9245 - val_loss: 0.4316 - val_accuracy: 0.8866
Epoch 105/350
391/391 - 25s - loss: 0.2480 - accuracy: 0.9257 - val_loss: 0.4329 - val_accuracy: 0.8852
Epoch 106/350
391/391 - 24s - loss: 0.2475 - accuracy: 0.9258 - val_loss: 0.4540 - val_accuracy: 0.8836
Epoch 107/350
391/391 - 24s - loss: 0.2447 - accuracy: 0.9268 - val_loss: 0.4369 - val_accuracy: 0.8826
Epoch 108/350
391/391 - 24s - loss: 0.2401 - accuracy: 0.9293 - val_loss: 0.4207 - val_accuracy: 0.8897
Epoch 109/350
391/391 - 24s - loss: 0.2418 - accuracy: 0.9284 - val_loss: 0.4405 - val_accuracy: 0.8841
Epoch 110/350
391/391 - 24s - loss: 0.2418 - accuracy: 0.9285 - val_loss: 0.4162 - val_accuracy: 0.8853
Epoch 111/350
391/391 - 24s - loss: 0.2360 - accuracy: 0.9300 - val_loss: 0.4251 - val_accuracy: 0.8894
Epoch 112/350
391/391 - 24s - loss: 0.2360 - accuracy: 0.9292 - val_loss: 0.4346 - val_accuracy: 0.8863
Epoch 113/350
391/391 - 24s - loss: 0.2353 - accuracy: 0.9315 - val_loss: 0.4287 - val_accuracy: 0.8926
Epoch 114/350
391/391 - 24s - loss: 0.2324 - accuracy: 0.9306 - val_loss: 0.4550 - val_accuracy: 0.8855
Epoch 115/350
391/391 - 24s - loss: 0.2312 - accuracy: 0.9322 - val_loss: 0.4244 - val_accuracy: 0.8869
Epoch 116/350
391/391 - 24s - loss: 0.2303 - accuracy: 0.9322 - val_loss: 0.4564 - val_accuracy: 0.8844
Epoch 117/350
391/391 - 24s - loss: 0.2291 - accuracy: 0.9332 - val_loss: 0.4521 - val_accuracy: 0.8901
Epoch 118/350
391/391 - 24s - loss: 0.2302 - accuracy: 0.9326 - val_loss: 0.4296 - val_accuracy: 0.8895
Epoch 119/350
391/391 - 24s - loss: 0.2278 - accuracy: 0.9335 - val_loss: 0.4339 - val_accuracy: 0.8850
Epoch 120/350
391/391 - 24s - loss: 0.2269 - accuracy: 0.9342 - val_loss: 0.4506 - val_accuracy: 0.8835
Epoch 121/350
391/391 - 24s - loss: 0.2187 - accuracy: 0.9364 - val_loss: 0.4491 - val_accuracy: 0.8887
Epoch 122/350
391/391 - 24s - loss: 0.2251 - accuracy: 0.9345 - val_loss: 0.4613 - val_accuracy: 0.8844
Epoch 123/350
391/391 - 25s - loss: 0.2186 - accuracy: 0.9371 - val_loss: 0.4501 - val_accuracy: 0.8896
Epoch 124/350
391/391 - 24s - loss: 0.2189 - accuracy: 0.9370 - val_loss: 0.4482 - val_accuracy: 0.8816
Epoch 125/350
391/391 - 24s - loss: 0.2180 - accuracy: 0.9369 - val_loss: 0.4707 - val_accuracy: 0.8848
Epoch 126/350
391/391 - 24s - loss: 0.2158 - accuracy: 0.9385 - val_loss: 0.4301 - val_accuracy: 0.8877
Epoch 127/350
391/391 - 24s - loss: 0.2190 - accuracy: 0.9357 - val_loss: 0.4437 - val_accuracy: 0.8855
Epoch 128/350
391/391 - 24s - loss: 0.2147 - accuracy: 0.9388 - val_loss: 0.4339 - val_accuracy: 0.8881
Epoch 129/350
391/391 - 24s - loss: 0.2160 - accuracy: 0.9372 - val_loss: 0.4615 - val_accuracy: 0.8833
Epoch 130/350
391/391 - 24s - loss: 0.2163 - accuracy: 0.9392 - val_loss: 0.4337 - val_accuracy: 0.8902
Epoch 131/350
391/391 - 24s - loss: 0.2154 - accuracy: 0.9373 - val_loss: 0.4758 - val_accuracy: 0.8846
Epoch 132/350
391/391 - 24s - loss: 0.2149 - accuracy: 0.9384 - val_loss: 0.4357 - val_accuracy: 0.8888
Epoch 133/350
391/391 - 24s - loss: 0.2099 - accuracy: 0.9392 - val_loss: 0.4520 - val_accuracy: 0.8841
Epoch 134/350
391/391 - 24s - loss: 0.2145 - accuracy: 0.9383 - val_loss: 0.4541 - val_accuracy: 0.8856
Epoch 135/350
391/391 - 24s - loss: 0.2096 - accuracy: 0.9404 - val_loss: 0.4441 - val_accuracy: 0.8959
Epoch 136/350
391/391 - 24s - loss: 0.2088 - accuracy: 0.9406 - val_loss: 0.4216 - val_accuracy: 0.8957
Epoch 137/350
391/391 - 24s - loss: 0.2085 - accuracy: 0.9403 - val_loss: 0.4583 - val_accuracy: 0.8864
Epoch 138/350
391/391 - 24s - loss: 0.2101 - accuracy: 0.9400 - val_loss: 0.4343 - val_accuracy: 0.8908
Epoch 139/350
391/391 - 25s - loss: 0.1992 - accuracy: 0.9444 - val_loss: 0.4440 - val_accuracy: 0.8900
Epoch 140/350
391/391 - 24s - loss: 0.2070 - accuracy: 0.9409 - val_loss: 0.4535 - val_accuracy: 0.8915
Epoch 141/350
391/391 - 24s - loss: 0.2030 - accuracy: 0.9431 - val_loss: 0.4165 - val_accuracy: 0.8927
Epoch 142/350
391/391 - 24s - loss: 0.1984 - accuracy: 0.9449 - val_loss: 0.4481 - val_accuracy: 0.8914
Epoch 143/350
391/391 - 24s - loss: 0.1964 - accuracy: 0.9452 - val_loss: 0.4368 - val_accuracy: 0.8916
Epoch 144/350
391/391 - 24s - loss: 0.2017 - accuracy: 0.9440 - val_loss: 0.4676 - val_accuracy: 0.8898
Epoch 145/350
391/391 - 24s - loss: 0.1991 - accuracy: 0.9447 - val_loss: 0.4827 - val_accuracy: 0.8837
Epoch 146/350
391/391 - 24s - loss: 0.1958 - accuracy: 0.9449 - val_loss: 0.4460 - val_accuracy: 0.8929
Epoch 147/350
391/391 - 24s - loss: 0.1996 - accuracy: 0.9441 - val_loss: 0.4783 - val_accuracy: 0.8883
Epoch 148/350
391/391 - 25s - loss: 0.1967 - accuracy: 0.9450 - val_loss: 0.4435 - val_accuracy: 0.8952
Epoch 149/350
391/391 - 24s - loss: 0.1959 - accuracy: 0.9453 - val_loss: 0.4378 - val_accuracy: 0.8935
Epoch 150/350


Snapshot weight 2 shuffle 3 at epoch 150
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1910 - accuracy: 0.9473 - val_loss: 0.4590 - val_accuracy: 0.8931
Epoch 151/350
391/391 - 25s - loss: 0.1932 - accuracy: 0.9459 - val_loss: 0.4595 - val_accuracy: 0.8953
Epoch 152/350
391/391 - 24s - loss: 0.1893 - accuracy: 0.9468 - val_loss: 0.4947 - val_accuracy: 0.8877
Epoch 153/350
391/391 - 24s - loss: 0.1908 - accuracy: 0.9459 - val_loss: 0.4365 - val_accuracy: 0.8967
Epoch 154/350
391/391 - 24s - loss: 0.1973 - accuracy: 0.9442 - val_loss: 0.4367 - val_accuracy: 0.8935
Epoch 155/350
391/391 - 24s - loss: 0.1894 - accuracy: 0.9479 - val_loss: 0.4348 - val_accuracy: 0.8934
Epoch 156/350
391/391 - 25s - loss: 0.1887 - accuracy: 0.9478 - val_loss: 0.4427 - val_accuracy: 0.8960
Epoch 157/350
391/391 - 24s - loss: 0.1906 - accuracy: 0.9474 - val_loss: 0.4661 - val_accuracy: 0.8895
Epoch 158/350
391/391 - 24s - loss: 0.1943 - accuracy: 0.9455 - val_loss: 0.4623 - val_accuracy: 0.8919
Epoch 159/350
391/391 - 24s - loss: 0.1856 - accuracy: 0.9502 - val_loss: 0.4831 - val_accuracy: 0.8903
Epoch 160/350
391/391 - 24s - loss: 0.1901 - accuracy: 0.9474 - val_loss: 0.4359 - val_accuracy: 0.8962
Epoch 161/350
391/391 - 24s - loss: 0.1825 - accuracy: 0.9515 - val_loss: 0.4474 - val_accuracy: 0.8951
Epoch 162/350
391/391 - 24s - loss: 0.1881 - accuracy: 0.9487 - val_loss: 0.4459 - val_accuracy: 0.8952
Epoch 163/350
391/391 - 24s - loss: 0.1879 - accuracy: 0.9488 - val_loss: 0.4694 - val_accuracy: 0.8912
Epoch 164/350
391/391 - 24s - loss: 0.1909 - accuracy: 0.9479 - val_loss: 0.4384 - val_accuracy: 0.8963
Epoch 165/350
391/391 - 24s - loss: 0.1799 - accuracy: 0.9516 - val_loss: 0.4911 - val_accuracy: 0.8933
Epoch 166/350
391/391 - 24s - loss: 0.1863 - accuracy: 0.9488 - val_loss: 0.4464 - val_accuracy: 0.8939
Epoch 167/350
391/391 - 24s - loss: 0.1829 - accuracy: 0.9502 - val_loss: 0.4405 - val_accuracy: 0.8977
Epoch 168/350
391/391 - 24s - loss: 0.1846 - accuracy: 0.9498 - val_loss: 0.4602 - val_accuracy: 0.8940
Epoch 169/350
391/391 - 24s - loss: 0.1787 - accuracy: 0.9522 - val_loss: 0.4751 - val_accuracy: 0.8936
Epoch 170/350
391/391 - 24s - loss: 0.1860 - accuracy: 0.9497 - val_loss: 0.4580 - val_accuracy: 0.8935
Epoch 171/350
391/391 - 24s - loss: 0.1808 - accuracy: 0.9511 - val_loss: 0.4419 - val_accuracy: 0.8970
Epoch 172/350
391/391 - 24s - loss: 0.1791 - accuracy: 0.9530 - val_loss: 0.4318 - val_accuracy: 0.8988
Epoch 173/350
391/391 - 24s - loss: 0.1779 - accuracy: 0.9535 - val_loss: 0.4192 - val_accuracy: 0.8958
Epoch 174/350
391/391 - 24s - loss: 0.1764 - accuracy: 0.9532 - val_loss: 0.4670 - val_accuracy: 0.8936
Epoch 175/350
391/391 - 24s - loss: 0.1767 - accuracy: 0.9525 - val_loss: 0.4802 - val_accuracy: 0.8903
Epoch 176/350
391/391 - 24s - loss: 0.1757 - accuracy: 0.9534 - val_loss: 0.4645 - val_accuracy: 0.8903
Epoch 177/350
391/391 - 24s - loss: 0.1768 - accuracy: 0.9540 - val_loss: 0.4662 - val_accuracy: 0.8913
Epoch 178/350
391/391 - 25s - loss: 0.1738 - accuracy: 0.9537 - val_loss: 0.4636 - val_accuracy: 0.8988
Epoch 179/350
391/391 - 24s - loss: 0.1722 - accuracy: 0.9548 - val_loss: 0.4865 - val_accuracy: 0.8886
Epoch 180/350
391/391 - 24s - loss: 0.1731 - accuracy: 0.9557 - val_loss: 0.4439 - val_accuracy: 0.8938
Epoch 181/350
391/391 - 24s - loss: 0.1782 - accuracy: 0.9526 - val_loss: 0.4620 - val_accuracy: 0.8946
Epoch 182/350
391/391 - 24s - loss: 0.1764 - accuracy: 0.9540 - val_loss: 0.4940 - val_accuracy: 0.8921
Epoch 183/350
391/391 - 24s - loss: 0.1754 - accuracy: 0.9523 - val_loss: 0.4600 - val_accuracy: 0.8969
Epoch 184/350
391/391 - 24s - loss: 0.1701 - accuracy: 0.9558 - val_loss: 0.4854 - val_accuracy: 0.8954
Epoch 185/350
391/391 - 24s - loss: 0.1727 - accuracy: 0.9549 - val_loss: 0.4591 - val_accuracy: 0.8978
Epoch 186/350
391/391 - 24s - loss: 0.1708 - accuracy: 0.9562 - val_loss: 0.4615 - val_accuracy: 0.8920
Epoch 187/350
391/391 - 24s - loss: 0.1720 - accuracy: 0.9557 - val_loss: 0.4627 - val_accuracy: 0.8965
Epoch 188/350
391/391 - 25s - loss: 0.1710 - accuracy: 0.9559 - val_loss: 0.4491 - val_accuracy: 0.8978
Epoch 189/350
391/391 - 24s - loss: 0.1699 - accuracy: 0.9558 - val_loss: 0.4371 - val_accuracy: 0.9014
Epoch 190/350
391/391 - 24s - loss: 0.1663 - accuracy: 0.9577 - val_loss: 0.4491 - val_accuracy: 0.9006
Epoch 191/350
391/391 - 24s - loss: 0.1708 - accuracy: 0.9565 - val_loss: 0.4970 - val_accuracy: 0.8927
Epoch 192/350
391/391 - 24s - loss: 0.1688 - accuracy: 0.9577 - val_loss: 0.4780 - val_accuracy: 0.8979
Epoch 193/350
391/391 - 24s - loss: 0.1621 - accuracy: 0.9588 - val_loss: 0.4655 - val_accuracy: 0.9002
Epoch 194/350
391/391 - 24s - loss: 0.1707 - accuracy: 0.9567 - val_loss: 0.5327 - val_accuracy: 0.8923
Epoch 195/350
391/391 - 24s - loss: 0.1660 - accuracy: 0.9567 - val_loss: 0.4953 - val_accuracy: 0.8968
Epoch 196/350
391/391 - 24s - loss: 0.1699 - accuracy: 0.9561 - val_loss: 0.4391 - val_accuracy: 0.8995
Epoch 197/350
391/391 - 24s - loss: 0.1660 - accuracy: 0.9575 - val_loss: 0.4699 - val_accuracy: 0.8955
Epoch 198/350
391/391 - 25s - loss: 0.1649 - accuracy: 0.9576 - val_loss: 0.4625 - val_accuracy: 0.8992
Epoch 199/350
391/391 - 24s - loss: 0.1646 - accuracy: 0.9583 - val_loss: 0.4969 - val_accuracy: 0.8965
Epoch 200/350


Snapshot weight 2 shuffle 3 at epoch 200
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1647 - accuracy: 0.9575 - val_loss: 0.4715 - val_accuracy: 0.8988
Epoch 201/350
391/391 - 24s - loss: 0.1375 - accuracy: 0.9678 - val_loss: 0.4636 - val_accuracy: 0.9058
Epoch 202/350
391/391 - 24s - loss: 0.1258 - accuracy: 0.9726 - val_loss: 0.4635 - val_accuracy: 0.9052
Epoch 203/350
391/391 - 24s - loss: 0.1230 - accuracy: 0.9728 - val_loss: 0.4592 - val_accuracy: 0.9074
Epoch 204/350
391/391 - 24s - loss: 0.1209 - accuracy: 0.9741 - val_loss: 0.4649 - val_accuracy: 0.9075
Epoch 205/350
391/391 - 24s - loss: 0.1186 - accuracy: 0.9739 - val_loss: 0.4759 - val_accuracy: 0.9070
Epoch 206/350
391/391 - 24s - loss: 0.1168 - accuracy: 0.9757 - val_loss: 0.4631 - val_accuracy: 0.9081
Epoch 207/350
391/391 - 24s - loss: 0.1166 - accuracy: 0.9755 - val_loss: 0.4786 - val_accuracy: 0.9080
Epoch 208/350
391/391 - 24s - loss: 0.1171 - accuracy: 0.9752 - val_loss: 0.4826 - val_accuracy: 0.9075
Epoch 209/350
391/391 - 24s - loss: 0.1157 - accuracy: 0.9755 - val_loss: 0.4675 - val_accuracy: 0.9058
Epoch 210/350
391/391 - 24s - loss: 0.1150 - accuracy: 0.9761 - val_loss: 0.4813 - val_accuracy: 0.9050
Epoch 211/350
391/391 - 25s - loss: 0.1134 - accuracy: 0.9763 - val_loss: 0.4728 - val_accuracy: 0.9068
Epoch 212/350
391/391 - 24s - loss: 0.1126 - accuracy: 0.9761 - val_loss: 0.4861 - val_accuracy: 0.9073
Epoch 213/350
391/391 - 24s - loss: 0.1125 - accuracy: 0.9771 - val_loss: 0.4784 - val_accuracy: 0.9071
Epoch 214/350
391/391 - 24s - loss: 0.1108 - accuracy: 0.9770 - val_loss: 0.4907 - val_accuracy: 0.9055
Epoch 215/350
391/391 - 24s - loss: 0.1130 - accuracy: 0.9764 - val_loss: 0.4755 - val_accuracy: 0.9078
Epoch 216/350
391/391 - 24s - loss: 0.1111 - accuracy: 0.9768 - val_loss: 0.4861 - val_accuracy: 0.9074
Epoch 217/350
391/391 - 24s - loss: 0.1105 - accuracy: 0.9774 - val_loss: 0.4865 - val_accuracy: 0.9081
Epoch 218/350
391/391 - 24s - loss: 0.1108 - accuracy: 0.9770 - val_loss: 0.4783 - val_accuracy: 0.9088
Epoch 219/350
391/391 - 24s - loss: 0.1107 - accuracy: 0.9775 - val_loss: 0.4901 - val_accuracy: 0.9070
Epoch 220/350
391/391 - 24s - loss: 0.1083 - accuracy: 0.9776 - val_loss: 0.4840 - val_accuracy: 0.9081
Epoch 221/350
391/391 - 24s - loss: 0.1084 - accuracy: 0.9788 - val_loss: 0.4856 - val_accuracy: 0.9079
Epoch 222/350
391/391 - 24s - loss: 0.1067 - accuracy: 0.9793 - val_loss: 0.4886 - val_accuracy: 0.9079
Epoch 223/350
391/391 - 25s - loss: 0.1098 - accuracy: 0.9772 - val_loss: 0.4798 - val_accuracy: 0.9088
Epoch 224/350
391/391 - 24s - loss: 0.1105 - accuracy: 0.9766 - val_loss: 0.4888 - val_accuracy: 0.9073
Epoch 225/350
391/391 - 24s - loss: 0.1080 - accuracy: 0.9781 - val_loss: 0.4871 - val_accuracy: 0.9079
Epoch 226/350
391/391 - 24s - loss: 0.1069 - accuracy: 0.9785 - val_loss: 0.4929 - val_accuracy: 0.9082
Epoch 227/350
391/391 - 24s - loss: 0.1070 - accuracy: 0.9784 - val_loss: 0.4854 - val_accuracy: 0.9087
Epoch 228/350
391/391 - 24s - loss: 0.1057 - accuracy: 0.9786 - val_loss: 0.4876 - val_accuracy: 0.9101
Epoch 229/350
391/391 - 24s - loss: 0.1073 - accuracy: 0.9779 - val_loss: 0.4858 - val_accuracy: 0.9092
Epoch 230/350
391/391 - 24s - loss: 0.1041 - accuracy: 0.9791 - val_loss: 0.4882 - val_accuracy: 0.9079
Epoch 231/350
391/391 - 24s - loss: 0.1072 - accuracy: 0.9785 - val_loss: 0.4862 - val_accuracy: 0.9090
Epoch 232/350
391/391 - 24s - loss: 0.1036 - accuracy: 0.9800 - val_loss: 0.4988 - val_accuracy: 0.9082
Epoch 233/350
391/391 - 24s - loss: 0.1043 - accuracy: 0.9801 - val_loss: 0.4961 - val_accuracy: 0.9088
Epoch 234/350
391/391 - 25s - loss: 0.1034 - accuracy: 0.9800 - val_loss: 0.5010 - val_accuracy: 0.9081
Epoch 235/350
391/391 - 24s - loss: 0.1069 - accuracy: 0.9779 - val_loss: 0.4855 - val_accuracy: 0.9090
Epoch 236/350
391/391 - 24s - loss: 0.1083 - accuracy: 0.9789 - val_loss: 0.5007 - val_accuracy: 0.9093
Epoch 237/350
391/391 - 24s - loss: 0.1035 - accuracy: 0.9798 - val_loss: 0.4906 - val_accuracy: 0.9083
Epoch 238/350
391/391 - 24s - loss: 0.1046 - accuracy: 0.9791 - val_loss: 0.4890 - val_accuracy: 0.9068
Epoch 239/350
391/391 - 24s - loss: 0.1050 - accuracy: 0.9798 - val_loss: 0.5008 - val_accuracy: 0.9081
Epoch 240/350
391/391 - 24s - loss: 0.1053 - accuracy: 0.9792 - val_loss: 0.4892 - val_accuracy: 0.9088
Epoch 241/350
391/391 - 24s - loss: 0.1043 - accuracy: 0.9795 - val_loss: 0.4929 - val_accuracy: 0.9075
Epoch 242/350
391/391 - 24s - loss: 0.1039 - accuracy: 0.9795 - val_loss: 0.4939 - val_accuracy: 0.9072
Epoch 243/350
391/391 - 24s - loss: 0.1039 - accuracy: 0.9802 - val_loss: 0.5009 - val_accuracy: 0.9091
Epoch 244/350
391/391 - 24s - loss: 0.1058 - accuracy: 0.9794 - val_loss: 0.4912 - val_accuracy: 0.9087
Epoch 245/350
391/391 - 24s - loss: 0.1027 - accuracy: 0.9803 - val_loss: 0.4895 - val_accuracy: 0.9086
Epoch 246/350
391/391 - 24s - loss: 0.1019 - accuracy: 0.9803 - val_loss: 0.4963 - val_accuracy: 0.9081
Epoch 247/350
391/391 - 24s - loss: 0.1029 - accuracy: 0.9796 - val_loss: 0.4942 - val_accuracy: 0.9080
Epoch 248/350
391/391 - 24s - loss: 0.1035 - accuracy: 0.9796 - val_loss: 0.4892 - val_accuracy: 0.9104
Epoch 249/350
391/391 - 24s - loss: 0.1036 - accuracy: 0.9800 - val_loss: 0.4917 - val_accuracy: 0.9085
Epoch 250/350


Snapshot weight 2 shuffle 3 at epoch 250
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1047 - accuracy: 0.9803 - val_loss: 0.4849 - val_accuracy: 0.9083
Epoch 251/350
391/391 - 24s - loss: 0.0995 - accuracy: 0.9810 - val_loss: 0.4913 - val_accuracy: 0.9097
Epoch 252/350
391/391 - 24s - loss: 0.0985 - accuracy: 0.9821 - val_loss: 0.4935 - val_accuracy: 0.9096
Epoch 253/350
391/391 - 24s - loss: 0.0999 - accuracy: 0.9811 - val_loss: 0.4925 - val_accuracy: 0.9095
Epoch 254/350
391/391 - 24s - loss: 0.0991 - accuracy: 0.9810 - val_loss: 0.4932 - val_accuracy: 0.9097
Epoch 255/350
391/391 - 24s - loss: 0.0994 - accuracy: 0.9807 - val_loss: 0.4951 - val_accuracy: 0.9096
Epoch 256/350
391/391 - 24s - loss: 0.0975 - accuracy: 0.9818 - val_loss: 0.4922 - val_accuracy: 0.9106
Epoch 257/350
391/391 - 24s - loss: 0.1001 - accuracy: 0.9803 - val_loss: 0.4952 - val_accuracy: 0.9107
Epoch 258/350
391/391 - 24s - loss: 0.1004 - accuracy: 0.9807 - val_loss: 0.4950 - val_accuracy: 0.9094
Epoch 259/350
391/391 - 24s - loss: 0.0989 - accuracy: 0.9816 - val_loss: 0.4936 - val_accuracy: 0.9101
Epoch 260/350
391/391 - 24s - loss: 0.0983 - accuracy: 0.9817 - val_loss: 0.4960 - val_accuracy: 0.9091
Epoch 261/350
391/391 - 24s - loss: 0.0987 - accuracy: 0.9814 - val_loss: 0.4956 - val_accuracy: 0.9093
Epoch 262/350
391/391 - 24s - loss: 0.0998 - accuracy: 0.9817 - val_loss: 0.4978 - val_accuracy: 0.9087
Epoch 263/350
391/391 - 24s - loss: 0.0986 - accuracy: 0.9815 - val_loss: 0.4964 - val_accuracy: 0.9087
Epoch 264/350
391/391 - 24s - loss: 0.0980 - accuracy: 0.9815 - val_loss: 0.5001 - val_accuracy: 0.9084
Epoch 265/350
391/391 - 24s - loss: 0.0978 - accuracy: 0.9820 - val_loss: 0.4981 - val_accuracy: 0.9096
Epoch 266/350
391/391 - 24s - loss: 0.0996 - accuracy: 0.9804 - val_loss: 0.4973 - val_accuracy: 0.9091
Epoch 267/350
391/391 - 24s - loss: 0.1006 - accuracy: 0.9809 - val_loss: 0.4951 - val_accuracy: 0.9096
Epoch 268/350
391/391 - 24s - loss: 0.0990 - accuracy: 0.9816 - val_loss: 0.4960 - val_accuracy: 0.9096
Epoch 269/350
391/391 - 24s - loss: 0.0971 - accuracy: 0.9819 - val_loss: 0.4946 - val_accuracy: 0.9090
Epoch 270/350
391/391 - 24s - loss: 0.0970 - accuracy: 0.9817 - val_loss: 0.4986 - val_accuracy: 0.9092
Epoch 271/350
391/391 - 24s - loss: 0.0986 - accuracy: 0.9812 - val_loss: 0.5004 - val_accuracy: 0.9085
Epoch 272/350
391/391 - 24s - loss: 0.1010 - accuracy: 0.9801 - val_loss: 0.4977 - val_accuracy: 0.9088
Epoch 273/350
391/391 - 24s - loss: 0.0983 - accuracy: 0.9819 - val_loss: 0.4984 - val_accuracy: 0.9083
Epoch 274/350
391/391 - 24s - loss: 0.0997 - accuracy: 0.9809 - val_loss: 0.4975 - val_accuracy: 0.9093
Epoch 275/350
391/391 - 24s - loss: 0.0985 - accuracy: 0.9823 - val_loss: 0.4967 - val_accuracy: 0.9081
Epoch 276/350
391/391 - 24s - loss: 0.0980 - accuracy: 0.9814 - val_loss: 0.4987 - val_accuracy: 0.9090
Epoch 277/350
391/391 - 25s - loss: 0.0989 - accuracy: 0.9804 - val_loss: 0.4993 - val_accuracy: 0.9087
Epoch 278/350
391/391 - 24s - loss: 0.0993 - accuracy: 0.9812 - val_loss: 0.5012 - val_accuracy: 0.9085
Epoch 279/350
391/391 - 24s - loss: 0.1000 - accuracy: 0.9811 - val_loss: 0.4975 - val_accuracy: 0.9080
Epoch 280/350
391/391 - 25s - loss: 0.0990 - accuracy: 0.9806 - val_loss: 0.4997 - val_accuracy: 0.9078
Epoch 281/350
391/391 - 24s - loss: 0.0980 - accuracy: 0.9814 - val_loss: 0.5022 - val_accuracy: 0.9084
Epoch 282/350
391/391 - 24s - loss: 0.0987 - accuracy: 0.9814 - val_loss: 0.5000 - val_accuracy: 0.9079
Epoch 283/350
391/391 - 24s - loss: 0.0983 - accuracy: 0.9812 - val_loss: 0.4997 - val_accuracy: 0.9085
Epoch 284/350
391/391 - 24s - loss: 0.0996 - accuracy: 0.9815 - val_loss: 0.4988 - val_accuracy: 0.9098
Epoch 285/350
391/391 - 24s - loss: 0.0981 - accuracy: 0.9819 - val_loss: 0.4975 - val_accuracy: 0.9091
Epoch 286/350
391/391 - 24s - loss: 0.0978 - accuracy: 0.9821 - val_loss: 0.4988 - val_accuracy: 0.9088
Epoch 287/350
391/391 - 24s - loss: 0.0975 - accuracy: 0.9824 - val_loss: 0.4978 - val_accuracy: 0.9093
Epoch 288/350
391/391 - 24s - loss: 0.0984 - accuracy: 0.9821 - val_loss: 0.4996 - val_accuracy: 0.9089
Epoch 289/350
391/391 - 24s - loss: 0.0986 - accuracy: 0.9816 - val_loss: 0.5015 - val_accuracy: 0.9095
Epoch 290/350
391/391 - 24s - loss: 0.0996 - accuracy: 0.9813 - val_loss: 0.5000 - val_accuracy: 0.9089
Epoch 291/350
391/391 - 24s - loss: 0.0978 - accuracy: 0.9817 - val_loss: 0.4987 - val_accuracy: 0.9094
Epoch 292/350
391/391 - 24s - loss: 0.0995 - accuracy: 0.9812 - val_loss: 0.5002 - val_accuracy: 0.9090
Epoch 293/350
391/391 - 24s - loss: 0.0986 - accuracy: 0.9814 - val_loss: 0.5005 - val_accuracy: 0.9096
Epoch 294/350
391/391 - 24s - loss: 0.0959 - accuracy: 0.9823 - val_loss: 0.4993 - val_accuracy: 0.9088
Epoch 295/350
391/391 - 24s - loss: 0.0982 - accuracy: 0.9821 - val_loss: 0.4972 - val_accuracy: 0.9090
Epoch 296/350
391/391 - 24s - loss: 0.0969 - accuracy: 0.9826 - val_loss: 0.4998 - val_accuracy: 0.9097
Epoch 297/350
391/391 - 24s - loss: 0.0966 - accuracy: 0.9825 - val_loss: 0.4985 - val_accuracy: 0.9098
Epoch 298/350
391/391 - 24s - loss: 0.0971 - accuracy: 0.9824 - val_loss: 0.4992 - val_accuracy: 0.9092
Epoch 299/350
391/391 - 24s - loss: 0.0979 - accuracy: 0.9821 - val_loss: 0.5008 - val_accuracy: 0.9096
Epoch 300/350


Snapshot weight 2 shuffle 3 at epoch 300
Layer 11
Getting activations...


391/391 - 25s - loss: 0.0967 - accuracy: 0.9819 - val_loss: 0.5004 - val_accuracy: 0.9095
Epoch 301/350
391/391 - 24s - loss: 0.0970 - accuracy: 0.9820 - val_loss: 0.5006 - val_accuracy: 0.9094
Epoch 302/350
391/391 - 24s - loss: 0.0977 - accuracy: 0.9818 - val_loss: 0.5005 - val_accuracy: 0.9099
Epoch 303/350
391/391 - 24s - loss: 0.0970 - accuracy: 0.9819 - val_loss: 0.5003 - val_accuracy: 0.9097
Epoch 304/350
391/391 - 24s - loss: 0.0981 - accuracy: 0.9816 - val_loss: 0.5000 - val_accuracy: 0.9098
Epoch 305/350
391/391 - 24s - loss: 0.0959 - accuracy: 0.9823 - val_loss: 0.5003 - val_accuracy: 0.9099
Epoch 306/350
391/391 - 24s - loss: 0.0974 - accuracy: 0.9823 - val_loss: 0.4999 - val_accuracy: 0.9097
Epoch 307/350
391/391 - 24s - loss: 0.0967 - accuracy: 0.9826 - val_loss: 0.4999 - val_accuracy: 0.9093
Epoch 308/350
391/391 - 24s - loss: 0.1005 - accuracy: 0.9809 - val_loss: 0.4997 - val_accuracy: 0.9096
Epoch 309/350
391/391 - 24s - loss: 0.0958 - accuracy: 0.9824 - val_loss: 0.5001 - val_accuracy: 0.9092
Epoch 310/350
391/391 - 24s - loss: 0.0977 - accuracy: 0.9811 - val_loss: 0.4997 - val_accuracy: 0.9094
Epoch 311/350
391/391 - 24s - loss: 0.0993 - accuracy: 0.9813 - val_loss: 0.4997 - val_accuracy: 0.9095
Epoch 312/350
391/391 - 24s - loss: 0.0954 - accuracy: 0.9822 - val_loss: 0.4997 - val_accuracy: 0.9096
Epoch 313/350
391/391 - 24s - loss: 0.0964 - accuracy: 0.9830 - val_loss: 0.4997 - val_accuracy: 0.9094
Epoch 314/350
391/391 - 24s - loss: 0.0980 - accuracy: 0.9817 - val_loss: 0.5003 - val_accuracy: 0.9094
Epoch 315/350
391/391 - 24s - loss: 0.0970 - accuracy: 0.9825 - val_loss: 0.5003 - val_accuracy: 0.9092
Epoch 316/350
391/391 - 24s - loss: 0.0977 - accuracy: 0.9809 - val_loss: 0.5001 - val_accuracy: 0.9093
Epoch 317/350
391/391 - 25s - loss: 0.0982 - accuracy: 0.9817 - val_loss: 0.5000 - val_accuracy: 0.9094
Epoch 318/350
391/391 - 24s - loss: 0.0981 - accuracy: 0.9819 - val_loss: 0.4999 - val_accuracy: 0.9095
Epoch 319/350
391/391 - 24s - loss: 0.0972 - accuracy: 0.9822 - val_loss: 0.4998 - val_accuracy: 0.9097
Epoch 320/350
391/391 - 24s - loss: 0.0989 - accuracy: 0.9819 - val_loss: 0.4998 - val_accuracy: 0.9097
Epoch 321/350
391/391 - 24s - loss: 0.0995 - accuracy: 0.9810 - val_loss: 0.5002 - val_accuracy: 0.9097
Epoch 322/350
391/391 - 24s - loss: 0.0978 - accuracy: 0.9815 - val_loss: 0.5001 - val_accuracy: 0.9098
Epoch 323/350
391/391 - 24s - loss: 0.0979 - accuracy: 0.9819 - val_loss: 0.5001 - val_accuracy: 0.9098
Epoch 324/350
391/391 - 24s - loss: 0.1006 - accuracy: 0.9807 - val_loss: 0.4997 - val_accuracy: 0.9099
Epoch 325/350
391/391 - 24s - loss: 0.0976 - accuracy: 0.9813 - val_loss: 0.5000 - val_accuracy: 0.9098
Epoch 326/350
391/391 - 24s - loss: 0.0972 - accuracy: 0.9815 - val_loss: 0.4998 - val_accuracy: 0.9095
Epoch 327/350
391/391 - 24s - loss: 0.0990 - accuracy: 0.9820 - val_loss: 0.4996 - val_accuracy: 0.9095
Epoch 328/350
391/391 - 24s - loss: 0.0981 - accuracy: 0.9815 - val_loss: 0.4994 - val_accuracy: 0.9100
Epoch 329/350
391/391 - 24s - loss: 0.0960 - accuracy: 0.9825 - val_loss: 0.4996 - val_accuracy: 0.9095
Epoch 330/350
391/391 - 24s - loss: 0.0956 - accuracy: 0.9829 - val_loss: 0.4999 - val_accuracy: 0.9095
Epoch 331/350
391/391 - 24s - loss: 0.0980 - accuracy: 0.9821 - val_loss: 0.5000 - val_accuracy: 0.9095
Epoch 332/350
391/391 - 24s - loss: 0.0967 - accuracy: 0.9818 - val_loss: 0.5001 - val_accuracy: 0.9093
Epoch 333/350
391/391 - 24s - loss: 0.0972 - accuracy: 0.9823 - val_loss: 0.5002 - val_accuracy: 0.9091
Epoch 334/350
391/391 - 24s - loss: 0.0978 - accuracy: 0.9814 - val_loss: 0.5002 - val_accuracy: 0.9095
Epoch 335/350
391/391 - 24s - loss: 0.0967 - accuracy: 0.9822 - val_loss: 0.5002 - val_accuracy: 0.9095
Epoch 336/350
391/391 - 24s - loss: 0.0963 - accuracy: 0.9824 - val_loss: 0.5002 - val_accuracy: 0.9095
Epoch 337/350
391/391 - 24s - loss: 0.0975 - accuracy: 0.9821 - val_loss: 0.5005 - val_accuracy: 0.9094
Epoch 338/350
391/391 - 24s - loss: 0.0973 - accuracy: 0.9819 - val_loss: 0.5003 - val_accuracy: 0.9097
Epoch 339/350
391/391 - 24s - loss: 0.0987 - accuracy: 0.9814 - val_loss: 0.5004 - val_accuracy: 0.9093
Epoch 340/350
391/391 - 25s - loss: 0.0993 - accuracy: 0.9815 - val_loss: 0.5002 - val_accuracy: 0.9092
Epoch 341/350
391/391 - 24s - loss: 0.0969 - accuracy: 0.9819 - val_loss: 0.5004 - val_accuracy: 0.9091
Epoch 342/350
391/391 - 24s - loss: 0.0983 - accuracy: 0.9814 - val_loss: 0.5005 - val_accuracy: 0.9094
Epoch 343/350
391/391 - 24s - loss: 0.0967 - accuracy: 0.9818 - val_loss: 0.5001 - val_accuracy: 0.9096
Epoch 344/350
391/391 - 24s - loss: 0.0975 - accuracy: 0.9815 - val_loss: 0.5003 - val_accuracy: 0.9096
Epoch 345/350
391/391 - 24s - loss: 0.0985 - accuracy: 0.9811 - val_loss: 0.5007 - val_accuracy: 0.9091
Epoch 346/350
391/391 - 24s - loss: 0.0973 - accuracy: 0.9816 - val_loss: 0.5005 - val_accuracy: 0.9092
Epoch 347/350
391/391 - 24s - loss: 0.0983 - accuracy: 0.9815 - val_loss: 0.5005 - val_accuracy: 0.9095
Epoch 348/350
391/391 - 24s - loss: 0.0969 - accuracy: 0.9817 - val_loss: 0.5006 - val_accuracy: 0.9096
Epoch 349/350
391/391 - 24s - loss: 0.0962 - accuracy: 0.9827 - val_loss: 0.5007 - val_accuracy: 0.9096
Epoch 350/350


Snapshot weight 2 shuffle 3 at epoch 350
Layer 11
Getting activations...


391/391 - 24s - loss: 0.0983 - accuracy: 0.9813 - val_loss: 0.5007 - val_accuracy: 0.9098
/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:493: UserWarning: fill_value is not supported and is always 0 for TensorFlow < 2.4.0.
  return py_builtins.overload_of(f)(*args)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-07-02 02:58:53.928886: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
Saving, final validation acc: 0.9097999930381775
