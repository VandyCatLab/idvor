2021-07-01 23:45:31.981878: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 23:46:50.959474: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-07-01 23:46:50.995139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-01 23:46:50.995212: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 23:46:51.040144: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-01 23:46:51.063883: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-01 23:46:51.072702: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-01 23:46:51.118058: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-01 23:46:51.127030: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-01 23:46:51.207797: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-01 23:46:51.210331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-01 23:46:51.214249: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-01 23:46:51.231455: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600150000 Hz
2021-07-01 23:46:51.231625: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4380310 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-07-01 23:46:51.231646: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-07-01 23:46:51.392883: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4361e10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-07-01 23:46:51.392960: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN X (Pascal), Compute Capability 6.1
2021-07-01 23:46:51.398060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-01 23:46:51.398101: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 23:46:51.398130: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-01 23:46:51.398147: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-01 23:46:51.398164: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-01 23:46:51.398180: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-01 23:46:51.398196: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-01 23:46:51.398809: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-01 23:46:51.400448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-01 23:46:51.402316: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 23:46:53.286590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-01 23:46:53.286664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-07-01 23:46:53.286676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-07-01 23:46:53.292599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11228 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
2021-07-01 23:46:59.165599: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-01 23:47:04.929417: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
Using model index: 30
Making train data...
GCN...
ZCA...
Done!
Making test data...
Done!
Epoch 1/350


Snapshot weight 0 shuffle 3 at epoch 1
Layer 11
Getting activations...


391/391 - 25s - loss: 2.3209 - accuracy: 0.1126 - val_loss: 2.3056 - val_accuracy: 0.1642
Epoch 2/350


Snapshot weight 0 shuffle 3 at epoch 2
Layer 11
Getting activations...


391/391 - 24s - loss: 2.2886 - accuracy: 0.1314 - val_loss: 2.3267 - val_accuracy: 0.1000
Epoch 3/350


Snapshot weight 0 shuffle 3 at epoch 3
Layer 11
Getting activations...


391/391 - 25s - loss: 2.2827 - accuracy: 0.1383 - val_loss: 2.1437 - val_accuracy: 0.2248
Epoch 4/350


Snapshot weight 0 shuffle 3 at epoch 4
Layer 11
Getting activations...


391/391 - 25s - loss: 1.9763 - accuracy: 0.3034 - val_loss: 1.6142 - val_accuracy: 0.4287
Epoch 5/350


Snapshot weight 0 shuffle 3 at epoch 5
Layer 11
Getting activations...


391/391 - 25s - loss: 1.5974 - accuracy: 0.4274 - val_loss: 1.4068 - val_accuracy: 0.5167
Epoch 6/350


Snapshot weight 0 shuffle 3 at epoch 6
Layer 11
Getting activations...


391/391 - 25s - loss: 1.4232 - accuracy: 0.4945 - val_loss: 1.2329 - val_accuracy: 0.5650
Epoch 7/350


Snapshot weight 0 shuffle 3 at epoch 7
Layer 11
Getting activations...


391/391 - 25s - loss: 1.3184 - accuracy: 0.5350 - val_loss: 1.1739 - val_accuracy: 0.5912
Epoch 8/350


Snapshot weight 0 shuffle 3 at epoch 8
Layer 11
Getting activations...


391/391 - 25s - loss: 1.2251 - accuracy: 0.5735 - val_loss: 1.0766 - val_accuracy: 0.6332
Epoch 9/350


Snapshot weight 0 shuffle 3 at epoch 9
Layer 11
Getting activations...


391/391 - 25s - loss: 1.1590 - accuracy: 0.5988 - val_loss: 1.0112 - val_accuracy: 0.6490
Epoch 10/350


Snapshot weight 0 shuffle 3 at epoch 10
Layer 11
Getting activations...


391/391 - 25s - loss: 1.0803 - accuracy: 0.6241 - val_loss: 0.9798 - val_accuracy: 0.6629
Epoch 11/350
391/391 - 25s - loss: 1.0373 - accuracy: 0.6396 - val_loss: 0.9266 - val_accuracy: 0.6804
Epoch 12/350
391/391 - 25s - loss: 0.9892 - accuracy: 0.6600 - val_loss: 0.9826 - val_accuracy: 0.6631
Epoch 13/350
391/391 - 25s - loss: 0.9488 - accuracy: 0.6714 - val_loss: 0.8836 - val_accuracy: 0.6997
Epoch 14/350
391/391 - 25s - loss: 0.9099 - accuracy: 0.6876 - val_loss: 0.8320 - val_accuracy: 0.7154
Epoch 15/350
391/391 - 25s - loss: 0.8765 - accuracy: 0.7002 - val_loss: 0.8109 - val_accuracy: 0.7296
Epoch 16/350
391/391 - 24s - loss: 0.8403 - accuracy: 0.7151 - val_loss: 0.7952 - val_accuracy: 0.7370
Epoch 17/350
391/391 - 25s - loss: 0.8121 - accuracy: 0.7240 - val_loss: 0.7476 - val_accuracy: 0.7537
Epoch 18/350
391/391 - 25s - loss: 0.7797 - accuracy: 0.7346 - val_loss: 0.7752 - val_accuracy: 0.7477
Epoch 19/350
391/391 - 24s - loss: 0.7567 - accuracy: 0.7454 - val_loss: 0.7336 - val_accuracy: 0.7615
Epoch 20/350
391/391 - 25s - loss: 0.7386 - accuracy: 0.7505 - val_loss: 0.6828 - val_accuracy: 0.7768
Epoch 21/350
391/391 - 24s - loss: 0.7069 - accuracy: 0.7640 - val_loss: 0.6571 - val_accuracy: 0.7808
Epoch 22/350
391/391 - 24s - loss: 0.6807 - accuracy: 0.7717 - val_loss: 0.6421 - val_accuracy: 0.7897
Epoch 23/350
391/391 - 25s - loss: 0.6681 - accuracy: 0.7783 - val_loss: 0.6563 - val_accuracy: 0.7899
Epoch 24/350
391/391 - 25s - loss: 0.6481 - accuracy: 0.7852 - val_loss: 0.5956 - val_accuracy: 0.8088
Epoch 25/350
391/391 - 24s - loss: 0.6327 - accuracy: 0.7891 - val_loss: 0.6306 - val_accuracy: 0.7978
Epoch 26/350
391/391 - 24s - loss: 0.6077 - accuracy: 0.7990 - val_loss: 0.5916 - val_accuracy: 0.8060
Epoch 27/350
391/391 - 25s - loss: 0.6021 - accuracy: 0.8014 - val_loss: 0.6151 - val_accuracy: 0.8052
Epoch 28/350
391/391 - 24s - loss: 0.5884 - accuracy: 0.8050 - val_loss: 0.5383 - val_accuracy: 0.8230
Epoch 29/350
391/391 - 25s - loss: 0.5791 - accuracy: 0.8087 - val_loss: 0.5789 - val_accuracy: 0.8133
Epoch 30/350
391/391 - 24s - loss: 0.5652 - accuracy: 0.8155 - val_loss: 0.5456 - val_accuracy: 0.8264
Epoch 31/350
391/391 - 25s - loss: 0.5515 - accuracy: 0.8190 - val_loss: 0.5242 - val_accuracy: 0.8283
Epoch 32/350
391/391 - 24s - loss: 0.5444 - accuracy: 0.8201 - val_loss: 0.5181 - val_accuracy: 0.8340
Epoch 33/350
391/391 - 25s - loss: 0.5279 - accuracy: 0.8275 - val_loss: 0.5135 - val_accuracy: 0.8341
Epoch 34/350
391/391 - 25s - loss: 0.5196 - accuracy: 0.8280 - val_loss: 0.5159 - val_accuracy: 0.8332
Epoch 35/350
391/391 - 24s - loss: 0.5101 - accuracy: 0.8334 - val_loss: 0.5224 - val_accuracy: 0.8383
Epoch 36/350
391/391 - 25s - loss: 0.5056 - accuracy: 0.8357 - val_loss: 0.4892 - val_accuracy: 0.8455
Epoch 37/350
391/391 - 24s - loss: 0.4939 - accuracy: 0.8376 - val_loss: 0.5316 - val_accuracy: 0.8357
Epoch 38/350
391/391 - 25s - loss: 0.4827 - accuracy: 0.8428 - val_loss: 0.4851 - val_accuracy: 0.8460
Epoch 39/350
391/391 - 24s - loss: 0.4822 - accuracy: 0.8407 - val_loss: 0.5021 - val_accuracy: 0.8421
Epoch 40/350
391/391 - 25s - loss: 0.4750 - accuracy: 0.8470 - val_loss: 0.5011 - val_accuracy: 0.8404
Epoch 41/350
391/391 - 25s - loss: 0.4662 - accuracy: 0.8482 - val_loss: 0.4735 - val_accuracy: 0.8523
Epoch 42/350
391/391 - 25s - loss: 0.4535 - accuracy: 0.8516 - val_loss: 0.4924 - val_accuracy: 0.8445
Epoch 43/350
391/391 - 25s - loss: 0.4523 - accuracy: 0.8537 - val_loss: 0.5005 - val_accuracy: 0.8431
Epoch 44/350
391/391 - 24s - loss: 0.4410 - accuracy: 0.8570 - val_loss: 0.4839 - val_accuracy: 0.8542
Epoch 45/350
391/391 - 25s - loss: 0.4407 - accuracy: 0.8580 - val_loss: 0.4864 - val_accuracy: 0.8493
Epoch 46/350
391/391 - 25s - loss: 0.4373 - accuracy: 0.8579 - val_loss: 0.4593 - val_accuracy: 0.8554
Epoch 47/350
391/391 - 25s - loss: 0.4268 - accuracy: 0.8610 - val_loss: 0.4743 - val_accuracy: 0.8526
Epoch 48/350
391/391 - 25s - loss: 0.4206 - accuracy: 0.8648 - val_loss: 0.4609 - val_accuracy: 0.8569
Epoch 49/350
391/391 - 25s - loss: 0.4150 - accuracy: 0.8679 - val_loss: 0.4425 - val_accuracy: 0.8650
Epoch 50/350


Snapshot weight 0 shuffle 3 at epoch 50
Layer 11
Getting activations...


391/391 - 25s - loss: 0.4070 - accuracy: 0.8696 - val_loss: 0.4607 - val_accuracy: 0.8594
Epoch 51/350
391/391 - 25s - loss: 0.4098 - accuracy: 0.8698 - val_loss: 0.4366 - val_accuracy: 0.8604
Epoch 52/350
391/391 - 24s - loss: 0.4009 - accuracy: 0.8713 - val_loss: 0.4411 - val_accuracy: 0.8625
Epoch 53/350
391/391 - 24s - loss: 0.3949 - accuracy: 0.8741 - val_loss: 0.4428 - val_accuracy: 0.8656
Epoch 54/350
391/391 - 25s - loss: 0.3941 - accuracy: 0.8732 - val_loss: 0.4303 - val_accuracy: 0.8660
Epoch 55/350
391/391 - 25s - loss: 0.3893 - accuracy: 0.8753 - val_loss: 0.4444 - val_accuracy: 0.8642
Epoch 56/350
391/391 - 25s - loss: 0.3798 - accuracy: 0.8770 - val_loss: 0.4656 - val_accuracy: 0.8634
Epoch 57/350
391/391 - 24s - loss: 0.3818 - accuracy: 0.8787 - val_loss: 0.4172 - val_accuracy: 0.8743
Epoch 58/350
391/391 - 25s - loss: 0.3743 - accuracy: 0.8783 - val_loss: 0.4472 - val_accuracy: 0.8638
Epoch 59/350
391/391 - 25s - loss: 0.3716 - accuracy: 0.8817 - val_loss: 0.4295 - val_accuracy: 0.8697
Epoch 60/350
391/391 - 24s - loss: 0.3671 - accuracy: 0.8826 - val_loss: 0.4504 - val_accuracy: 0.8627
Epoch 61/350
391/391 - 24s - loss: 0.3642 - accuracy: 0.8846 - val_loss: 0.4404 - val_accuracy: 0.8695
Epoch 62/350
391/391 - 24s - loss: 0.3589 - accuracy: 0.8866 - val_loss: 0.4260 - val_accuracy: 0.8715
Epoch 63/350
391/391 - 24s - loss: 0.3585 - accuracy: 0.8859 - val_loss: 0.4366 - val_accuracy: 0.8702
Epoch 64/350
391/391 - 24s - loss: 0.3540 - accuracy: 0.8872 - val_loss: 0.4752 - val_accuracy: 0.8657
Epoch 65/350
391/391 - 24s - loss: 0.3446 - accuracy: 0.8902 - val_loss: 0.4594 - val_accuracy: 0.8652
Epoch 66/350
391/391 - 24s - loss: 0.3447 - accuracy: 0.8906 - val_loss: 0.4486 - val_accuracy: 0.8693
Epoch 67/350
391/391 - 25s - loss: 0.3429 - accuracy: 0.8929 - val_loss: 0.4334 - val_accuracy: 0.8700
Epoch 68/350
391/391 - 24s - loss: 0.3372 - accuracy: 0.8947 - val_loss: 0.4064 - val_accuracy: 0.8812
Epoch 69/350
391/391 - 25s - loss: 0.3333 - accuracy: 0.8955 - val_loss: 0.4236 - val_accuracy: 0.8768
Epoch 70/350
391/391 - 25s - loss: 0.3294 - accuracy: 0.8970 - val_loss: 0.4108 - val_accuracy: 0.8791
Epoch 71/350
391/391 - 24s - loss: 0.3275 - accuracy: 0.8970 - val_loss: 0.4321 - val_accuracy: 0.8740
Epoch 72/350
391/391 - 24s - loss: 0.3272 - accuracy: 0.8960 - val_loss: 0.4213 - val_accuracy: 0.8792
Epoch 73/350
391/391 - 24s - loss: 0.3185 - accuracy: 0.9005 - val_loss: 0.4390 - val_accuracy: 0.8748
Epoch 74/350
391/391 - 25s - loss: 0.3219 - accuracy: 0.8993 - val_loss: 0.4198 - val_accuracy: 0.8794
Epoch 75/350
391/391 - 25s - loss: 0.3158 - accuracy: 0.9006 - val_loss: 0.4445 - val_accuracy: 0.8737
Epoch 76/350
391/391 - 24s - loss: 0.3118 - accuracy: 0.9015 - val_loss: 0.4452 - val_accuracy: 0.8725
Epoch 77/350
391/391 - 25s - loss: 0.3077 - accuracy: 0.9046 - val_loss: 0.4241 - val_accuracy: 0.8797
Epoch 78/350
391/391 - 24s - loss: 0.3055 - accuracy: 0.9058 - val_loss: 0.4345 - val_accuracy: 0.8702
Epoch 79/350
391/391 - 25s - loss: 0.3024 - accuracy: 0.9065 - val_loss: 0.4088 - val_accuracy: 0.8784
Epoch 80/350
391/391 - 25s - loss: 0.2988 - accuracy: 0.9076 - val_loss: 0.3917 - val_accuracy: 0.8852
Epoch 81/350
391/391 - 25s - loss: 0.3047 - accuracy: 0.9055 - val_loss: 0.4220 - val_accuracy: 0.8804
Epoch 82/350
391/391 - 25s - loss: 0.2963 - accuracy: 0.9083 - val_loss: 0.4177 - val_accuracy: 0.8811
Epoch 83/350
391/391 - 25s - loss: 0.2934 - accuracy: 0.9080 - val_loss: 0.4294 - val_accuracy: 0.8751
Epoch 84/350
391/391 - 24s - loss: 0.2930 - accuracy: 0.9090 - val_loss: 0.4095 - val_accuracy: 0.8797
Epoch 85/350
391/391 - 25s - loss: 0.2840 - accuracy: 0.9136 - val_loss: 0.4273 - val_accuracy: 0.8814
Epoch 86/350
391/391 - 25s - loss: 0.2844 - accuracy: 0.9120 - val_loss: 0.4296 - val_accuracy: 0.8771
Epoch 87/350
391/391 - 24s - loss: 0.2836 - accuracy: 0.9124 - val_loss: 0.4325 - val_accuracy: 0.8755
Epoch 88/350
391/391 - 24s - loss: 0.2789 - accuracy: 0.9129 - val_loss: 0.4471 - val_accuracy: 0.8779
Epoch 89/350
391/391 - 25s - loss: 0.2789 - accuracy: 0.9135 - val_loss: 0.4168 - val_accuracy: 0.8829
Epoch 90/350
391/391 - 25s - loss: 0.2795 - accuracy: 0.9137 - val_loss: 0.4008 - val_accuracy: 0.8863
Epoch 91/350
391/391 - 25s - loss: 0.2757 - accuracy: 0.9150 - val_loss: 0.4127 - val_accuracy: 0.8850
Epoch 92/350
391/391 - 25s - loss: 0.2740 - accuracy: 0.9151 - val_loss: 0.4168 - val_accuracy: 0.8839
Epoch 93/350
391/391 - 25s - loss: 0.2771 - accuracy: 0.9147 - val_loss: 0.4116 - val_accuracy: 0.8868
Epoch 94/350
391/391 - 25s - loss: 0.2727 - accuracy: 0.9157 - val_loss: 0.4321 - val_accuracy: 0.8833
Epoch 95/350
391/391 - 25s - loss: 0.2673 - accuracy: 0.9190 - val_loss: 0.4162 - val_accuracy: 0.8888
Epoch 96/350
391/391 - 25s - loss: 0.2693 - accuracy: 0.9171 - val_loss: 0.4232 - val_accuracy: 0.8824
Epoch 97/350
391/391 - 24s - loss: 0.2646 - accuracy: 0.9206 - val_loss: 0.4303 - val_accuracy: 0.8831
Epoch 98/350
391/391 - 24s - loss: 0.2590 - accuracy: 0.9211 - val_loss: 0.4139 - val_accuracy: 0.8845
Epoch 99/350
391/391 - 24s - loss: 0.2595 - accuracy: 0.9208 - val_loss: 0.4037 - val_accuracy: 0.8903
Epoch 100/350


Snapshot weight 0 shuffle 3 at epoch 100
Layer 11
Getting activations...


391/391 - 25s - loss: 0.2614 - accuracy: 0.9221 - val_loss: 0.4271 - val_accuracy: 0.8865
Epoch 101/350
391/391 - 25s - loss: 0.2619 - accuracy: 0.9213 - val_loss: 0.4471 - val_accuracy: 0.8772
Epoch 102/350
391/391 - 24s - loss: 0.2559 - accuracy: 0.9220 - val_loss: 0.4291 - val_accuracy: 0.8865
Epoch 103/350
391/391 - 24s - loss: 0.2493 - accuracy: 0.9261 - val_loss: 0.4031 - val_accuracy: 0.8939
Epoch 104/350
391/391 - 25s - loss: 0.2474 - accuracy: 0.9264 - val_loss: 0.4533 - val_accuracy: 0.8815
Epoch 105/350
391/391 - 25s - loss: 0.2501 - accuracy: 0.9249 - val_loss: 0.4166 - val_accuracy: 0.8871
Epoch 106/350
391/391 - 24s - loss: 0.2489 - accuracy: 0.9256 - val_loss: 0.4230 - val_accuracy: 0.8919
Epoch 107/350
391/391 - 25s - loss: 0.2445 - accuracy: 0.9269 - val_loss: 0.4001 - val_accuracy: 0.8910
Epoch 108/350
391/391 - 24s - loss: 0.2417 - accuracy: 0.9277 - val_loss: 0.3867 - val_accuracy: 0.8966
Epoch 109/350
391/391 - 24s - loss: 0.2467 - accuracy: 0.9261 - val_loss: 0.4357 - val_accuracy: 0.8865
Epoch 110/350
391/391 - 24s - loss: 0.2424 - accuracy: 0.9270 - val_loss: 0.4011 - val_accuracy: 0.8873
Epoch 111/350
391/391 - 24s - loss: 0.2405 - accuracy: 0.9286 - val_loss: 0.4404 - val_accuracy: 0.8848
Epoch 112/350
391/391 - 24s - loss: 0.2420 - accuracy: 0.9272 - val_loss: 0.4325 - val_accuracy: 0.8835
Epoch 113/350
391/391 - 25s - loss: 0.2366 - accuracy: 0.9298 - val_loss: 0.4290 - val_accuracy: 0.8933
Epoch 114/350
391/391 - 25s - loss: 0.2382 - accuracy: 0.9295 - val_loss: 0.4054 - val_accuracy: 0.8916
Epoch 115/350
391/391 - 25s - loss: 0.2395 - accuracy: 0.9289 - val_loss: 0.4336 - val_accuracy: 0.8852
Epoch 116/350
391/391 - 25s - loss: 0.2328 - accuracy: 0.9310 - val_loss: 0.4664 - val_accuracy: 0.8803
Epoch 117/350
391/391 - 25s - loss: 0.2347 - accuracy: 0.9307 - val_loss: 0.4436 - val_accuracy: 0.8880
Epoch 118/350
391/391 - 24s - loss: 0.2300 - accuracy: 0.9322 - val_loss: 0.4221 - val_accuracy: 0.8890
Epoch 119/350
391/391 - 25s - loss: 0.2269 - accuracy: 0.9339 - val_loss: 0.4605 - val_accuracy: 0.8875
Epoch 120/350
391/391 - 25s - loss: 0.2305 - accuracy: 0.9314 - val_loss: 0.4450 - val_accuracy: 0.8826
Epoch 121/350
391/391 - 25s - loss: 0.2274 - accuracy: 0.9321 - val_loss: 0.4282 - val_accuracy: 0.8903
Epoch 122/350
391/391 - 25s - loss: 0.2244 - accuracy: 0.9338 - val_loss: 0.4946 - val_accuracy: 0.8819
Epoch 123/350
391/391 - 24s - loss: 0.2272 - accuracy: 0.9328 - val_loss: 0.4251 - val_accuracy: 0.8871
Epoch 124/350
391/391 - 25s - loss: 0.2225 - accuracy: 0.9339 - val_loss: 0.4661 - val_accuracy: 0.8792
Epoch 125/350
391/391 - 24s - loss: 0.2235 - accuracy: 0.9342 - val_loss: 0.4488 - val_accuracy: 0.8853
Epoch 126/350
391/391 - 25s - loss: 0.2172 - accuracy: 0.9367 - val_loss: 0.4167 - val_accuracy: 0.8922
Epoch 127/350
391/391 - 24s - loss: 0.2188 - accuracy: 0.9373 - val_loss: 0.4250 - val_accuracy: 0.8926
Epoch 128/350
391/391 - 25s - loss: 0.2214 - accuracy: 0.9351 - val_loss: 0.4277 - val_accuracy: 0.8889
Epoch 129/350
391/391 - 24s - loss: 0.2195 - accuracy: 0.9352 - val_loss: 0.4221 - val_accuracy: 0.8885
Epoch 130/350
391/391 - 24s - loss: 0.2177 - accuracy: 0.9374 - val_loss: 0.4123 - val_accuracy: 0.8947
Epoch 131/350
391/391 - 25s - loss: 0.2123 - accuracy: 0.9394 - val_loss: 0.4583 - val_accuracy: 0.8866
Epoch 132/350
391/391 - 24s - loss: 0.2164 - accuracy: 0.9368 - val_loss: 0.4274 - val_accuracy: 0.8908
Epoch 133/350
391/391 - 25s - loss: 0.2140 - accuracy: 0.9384 - val_loss: 0.4587 - val_accuracy: 0.8875
Epoch 134/350
391/391 - 24s - loss: 0.2174 - accuracy: 0.9369 - val_loss: 0.4235 - val_accuracy: 0.8907
Epoch 135/350
391/391 - 24s - loss: 0.2092 - accuracy: 0.9410 - val_loss: 0.4740 - val_accuracy: 0.8853
Epoch 136/350
391/391 - 25s - loss: 0.2083 - accuracy: 0.9405 - val_loss: 0.4239 - val_accuracy: 0.8939
Epoch 137/350
391/391 - 24s - loss: 0.2088 - accuracy: 0.9412 - val_loss: 0.4685 - val_accuracy: 0.8869
Epoch 138/350
391/391 - 25s - loss: 0.2050 - accuracy: 0.9413 - val_loss: 0.4361 - val_accuracy: 0.8894
Epoch 139/350
391/391 - 24s - loss: 0.2047 - accuracy: 0.9413 - val_loss: 0.4510 - val_accuracy: 0.8882
Epoch 140/350
391/391 - 25s - loss: 0.2059 - accuracy: 0.9416 - val_loss: 0.4575 - val_accuracy: 0.8893
Epoch 141/350
391/391 - 25s - loss: 0.2011 - accuracy: 0.9428 - val_loss: 0.4295 - val_accuracy: 0.8930
Epoch 142/350
391/391 - 24s - loss: 0.2065 - accuracy: 0.9410 - val_loss: 0.4555 - val_accuracy: 0.8875
Epoch 143/350
391/391 - 24s - loss: 0.2025 - accuracy: 0.9436 - val_loss: 0.4495 - val_accuracy: 0.8924
Epoch 144/350
391/391 - 25s - loss: 0.2003 - accuracy: 0.9441 - val_loss: 0.4338 - val_accuracy: 0.8962
Epoch 145/350
391/391 - 24s - loss: 0.2034 - accuracy: 0.9432 - val_loss: 0.4470 - val_accuracy: 0.8936
Epoch 146/350
391/391 - 24s - loss: 0.2023 - accuracy: 0.9432 - val_loss: 0.4469 - val_accuracy: 0.8941
Epoch 147/350
391/391 - 24s - loss: 0.2007 - accuracy: 0.9451 - val_loss: 0.4235 - val_accuracy: 0.8979
Epoch 148/350
391/391 - 25s - loss: 0.2023 - accuracy: 0.9437 - val_loss: 0.4515 - val_accuracy: 0.8911
Epoch 149/350
391/391 - 24s - loss: 0.1969 - accuracy: 0.9450 - val_loss: 0.4890 - val_accuracy: 0.8863
Epoch 150/350


Snapshot weight 0 shuffle 3 at epoch 150
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1986 - accuracy: 0.9446 - val_loss: 0.4176 - val_accuracy: 0.8965
Epoch 151/350
391/391 - 25s - loss: 0.2025 - accuracy: 0.9431 - val_loss: 0.4205 - val_accuracy: 0.8993
Epoch 152/350
391/391 - 24s - loss: 0.1912 - accuracy: 0.9469 - val_loss: 0.4906 - val_accuracy: 0.8878
Epoch 153/350
391/391 - 25s - loss: 0.1911 - accuracy: 0.9458 - val_loss: 0.4863 - val_accuracy: 0.8903
Epoch 154/350
391/391 - 25s - loss: 0.1964 - accuracy: 0.9454 - val_loss: 0.4531 - val_accuracy: 0.8920
Epoch 155/350
391/391 - 24s - loss: 0.1953 - accuracy: 0.9458 - val_loss: 0.4287 - val_accuracy: 0.8945
Epoch 156/350
391/391 - 24s - loss: 0.1892 - accuracy: 0.9493 - val_loss: 0.4368 - val_accuracy: 0.8951
Epoch 157/350
391/391 - 24s - loss: 0.1904 - accuracy: 0.9471 - val_loss: 0.4494 - val_accuracy: 0.8920
Epoch 158/350
391/391 - 25s - loss: 0.1937 - accuracy: 0.9463 - val_loss: 0.4283 - val_accuracy: 0.8933
Epoch 159/350
391/391 - 25s - loss: 0.1895 - accuracy: 0.9474 - val_loss: 0.4413 - val_accuracy: 0.8959
Epoch 160/350
391/391 - 24s - loss: 0.1882 - accuracy: 0.9483 - val_loss: 0.4358 - val_accuracy: 0.8970
Epoch 161/350
391/391 - 25s - loss: 0.1832 - accuracy: 0.9505 - val_loss: 0.4598 - val_accuracy: 0.8942
Epoch 162/350
391/391 - 25s - loss: 0.1857 - accuracy: 0.9492 - val_loss: 0.4466 - val_accuracy: 0.8980
Epoch 163/350
391/391 - 24s - loss: 0.1918 - accuracy: 0.9480 - val_loss: 0.4505 - val_accuracy: 0.8924
Epoch 164/350
391/391 - 24s - loss: 0.1852 - accuracy: 0.9500 - val_loss: 0.4784 - val_accuracy: 0.8953
Epoch 165/350
391/391 - 24s - loss: 0.1842 - accuracy: 0.9489 - val_loss: 0.4296 - val_accuracy: 0.8964
Epoch 166/350
391/391 - 24s - loss: 0.1867 - accuracy: 0.9486 - val_loss: 0.4563 - val_accuracy: 0.8951
Epoch 167/350
391/391 - 24s - loss: 0.1868 - accuracy: 0.9480 - val_loss: 0.4684 - val_accuracy: 0.8950
Epoch 168/350
391/391 - 24s - loss: 0.1855 - accuracy: 0.9502 - val_loss: 0.4563 - val_accuracy: 0.8960
Epoch 169/350
391/391 - 24s - loss: 0.1806 - accuracy: 0.9508 - val_loss: 0.4664 - val_accuracy: 0.8957
Epoch 170/350
391/391 - 25s - loss: 0.1828 - accuracy: 0.9500 - val_loss: 0.4423 - val_accuracy: 0.8942
Epoch 171/350
391/391 - 24s - loss: 0.1789 - accuracy: 0.9519 - val_loss: 0.4401 - val_accuracy: 0.8992
Epoch 172/350
391/391 - 25s - loss: 0.1776 - accuracy: 0.9534 - val_loss: 0.4422 - val_accuracy: 0.8999
Epoch 173/350
391/391 - 24s - loss: 0.1752 - accuracy: 0.9537 - val_loss: 0.4498 - val_accuracy: 0.8924
Epoch 174/350
391/391 - 25s - loss: 0.1784 - accuracy: 0.9530 - val_loss: 0.4321 - val_accuracy: 0.8980
Epoch 175/350
391/391 - 25s - loss: 0.1772 - accuracy: 0.9521 - val_loss: 0.4827 - val_accuracy: 0.8943
Epoch 176/350
391/391 - 24s - loss: 0.1791 - accuracy: 0.9527 - val_loss: 0.4559 - val_accuracy: 0.8950
Epoch 177/350
391/391 - 24s - loss: 0.1736 - accuracy: 0.9541 - val_loss: 0.4560 - val_accuracy: 0.8935
Epoch 178/350
391/391 - 24s - loss: 0.1757 - accuracy: 0.9533 - val_loss: 0.4384 - val_accuracy: 0.8976
Epoch 179/350
391/391 - 24s - loss: 0.1770 - accuracy: 0.9540 - val_loss: 0.4701 - val_accuracy: 0.8974
Epoch 180/350
391/391 - 24s - loss: 0.1760 - accuracy: 0.9535 - val_loss: 0.4492 - val_accuracy: 0.8993
Epoch 181/350
391/391 - 25s - loss: 0.1785 - accuracy: 0.9525 - val_loss: 0.4518 - val_accuracy: 0.8948
Epoch 182/350
391/391 - 24s - loss: 0.1745 - accuracy: 0.9536 - val_loss: 0.5037 - val_accuracy: 0.8930
Epoch 183/350
391/391 - 24s - loss: 0.1756 - accuracy: 0.9540 - val_loss: 0.4640 - val_accuracy: 0.8957
Epoch 184/350
391/391 - 25s - loss: 0.1730 - accuracy: 0.9548 - val_loss: 0.4805 - val_accuracy: 0.8949
Epoch 185/350
391/391 - 24s - loss: 0.1716 - accuracy: 0.9546 - val_loss: 0.4605 - val_accuracy: 0.8993
Epoch 186/350
391/391 - 25s - loss: 0.1717 - accuracy: 0.9549 - val_loss: 0.4546 - val_accuracy: 0.8979
Epoch 187/350
391/391 - 24s - loss: 0.1669 - accuracy: 0.9564 - val_loss: 0.4745 - val_accuracy: 0.8989
Epoch 188/350
391/391 - 24s - loss: 0.1673 - accuracy: 0.9566 - val_loss: 0.4861 - val_accuracy: 0.8958
Epoch 189/350
391/391 - 24s - loss: 0.1699 - accuracy: 0.9556 - val_loss: 0.4325 - val_accuracy: 0.9013
Epoch 190/350
391/391 - 25s - loss: 0.1662 - accuracy: 0.9573 - val_loss: 0.4539 - val_accuracy: 0.8994
Epoch 191/350
391/391 - 25s - loss: 0.1711 - accuracy: 0.9566 - val_loss: 0.4739 - val_accuracy: 0.8965
Epoch 192/350
391/391 - 24s - loss: 0.1674 - accuracy: 0.9576 - val_loss: 0.4935 - val_accuracy: 0.8913
Epoch 193/350
391/391 - 24s - loss: 0.1646 - accuracy: 0.9580 - val_loss: 0.4900 - val_accuracy: 0.8976
Epoch 194/350
391/391 - 24s - loss: 0.1693 - accuracy: 0.9561 - val_loss: 0.4790 - val_accuracy: 0.8957
Epoch 195/350
391/391 - 24s - loss: 0.1631 - accuracy: 0.9580 - val_loss: 0.4747 - val_accuracy: 0.8952
Epoch 196/350
391/391 - 24s - loss: 0.1704 - accuracy: 0.9558 - val_loss: 0.4585 - val_accuracy: 0.8978
Epoch 197/350
391/391 - 24s - loss: 0.1665 - accuracy: 0.9569 - val_loss: 0.4625 - val_accuracy: 0.8943
Epoch 198/350
391/391 - 25s - loss: 0.1664 - accuracy: 0.9574 - val_loss: 0.4477 - val_accuracy: 0.8980
Epoch 199/350
391/391 - 24s - loss: 0.1623 - accuracy: 0.9578 - val_loss: 0.4821 - val_accuracy: 0.8939
Epoch 200/350


Snapshot weight 0 shuffle 3 at epoch 200
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1631 - accuracy: 0.9591 - val_loss: 0.4913 - val_accuracy: 0.8942
Epoch 201/350
391/391 - 24s - loss: 0.1390 - accuracy: 0.9668 - val_loss: 0.4602 - val_accuracy: 0.9032
Epoch 202/350
391/391 - 24s - loss: 0.1267 - accuracy: 0.9717 - val_loss: 0.4592 - val_accuracy: 0.9044
Epoch 203/350
391/391 - 24s - loss: 0.1244 - accuracy: 0.9723 - val_loss: 0.4650 - val_accuracy: 0.9038
Epoch 204/350
391/391 - 24s - loss: 0.1184 - accuracy: 0.9745 - val_loss: 0.4698 - val_accuracy: 0.9056
Epoch 205/350
391/391 - 24s - loss: 0.1226 - accuracy: 0.9735 - val_loss: 0.4598 - val_accuracy: 0.9067
Epoch 206/350
391/391 - 24s - loss: 0.1174 - accuracy: 0.9750 - val_loss: 0.4729 - val_accuracy: 0.9058
Epoch 207/350
391/391 - 24s - loss: 0.1178 - accuracy: 0.9740 - val_loss: 0.4596 - val_accuracy: 0.9076
Epoch 208/350
391/391 - 25s - loss: 0.1182 - accuracy: 0.9744 - val_loss: 0.4704 - val_accuracy: 0.9060
Epoch 209/350
391/391 - 25s - loss: 0.1138 - accuracy: 0.9759 - val_loss: 0.4680 - val_accuracy: 0.9079
Epoch 210/350
391/391 - 24s - loss: 0.1151 - accuracy: 0.9754 - val_loss: 0.4757 - val_accuracy: 0.9058
Epoch 211/350
391/391 - 24s - loss: 0.1137 - accuracy: 0.9755 - val_loss: 0.4729 - val_accuracy: 0.9072
Epoch 212/350
391/391 - 24s - loss: 0.1137 - accuracy: 0.9753 - val_loss: 0.4747 - val_accuracy: 0.9087
Epoch 213/350
391/391 - 24s - loss: 0.1113 - accuracy: 0.9762 - val_loss: 0.4799 - val_accuracy: 0.9095
Epoch 214/350
391/391 - 24s - loss: 0.1139 - accuracy: 0.9767 - val_loss: 0.4767 - val_accuracy: 0.9094
Epoch 215/350
391/391 - 24s - loss: 0.1120 - accuracy: 0.9760 - val_loss: 0.4830 - val_accuracy: 0.9069
Epoch 216/350
391/391 - 24s - loss: 0.1112 - accuracy: 0.9770 - val_loss: 0.4880 - val_accuracy: 0.9050
Epoch 217/350
391/391 - 24s - loss: 0.1107 - accuracy: 0.9771 - val_loss: 0.4794 - val_accuracy: 0.9070
Epoch 218/350
391/391 - 25s - loss: 0.1106 - accuracy: 0.9775 - val_loss: 0.4859 - val_accuracy: 0.9059
Epoch 219/350
391/391 - 24s - loss: 0.1097 - accuracy: 0.9773 - val_loss: 0.4847 - val_accuracy: 0.9062
Epoch 220/350
391/391 - 24s - loss: 0.1078 - accuracy: 0.9781 - val_loss: 0.4867 - val_accuracy: 0.9068
Epoch 221/350
391/391 - 25s - loss: 0.1114 - accuracy: 0.9765 - val_loss: 0.4823 - val_accuracy: 0.9066
Epoch 222/350
391/391 - 25s - loss: 0.1105 - accuracy: 0.9775 - val_loss: 0.4779 - val_accuracy: 0.9057
Epoch 223/350
391/391 - 24s - loss: 0.1124 - accuracy: 0.9768 - val_loss: 0.4895 - val_accuracy: 0.9046
Epoch 224/350
391/391 - 24s - loss: 0.1099 - accuracy: 0.9778 - val_loss: 0.4904 - val_accuracy: 0.9069
Epoch 225/350
391/391 - 24s - loss: 0.1085 - accuracy: 0.9778 - val_loss: 0.4844 - val_accuracy: 0.9081
Epoch 226/350
391/391 - 24s - loss: 0.1098 - accuracy: 0.9777 - val_loss: 0.4846 - val_accuracy: 0.9055
Epoch 227/350
391/391 - 24s - loss: 0.1098 - accuracy: 0.9777 - val_loss: 0.4793 - val_accuracy: 0.9087
Epoch 228/350
391/391 - 25s - loss: 0.1051 - accuracy: 0.9792 - val_loss: 0.4995 - val_accuracy: 0.9044
Epoch 229/350
391/391 - 24s - loss: 0.1091 - accuracy: 0.9774 - val_loss: 0.4806 - val_accuracy: 0.9083
Epoch 230/350
391/391 - 24s - loss: 0.1092 - accuracy: 0.9773 - val_loss: 0.4873 - val_accuracy: 0.9082
Epoch 231/350
391/391 - 24s - loss: 0.1078 - accuracy: 0.9781 - val_loss: 0.4918 - val_accuracy: 0.9098
Epoch 232/350
391/391 - 24s - loss: 0.1098 - accuracy: 0.9775 - val_loss: 0.4918 - val_accuracy: 0.9064
Epoch 233/350
391/391 - 25s - loss: 0.1065 - accuracy: 0.9788 - val_loss: 0.5062 - val_accuracy: 0.9053
Epoch 234/350
391/391 - 24s - loss: 0.1080 - accuracy: 0.9778 - val_loss: 0.4874 - val_accuracy: 0.9065
Epoch 235/350
391/391 - 24s - loss: 0.1068 - accuracy: 0.9786 - val_loss: 0.4927 - val_accuracy: 0.9064
Epoch 236/350
391/391 - 24s - loss: 0.1076 - accuracy: 0.9780 - val_loss: 0.4872 - val_accuracy: 0.9062
Epoch 237/350
391/391 - 24s - loss: 0.1077 - accuracy: 0.9793 - val_loss: 0.4900 - val_accuracy: 0.9057
Epoch 238/350
391/391 - 24s - loss: 0.1028 - accuracy: 0.9802 - val_loss: 0.4966 - val_accuracy: 0.9056
Epoch 239/350
391/391 - 24s - loss: 0.1060 - accuracy: 0.9788 - val_loss: 0.4915 - val_accuracy: 0.9060
Epoch 240/350
391/391 - 24s - loss: 0.1059 - accuracy: 0.9784 - val_loss: 0.5065 - val_accuracy: 0.9041
Epoch 241/350
391/391 - 24s - loss: 0.1062 - accuracy: 0.9783 - val_loss: 0.4966 - val_accuracy: 0.9058
Epoch 242/350
391/391 - 25s - loss: 0.1055 - accuracy: 0.9788 - val_loss: 0.4907 - val_accuracy: 0.9074
Epoch 243/350
391/391 - 24s - loss: 0.1039 - accuracy: 0.9797 - val_loss: 0.4980 - val_accuracy: 0.9068
Epoch 244/350
391/391 - 25s - loss: 0.1058 - accuracy: 0.9795 - val_loss: 0.4995 - val_accuracy: 0.9065
Epoch 245/350
391/391 - 25s - loss: 0.1050 - accuracy: 0.9799 - val_loss: 0.4984 - val_accuracy: 0.9057
Epoch 246/350
391/391 - 24s - loss: 0.1046 - accuracy: 0.9790 - val_loss: 0.4925 - val_accuracy: 0.9067
Epoch 247/350
391/391 - 24s - loss: 0.1053 - accuracy: 0.9788 - val_loss: 0.4973 - val_accuracy: 0.9076
Epoch 248/350
391/391 - 24s - loss: 0.1028 - accuracy: 0.9796 - val_loss: 0.5042 - val_accuracy: 0.9063
Epoch 249/350
391/391 - 25s - loss: 0.1034 - accuracy: 0.9795 - val_loss: 0.4986 - val_accuracy: 0.9070
Epoch 250/350


Snapshot weight 0 shuffle 3 at epoch 250
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1012 - accuracy: 0.9804 - val_loss: 0.5047 - val_accuracy: 0.9079
Epoch 251/350
391/391 - 24s - loss: 0.1038 - accuracy: 0.9786 - val_loss: 0.5051 - val_accuracy: 0.9071
Epoch 252/350
391/391 - 24s - loss: 0.1003 - accuracy: 0.9804 - val_loss: 0.5043 - val_accuracy: 0.9080
Epoch 253/350
391/391 - 24s - loss: 0.1019 - accuracy: 0.9806 - val_loss: 0.5051 - val_accuracy: 0.9075
Epoch 254/350
391/391 - 24s - loss: 0.0998 - accuracy: 0.9813 - val_loss: 0.5026 - val_accuracy: 0.9077
Epoch 255/350
391/391 - 24s - loss: 0.1021 - accuracy: 0.9796 - val_loss: 0.5012 - val_accuracy: 0.9080
Epoch 256/350
391/391 - 25s - loss: 0.1032 - accuracy: 0.9800 - val_loss: 0.5004 - val_accuracy: 0.9088
Epoch 257/350
391/391 - 24s - loss: 0.1010 - accuracy: 0.9799 - val_loss: 0.4992 - val_accuracy: 0.9086
Epoch 258/350
391/391 - 24s - loss: 0.1025 - accuracy: 0.9800 - val_loss: 0.4968 - val_accuracy: 0.9088
Epoch 259/350
391/391 - 24s - loss: 0.1021 - accuracy: 0.9799 - val_loss: 0.4954 - val_accuracy: 0.9082
Epoch 260/350
391/391 - 24s - loss: 0.0987 - accuracy: 0.9812 - val_loss: 0.4988 - val_accuracy: 0.9077
Epoch 261/350
391/391 - 24s - loss: 0.0991 - accuracy: 0.9815 - val_loss: 0.4963 - val_accuracy: 0.9088
Epoch 262/350
391/391 - 24s - loss: 0.0984 - accuracy: 0.9818 - val_loss: 0.4996 - val_accuracy: 0.9073
Epoch 263/350
391/391 - 25s - loss: 0.1014 - accuracy: 0.9810 - val_loss: 0.4985 - val_accuracy: 0.9083
Epoch 264/350
391/391 - 24s - loss: 0.0992 - accuracy: 0.9819 - val_loss: 0.4987 - val_accuracy: 0.9080
Epoch 265/350
391/391 - 24s - loss: 0.1011 - accuracy: 0.9812 - val_loss: 0.4982 - val_accuracy: 0.9088
Epoch 266/350
391/391 - 24s - loss: 0.0989 - accuracy: 0.9817 - val_loss: 0.4979 - val_accuracy: 0.9088
Epoch 267/350
391/391 - 24s - loss: 0.1005 - accuracy: 0.9809 - val_loss: 0.4966 - val_accuracy: 0.9095
Epoch 268/350
391/391 - 25s - loss: 0.0995 - accuracy: 0.9809 - val_loss: 0.5005 - val_accuracy: 0.9074
Epoch 269/350
391/391 - 24s - loss: 0.1011 - accuracy: 0.9806 - val_loss: 0.4966 - val_accuracy: 0.9090
Epoch 270/350
391/391 - 24s - loss: 0.1011 - accuracy: 0.9807 - val_loss: 0.4980 - val_accuracy: 0.9084
Epoch 271/350
391/391 - 24s - loss: 0.0995 - accuracy: 0.9807 - val_loss: 0.4989 - val_accuracy: 0.9083
Epoch 272/350
391/391 - 24s - loss: 0.1012 - accuracy: 0.9810 - val_loss: 0.5002 - val_accuracy: 0.9088
Epoch 273/350
391/391 - 24s - loss: 0.0987 - accuracy: 0.9816 - val_loss: 0.5007 - val_accuracy: 0.9077
Epoch 274/350
391/391 - 24s - loss: 0.0981 - accuracy: 0.9815 - val_loss: 0.5006 - val_accuracy: 0.9088
Epoch 275/350
391/391 - 24s - loss: 0.0997 - accuracy: 0.9813 - val_loss: 0.5012 - val_accuracy: 0.9087
Epoch 276/350
391/391 - 24s - loss: 0.1000 - accuracy: 0.9809 - val_loss: 0.5024 - val_accuracy: 0.9083
Epoch 277/350
391/391 - 24s - loss: 0.1002 - accuracy: 0.9813 - val_loss: 0.5013 - val_accuracy: 0.9079
Epoch 278/350
391/391 - 24s - loss: 0.1001 - accuracy: 0.9814 - val_loss: 0.4995 - val_accuracy: 0.9090
Epoch 279/350
391/391 - 25s - loss: 0.1003 - accuracy: 0.9804 - val_loss: 0.5011 - val_accuracy: 0.9094
Epoch 280/350
391/391 - 25s - loss: 0.0998 - accuracy: 0.9813 - val_loss: 0.5008 - val_accuracy: 0.9091
Epoch 281/350
391/391 - 24s - loss: 0.1006 - accuracy: 0.9806 - val_loss: 0.5027 - val_accuracy: 0.9077
Epoch 282/350
391/391 - 25s - loss: 0.1004 - accuracy: 0.9807 - val_loss: 0.5028 - val_accuracy: 0.9074
Epoch 283/350
391/391 - 24s - loss: 0.0979 - accuracy: 0.9812 - val_loss: 0.5016 - val_accuracy: 0.9083
Epoch 284/350
391/391 - 24s - loss: 0.0998 - accuracy: 0.9809 - val_loss: 0.5023 - val_accuracy: 0.9075
Epoch 285/350
391/391 - 25s - loss: 0.0999 - accuracy: 0.9805 - val_loss: 0.5014 - val_accuracy: 0.9085
Epoch 286/350
391/391 - 24s - loss: 0.0996 - accuracy: 0.9810 - val_loss: 0.5041 - val_accuracy: 0.9088
Epoch 287/350
391/391 - 24s - loss: 0.1006 - accuracy: 0.9802 - val_loss: 0.5045 - val_accuracy: 0.9083
Epoch 288/350
391/391 - 24s - loss: 0.1000 - accuracy: 0.9807 - val_loss: 0.5019 - val_accuracy: 0.9087
Epoch 289/350
391/391 - 24s - loss: 0.1001 - accuracy: 0.9809 - val_loss: 0.5012 - val_accuracy: 0.9089
Epoch 290/350
391/391 - 25s - loss: 0.0985 - accuracy: 0.9818 - val_loss: 0.4994 - val_accuracy: 0.9090
Epoch 291/350
391/391 - 25s - loss: 0.0966 - accuracy: 0.9822 - val_loss: 0.5012 - val_accuracy: 0.9086
Epoch 292/350
391/391 - 24s - loss: 0.0978 - accuracy: 0.9816 - val_loss: 0.5013 - val_accuracy: 0.9088
Epoch 293/350
391/391 - 24s - loss: 0.0985 - accuracy: 0.9812 - val_loss: 0.5024 - val_accuracy: 0.9090
Epoch 294/350
391/391 - 24s - loss: 0.0980 - accuracy: 0.9812 - val_loss: 0.5029 - val_accuracy: 0.9078
Epoch 295/350
391/391 - 24s - loss: 0.1032 - accuracy: 0.9797 - val_loss: 0.5031 - val_accuracy: 0.9084
Epoch 296/350
391/391 - 24s - loss: 0.0989 - accuracy: 0.9814 - val_loss: 0.5027 - val_accuracy: 0.9086
Epoch 297/350
391/391 - 24s - loss: 0.0965 - accuracy: 0.9825 - val_loss: 0.5024 - val_accuracy: 0.9091
Epoch 298/350
391/391 - 24s - loss: 0.0985 - accuracy: 0.9814 - val_loss: 0.5018 - val_accuracy: 0.9091
Epoch 299/350
391/391 - 24s - loss: 0.1004 - accuracy: 0.9809 - val_loss: 0.5041 - val_accuracy: 0.9087
Epoch 300/350


Snapshot weight 0 shuffle 3 at epoch 300
Layer 11
Getting activations...


391/391 - 25s - loss: 0.0989 - accuracy: 0.9813 - val_loss: 0.5046 - val_accuracy: 0.9090
Epoch 301/350
391/391 - 24s - loss: 0.1001 - accuracy: 0.9812 - val_loss: 0.5050 - val_accuracy: 0.9089
Epoch 302/350
391/391 - 24s - loss: 0.0996 - accuracy: 0.9811 - val_loss: 0.5049 - val_accuracy: 0.9084
Epoch 303/350
391/391 - 25s - loss: 0.0980 - accuracy: 0.9815 - val_loss: 0.5045 - val_accuracy: 0.9084
Epoch 304/350
391/391 - 25s - loss: 0.0988 - accuracy: 0.9815 - val_loss: 0.5045 - val_accuracy: 0.9087
Epoch 305/350
391/391 - 24s - loss: 0.0983 - accuracy: 0.9818 - val_loss: 0.5044 - val_accuracy: 0.9082
Epoch 306/350
391/391 - 24s - loss: 0.0989 - accuracy: 0.9811 - val_loss: 0.5046 - val_accuracy: 0.9083
Epoch 307/350
391/391 - 24s - loss: 0.0997 - accuracy: 0.9810 - val_loss: 0.5045 - val_accuracy: 0.9082
Epoch 308/350
391/391 - 25s - loss: 0.0981 - accuracy: 0.9814 - val_loss: 0.5044 - val_accuracy: 0.9084
Epoch 309/350
391/391 - 24s - loss: 0.0980 - accuracy: 0.9818 - val_loss: 0.5047 - val_accuracy: 0.9085
Epoch 310/350
391/391 - 24s - loss: 0.1021 - accuracy: 0.9798 - val_loss: 0.5047 - val_accuracy: 0.9081
Epoch 311/350
391/391 - 24s - loss: 0.0983 - accuracy: 0.9819 - val_loss: 0.5046 - val_accuracy: 0.9080
Epoch 312/350
391/391 - 24s - loss: 0.0957 - accuracy: 0.9825 - val_loss: 0.5047 - val_accuracy: 0.9082
Epoch 313/350
391/391 - 24s - loss: 0.0980 - accuracy: 0.9817 - val_loss: 0.5049 - val_accuracy: 0.9083
Epoch 314/350
391/391 - 24s - loss: 0.0976 - accuracy: 0.9810 - val_loss: 0.5053 - val_accuracy: 0.9084
Epoch 315/350
391/391 - 25s - loss: 0.0989 - accuracy: 0.9809 - val_loss: 0.5054 - val_accuracy: 0.9083
Epoch 316/350
391/391 - 24s - loss: 0.0977 - accuracy: 0.9814 - val_loss: 0.5049 - val_accuracy: 0.9084
Epoch 317/350
391/391 - 24s - loss: 0.0997 - accuracy: 0.9812 - val_loss: 0.5047 - val_accuracy: 0.9083
Epoch 318/350
391/391 - 24s - loss: 0.0990 - accuracy: 0.9813 - val_loss: 0.5046 - val_accuracy: 0.9084
Epoch 319/350
391/391 - 24s - loss: 0.1010 - accuracy: 0.9810 - val_loss: 0.5047 - val_accuracy: 0.9083
Epoch 320/350
391/391 - 24s - loss: 0.0982 - accuracy: 0.9817 - val_loss: 0.5047 - val_accuracy: 0.9085
Epoch 321/350
391/391 - 24s - loss: 0.0990 - accuracy: 0.9814 - val_loss: 0.5050 - val_accuracy: 0.9085
Epoch 322/350
391/391 - 25s - loss: 0.0997 - accuracy: 0.9811 - val_loss: 0.5051 - val_accuracy: 0.9083
Epoch 323/350
391/391 - 24s - loss: 0.1002 - accuracy: 0.9810 - val_loss: 0.5048 - val_accuracy: 0.9084
Epoch 324/350
391/391 - 24s - loss: 0.0990 - accuracy: 0.9812 - val_loss: 0.5050 - val_accuracy: 0.9086
Epoch 325/350
391/391 - 24s - loss: 0.0989 - accuracy: 0.9818 - val_loss: 0.5051 - val_accuracy: 0.9084
Epoch 326/350
391/391 - 25s - loss: 0.0981 - accuracy: 0.9817 - val_loss: 0.5046 - val_accuracy: 0.9087
Epoch 327/350
391/391 - 24s - loss: 0.0982 - accuracy: 0.9813 - val_loss: 0.5047 - val_accuracy: 0.9081
Epoch 328/350
391/391 - 24s - loss: 0.0974 - accuracy: 0.9822 - val_loss: 0.5045 - val_accuracy: 0.9080
Epoch 329/350
391/391 - 24s - loss: 0.0968 - accuracy: 0.9823 - val_loss: 0.5044 - val_accuracy: 0.9085
Epoch 330/350
391/391 - 24s - loss: 0.0974 - accuracy: 0.9817 - val_loss: 0.5046 - val_accuracy: 0.9084
Epoch 331/350
391/391 - 24s - loss: 0.0987 - accuracy: 0.9809 - val_loss: 0.5047 - val_accuracy: 0.9085
Epoch 332/350
391/391 - 24s - loss: 0.0981 - accuracy: 0.9820 - val_loss: 0.5045 - val_accuracy: 0.9084
Epoch 333/350
391/391 - 25s - loss: 0.0988 - accuracy: 0.9807 - val_loss: 0.5046 - val_accuracy: 0.9084
Epoch 334/350
391/391 - 24s - loss: 0.1006 - accuracy: 0.9803 - val_loss: 0.5047 - val_accuracy: 0.9085
Epoch 335/350
391/391 - 24s - loss: 0.0975 - accuracy: 0.9819 - val_loss: 0.5051 - val_accuracy: 0.9088
Epoch 336/350
391/391 - 24s - loss: 0.1010 - accuracy: 0.9805 - val_loss: 0.5049 - val_accuracy: 0.9091
Epoch 337/350
391/391 - 24s - loss: 0.1002 - accuracy: 0.9811 - val_loss: 0.5047 - val_accuracy: 0.9083
Epoch 338/350
391/391 - 25s - loss: 0.0995 - accuracy: 0.9814 - val_loss: 0.5043 - val_accuracy: 0.9084
Epoch 339/350
391/391 - 24s - loss: 0.0978 - accuracy: 0.9818 - val_loss: 0.5041 - val_accuracy: 0.9086
Epoch 340/350
391/391 - 24s - loss: 0.0986 - accuracy: 0.9812 - val_loss: 0.5041 - val_accuracy: 0.9085
Epoch 341/350
391/391 - 24s - loss: 0.0991 - accuracy: 0.9813 - val_loss: 0.5042 - val_accuracy: 0.9085
Epoch 342/350
391/391 - 25s - loss: 0.0976 - accuracy: 0.9816 - val_loss: 0.5041 - val_accuracy: 0.9085
Epoch 343/350
391/391 - 24s - loss: 0.0982 - accuracy: 0.9818 - val_loss: 0.5040 - val_accuracy: 0.9089
Epoch 344/350
391/391 - 25s - loss: 0.0999 - accuracy: 0.9808 - val_loss: 0.5042 - val_accuracy: 0.9087
Epoch 345/350
391/391 - 25s - loss: 0.0981 - accuracy: 0.9823 - val_loss: 0.5042 - val_accuracy: 0.9086
Epoch 346/350
391/391 - 24s - loss: 0.0990 - accuracy: 0.9810 - val_loss: 0.5044 - val_accuracy: 0.9085
Epoch 347/350
391/391 - 24s - loss: 0.0989 - accuracy: 0.9815 - val_loss: 0.5046 - val_accuracy: 0.9086
Epoch 348/350
391/391 - 25s - loss: 0.0982 - accuracy: 0.9809 - val_loss: 0.5047 - val_accuracy: 0.9085
Epoch 349/350
391/391 - 24s - loss: 0.0975 - accuracy: 0.9810 - val_loss: 0.5047 - val_accuracy: 0.9082
Epoch 350/350


Snapshot weight 0 shuffle 3 at epoch 350
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1000 - accuracy: 0.9804 - val_loss: 0.5045 - val_accuracy: 0.9085
/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:493: UserWarning: fill_value is not supported and is always 0 for TensorFlow < 2.4.0.
  return py_builtins.overload_of(f)(*args)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-07-02 02:16:50.996278: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
Saving, final validation acc: 0.9085000157356262
