2021-07-02 18:10:25.556387: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 18:11:40.778560: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-07-02 18:11:40.829460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-02 18:11:40.829556: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 18:11:40.872637: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-02 18:11:40.894746: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-02 18:11:40.903775: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-02 18:11:40.949281: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-02 18:11:40.958269: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-02 18:11:41.039297: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 18:11:41.041745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-02 18:11:41.045540: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-02 18:11:41.062170: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599865000 Hz
2021-07-02 18:11:41.062346: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5a497b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-07-02 18:11:41.062372: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-07-02 18:11:41.247624: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5a479b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-07-02 18:11:41.247714: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN X (Pascal), Compute Capability 6.1
2021-07-02 18:11:41.250421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-02 18:11:41.250501: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 18:11:41.250543: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-02 18:11:41.250563: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-02 18:11:41.250582: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-02 18:11:41.250600: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-02 18:11:41.250617: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-02 18:11:41.251239: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 18:11:41.254365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-02 18:11:41.256301: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 18:11:43.154335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-02 18:11:43.154429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-07-02 18:11:43.154445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-07-02 18:11:43.160628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11228 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
2021-07-02 18:11:49.294526: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 18:11:51.925696: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
Using model index: 88
Making train data...
GCN...
ZCA...
Done!
Making test data...
Done!
Epoch 1/350


Snapshot weight 8 shuffle 8 at epoch 1
Layer 11
Getting activations...


391/391 - 26s - loss: 2.3174 - accuracy: 0.1141 - val_loss: 2.2699 - val_accuracy: 0.1821
Epoch 2/350


Snapshot weight 8 shuffle 8 at epoch 2
Layer 11
Getting activations...


391/391 - 25s - loss: 2.1362 - accuracy: 0.2320 - val_loss: 2.0709 - val_accuracy: 0.2672
Epoch 3/350


Snapshot weight 8 shuffle 8 at epoch 3
Layer 11
Getting activations...


391/391 - 26s - loss: 1.8372 - accuracy: 0.3386 - val_loss: 1.5933 - val_accuracy: 0.4118
Epoch 4/350


Snapshot weight 8 shuffle 8 at epoch 4
Layer 11
Getting activations...


391/391 - 25s - loss: 1.5677 - accuracy: 0.4334 - val_loss: 1.4020 - val_accuracy: 0.4919
Epoch 5/350


Snapshot weight 8 shuffle 8 at epoch 5
Layer 11
Getting activations...


391/391 - 26s - loss: 1.4255 - accuracy: 0.4962 - val_loss: 1.2905 - val_accuracy: 0.5488
Epoch 6/350


Snapshot weight 8 shuffle 8 at epoch 6
Layer 11
Getting activations...


391/391 - 25s - loss: 1.3202 - accuracy: 0.5327 - val_loss: 1.3450 - val_accuracy: 0.5257
Epoch 7/350


Snapshot weight 8 shuffle 8 at epoch 7
Layer 11
Getting activations...


391/391 - 25s - loss: 1.2274 - accuracy: 0.5701 - val_loss: 1.2190 - val_accuracy: 0.5903
Epoch 8/350


Snapshot weight 8 shuffle 8 at epoch 8
Layer 11
Getting activations...


391/391 - 25s - loss: 1.1509 - accuracy: 0.5983 - val_loss: 1.1279 - val_accuracy: 0.6116
Epoch 9/350


Snapshot weight 8 shuffle 8 at epoch 9
Layer 11
Getting activations...


391/391 - 25s - loss: 1.1088 - accuracy: 0.6131 - val_loss: 1.1115 - val_accuracy: 0.6230
Epoch 10/350


Snapshot weight 8 shuffle 8 at epoch 10
Layer 11
Getting activations...


391/391 - 25s - loss: 1.0405 - accuracy: 0.6419 - val_loss: 0.9952 - val_accuracy: 0.6641
Epoch 11/350
391/391 - 25s - loss: 1.0072 - accuracy: 0.6499 - val_loss: 0.9656 - val_accuracy: 0.6689
Epoch 12/350
391/391 - 25s - loss: 0.9604 - accuracy: 0.6698 - val_loss: 0.9194 - val_accuracy: 0.6836
Epoch 13/350
391/391 - 25s - loss: 0.9340 - accuracy: 0.6786 - val_loss: 0.9100 - val_accuracy: 0.7027
Epoch 14/350
391/391 - 25s - loss: 0.8950 - accuracy: 0.6928 - val_loss: 0.8530 - val_accuracy: 0.7170
Epoch 15/350
391/391 - 25s - loss: 0.8535 - accuracy: 0.7075 - val_loss: 0.9090 - val_accuracy: 0.7036
Epoch 16/350
391/391 - 25s - loss: 0.8308 - accuracy: 0.7172 - val_loss: 0.7867 - val_accuracy: 0.7369
Epoch 17/350
391/391 - 25s - loss: 0.7924 - accuracy: 0.7339 - val_loss: 0.7264 - val_accuracy: 0.7606
Epoch 18/350
391/391 - 25s - loss: 0.7645 - accuracy: 0.7409 - val_loss: 0.7359 - val_accuracy: 0.7572
Epoch 19/350
391/391 - 25s - loss: 0.7459 - accuracy: 0.7489 - val_loss: 0.7947 - val_accuracy: 0.7299
Epoch 20/350
391/391 - 25s - loss: 0.7179 - accuracy: 0.7590 - val_loss: 0.6732 - val_accuracy: 0.7814
Epoch 21/350
391/391 - 25s - loss: 0.6999 - accuracy: 0.7660 - val_loss: 0.6801 - val_accuracy: 0.7821
Epoch 22/350
391/391 - 25s - loss: 0.6815 - accuracy: 0.7720 - val_loss: 0.6516 - val_accuracy: 0.7887
Epoch 23/350
391/391 - 25s - loss: 0.6675 - accuracy: 0.7764 - val_loss: 0.6344 - val_accuracy: 0.7903
Epoch 24/350
391/391 - 25s - loss: 0.6453 - accuracy: 0.7841 - val_loss: 0.6214 - val_accuracy: 0.7987
Epoch 25/350
391/391 - 25s - loss: 0.6313 - accuracy: 0.7913 - val_loss: 0.6415 - val_accuracy: 0.7981
Epoch 26/350
391/391 - 25s - loss: 0.6167 - accuracy: 0.7968 - val_loss: 0.6162 - val_accuracy: 0.8087
Epoch 27/350
391/391 - 25s - loss: 0.6055 - accuracy: 0.7992 - val_loss: 0.5692 - val_accuracy: 0.8145
Epoch 28/350
391/391 - 25s - loss: 0.5879 - accuracy: 0.8069 - val_loss: 0.5752 - val_accuracy: 0.8153
Epoch 29/350
391/391 - 25s - loss: 0.5844 - accuracy: 0.8062 - val_loss: 0.6216 - val_accuracy: 0.8067
Epoch 30/350
391/391 - 25s - loss: 0.5687 - accuracy: 0.8120 - val_loss: 0.5677 - val_accuracy: 0.8197
Epoch 31/350
391/391 - 25s - loss: 0.5534 - accuracy: 0.8195 - val_loss: 0.5612 - val_accuracy: 0.8166
Epoch 32/350
391/391 - 25s - loss: 0.5440 - accuracy: 0.8207 - val_loss: 0.5504 - val_accuracy: 0.8252
Epoch 33/350
391/391 - 25s - loss: 0.5399 - accuracy: 0.8250 - val_loss: 0.5442 - val_accuracy: 0.8232
Epoch 34/350
391/391 - 25s - loss: 0.5226 - accuracy: 0.8289 - val_loss: 0.5166 - val_accuracy: 0.8390
Epoch 35/350
391/391 - 25s - loss: 0.5141 - accuracy: 0.8304 - val_loss: 0.5163 - val_accuracy: 0.8392
Epoch 36/350
391/391 - 25s - loss: 0.5067 - accuracy: 0.8350 - val_loss: 0.5134 - val_accuracy: 0.8346
Epoch 37/350
391/391 - 25s - loss: 0.5006 - accuracy: 0.8356 - val_loss: 0.5136 - val_accuracy: 0.8389
Epoch 38/350
391/391 - 25s - loss: 0.4937 - accuracy: 0.8366 - val_loss: 0.4944 - val_accuracy: 0.8438
Epoch 39/350
391/391 - 25s - loss: 0.4838 - accuracy: 0.8438 - val_loss: 0.5425 - val_accuracy: 0.8341
Epoch 40/350
391/391 - 25s - loss: 0.4779 - accuracy: 0.8449 - val_loss: 0.4990 - val_accuracy: 0.8479
Epoch 41/350
391/391 - 26s - loss: 0.4721 - accuracy: 0.8460 - val_loss: 0.4934 - val_accuracy: 0.8470
Epoch 42/350
391/391 - 25s - loss: 0.4642 - accuracy: 0.8485 - val_loss: 0.4998 - val_accuracy: 0.8444
Epoch 43/350
391/391 - 25s - loss: 0.4641 - accuracy: 0.8475 - val_loss: 0.4786 - val_accuracy: 0.8524
Epoch 44/350
391/391 - 25s - loss: 0.4549 - accuracy: 0.8516 - val_loss: 0.4887 - val_accuracy: 0.8508
Epoch 45/350
391/391 - 25s - loss: 0.4440 - accuracy: 0.8556 - val_loss: 0.5250 - val_accuracy: 0.8407
Epoch 46/350
391/391 - 25s - loss: 0.4417 - accuracy: 0.8563 - val_loss: 0.5162 - val_accuracy: 0.8378
Epoch 47/350
391/391 - 25s - loss: 0.4373 - accuracy: 0.8580 - val_loss: 0.4557 - val_accuracy: 0.8554
Epoch 48/350
391/391 - 25s - loss: 0.4352 - accuracy: 0.8576 - val_loss: 0.5002 - val_accuracy: 0.8457
Epoch 49/350
391/391 - 25s - loss: 0.4216 - accuracy: 0.8652 - val_loss: 0.4971 - val_accuracy: 0.8490
Epoch 50/350


Snapshot weight 8 shuffle 8 at epoch 50
Layer 11
Getting activations...


391/391 - 26s - loss: 0.4190 - accuracy: 0.8642 - val_loss: 0.4612 - val_accuracy: 0.8585
Epoch 51/350
391/391 - 25s - loss: 0.4088 - accuracy: 0.8679 - val_loss: 0.4541 - val_accuracy: 0.8619
Epoch 52/350
391/391 - 25s - loss: 0.4045 - accuracy: 0.8692 - val_loss: 0.5089 - val_accuracy: 0.8460
Epoch 53/350
391/391 - 25s - loss: 0.4017 - accuracy: 0.8705 - val_loss: 0.4836 - val_accuracy: 0.8529
Epoch 54/350
391/391 - 25s - loss: 0.4016 - accuracy: 0.8711 - val_loss: 0.4779 - val_accuracy: 0.8555
Epoch 55/350
391/391 - 25s - loss: 0.3948 - accuracy: 0.8726 - val_loss: 0.4676 - val_accuracy: 0.8629
Epoch 56/350
391/391 - 25s - loss: 0.3888 - accuracy: 0.8754 - val_loss: 0.4442 - val_accuracy: 0.8674
Epoch 57/350
391/391 - 25s - loss: 0.3885 - accuracy: 0.8773 - val_loss: 0.5642 - val_accuracy: 0.8368
Epoch 58/350
391/391 - 25s - loss: 0.3796 - accuracy: 0.8782 - val_loss: 0.4585 - val_accuracy: 0.8613
Epoch 59/350
391/391 - 25s - loss: 0.3766 - accuracy: 0.8782 - val_loss: 0.4324 - val_accuracy: 0.8679
Epoch 60/350
391/391 - 25s - loss: 0.3766 - accuracy: 0.8818 - val_loss: 0.4979 - val_accuracy: 0.8528
Epoch 61/350
391/391 - 25s - loss: 0.3660 - accuracy: 0.8823 - val_loss: 0.4763 - val_accuracy: 0.8632
Epoch 62/350
391/391 - 25s - loss: 0.3710 - accuracy: 0.8818 - val_loss: 0.4282 - val_accuracy: 0.8698
Epoch 63/350
391/391 - 25s - loss: 0.3628 - accuracy: 0.8842 - val_loss: 0.4375 - val_accuracy: 0.8686
Epoch 64/350
391/391 - 25s - loss: 0.3583 - accuracy: 0.8872 - val_loss: 0.4315 - val_accuracy: 0.8707
Epoch 65/350
391/391 - 25s - loss: 0.3542 - accuracy: 0.8868 - val_loss: 0.4116 - val_accuracy: 0.8776
Epoch 66/350
391/391 - 25s - loss: 0.3555 - accuracy: 0.8862 - val_loss: 0.4370 - val_accuracy: 0.8725
Epoch 67/350
391/391 - 25s - loss: 0.3479 - accuracy: 0.8894 - val_loss: 0.4269 - val_accuracy: 0.8691
Epoch 68/350
391/391 - 25s - loss: 0.3426 - accuracy: 0.8912 - val_loss: 0.4095 - val_accuracy: 0.8755
Epoch 69/350
391/391 - 25s - loss: 0.3426 - accuracy: 0.8926 - val_loss: 0.4358 - val_accuracy: 0.8724
Epoch 70/350
391/391 - 25s - loss: 0.3383 - accuracy: 0.8923 - val_loss: 0.4330 - val_accuracy: 0.8722
Epoch 71/350
391/391 - 25s - loss: 0.3342 - accuracy: 0.8941 - val_loss: 0.4171 - val_accuracy: 0.8773
Epoch 72/350
391/391 - 25s - loss: 0.3319 - accuracy: 0.8968 - val_loss: 0.4214 - val_accuracy: 0.8751
Epoch 73/350
391/391 - 25s - loss: 0.3250 - accuracy: 0.8984 - val_loss: 0.4170 - val_accuracy: 0.8782
Epoch 74/350
391/391 - 25s - loss: 0.3265 - accuracy: 0.8982 - val_loss: 0.4116 - val_accuracy: 0.8793
Epoch 75/350
391/391 - 25s - loss: 0.3231 - accuracy: 0.8995 - val_loss: 0.4690 - val_accuracy: 0.8642
Epoch 76/350
391/391 - 25s - loss: 0.3221 - accuracy: 0.8986 - val_loss: 0.4022 - val_accuracy: 0.8843
Epoch 77/350
391/391 - 25s - loss: 0.3136 - accuracy: 0.9006 - val_loss: 0.3987 - val_accuracy: 0.8793
Epoch 78/350
391/391 - 25s - loss: 0.3190 - accuracy: 0.8986 - val_loss: 0.4850 - val_accuracy: 0.8622
Epoch 79/350
391/391 - 25s - loss: 0.3115 - accuracy: 0.9020 - val_loss: 0.4518 - val_accuracy: 0.8669
Epoch 80/350
391/391 - 25s - loss: 0.3123 - accuracy: 0.9028 - val_loss: 0.4322 - val_accuracy: 0.8760
Epoch 81/350
391/391 - 25s - loss: 0.3067 - accuracy: 0.9048 - val_loss: 0.4844 - val_accuracy: 0.8645
Epoch 82/350
391/391 - 25s - loss: 0.3092 - accuracy: 0.9055 - val_loss: 0.4007 - val_accuracy: 0.8803
Epoch 83/350
391/391 - 25s - loss: 0.3040 - accuracy: 0.9056 - val_loss: 0.4215 - val_accuracy: 0.8754
Epoch 84/350
391/391 - 25s - loss: 0.3023 - accuracy: 0.9059 - val_loss: 0.4245 - val_accuracy: 0.8775
Epoch 85/350
391/391 - 25s - loss: 0.2976 - accuracy: 0.9076 - val_loss: 0.4420 - val_accuracy: 0.8723
Epoch 86/350
391/391 - 25s - loss: 0.2971 - accuracy: 0.9082 - val_loss: 0.4006 - val_accuracy: 0.8864
Epoch 87/350
391/391 - 25s - loss: 0.2891 - accuracy: 0.9101 - val_loss: 0.4271 - val_accuracy: 0.8770
Epoch 88/350
391/391 - 25s - loss: 0.2936 - accuracy: 0.9091 - val_loss: 0.4132 - val_accuracy: 0.8822
Epoch 89/350
391/391 - 25s - loss: 0.2907 - accuracy: 0.9095 - val_loss: 0.4057 - val_accuracy: 0.8828
Epoch 90/350
391/391 - 25s - loss: 0.2847 - accuracy: 0.9117 - val_loss: 0.4475 - val_accuracy: 0.8766
Epoch 91/350
391/391 - 25s - loss: 0.2811 - accuracy: 0.9129 - val_loss: 0.4306 - val_accuracy: 0.8820
Epoch 92/350
391/391 - 25s - loss: 0.2850 - accuracy: 0.9120 - val_loss: 0.4098 - val_accuracy: 0.8836
Epoch 93/350
391/391 - 25s - loss: 0.2792 - accuracy: 0.9159 - val_loss: 0.4314 - val_accuracy: 0.8795
Epoch 94/350
391/391 - 25s - loss: 0.2806 - accuracy: 0.9105 - val_loss: 0.4186 - val_accuracy: 0.8851
Epoch 95/350
391/391 - 25s - loss: 0.2818 - accuracy: 0.9135 - val_loss: 0.4300 - val_accuracy: 0.8809
Epoch 96/350
391/391 - 25s - loss: 0.2789 - accuracy: 0.9150 - val_loss: 0.4125 - val_accuracy: 0.8844
Epoch 97/350
391/391 - 25s - loss: 0.2704 - accuracy: 0.9181 - val_loss: 0.3989 - val_accuracy: 0.8889
Epoch 98/350
391/391 - 25s - loss: 0.2708 - accuracy: 0.9174 - val_loss: 0.4481 - val_accuracy: 0.8761
Epoch 99/350
391/391 - 25s - loss: 0.2658 - accuracy: 0.9192 - val_loss: 0.4630 - val_accuracy: 0.8772
Epoch 100/350


Snapshot weight 8 shuffle 8 at epoch 100
Layer 11
Getting activations...


391/391 - 25s - loss: 0.2707 - accuracy: 0.9175 - val_loss: 0.4237 - val_accuracy: 0.8814
Epoch 101/350
391/391 - 25s - loss: 0.2676 - accuracy: 0.9180 - val_loss: 0.4156 - val_accuracy: 0.8855
Epoch 102/350
391/391 - 25s - loss: 0.2629 - accuracy: 0.9202 - val_loss: 0.4176 - val_accuracy: 0.8852
Epoch 103/350
391/391 - 25s - loss: 0.2613 - accuracy: 0.9200 - val_loss: 0.4103 - val_accuracy: 0.8889
Epoch 104/350
391/391 - 25s - loss: 0.2580 - accuracy: 0.9225 - val_loss: 0.4347 - val_accuracy: 0.8843
Epoch 105/350
391/391 - 25s - loss: 0.2619 - accuracy: 0.9212 - val_loss: 0.4206 - val_accuracy: 0.8860
Epoch 106/350
391/391 - 25s - loss: 0.2551 - accuracy: 0.9237 - val_loss: 0.4127 - val_accuracy: 0.8874
Epoch 107/350
391/391 - 25s - loss: 0.2594 - accuracy: 0.9209 - val_loss: 0.4443 - val_accuracy: 0.8837
Epoch 108/350
391/391 - 25s - loss: 0.2554 - accuracy: 0.9237 - val_loss: 0.4412 - val_accuracy: 0.8848
Epoch 109/350
391/391 - 25s - loss: 0.2524 - accuracy: 0.9238 - val_loss: 0.4647 - val_accuracy: 0.8784
Epoch 110/350
391/391 - 25s - loss: 0.2488 - accuracy: 0.9260 - val_loss: 0.3957 - val_accuracy: 0.8897
Epoch 111/350
391/391 - 25s - loss: 0.2455 - accuracy: 0.9255 - val_loss: 0.4331 - val_accuracy: 0.8875
Epoch 112/350
391/391 - 25s - loss: 0.2494 - accuracy: 0.9252 - val_loss: 0.4134 - val_accuracy: 0.8870
Epoch 113/350
391/391 - 25s - loss: 0.2454 - accuracy: 0.9269 - val_loss: 0.4118 - val_accuracy: 0.8893
Epoch 114/350
391/391 - 25s - loss: 0.2437 - accuracy: 0.9276 - val_loss: 0.4210 - val_accuracy: 0.8889
Epoch 115/350
391/391 - 25s - loss: 0.2406 - accuracy: 0.9301 - val_loss: 0.4378 - val_accuracy: 0.8855
Epoch 116/350
391/391 - 25s - loss: 0.2398 - accuracy: 0.9285 - val_loss: 0.4317 - val_accuracy: 0.8890
Epoch 117/350
391/391 - 25s - loss: 0.2447 - accuracy: 0.9271 - val_loss: 0.4235 - val_accuracy: 0.8903
Epoch 118/350
391/391 - 25s - loss: 0.2378 - accuracy: 0.9292 - val_loss: 0.4610 - val_accuracy: 0.8833
Epoch 119/350
391/391 - 25s - loss: 0.2415 - accuracy: 0.9270 - val_loss: 0.4364 - val_accuracy: 0.8855
Epoch 120/350
391/391 - 25s - loss: 0.2367 - accuracy: 0.9292 - val_loss: 0.4113 - val_accuracy: 0.8899
Epoch 121/350
391/391 - 25s - loss: 0.2386 - accuracy: 0.9298 - val_loss: 0.4276 - val_accuracy: 0.8858
Epoch 122/350
391/391 - 25s - loss: 0.2350 - accuracy: 0.9310 - val_loss: 0.4324 - val_accuracy: 0.8870
Epoch 123/350
391/391 - 25s - loss: 0.2265 - accuracy: 0.9339 - val_loss: 0.4413 - val_accuracy: 0.8865
Epoch 124/350
391/391 - 25s - loss: 0.2318 - accuracy: 0.9320 - val_loss: 0.4432 - val_accuracy: 0.8857
Epoch 125/350
391/391 - 25s - loss: 0.2266 - accuracy: 0.9351 - val_loss: 0.4351 - val_accuracy: 0.8886
Epoch 126/350
391/391 - 25s - loss: 0.2262 - accuracy: 0.9324 - val_loss: 0.4115 - val_accuracy: 0.8907
Epoch 127/350
391/391 - 25s - loss: 0.2215 - accuracy: 0.9359 - val_loss: 0.4289 - val_accuracy: 0.8938
Epoch 128/350
391/391 - 25s - loss: 0.2276 - accuracy: 0.9340 - val_loss: 0.4454 - val_accuracy: 0.8886
Epoch 129/350
391/391 - 25s - loss: 0.2274 - accuracy: 0.9330 - val_loss: 0.4314 - val_accuracy: 0.8916
Epoch 130/350
391/391 - 25s - loss: 0.2209 - accuracy: 0.9359 - val_loss: 0.4471 - val_accuracy: 0.8868
Epoch 131/350
391/391 - 25s - loss: 0.2253 - accuracy: 0.9352 - val_loss: 0.4646 - val_accuracy: 0.8861
Epoch 132/350
391/391 - 25s - loss: 0.2254 - accuracy: 0.9347 - val_loss: 0.4352 - val_accuracy: 0.8884
Epoch 133/350
391/391 - 25s - loss: 0.2246 - accuracy: 0.9343 - val_loss: 0.4332 - val_accuracy: 0.8899
Epoch 134/350
391/391 - 25s - loss: 0.2213 - accuracy: 0.9355 - val_loss: 0.4426 - val_accuracy: 0.8903
Epoch 135/350
391/391 - 25s - loss: 0.2175 - accuracy: 0.9380 - val_loss: 0.4351 - val_accuracy: 0.8852
Epoch 136/350
391/391 - 25s - loss: 0.2170 - accuracy: 0.9373 - val_loss: 0.4217 - val_accuracy: 0.8953
Epoch 137/350
391/391 - 25s - loss: 0.2191 - accuracy: 0.9364 - val_loss: 0.4577 - val_accuracy: 0.8862
Epoch 138/350
391/391 - 25s - loss: 0.2192 - accuracy: 0.9370 - val_loss: 0.4227 - val_accuracy: 0.8937
Epoch 139/350
391/391 - 25s - loss: 0.2131 - accuracy: 0.9394 - val_loss: 0.4655 - val_accuracy: 0.8868
Epoch 140/350
391/391 - 25s - loss: 0.2143 - accuracy: 0.9380 - val_loss: 0.4143 - val_accuracy: 0.8932
Epoch 141/350
391/391 - 25s - loss: 0.2147 - accuracy: 0.9389 - val_loss: 0.4498 - val_accuracy: 0.8876
Epoch 142/350
391/391 - 25s - loss: 0.2098 - accuracy: 0.9420 - val_loss: 0.4511 - val_accuracy: 0.8894
Epoch 143/350
391/391 - 25s - loss: 0.2077 - accuracy: 0.9408 - val_loss: 0.4861 - val_accuracy: 0.8868
Epoch 144/350
391/391 - 25s - loss: 0.2098 - accuracy: 0.9405 - val_loss: 0.4437 - val_accuracy: 0.8905
Epoch 145/350
391/391 - 25s - loss: 0.2102 - accuracy: 0.9398 - val_loss: 0.4231 - val_accuracy: 0.8954
Epoch 146/350
391/391 - 25s - loss: 0.2023 - accuracy: 0.9430 - val_loss: 0.4370 - val_accuracy: 0.8953
Epoch 147/350
391/391 - 25s - loss: 0.2112 - accuracy: 0.9404 - val_loss: 0.4323 - val_accuracy: 0.8921
Epoch 148/350
391/391 - 25s - loss: 0.2050 - accuracy: 0.9421 - val_loss: 0.4224 - val_accuracy: 0.8957
Epoch 149/350
391/391 - 25s - loss: 0.2025 - accuracy: 0.9432 - val_loss: 0.4287 - val_accuracy: 0.8990
Epoch 150/350


Snapshot weight 8 shuffle 8 at epoch 150
Layer 11
Getting activations...


391/391 - 25s - loss: 0.2013 - accuracy: 0.9429 - val_loss: 0.4372 - val_accuracy: 0.8947
Epoch 151/350
391/391 - 25s - loss: 0.2045 - accuracy: 0.9418 - val_loss: 0.4738 - val_accuracy: 0.8914
Epoch 152/350
391/391 - 25s - loss: 0.2030 - accuracy: 0.9428 - val_loss: 0.4337 - val_accuracy: 0.8939
Epoch 153/350
391/391 - 25s - loss: 0.2020 - accuracy: 0.9430 - val_loss: 0.4379 - val_accuracy: 0.8914
Epoch 154/350
391/391 - 25s - loss: 0.1995 - accuracy: 0.9442 - val_loss: 0.4583 - val_accuracy: 0.8943
Epoch 155/350
391/391 - 25s - loss: 0.1996 - accuracy: 0.9440 - val_loss: 0.4271 - val_accuracy: 0.8997
Epoch 156/350
391/391 - 25s - loss: 0.2005 - accuracy: 0.9443 - val_loss: 0.4253 - val_accuracy: 0.8976
Epoch 157/350
391/391 - 25s - loss: 0.1960 - accuracy: 0.9446 - val_loss: 0.4128 - val_accuracy: 0.8981
Epoch 158/350
391/391 - 25s - loss: 0.1955 - accuracy: 0.9459 - val_loss: 0.4613 - val_accuracy: 0.8921
Epoch 159/350
391/391 - 25s - loss: 0.1958 - accuracy: 0.9463 - val_loss: 0.4500 - val_accuracy: 0.8942
Epoch 160/350
391/391 - 25s - loss: 0.1983 - accuracy: 0.9446 - val_loss: 0.4918 - val_accuracy: 0.8876
Epoch 161/350
391/391 - 25s - loss: 0.1918 - accuracy: 0.9476 - val_loss: 0.4433 - val_accuracy: 0.8914
Epoch 162/350
391/391 - 25s - loss: 0.1936 - accuracy: 0.9460 - val_loss: 0.4525 - val_accuracy: 0.8922
Epoch 163/350
391/391 - 25s - loss: 0.1897 - accuracy: 0.9484 - val_loss: 0.4290 - val_accuracy: 0.8977
Epoch 164/350
391/391 - 25s - loss: 0.1952 - accuracy: 0.9460 - val_loss: 0.4491 - val_accuracy: 0.8904
Epoch 165/350
391/391 - 25s - loss: 0.1887 - accuracy: 0.9475 - val_loss: 0.4588 - val_accuracy: 0.8943
Epoch 166/350
391/391 - 25s - loss: 0.1912 - accuracy: 0.9466 - val_loss: 0.4324 - val_accuracy: 0.8989
Epoch 167/350
391/391 - 25s - loss: 0.1892 - accuracy: 0.9483 - val_loss: 0.4639 - val_accuracy: 0.8890
Epoch 168/350
391/391 - 25s - loss: 0.1909 - accuracy: 0.9484 - val_loss: 0.4588 - val_accuracy: 0.8899
Epoch 169/350
391/391 - 25s - loss: 0.1878 - accuracy: 0.9485 - val_loss: 0.4550 - val_accuracy: 0.8938
Epoch 170/350
391/391 - 25s - loss: 0.1869 - accuracy: 0.9486 - val_loss: 0.4438 - val_accuracy: 0.8943
Epoch 171/350
391/391 - 25s - loss: 0.1874 - accuracy: 0.9484 - val_loss: 0.4553 - val_accuracy: 0.8941
Epoch 172/350
391/391 - 25s - loss: 0.1916 - accuracy: 0.9477 - val_loss: 0.4506 - val_accuracy: 0.8959
Epoch 173/350
391/391 - 25s - loss: 0.1871 - accuracy: 0.9481 - val_loss: 0.4341 - val_accuracy: 0.9002
Epoch 174/350
391/391 - 25s - loss: 0.1850 - accuracy: 0.9503 - val_loss: 0.4629 - val_accuracy: 0.8970
Epoch 175/350
391/391 - 25s - loss: 0.1853 - accuracy: 0.9499 - val_loss: 0.4715 - val_accuracy: 0.8935
Epoch 176/350
391/391 - 25s - loss: 0.1809 - accuracy: 0.9509 - val_loss: 0.4593 - val_accuracy: 0.8970
Epoch 177/350
391/391 - 25s - loss: 0.1844 - accuracy: 0.9507 - val_loss: 0.4827 - val_accuracy: 0.8948
Epoch 178/350
391/391 - 25s - loss: 0.1779 - accuracy: 0.9528 - val_loss: 0.4586 - val_accuracy: 0.8971
Epoch 179/350
391/391 - 25s - loss: 0.1790 - accuracy: 0.9523 - val_loss: 0.4578 - val_accuracy: 0.8930
Epoch 180/350
391/391 - 25s - loss: 0.1839 - accuracy: 0.9505 - val_loss: 0.4711 - val_accuracy: 0.8920
Epoch 181/350
391/391 - 25s - loss: 0.1815 - accuracy: 0.9518 - val_loss: 0.4544 - val_accuracy: 0.8967
Epoch 182/350
391/391 - 25s - loss: 0.1811 - accuracy: 0.9516 - val_loss: 0.4460 - val_accuracy: 0.8978
Epoch 183/350
391/391 - 25s - loss: 0.1759 - accuracy: 0.9526 - val_loss: 0.4347 - val_accuracy: 0.9005
Epoch 184/350
391/391 - 25s - loss: 0.1805 - accuracy: 0.9526 - val_loss: 0.4341 - val_accuracy: 0.9008
Epoch 185/350
391/391 - 25s - loss: 0.1816 - accuracy: 0.9512 - val_loss: 0.4945 - val_accuracy: 0.8932
Epoch 186/350
391/391 - 25s - loss: 0.1776 - accuracy: 0.9522 - val_loss: 0.4767 - val_accuracy: 0.8916
Epoch 187/350
391/391 - 25s - loss: 0.1779 - accuracy: 0.9528 - val_loss: 0.4423 - val_accuracy: 0.8997
Epoch 188/350
391/391 - 25s - loss: 0.1757 - accuracy: 0.9541 - val_loss: 0.4394 - val_accuracy: 0.9004
Epoch 189/350
391/391 - 25s - loss: 0.1764 - accuracy: 0.9529 - val_loss: 0.4812 - val_accuracy: 0.8907
Epoch 190/350
391/391 - 25s - loss: 0.1775 - accuracy: 0.9535 - val_loss: 0.4608 - val_accuracy: 0.8978
Epoch 191/350
391/391 - 25s - loss: 0.1762 - accuracy: 0.9535 - val_loss: 0.4545 - val_accuracy: 0.8987
Epoch 192/350
391/391 - 25s - loss: 0.1739 - accuracy: 0.9541 - val_loss: 0.4828 - val_accuracy: 0.8988
Epoch 193/350
391/391 - 25s - loss: 0.1736 - accuracy: 0.9547 - val_loss: 0.5000 - val_accuracy: 0.8891
Epoch 194/350
391/391 - 25s - loss: 0.1724 - accuracy: 0.9556 - val_loss: 0.4426 - val_accuracy: 0.9018
Epoch 195/350
391/391 - 25s - loss: 0.1731 - accuracy: 0.9550 - val_loss: 0.4526 - val_accuracy: 0.8966
Epoch 196/350
391/391 - 25s - loss: 0.1718 - accuracy: 0.9554 - val_loss: 0.4920 - val_accuracy: 0.8970
Epoch 197/350
391/391 - 25s - loss: 0.1693 - accuracy: 0.9571 - val_loss: 0.4810 - val_accuracy: 0.8961
Epoch 198/350
391/391 - 25s - loss: 0.1687 - accuracy: 0.9574 - val_loss: 0.4781 - val_accuracy: 0.8990
Epoch 199/350
391/391 - 25s - loss: 0.1726 - accuracy: 0.9558 - val_loss: 0.4850 - val_accuracy: 0.8945
Epoch 200/350


Snapshot weight 8 shuffle 8 at epoch 200
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1648 - accuracy: 0.9575 - val_loss: 0.4472 - val_accuracy: 0.9030
Epoch 201/350
391/391 - 25s - loss: 0.1474 - accuracy: 0.9645 - val_loss: 0.4540 - val_accuracy: 0.9039
Epoch 202/350
391/391 - 25s - loss: 0.1295 - accuracy: 0.9700 - val_loss: 0.4497 - val_accuracy: 0.9070
Epoch 203/350
391/391 - 25s - loss: 0.1279 - accuracy: 0.9711 - val_loss: 0.4406 - val_accuracy: 0.9098
Epoch 204/350
391/391 - 25s - loss: 0.1271 - accuracy: 0.9706 - val_loss: 0.4498 - val_accuracy: 0.9076
Epoch 205/350
391/391 - 25s - loss: 0.1298 - accuracy: 0.9715 - val_loss: 0.4509 - val_accuracy: 0.9079
Epoch 206/350
391/391 - 25s - loss: 0.1198 - accuracy: 0.9741 - val_loss: 0.4640 - val_accuracy: 0.9084
Epoch 207/350
391/391 - 25s - loss: 0.1271 - accuracy: 0.9712 - val_loss: 0.4491 - val_accuracy: 0.9077
Epoch 208/350
391/391 - 25s - loss: 0.1217 - accuracy: 0.9731 - val_loss: 0.4687 - val_accuracy: 0.9060
Epoch 209/350
391/391 - 25s - loss: 0.1188 - accuracy: 0.9734 - val_loss: 0.4673 - val_accuracy: 0.9086
Epoch 210/350
391/391 - 25s - loss: 0.1211 - accuracy: 0.9736 - val_loss: 0.4678 - val_accuracy: 0.9072
Epoch 211/350
391/391 - 25s - loss: 0.1159 - accuracy: 0.9752 - val_loss: 0.4668 - val_accuracy: 0.9094
Epoch 212/350
391/391 - 25s - loss: 0.1187 - accuracy: 0.9745 - val_loss: 0.4640 - val_accuracy: 0.9085
Epoch 213/350
391/391 - 25s - loss: 0.1177 - accuracy: 0.9739 - val_loss: 0.4618 - val_accuracy: 0.9082
Epoch 214/350
391/391 - 25s - loss: 0.1175 - accuracy: 0.9742 - val_loss: 0.4667 - val_accuracy: 0.9089
Epoch 215/350
391/391 - 25s - loss: 0.1175 - accuracy: 0.9743 - val_loss: 0.4704 - val_accuracy: 0.9078
Epoch 216/350
391/391 - 25s - loss: 0.1172 - accuracy: 0.9750 - val_loss: 0.4789 - val_accuracy: 0.9079
Epoch 217/350
391/391 - 25s - loss: 0.1188 - accuracy: 0.9739 - val_loss: 0.4624 - val_accuracy: 0.9090
Epoch 218/350
391/391 - 25s - loss: 0.1169 - accuracy: 0.9741 - val_loss: 0.4664 - val_accuracy: 0.9090
Epoch 219/350
391/391 - 25s - loss: 0.1144 - accuracy: 0.9758 - val_loss: 0.4701 - val_accuracy: 0.9094
Epoch 220/350
391/391 - 25s - loss: 0.1120 - accuracy: 0.9765 - val_loss: 0.4751 - val_accuracy: 0.9088
Epoch 221/350
391/391 - 25s - loss: 0.1132 - accuracy: 0.9761 - val_loss: 0.4804 - val_accuracy: 0.9101
Epoch 222/350
391/391 - 25s - loss: 0.1159 - accuracy: 0.9753 - val_loss: 0.4807 - val_accuracy: 0.9087
Epoch 223/350
391/391 - 25s - loss: 0.1149 - accuracy: 0.9754 - val_loss: 0.4716 - val_accuracy: 0.9087
Epoch 224/350
391/391 - 25s - loss: 0.1138 - accuracy: 0.9762 - val_loss: 0.4762 - val_accuracy: 0.9089
Epoch 225/350
391/391 - 25s - loss: 0.1165 - accuracy: 0.9743 - val_loss: 0.4773 - val_accuracy: 0.9091
Epoch 226/350
391/391 - 25s - loss: 0.1138 - accuracy: 0.9755 - val_loss: 0.4765 - val_accuracy: 0.9082
Epoch 227/350
391/391 - 25s - loss: 0.1126 - accuracy: 0.9765 - val_loss: 0.4762 - val_accuracy: 0.9086
Epoch 228/350
391/391 - 25s - loss: 0.1114 - accuracy: 0.9767 - val_loss: 0.4860 - val_accuracy: 0.9102
Epoch 229/350
391/391 - 25s - loss: 0.1100 - accuracy: 0.9773 - val_loss: 0.4886 - val_accuracy: 0.9087
Epoch 230/350
391/391 - 25s - loss: 0.1145 - accuracy: 0.9755 - val_loss: 0.4865 - val_accuracy: 0.9089
Epoch 231/350
391/391 - 25s - loss: 0.1118 - accuracy: 0.9769 - val_loss: 0.4859 - val_accuracy: 0.9084
Epoch 232/350
391/391 - 25s - loss: 0.1116 - accuracy: 0.9766 - val_loss: 0.4881 - val_accuracy: 0.9090
Epoch 233/350
391/391 - 25s - loss: 0.1131 - accuracy: 0.9758 - val_loss: 0.4973 - val_accuracy: 0.9074
Epoch 234/350
391/391 - 25s - loss: 0.1131 - accuracy: 0.9760 - val_loss: 0.4859 - val_accuracy: 0.9089
Epoch 235/350
391/391 - 25s - loss: 0.1100 - accuracy: 0.9771 - val_loss: 0.4853 - val_accuracy: 0.9112
Epoch 236/350
391/391 - 25s - loss: 0.1091 - accuracy: 0.9776 - val_loss: 0.4865 - val_accuracy: 0.9086
Epoch 237/350
391/391 - 25s - loss: 0.1109 - accuracy: 0.9770 - val_loss: 0.4811 - val_accuracy: 0.9111
Epoch 238/350
391/391 - 25s - loss: 0.1100 - accuracy: 0.9774 - val_loss: 0.4910 - val_accuracy: 0.9081
Epoch 239/350
391/391 - 25s - loss: 0.1079 - accuracy: 0.9781 - val_loss: 0.4939 - val_accuracy: 0.9083
Epoch 240/350
391/391 - 25s - loss: 0.1113 - accuracy: 0.9767 - val_loss: 0.4944 - val_accuracy: 0.9071
Epoch 241/350
391/391 - 25s - loss: 0.1106 - accuracy: 0.9776 - val_loss: 0.4912 - val_accuracy: 0.9080
Epoch 242/350
391/391 - 25s - loss: 0.1116 - accuracy: 0.9761 - val_loss: 0.4890 - val_accuracy: 0.9083
Epoch 243/350
391/391 - 25s - loss: 0.1085 - accuracy: 0.9770 - val_loss: 0.4943 - val_accuracy: 0.9100
Epoch 244/350
391/391 - 25s - loss: 0.1099 - accuracy: 0.9775 - val_loss: 0.4824 - val_accuracy: 0.9102
Epoch 245/350
391/391 - 25s - loss: 0.1067 - accuracy: 0.9782 - val_loss: 0.4972 - val_accuracy: 0.9085
Epoch 246/350
391/391 - 25s - loss: 0.1095 - accuracy: 0.9781 - val_loss: 0.4890 - val_accuracy: 0.9105
Epoch 247/350
391/391 - 25s - loss: 0.1092 - accuracy: 0.9780 - val_loss: 0.4933 - val_accuracy: 0.9094
Epoch 248/350
391/391 - 25s - loss: 0.1073 - accuracy: 0.9783 - val_loss: 0.4909 - val_accuracy: 0.9097
Epoch 249/350
391/391 - 25s - loss: 0.1091 - accuracy: 0.9775 - val_loss: 0.5033 - val_accuracy: 0.9078
Epoch 250/350


Snapshot weight 8 shuffle 8 at epoch 250
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1074 - accuracy: 0.9779 - val_loss: 0.4958 - val_accuracy: 0.9080
Epoch 251/350
391/391 - 25s - loss: 0.1082 - accuracy: 0.9776 - val_loss: 0.4820 - val_accuracy: 0.9110
Epoch 252/350
391/391 - 25s - loss: 0.1062 - accuracy: 0.9794 - val_loss: 0.4861 - val_accuracy: 0.9106
Epoch 253/350
391/391 - 25s - loss: 0.1032 - accuracy: 0.9803 - val_loss: 0.4875 - val_accuracy: 0.9106
Epoch 254/350
391/391 - 25s - loss: 0.1053 - accuracy: 0.9787 - val_loss: 0.4904 - val_accuracy: 0.9096
Epoch 255/350
391/391 - 25s - loss: 0.1026 - accuracy: 0.9803 - val_loss: 0.4904 - val_accuracy: 0.9107
Epoch 256/350
391/391 - 25s - loss: 0.1045 - accuracy: 0.9787 - val_loss: 0.4923 - val_accuracy: 0.9105
Epoch 257/350
391/391 - 25s - loss: 0.1039 - accuracy: 0.9796 - val_loss: 0.4921 - val_accuracy: 0.9099
Epoch 258/350
391/391 - 25s - loss: 0.1040 - accuracy: 0.9791 - val_loss: 0.4944 - val_accuracy: 0.9103
Epoch 259/350
391/391 - 25s - loss: 0.1064 - accuracy: 0.9784 - val_loss: 0.4919 - val_accuracy: 0.9100
Epoch 260/350
391/391 - 25s - loss: 0.1050 - accuracy: 0.9790 - val_loss: 0.4928 - val_accuracy: 0.9098
Epoch 261/350
391/391 - 25s - loss: 0.1068 - accuracy: 0.9774 - val_loss: 0.4921 - val_accuracy: 0.9100
Epoch 262/350
391/391 - 25s - loss: 0.1046 - accuracy: 0.9786 - val_loss: 0.4898 - val_accuracy: 0.9102
Epoch 263/350
391/391 - 25s - loss: 0.1038 - accuracy: 0.9792 - val_loss: 0.4944 - val_accuracy: 0.9094
Epoch 264/350
391/391 - 25s - loss: 0.1053 - accuracy: 0.9791 - val_loss: 0.4911 - val_accuracy: 0.9102
Epoch 265/350
391/391 - 25s - loss: 0.1048 - accuracy: 0.9791 - val_loss: 0.4931 - val_accuracy: 0.9101
Epoch 266/350
391/391 - 25s - loss: 0.1047 - accuracy: 0.9793 - val_loss: 0.4936 - val_accuracy: 0.9090
Epoch 267/350
391/391 - 25s - loss: 0.1037 - accuracy: 0.9794 - val_loss: 0.4932 - val_accuracy: 0.9098
Epoch 268/350
391/391 - 25s - loss: 0.1057 - accuracy: 0.9786 - val_loss: 0.4938 - val_accuracy: 0.9101
Epoch 269/350
391/391 - 25s - loss: 0.1027 - accuracy: 0.9793 - val_loss: 0.4924 - val_accuracy: 0.9101
Epoch 270/350
391/391 - 25s - loss: 0.1049 - accuracy: 0.9789 - val_loss: 0.4932 - val_accuracy: 0.9105
Epoch 271/350
391/391 - 25s - loss: 0.1039 - accuracy: 0.9799 - val_loss: 0.4928 - val_accuracy: 0.9109
Epoch 272/350
391/391 - 25s - loss: 0.1031 - accuracy: 0.9792 - val_loss: 0.4942 - val_accuracy: 0.9101
Epoch 273/350
391/391 - 25s - loss: 0.1011 - accuracy: 0.9808 - val_loss: 0.4924 - val_accuracy: 0.9109
Epoch 274/350
391/391 - 25s - loss: 0.1053 - accuracy: 0.9788 - val_loss: 0.4946 - val_accuracy: 0.9101
Epoch 275/350
391/391 - 25s - loss: 0.1052 - accuracy: 0.9788 - val_loss: 0.4949 - val_accuracy: 0.9103
Epoch 276/350
391/391 - 25s - loss: 0.1033 - accuracy: 0.9797 - val_loss: 0.4965 - val_accuracy: 0.9100
Epoch 277/350
391/391 - 25s - loss: 0.1010 - accuracy: 0.9807 - val_loss: 0.4957 - val_accuracy: 0.9093
Epoch 278/350
391/391 - 25s - loss: 0.1037 - accuracy: 0.9793 - val_loss: 0.4947 - val_accuracy: 0.9103
Epoch 279/350
391/391 - 25s - loss: 0.1041 - accuracy: 0.9798 - val_loss: 0.4957 - val_accuracy: 0.9099
Epoch 280/350
391/391 - 25s - loss: 0.1042 - accuracy: 0.9794 - val_loss: 0.4975 - val_accuracy: 0.9098
Epoch 281/350
391/391 - 25s - loss: 0.1041 - accuracy: 0.9786 - val_loss: 0.4966 - val_accuracy: 0.9099
Epoch 282/350
391/391 - 25s - loss: 0.1045 - accuracy: 0.9785 - val_loss: 0.4939 - val_accuracy: 0.9101
Epoch 283/350
391/391 - 25s - loss: 0.1022 - accuracy: 0.9798 - val_loss: 0.4944 - val_accuracy: 0.9107
Epoch 284/350
391/391 - 25s - loss: 0.1044 - accuracy: 0.9789 - val_loss: 0.4961 - val_accuracy: 0.9102
Epoch 285/350
391/391 - 25s - loss: 0.1042 - accuracy: 0.9789 - val_loss: 0.4939 - val_accuracy: 0.9097
Epoch 286/350
391/391 - 25s - loss: 0.1054 - accuracy: 0.9786 - val_loss: 0.4951 - val_accuracy: 0.9102
Epoch 287/350
391/391 - 25s - loss: 0.1039 - accuracy: 0.9794 - val_loss: 0.4934 - val_accuracy: 0.9107
Epoch 288/350
391/391 - 25s - loss: 0.1020 - accuracy: 0.9804 - val_loss: 0.4956 - val_accuracy: 0.9102
Epoch 289/350
391/391 - 25s - loss: 0.1036 - accuracy: 0.9792 - val_loss: 0.4953 - val_accuracy: 0.9105
Epoch 290/350
391/391 - 25s - loss: 0.1022 - accuracy: 0.9796 - val_loss: 0.4949 - val_accuracy: 0.9097
Epoch 291/350
391/391 - 25s - loss: 0.1014 - accuracy: 0.9804 - val_loss: 0.4948 - val_accuracy: 0.9094
Epoch 292/350
391/391 - 25s - loss: 0.1039 - accuracy: 0.9791 - val_loss: 0.4969 - val_accuracy: 0.9110
Epoch 293/350
391/391 - 25s - loss: 0.1034 - accuracy: 0.9800 - val_loss: 0.4970 - val_accuracy: 0.9094
Epoch 294/350
391/391 - 25s - loss: 0.1025 - accuracy: 0.9797 - val_loss: 0.4951 - val_accuracy: 0.9101
Epoch 295/350
391/391 - 25s - loss: 0.1022 - accuracy: 0.9797 - val_loss: 0.4952 - val_accuracy: 0.9105
Epoch 296/350
391/391 - 25s - loss: 0.1026 - accuracy: 0.9800 - val_loss: 0.4956 - val_accuracy: 0.9097
Epoch 297/350
391/391 - 25s - loss: 0.1025 - accuracy: 0.9795 - val_loss: 0.4966 - val_accuracy: 0.9098
Epoch 298/350
391/391 - 25s - loss: 0.1038 - accuracy: 0.9796 - val_loss: 0.4972 - val_accuracy: 0.9097
Epoch 299/350
391/391 - 25s - loss: 0.1018 - accuracy: 0.9800 - val_loss: 0.4958 - val_accuracy: 0.9102
Epoch 300/350


Snapshot weight 8 shuffle 8 at epoch 300
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1017 - accuracy: 0.9804 - val_loss: 0.4970 - val_accuracy: 0.9097
Epoch 301/350
391/391 - 25s - loss: 0.1032 - accuracy: 0.9796 - val_loss: 0.4970 - val_accuracy: 0.9093
Epoch 302/350
391/391 - 25s - loss: 0.1034 - accuracy: 0.9793 - val_loss: 0.4967 - val_accuracy: 0.9095
Epoch 303/350
391/391 - 25s - loss: 0.1046 - accuracy: 0.9794 - val_loss: 0.4966 - val_accuracy: 0.9094
Epoch 304/350
391/391 - 25s - loss: 0.1040 - accuracy: 0.9799 - val_loss: 0.4967 - val_accuracy: 0.9096
Epoch 305/350
391/391 - 25s - loss: 0.1031 - accuracy: 0.9803 - val_loss: 0.4967 - val_accuracy: 0.9097
Epoch 306/350
391/391 - 25s - loss: 0.1027 - accuracy: 0.9802 - val_loss: 0.4966 - val_accuracy: 0.9094
Epoch 307/350
391/391 - 25s - loss: 0.1027 - accuracy: 0.9798 - val_loss: 0.4966 - val_accuracy: 0.9097
Epoch 308/350
391/391 - 25s - loss: 0.1050 - accuracy: 0.9787 - val_loss: 0.4964 - val_accuracy: 0.9098
Epoch 309/350
391/391 - 25s - loss: 0.1042 - accuracy: 0.9789 - val_loss: 0.4964 - val_accuracy: 0.9099
Epoch 310/350
391/391 - 25s - loss: 0.1031 - accuracy: 0.9794 - val_loss: 0.4965 - val_accuracy: 0.9099
Epoch 311/350
391/391 - 25s - loss: 0.1046 - accuracy: 0.9792 - val_loss: 0.4964 - val_accuracy: 0.9096
Epoch 312/350
391/391 - 25s - loss: 0.1030 - accuracy: 0.9801 - val_loss: 0.4964 - val_accuracy: 0.9099
Epoch 313/350
391/391 - 25s - loss: 0.1028 - accuracy: 0.9801 - val_loss: 0.4965 - val_accuracy: 0.9097
Epoch 314/350
391/391 - 25s - loss: 0.1044 - accuracy: 0.9789 - val_loss: 0.4962 - val_accuracy: 0.9101
Epoch 315/350
391/391 - 25s - loss: 0.1029 - accuracy: 0.9797 - val_loss: 0.4961 - val_accuracy: 0.9100
Epoch 316/350
391/391 - 25s - loss: 0.1028 - accuracy: 0.9794 - val_loss: 0.4962 - val_accuracy: 0.9098
Epoch 317/350
391/391 - 25s - loss: 0.1030 - accuracy: 0.9796 - val_loss: 0.4964 - val_accuracy: 0.9098
Epoch 318/350
391/391 - 25s - loss: 0.1039 - accuracy: 0.9796 - val_loss: 0.4961 - val_accuracy: 0.9100
Epoch 319/350
391/391 - 25s - loss: 0.1034 - accuracy: 0.9801 - val_loss: 0.4963 - val_accuracy: 0.9099
Epoch 320/350
391/391 - 25s - loss: 0.1020 - accuracy: 0.9804 - val_loss: 0.4964 - val_accuracy: 0.9100
Epoch 321/350
391/391 - 25s - loss: 0.1052 - accuracy: 0.9796 - val_loss: 0.4960 - val_accuracy: 0.9099
Epoch 322/350
391/391 - 25s - loss: 0.1027 - accuracy: 0.9793 - val_loss: 0.4964 - val_accuracy: 0.9098
Epoch 323/350
391/391 - 25s - loss: 0.1036 - accuracy: 0.9791 - val_loss: 0.4963 - val_accuracy: 0.9098
Epoch 324/350
391/391 - 25s - loss: 0.1048 - accuracy: 0.9792 - val_loss: 0.4961 - val_accuracy: 0.9097
Epoch 325/350
391/391 - 25s - loss: 0.1039 - accuracy: 0.9791 - val_loss: 0.4958 - val_accuracy: 0.9102
Epoch 326/350
391/391 - 25s - loss: 0.1029 - accuracy: 0.9791 - val_loss: 0.4960 - val_accuracy: 0.9101
Epoch 327/350
391/391 - 25s - loss: 0.1047 - accuracy: 0.9790 - val_loss: 0.4960 - val_accuracy: 0.9101
Epoch 328/350
391/391 - 25s - loss: 0.1028 - accuracy: 0.9810 - val_loss: 0.4959 - val_accuracy: 0.9101
Epoch 329/350
391/391 - 25s - loss: 0.1012 - accuracy: 0.9798 - val_loss: 0.4957 - val_accuracy: 0.9101
Epoch 330/350
391/391 - 25s - loss: 0.1050 - accuracy: 0.9792 - val_loss: 0.4955 - val_accuracy: 0.9101
Epoch 331/350
391/391 - 25s - loss: 0.1033 - accuracy: 0.9798 - val_loss: 0.4955 - val_accuracy: 0.9100
Epoch 332/350
391/391 - 25s - loss: 0.1039 - accuracy: 0.9792 - val_loss: 0.4954 - val_accuracy: 0.9098
Epoch 333/350
391/391 - 25s - loss: 0.1025 - accuracy: 0.9798 - val_loss: 0.4954 - val_accuracy: 0.9102
Epoch 334/350
391/391 - 25s - loss: 0.1036 - accuracy: 0.9801 - val_loss: 0.4956 - val_accuracy: 0.9101
Epoch 335/350
391/391 - 25s - loss: 0.1045 - accuracy: 0.9793 - val_loss: 0.4957 - val_accuracy: 0.9100
Epoch 336/350
391/391 - 25s - loss: 0.1057 - accuracy: 0.9787 - val_loss: 0.4954 - val_accuracy: 0.9101
Epoch 337/350
391/391 - 25s - loss: 0.1027 - accuracy: 0.9800 - val_loss: 0.4953 - val_accuracy: 0.9102
Epoch 338/350
391/391 - 25s - loss: 0.1027 - accuracy: 0.9791 - val_loss: 0.4954 - val_accuracy: 0.9096
Epoch 339/350
391/391 - 25s - loss: 0.1018 - accuracy: 0.9804 - val_loss: 0.4956 - val_accuracy: 0.9094
Epoch 340/350
391/391 - 25s - loss: 0.1024 - accuracy: 0.9803 - val_loss: 0.4956 - val_accuracy: 0.9095
Epoch 341/350
391/391 - 25s - loss: 0.1026 - accuracy: 0.9806 - val_loss: 0.4957 - val_accuracy: 0.9095
Epoch 342/350
391/391 - 25s - loss: 0.1038 - accuracy: 0.9797 - val_loss: 0.4958 - val_accuracy: 0.9097
Epoch 343/350
391/391 - 25s - loss: 0.1052 - accuracy: 0.9795 - val_loss: 0.4959 - val_accuracy: 0.9097
Epoch 344/350
391/391 - 25s - loss: 0.1048 - accuracy: 0.9795 - val_loss: 0.4955 - val_accuracy: 0.9097
Epoch 345/350
391/391 - 25s - loss: 0.1038 - accuracy: 0.9792 - val_loss: 0.4952 - val_accuracy: 0.9101
Epoch 346/350
391/391 - 25s - loss: 0.1042 - accuracy: 0.9790 - val_loss: 0.4951 - val_accuracy: 0.9099
Epoch 347/350
391/391 - 25s - loss: 0.1028 - accuracy: 0.9797 - val_loss: 0.4955 - val_accuracy: 0.9100
Epoch 348/350
391/391 - 25s - loss: 0.1029 - accuracy: 0.9796 - val_loss: 0.4954 - val_accuracy: 0.9099
Epoch 349/350
391/391 - 25s - loss: 0.1045 - accuracy: 0.9793 - val_loss: 0.4955 - val_accuracy: 0.9097
Epoch 350/350


Snapshot weight 8 shuffle 8 at epoch 350
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1020 - accuracy: 0.9800 - val_loss: 0.4954 - val_accuracy: 0.9100
/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:493: UserWarning: fill_value is not supported and is always 0 for TensorFlow < 2.4.0.
  return py_builtins.overload_of(f)(*args)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-07-02 20:44:20.069100: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
Saving, final validation acc: 0.9100000262260437
