2021-07-02 16:54:57.036567: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 16:56:20.889169: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-07-02 16:56:20.918444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2021-07-02 16:56:20.918529: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 16:56:20.959624: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-02 16:56:20.980040: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-02 16:56:20.988550: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-02 16:56:21.031324: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-02 16:56:21.039900: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-02 16:56:21.117001: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 16:56:21.118997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-02 16:56:21.122732: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-02 16:56:21.139113: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600265000 Hz
2021-07-02 16:56:21.139279: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x45fbe50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-07-02 16:56:21.139301: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-07-02 16:56:21.299530: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x45dd6b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-07-02 16:56:21.299615: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN Xp, Compute Capability 6.1
2021-07-02 16:56:21.304058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2021-07-02 16:56:21.304165: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 16:56:21.304204: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-02 16:56:21.304223: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-02 16:56:21.304239: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-02 16:56:21.304255: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-02 16:56:21.304270: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-02 16:56:21.304285: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 16:56:21.310199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-02 16:56:21.312063: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 16:56:23.138724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-02 16:56:23.138820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-07-02 16:56:23.138833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-07-02 16:56:23.144958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11218 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
2021-07-02 16:56:29.291940: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 16:56:31.928398: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
Using model index: 84
Making train data...
GCN...
ZCA...
Done!
Making test data...
Done!
Epoch 1/350


Snapshot weight 4 shuffle 8 at epoch 1
Layer 11
Getting activations...


391/391 - 24s - loss: 2.3200 - accuracy: 0.1108 - val_loss: 2.3073 - val_accuracy: 0.1110
Epoch 2/350


Snapshot weight 4 shuffle 8 at epoch 2
Layer 11
Getting activations...


391/391 - 23s - loss: 2.2678 - accuracy: 0.1561 - val_loss: 2.1265 - val_accuracy: 0.2108
Epoch 3/350


Snapshot weight 4 shuffle 8 at epoch 3
Layer 11
Getting activations...


391/391 - 23s - loss: 2.0501 - accuracy: 0.2609 - val_loss: 1.9227 - val_accuracy: 0.3079
Epoch 4/350


Snapshot weight 4 shuffle 8 at epoch 4
Layer 11
Getting activations...


391/391 - 23s - loss: 1.8549 - accuracy: 0.3496 - val_loss: 1.6920 - val_accuracy: 0.4364
Epoch 5/350


Snapshot weight 4 shuffle 8 at epoch 5
Layer 11
Getting activations...


391/391 - 23s - loss: 1.5627 - accuracy: 0.4468 - val_loss: 1.3638 - val_accuracy: 0.5226
Epoch 6/350


Snapshot weight 4 shuffle 8 at epoch 6
Layer 11
Getting activations...


391/391 - 23s - loss: 1.4004 - accuracy: 0.5054 - val_loss: 1.3208 - val_accuracy: 0.5339
Epoch 7/350


Snapshot weight 4 shuffle 8 at epoch 7
Layer 11
Getting activations...


391/391 - 24s - loss: 1.2806 - accuracy: 0.5488 - val_loss: 1.1549 - val_accuracy: 0.5971
Epoch 8/350


Snapshot weight 4 shuffle 8 at epoch 8
Layer 11
Getting activations...


391/391 - 23s - loss: 1.1886 - accuracy: 0.5832 - val_loss: 1.2308 - val_accuracy: 0.5629
Epoch 9/350


Snapshot weight 4 shuffle 8 at epoch 9
Layer 11
Getting activations...


391/391 - 24s - loss: 1.1187 - accuracy: 0.6124 - val_loss: 1.0823 - val_accuracy: 0.6270
Epoch 10/350


Snapshot weight 4 shuffle 8 at epoch 10
Layer 11
Getting activations...


391/391 - 24s - loss: 1.0511 - accuracy: 0.6335 - val_loss: 0.9245 - val_accuracy: 0.6828
Epoch 11/350
391/391 - 23s - loss: 1.0111 - accuracy: 0.6507 - val_loss: 0.9136 - val_accuracy: 0.6876
Epoch 12/350
391/391 - 23s - loss: 0.9580 - accuracy: 0.6708 - val_loss: 0.8762 - val_accuracy: 0.7023
Epoch 13/350
391/391 - 23s - loss: 0.9172 - accuracy: 0.6846 - val_loss: 0.8322 - val_accuracy: 0.7148
Epoch 14/350
391/391 - 23s - loss: 0.8861 - accuracy: 0.6976 - val_loss: 0.8102 - val_accuracy: 0.7303
Epoch 15/350
391/391 - 23s - loss: 0.8484 - accuracy: 0.7110 - val_loss: 0.9047 - val_accuracy: 0.7124
Epoch 16/350
391/391 - 23s - loss: 0.8200 - accuracy: 0.7203 - val_loss: 0.8112 - val_accuracy: 0.7283
Epoch 17/350
391/391 - 24s - loss: 0.7820 - accuracy: 0.7353 - val_loss: 0.7074 - val_accuracy: 0.7672
Epoch 18/350
391/391 - 23s - loss: 0.7558 - accuracy: 0.7457 - val_loss: 0.7196 - val_accuracy: 0.7582
Epoch 19/350
391/391 - 23s - loss: 0.7312 - accuracy: 0.7557 - val_loss: 0.7324 - val_accuracy: 0.7627
Epoch 20/350
391/391 - 23s - loss: 0.6999 - accuracy: 0.7653 - val_loss: 0.6466 - val_accuracy: 0.7920
Epoch 21/350
391/391 - 23s - loss: 0.6876 - accuracy: 0.7684 - val_loss: 0.7155 - val_accuracy: 0.7754
Epoch 22/350
391/391 - 23s - loss: 0.6709 - accuracy: 0.7760 - val_loss: 0.6074 - val_accuracy: 0.8018
Epoch 23/350
391/391 - 23s - loss: 0.6547 - accuracy: 0.7821 - val_loss: 0.6292 - val_accuracy: 0.7948
Epoch 24/350
391/391 - 23s - loss: 0.6338 - accuracy: 0.7905 - val_loss: 0.5872 - val_accuracy: 0.8112
Epoch 25/350
391/391 - 23s - loss: 0.6227 - accuracy: 0.7945 - val_loss: 0.6076 - val_accuracy: 0.8071
Epoch 26/350
391/391 - 23s - loss: 0.5973 - accuracy: 0.8030 - val_loss: 0.5569 - val_accuracy: 0.8204
Epoch 27/350
391/391 - 23s - loss: 0.5932 - accuracy: 0.8046 - val_loss: 0.5383 - val_accuracy: 0.8280
Epoch 28/350
391/391 - 23s - loss: 0.5766 - accuracy: 0.8082 - val_loss: 0.5561 - val_accuracy: 0.8195
Epoch 29/350
391/391 - 24s - loss: 0.5692 - accuracy: 0.8134 - val_loss: 0.6192 - val_accuracy: 0.8159
Epoch 30/350
391/391 - 23s - loss: 0.5561 - accuracy: 0.8190 - val_loss: 0.5493 - val_accuracy: 0.8273
Epoch 31/350
391/391 - 23s - loss: 0.5424 - accuracy: 0.8212 - val_loss: 0.5900 - val_accuracy: 0.8171
Epoch 32/350
391/391 - 23s - loss: 0.5391 - accuracy: 0.8217 - val_loss: 0.5267 - val_accuracy: 0.8310
Epoch 33/350
391/391 - 23s - loss: 0.5253 - accuracy: 0.8272 - val_loss: 0.5238 - val_accuracy: 0.8293
Epoch 34/350
391/391 - 23s - loss: 0.5155 - accuracy: 0.8301 - val_loss: 0.5174 - val_accuracy: 0.8363
Epoch 35/350
391/391 - 23s - loss: 0.5034 - accuracy: 0.8348 - val_loss: 0.5248 - val_accuracy: 0.8357
Epoch 36/350
391/391 - 23s - loss: 0.4979 - accuracy: 0.8393 - val_loss: 0.4849 - val_accuracy: 0.8424
Epoch 37/350
391/391 - 23s - loss: 0.4971 - accuracy: 0.8384 - val_loss: 0.4921 - val_accuracy: 0.8432
Epoch 38/350
391/391 - 23s - loss: 0.4882 - accuracy: 0.8403 - val_loss: 0.5354 - val_accuracy: 0.8335
Epoch 39/350
391/391 - 23s - loss: 0.4750 - accuracy: 0.8454 - val_loss: 0.5220 - val_accuracy: 0.8364
Epoch 40/350
391/391 - 23s - loss: 0.4677 - accuracy: 0.8474 - val_loss: 0.5081 - val_accuracy: 0.8441
Epoch 41/350
391/391 - 23s - loss: 0.4617 - accuracy: 0.8496 - val_loss: 0.5048 - val_accuracy: 0.8413
Epoch 42/350
391/391 - 23s - loss: 0.4547 - accuracy: 0.8525 - val_loss: 0.4906 - val_accuracy: 0.8494
Epoch 43/350
391/391 - 23s - loss: 0.4494 - accuracy: 0.8543 - val_loss: 0.4598 - val_accuracy: 0.8576
Epoch 44/350
391/391 - 23s - loss: 0.4432 - accuracy: 0.8569 - val_loss: 0.5767 - val_accuracy: 0.8314
Epoch 45/350
391/391 - 23s - loss: 0.4415 - accuracy: 0.8575 - val_loss: 0.4806 - val_accuracy: 0.8509
Epoch 46/350
391/391 - 23s - loss: 0.4313 - accuracy: 0.8609 - val_loss: 0.5118 - val_accuracy: 0.8418
Epoch 47/350
391/391 - 23s - loss: 0.4291 - accuracy: 0.8611 - val_loss: 0.4572 - val_accuracy: 0.8582
Epoch 48/350
391/391 - 23s - loss: 0.4220 - accuracy: 0.8640 - val_loss: 0.4944 - val_accuracy: 0.8479
Epoch 49/350
391/391 - 23s - loss: 0.4128 - accuracy: 0.8668 - val_loss: 0.4753 - val_accuracy: 0.8569
Epoch 50/350


Snapshot weight 4 shuffle 8 at epoch 50
Layer 11
Getting activations...


391/391 - 23s - loss: 0.4062 - accuracy: 0.8690 - val_loss: 0.4940 - val_accuracy: 0.8469
Epoch 51/350
391/391 - 23s - loss: 0.4016 - accuracy: 0.8709 - val_loss: 0.4816 - val_accuracy: 0.8574
Epoch 52/350
391/391 - 23s - loss: 0.4012 - accuracy: 0.8708 - val_loss: 0.5141 - val_accuracy: 0.8476
Epoch 53/350
391/391 - 23s - loss: 0.3985 - accuracy: 0.8719 - val_loss: 0.4896 - val_accuracy: 0.8554
Epoch 54/350
391/391 - 23s - loss: 0.3915 - accuracy: 0.8747 - val_loss: 0.5068 - val_accuracy: 0.8507
Epoch 55/350
391/391 - 23s - loss: 0.3866 - accuracy: 0.8763 - val_loss: 0.4570 - val_accuracy: 0.8609
Epoch 56/350
391/391 - 23s - loss: 0.3807 - accuracy: 0.8782 - val_loss: 0.4348 - val_accuracy: 0.8692
Epoch 57/350
391/391 - 23s - loss: 0.3762 - accuracy: 0.8809 - val_loss: 0.5308 - val_accuracy: 0.8464
Epoch 58/350
391/391 - 23s - loss: 0.3706 - accuracy: 0.8816 - val_loss: 0.4786 - val_accuracy: 0.8559
Epoch 59/350
391/391 - 23s - loss: 0.3677 - accuracy: 0.8825 - val_loss: 0.4738 - val_accuracy: 0.8524
Epoch 60/350
391/391 - 23s - loss: 0.3672 - accuracy: 0.8833 - val_loss: 0.4493 - val_accuracy: 0.8644
Epoch 61/350
391/391 - 23s - loss: 0.3613 - accuracy: 0.8848 - val_loss: 0.4677 - val_accuracy: 0.8644
Epoch 62/350
391/391 - 23s - loss: 0.3590 - accuracy: 0.8840 - val_loss: 0.4539 - val_accuracy: 0.8635
Epoch 63/350
391/391 - 23s - loss: 0.3488 - accuracy: 0.8902 - val_loss: 0.4365 - val_accuracy: 0.8702
Epoch 64/350
391/391 - 23s - loss: 0.3497 - accuracy: 0.8883 - val_loss: 0.4957 - val_accuracy: 0.8555
Epoch 65/350
391/391 - 23s - loss: 0.3469 - accuracy: 0.8902 - val_loss: 0.4527 - val_accuracy: 0.8707
Epoch 66/350
391/391 - 23s - loss: 0.3396 - accuracy: 0.8917 - val_loss: 0.4257 - val_accuracy: 0.8768
Epoch 67/350
391/391 - 23s - loss: 0.3412 - accuracy: 0.8931 - val_loss: 0.4614 - val_accuracy: 0.8625
Epoch 68/350
391/391 - 23s - loss: 0.3349 - accuracy: 0.8936 - val_loss: 0.4251 - val_accuracy: 0.8754
Epoch 69/350
391/391 - 23s - loss: 0.3342 - accuracy: 0.8951 - val_loss: 0.4463 - val_accuracy: 0.8744
Epoch 70/350
391/391 - 23s - loss: 0.3275 - accuracy: 0.8978 - val_loss: 0.4360 - val_accuracy: 0.8717
Epoch 71/350
391/391 - 23s - loss: 0.3266 - accuracy: 0.8958 - val_loss: 0.4470 - val_accuracy: 0.8733
Epoch 72/350
391/391 - 23s - loss: 0.3284 - accuracy: 0.8973 - val_loss: 0.4190 - val_accuracy: 0.8748
Epoch 73/350
391/391 - 23s - loss: 0.3227 - accuracy: 0.8986 - val_loss: 0.4417 - val_accuracy: 0.8730
Epoch 74/350
391/391 - 23s - loss: 0.3176 - accuracy: 0.8991 - val_loss: 0.4163 - val_accuracy: 0.8782
Epoch 75/350
391/391 - 23s - loss: 0.3103 - accuracy: 0.9039 - val_loss: 0.4418 - val_accuracy: 0.8741
Epoch 76/350
391/391 - 23s - loss: 0.3071 - accuracy: 0.9032 - val_loss: 0.4286 - val_accuracy: 0.8789
Epoch 77/350
391/391 - 23s - loss: 0.3086 - accuracy: 0.9032 - val_loss: 0.4141 - val_accuracy: 0.8788
Epoch 78/350
391/391 - 23s - loss: 0.3046 - accuracy: 0.9057 - val_loss: 0.5595 - val_accuracy: 0.8534
Epoch 79/350
391/391 - 23s - loss: 0.3027 - accuracy: 0.9053 - val_loss: 0.4612 - val_accuracy: 0.8712
Epoch 80/350
391/391 - 23s - loss: 0.3037 - accuracy: 0.9048 - val_loss: 0.4359 - val_accuracy: 0.8738
Epoch 81/350
391/391 - 23s - loss: 0.3023 - accuracy: 0.9063 - val_loss: 0.4200 - val_accuracy: 0.8791
Epoch 82/350
391/391 - 23s - loss: 0.3003 - accuracy: 0.9060 - val_loss: 0.4239 - val_accuracy: 0.8764
Epoch 83/350
391/391 - 23s - loss: 0.2920 - accuracy: 0.9091 - val_loss: 0.4187 - val_accuracy: 0.8793
Epoch 84/350
391/391 - 23s - loss: 0.2888 - accuracy: 0.9100 - val_loss: 0.4485 - val_accuracy: 0.8776
Epoch 85/350
391/391 - 23s - loss: 0.2934 - accuracy: 0.9091 - val_loss: 0.4570 - val_accuracy: 0.8654
Epoch 86/350
391/391 - 23s - loss: 0.2860 - accuracy: 0.9111 - val_loss: 0.4039 - val_accuracy: 0.8833
Epoch 87/350
391/391 - 23s - loss: 0.2789 - accuracy: 0.9146 - val_loss: 0.4451 - val_accuracy: 0.8808
Epoch 88/350
391/391 - 23s - loss: 0.2794 - accuracy: 0.9137 - val_loss: 0.4229 - val_accuracy: 0.8855
Epoch 89/350
391/391 - 23s - loss: 0.2762 - accuracy: 0.9155 - val_loss: 0.4223 - val_accuracy: 0.8858
Epoch 90/350
391/391 - 23s - loss: 0.2829 - accuracy: 0.9146 - val_loss: 0.4239 - val_accuracy: 0.8846
Epoch 91/350
391/391 - 23s - loss: 0.2785 - accuracy: 0.9154 - val_loss: 0.4515 - val_accuracy: 0.8790
Epoch 92/350
391/391 - 23s - loss: 0.2750 - accuracy: 0.9168 - val_loss: 0.4108 - val_accuracy: 0.8843
Epoch 93/350
391/391 - 23s - loss: 0.2723 - accuracy: 0.9161 - val_loss: 0.4288 - val_accuracy: 0.8822
Epoch 94/350
391/391 - 23s - loss: 0.2726 - accuracy: 0.9157 - val_loss: 0.4434 - val_accuracy: 0.8763
Epoch 95/350
391/391 - 23s - loss: 0.2727 - accuracy: 0.9168 - val_loss: 0.4623 - val_accuracy: 0.8802
Epoch 96/350
391/391 - 23s - loss: 0.2687 - accuracy: 0.9195 - val_loss: 0.4202 - val_accuracy: 0.8829
Epoch 97/350
391/391 - 23s - loss: 0.2644 - accuracy: 0.9195 - val_loss: 0.4174 - val_accuracy: 0.8860
Epoch 98/350
391/391 - 23s - loss: 0.2608 - accuracy: 0.9207 - val_loss: 0.4261 - val_accuracy: 0.8834
Epoch 99/350
391/391 - 23s - loss: 0.2611 - accuracy: 0.9198 - val_loss: 0.4450 - val_accuracy: 0.8832
Epoch 100/350


Snapshot weight 4 shuffle 8 at epoch 100
Layer 11
Getting activations...


391/391 - 23s - loss: 0.2622 - accuracy: 0.9213 - val_loss: 0.4456 - val_accuracy: 0.8831
Epoch 101/350
391/391 - 23s - loss: 0.2579 - accuracy: 0.9211 - val_loss: 0.4225 - val_accuracy: 0.8843
Epoch 102/350
391/391 - 23s - loss: 0.2549 - accuracy: 0.9224 - val_loss: 0.4122 - val_accuracy: 0.8851
Epoch 103/350
391/391 - 23s - loss: 0.2543 - accuracy: 0.9237 - val_loss: 0.4080 - val_accuracy: 0.8904
Epoch 104/350
391/391 - 23s - loss: 0.2532 - accuracy: 0.9247 - val_loss: 0.4681 - val_accuracy: 0.8754
Epoch 105/350
391/391 - 23s - loss: 0.2524 - accuracy: 0.9239 - val_loss: 0.4286 - val_accuracy: 0.8878
Epoch 106/350
391/391 - 23s - loss: 0.2493 - accuracy: 0.9252 - val_loss: 0.4178 - val_accuracy: 0.8870
Epoch 107/350
391/391 - 23s - loss: 0.2491 - accuracy: 0.9256 - val_loss: 0.4351 - val_accuracy: 0.8843
Epoch 108/350
391/391 - 23s - loss: 0.2476 - accuracy: 0.9257 - val_loss: 0.4252 - val_accuracy: 0.8862
Epoch 109/350
391/391 - 23s - loss: 0.2409 - accuracy: 0.9281 - val_loss: 0.4792 - val_accuracy: 0.8729
Epoch 110/350
391/391 - 23s - loss: 0.2421 - accuracy: 0.9271 - val_loss: 0.4254 - val_accuracy: 0.8865
Epoch 111/350
391/391 - 23s - loss: 0.2384 - accuracy: 0.9296 - val_loss: 0.4338 - val_accuracy: 0.8861
Epoch 112/350
391/391 - 23s - loss: 0.2383 - accuracy: 0.9293 - val_loss: 0.4368 - val_accuracy: 0.8897
Epoch 113/350
391/391 - 23s - loss: 0.2459 - accuracy: 0.9265 - val_loss: 0.4374 - val_accuracy: 0.8835
Epoch 114/350
391/391 - 23s - loss: 0.2342 - accuracy: 0.9316 - val_loss: 0.4339 - val_accuracy: 0.8884
Epoch 115/350
391/391 - 23s - loss: 0.2319 - accuracy: 0.9315 - val_loss: 0.4154 - val_accuracy: 0.8918
Epoch 116/350
391/391 - 23s - loss: 0.2303 - accuracy: 0.9314 - val_loss: 0.4198 - val_accuracy: 0.8909
Epoch 117/350
391/391 - 23s - loss: 0.2299 - accuracy: 0.9321 - val_loss: 0.4406 - val_accuracy: 0.8848
Epoch 118/350
391/391 - 23s - loss: 0.2306 - accuracy: 0.9313 - val_loss: 0.4395 - val_accuracy: 0.8901
Epoch 119/350
391/391 - 23s - loss: 0.2284 - accuracy: 0.9338 - val_loss: 0.4457 - val_accuracy: 0.8849
Epoch 120/350
391/391 - 23s - loss: 0.2253 - accuracy: 0.9336 - val_loss: 0.4157 - val_accuracy: 0.8883
Epoch 121/350
391/391 - 23s - loss: 0.2229 - accuracy: 0.9355 - val_loss: 0.4416 - val_accuracy: 0.8867
Epoch 122/350
391/391 - 23s - loss: 0.2263 - accuracy: 0.9332 - val_loss: 0.4591 - val_accuracy: 0.8840
Epoch 123/350
391/391 - 23s - loss: 0.2250 - accuracy: 0.9337 - val_loss: 0.4282 - val_accuracy: 0.8884
Epoch 124/350
391/391 - 23s - loss: 0.2228 - accuracy: 0.9353 - val_loss: 0.4396 - val_accuracy: 0.8887
Epoch 125/350
391/391 - 23s - loss: 0.2236 - accuracy: 0.9353 - val_loss: 0.4125 - val_accuracy: 0.8920
Epoch 126/350
391/391 - 23s - loss: 0.2179 - accuracy: 0.9366 - val_loss: 0.4229 - val_accuracy: 0.8912
Epoch 127/350
391/391 - 23s - loss: 0.2215 - accuracy: 0.9359 - val_loss: 0.4234 - val_accuracy: 0.8925
Epoch 128/350
391/391 - 23s - loss: 0.2176 - accuracy: 0.9369 - val_loss: 0.4686 - val_accuracy: 0.8832
Epoch 129/350
391/391 - 23s - loss: 0.2181 - accuracy: 0.9365 - val_loss: 0.4676 - val_accuracy: 0.8844
Epoch 130/350
391/391 - 23s - loss: 0.2144 - accuracy: 0.9374 - val_loss: 0.4411 - val_accuracy: 0.8894
Epoch 131/350
391/391 - 23s - loss: 0.2158 - accuracy: 0.9373 - val_loss: 0.4783 - val_accuracy: 0.8812
Epoch 132/350
391/391 - 23s - loss: 0.2133 - accuracy: 0.9397 - val_loss: 0.4422 - val_accuracy: 0.8918
Epoch 133/350
391/391 - 23s - loss: 0.2132 - accuracy: 0.9398 - val_loss: 0.4624 - val_accuracy: 0.8814
Epoch 134/350
391/391 - 23s - loss: 0.2129 - accuracy: 0.9385 - val_loss: 0.4316 - val_accuracy: 0.8913
Epoch 135/350
391/391 - 23s - loss: 0.2111 - accuracy: 0.9394 - val_loss: 0.4096 - val_accuracy: 0.8954
Epoch 136/350
391/391 - 23s - loss: 0.2107 - accuracy: 0.9398 - val_loss: 0.4363 - val_accuracy: 0.8907
Epoch 137/350
391/391 - 23s - loss: 0.2136 - accuracy: 0.9396 - val_loss: 0.4529 - val_accuracy: 0.8896
Epoch 138/350
391/391 - 23s - loss: 0.2095 - accuracy: 0.9401 - val_loss: 0.4315 - val_accuracy: 0.8909
Epoch 139/350
391/391 - 23s - loss: 0.2058 - accuracy: 0.9422 - val_loss: 0.4597 - val_accuracy: 0.8913
Epoch 140/350
391/391 - 23s - loss: 0.2039 - accuracy: 0.9424 - val_loss: 0.4383 - val_accuracy: 0.8944
Epoch 141/350
391/391 - 23s - loss: 0.2025 - accuracy: 0.9424 - val_loss: 0.4427 - val_accuracy: 0.8936
Epoch 142/350
391/391 - 23s - loss: 0.2062 - accuracy: 0.9425 - val_loss: 0.4390 - val_accuracy: 0.8917
Epoch 143/350
391/391 - 23s - loss: 0.2004 - accuracy: 0.9440 - val_loss: 0.4673 - val_accuracy: 0.8901
Epoch 144/350
391/391 - 23s - loss: 0.2037 - accuracy: 0.9432 - val_loss: 0.4232 - val_accuracy: 0.8956
Epoch 145/350
391/391 - 23s - loss: 0.2006 - accuracy: 0.9437 - val_loss: 0.4286 - val_accuracy: 0.8962
Epoch 146/350
391/391 - 22s - loss: 0.2007 - accuracy: 0.9450 - val_loss: 0.4520 - val_accuracy: 0.8908
Epoch 147/350
391/391 - 23s - loss: 0.2002 - accuracy: 0.9438 - val_loss: 0.4430 - val_accuracy: 0.8929
Epoch 148/350
391/391 - 23s - loss: 0.2049 - accuracy: 0.9423 - val_loss: 0.4412 - val_accuracy: 0.8845
Epoch 149/350
391/391 - 23s - loss: 0.1946 - accuracy: 0.9457 - val_loss: 0.4379 - val_accuracy: 0.8926
Epoch 150/350


Snapshot weight 4 shuffle 8 at epoch 150
Layer 11
Getting activations...


391/391 - 23s - loss: 0.1983 - accuracy: 0.9455 - val_loss: 0.4330 - val_accuracy: 0.8912
Epoch 151/350
391/391 - 23s - loss: 0.1971 - accuracy: 0.9466 - val_loss: 0.4773 - val_accuracy: 0.8841
Epoch 152/350
391/391 - 23s - loss: 0.2006 - accuracy: 0.9443 - val_loss: 0.4621 - val_accuracy: 0.8873
Epoch 153/350
391/391 - 23s - loss: 0.1911 - accuracy: 0.9485 - val_loss: 0.4506 - val_accuracy: 0.8874
Epoch 154/350
391/391 - 23s - loss: 0.1945 - accuracy: 0.9474 - val_loss: 0.4562 - val_accuracy: 0.8931
Epoch 155/350
391/391 - 23s - loss: 0.1921 - accuracy: 0.9475 - val_loss: 0.4507 - val_accuracy: 0.8930
Epoch 156/350
391/391 - 23s - loss: 0.1889 - accuracy: 0.9485 - val_loss: 0.4862 - val_accuracy: 0.8884
Epoch 157/350
391/391 - 23s - loss: 0.1893 - accuracy: 0.9478 - val_loss: 0.4412 - val_accuracy: 0.8921
Epoch 158/350
391/391 - 23s - loss: 0.1873 - accuracy: 0.9493 - val_loss: 0.4391 - val_accuracy: 0.8918
Epoch 159/350
391/391 - 22s - loss: 0.1889 - accuracy: 0.9482 - val_loss: 0.4800 - val_accuracy: 0.8910
Epoch 160/350
391/391 - 23s - loss: 0.1918 - accuracy: 0.9476 - val_loss: 0.4671 - val_accuracy: 0.8844
Epoch 161/350
391/391 - 23s - loss: 0.1895 - accuracy: 0.9481 - val_loss: 0.4871 - val_accuracy: 0.8924
Epoch 162/350
391/391 - 23s - loss: 0.1917 - accuracy: 0.9474 - val_loss: 0.4632 - val_accuracy: 0.8940
Epoch 163/350
391/391 - 23s - loss: 0.1878 - accuracy: 0.9486 - val_loss: 0.4644 - val_accuracy: 0.8918
Epoch 164/350
391/391 - 23s - loss: 0.1882 - accuracy: 0.9481 - val_loss: 0.4387 - val_accuracy: 0.8924
Epoch 165/350
391/391 - 23s - loss: 0.1819 - accuracy: 0.9506 - val_loss: 0.4477 - val_accuracy: 0.8928
Epoch 166/350
391/391 - 23s - loss: 0.1859 - accuracy: 0.9500 - val_loss: 0.4346 - val_accuracy: 0.8966
Epoch 167/350
391/391 - 23s - loss: 0.1853 - accuracy: 0.9499 - val_loss: 0.4379 - val_accuracy: 0.8954
Epoch 168/350
391/391 - 22s - loss: 0.1857 - accuracy: 0.9498 - val_loss: 0.4560 - val_accuracy: 0.8923
Epoch 169/350
391/391 - 23s - loss: 0.1870 - accuracy: 0.9485 - val_loss: 0.4403 - val_accuracy: 0.8918
Epoch 170/350
391/391 - 23s - loss: 0.1860 - accuracy: 0.9507 - val_loss: 0.4358 - val_accuracy: 0.8974
Epoch 171/350
391/391 - 23s - loss: 0.1820 - accuracy: 0.9507 - val_loss: 0.4670 - val_accuracy: 0.8936
Epoch 172/350
391/391 - 23s - loss: 0.1850 - accuracy: 0.9503 - val_loss: 0.4909 - val_accuracy: 0.8902
Epoch 173/350
391/391 - 23s - loss: 0.1807 - accuracy: 0.9502 - val_loss: 0.4445 - val_accuracy: 0.8978
Epoch 174/350
391/391 - 23s - loss: 0.1818 - accuracy: 0.9514 - val_loss: 0.4396 - val_accuracy: 0.8964
Epoch 175/350
391/391 - 23s - loss: 0.1823 - accuracy: 0.9511 - val_loss: 0.4171 - val_accuracy: 0.8984
Epoch 176/350
391/391 - 23s - loss: 0.1739 - accuracy: 0.9525 - val_loss: 0.4780 - val_accuracy: 0.8960
Epoch 177/350
391/391 - 23s - loss: 0.1767 - accuracy: 0.9535 - val_loss: 0.4735 - val_accuracy: 0.8963
Epoch 178/350
391/391 - 23s - loss: 0.1754 - accuracy: 0.9537 - val_loss: 0.4228 - val_accuracy: 0.8988
Epoch 179/350
391/391 - 23s - loss: 0.1788 - accuracy: 0.9522 - val_loss: 0.4441 - val_accuracy: 0.8936
Epoch 180/350
391/391 - 23s - loss: 0.1717 - accuracy: 0.9546 - val_loss: 0.4458 - val_accuracy: 0.8958
Epoch 181/350
391/391 - 23s - loss: 0.1732 - accuracy: 0.9541 - val_loss: 0.4472 - val_accuracy: 0.8969
Epoch 182/350
391/391 - 23s - loss: 0.1732 - accuracy: 0.9537 - val_loss: 0.4618 - val_accuracy: 0.8933
Epoch 183/350
391/391 - 23s - loss: 0.1768 - accuracy: 0.9532 - val_loss: 0.4524 - val_accuracy: 0.8951
Epoch 184/350
391/391 - 23s - loss: 0.1742 - accuracy: 0.9541 - val_loss: 0.4550 - val_accuracy: 0.8972
Epoch 185/350
391/391 - 23s - loss: 0.1723 - accuracy: 0.9550 - val_loss: 0.4564 - val_accuracy: 0.8965
Epoch 186/350
391/391 - 23s - loss: 0.1726 - accuracy: 0.9550 - val_loss: 0.4724 - val_accuracy: 0.8967
Epoch 187/350
391/391 - 23s - loss: 0.1752 - accuracy: 0.9538 - val_loss: 0.4343 - val_accuracy: 0.8981
Epoch 188/350
391/391 - 23s - loss: 0.1736 - accuracy: 0.9545 - val_loss: 0.4746 - val_accuracy: 0.8930
Epoch 189/350
391/391 - 22s - loss: 0.1724 - accuracy: 0.9554 - val_loss: 0.4952 - val_accuracy: 0.8940
Epoch 190/350
391/391 - 23s - loss: 0.1722 - accuracy: 0.9564 - val_loss: 0.4555 - val_accuracy: 0.8952
Epoch 191/350
391/391 - 23s - loss: 0.1743 - accuracy: 0.9540 - val_loss: 0.4358 - val_accuracy: 0.9007
Epoch 192/350
391/391 - 23s - loss: 0.1669 - accuracy: 0.9567 - val_loss: 0.4867 - val_accuracy: 0.8940
Epoch 193/350
391/391 - 23s - loss: 0.1689 - accuracy: 0.9566 - val_loss: 0.4585 - val_accuracy: 0.8966
Epoch 194/350
391/391 - 23s - loss: 0.1677 - accuracy: 0.9568 - val_loss: 0.4663 - val_accuracy: 0.8959
Epoch 195/350
391/391 - 23s - loss: 0.1640 - accuracy: 0.9578 - val_loss: 0.4597 - val_accuracy: 0.8966
Epoch 196/350
391/391 - 23s - loss: 0.1665 - accuracy: 0.9572 - val_loss: 0.4595 - val_accuracy: 0.8974
Epoch 197/350
391/391 - 23s - loss: 0.1679 - accuracy: 0.9573 - val_loss: 0.4477 - val_accuracy: 0.8951
Epoch 198/350
391/391 - 23s - loss: 0.1602 - accuracy: 0.9600 - val_loss: 0.5005 - val_accuracy: 0.8959
Epoch 199/350
391/391 - 23s - loss: 0.1692 - accuracy: 0.9567 - val_loss: 0.4708 - val_accuracy: 0.8982
Epoch 200/350


Snapshot weight 4 shuffle 8 at epoch 200
Layer 11
Getting activations...


391/391 - 23s - loss: 0.1667 - accuracy: 0.9570 - val_loss: 0.4519 - val_accuracy: 0.8979
Epoch 201/350
391/391 - 22s - loss: 0.1363 - accuracy: 0.9681 - val_loss: 0.4434 - val_accuracy: 0.9024
Epoch 202/350
391/391 - 23s - loss: 0.1295 - accuracy: 0.9706 - val_loss: 0.4430 - val_accuracy: 0.9051
Epoch 203/350
391/391 - 22s - loss: 0.1218 - accuracy: 0.9730 - val_loss: 0.4527 - val_accuracy: 0.9058
Epoch 204/350
391/391 - 23s - loss: 0.1212 - accuracy: 0.9729 - val_loss: 0.4656 - val_accuracy: 0.9038
Epoch 205/350
391/391 - 23s - loss: 0.1215 - accuracy: 0.9732 - val_loss: 0.4552 - val_accuracy: 0.9071
Epoch 206/350
391/391 - 23s - loss: 0.1173 - accuracy: 0.9750 - val_loss: 0.4680 - val_accuracy: 0.9038
Epoch 207/350
391/391 - 23s - loss: 0.1194 - accuracy: 0.9742 - val_loss: 0.4708 - val_accuracy: 0.9043
Epoch 208/350
391/391 - 23s - loss: 0.1160 - accuracy: 0.9746 - val_loss: 0.4682 - val_accuracy: 0.9070
Epoch 209/350
391/391 - 23s - loss: 0.1165 - accuracy: 0.9749 - val_loss: 0.4649 - val_accuracy: 0.9058
Epoch 210/350
391/391 - 23s - loss: 0.1168 - accuracy: 0.9743 - val_loss: 0.4779 - val_accuracy: 0.9048
Epoch 211/350
391/391 - 23s - loss: 0.1173 - accuracy: 0.9748 - val_loss: 0.4714 - val_accuracy: 0.9055
Epoch 212/350
391/391 - 23s - loss: 0.1136 - accuracy: 0.9768 - val_loss: 0.4724 - val_accuracy: 0.9051
Epoch 213/350
391/391 - 23s - loss: 0.1139 - accuracy: 0.9762 - val_loss: 0.4763 - val_accuracy: 0.9067
Epoch 214/350
391/391 - 23s - loss: 0.1153 - accuracy: 0.9747 - val_loss: 0.4683 - val_accuracy: 0.9059
Epoch 215/350
391/391 - 23s - loss: 0.1136 - accuracy: 0.9764 - val_loss: 0.4787 - val_accuracy: 0.9059
Epoch 216/350
391/391 - 23s - loss: 0.1129 - accuracy: 0.9762 - val_loss: 0.4781 - val_accuracy: 0.9066
Epoch 217/350
391/391 - 23s - loss: 0.1133 - accuracy: 0.9755 - val_loss: 0.4739 - val_accuracy: 0.9050
Epoch 218/350
391/391 - 23s - loss: 0.1114 - accuracy: 0.9771 - val_loss: 0.4741 - val_accuracy: 0.9066
Epoch 219/350
391/391 - 23s - loss: 0.1105 - accuracy: 0.9771 - val_loss: 0.4797 - val_accuracy: 0.9066
Epoch 220/350
391/391 - 23s - loss: 0.1128 - accuracy: 0.9768 - val_loss: 0.4822 - val_accuracy: 0.9062
Epoch 221/350
391/391 - 23s - loss: 0.1125 - accuracy: 0.9767 - val_loss: 0.4819 - val_accuracy: 0.9053
Epoch 222/350
391/391 - 23s - loss: 0.1115 - accuracy: 0.9764 - val_loss: 0.4784 - val_accuracy: 0.9057
Epoch 223/350
391/391 - 23s - loss: 0.1090 - accuracy: 0.9770 - val_loss: 0.4754 - val_accuracy: 0.9065
Epoch 224/350
391/391 - 23s - loss: 0.1097 - accuracy: 0.9776 - val_loss: 0.4828 - val_accuracy: 0.9046
Epoch 225/350
391/391 - 23s - loss: 0.1100 - accuracy: 0.9769 - val_loss: 0.4779 - val_accuracy: 0.9057
Epoch 226/350
391/391 - 23s - loss: 0.1086 - accuracy: 0.9783 - val_loss: 0.4869 - val_accuracy: 0.9045
Epoch 227/350
391/391 - 23s - loss: 0.1091 - accuracy: 0.9778 - val_loss: 0.4885 - val_accuracy: 0.9053
Epoch 228/350
391/391 - 23s - loss: 0.1092 - accuracy: 0.9776 - val_loss: 0.4829 - val_accuracy: 0.9069
Epoch 229/350
391/391 - 23s - loss: 0.1105 - accuracy: 0.9776 - val_loss: 0.4893 - val_accuracy: 0.9053
Epoch 230/350
391/391 - 23s - loss: 0.1081 - accuracy: 0.9785 - val_loss: 0.4858 - val_accuracy: 0.9068
Epoch 231/350
391/391 - 23s - loss: 0.1084 - accuracy: 0.9774 - val_loss: 0.4905 - val_accuracy: 0.9067
Epoch 232/350
391/391 - 23s - loss: 0.1063 - accuracy: 0.9792 - val_loss: 0.4864 - val_accuracy: 0.9060
Epoch 233/350
391/391 - 23s - loss: 0.1100 - accuracy: 0.9769 - val_loss: 0.4847 - val_accuracy: 0.9071
Epoch 234/350
391/391 - 23s - loss: 0.1086 - accuracy: 0.9777 - val_loss: 0.4832 - val_accuracy: 0.9070
Epoch 235/350
391/391 - 23s - loss: 0.1081 - accuracy: 0.9786 - val_loss: 0.4905 - val_accuracy: 0.9069
Epoch 236/350
391/391 - 23s - loss: 0.1082 - accuracy: 0.9779 - val_loss: 0.4820 - val_accuracy: 0.9063
Epoch 237/350
391/391 - 23s - loss: 0.1087 - accuracy: 0.9777 - val_loss: 0.4869 - val_accuracy: 0.9072
Epoch 238/350
391/391 - 23s - loss: 0.1062 - accuracy: 0.9787 - val_loss: 0.4780 - val_accuracy: 0.9089
Epoch 239/350
391/391 - 23s - loss: 0.1068 - accuracy: 0.9788 - val_loss: 0.4951 - val_accuracy: 0.9071
Epoch 240/350
391/391 - 23s - loss: 0.1055 - accuracy: 0.9786 - val_loss: 0.4810 - val_accuracy: 0.9079
Epoch 241/350
391/391 - 23s - loss: 0.1056 - accuracy: 0.9790 - val_loss: 0.4993 - val_accuracy: 0.9057
Epoch 242/350
391/391 - 23s - loss: 0.1053 - accuracy: 0.9785 - val_loss: 0.5006 - val_accuracy: 0.9053
Epoch 243/350
391/391 - 23s - loss: 0.1045 - accuracy: 0.9798 - val_loss: 0.4908 - val_accuracy: 0.9065
Epoch 244/350
391/391 - 23s - loss: 0.1049 - accuracy: 0.9802 - val_loss: 0.4833 - val_accuracy: 0.9074
Epoch 245/350
391/391 - 23s - loss: 0.1052 - accuracy: 0.9795 - val_loss: 0.4842 - val_accuracy: 0.9087
Epoch 246/350
391/391 - 23s - loss: 0.1073 - accuracy: 0.9784 - val_loss: 0.4874 - val_accuracy: 0.9073
Epoch 247/350
391/391 - 23s - loss: 0.1041 - accuracy: 0.9797 - val_loss: 0.4993 - val_accuracy: 0.9067
Epoch 248/350
391/391 - 23s - loss: 0.1037 - accuracy: 0.9795 - val_loss: 0.4998 - val_accuracy: 0.9065
Epoch 249/350
391/391 - 23s - loss: 0.1038 - accuracy: 0.9794 - val_loss: 0.5052 - val_accuracy: 0.9058
Epoch 250/350


Snapshot weight 4 shuffle 8 at epoch 250
Layer 11
Getting activations...


391/391 - 23s - loss: 0.1038 - accuracy: 0.9793 - val_loss: 0.5019 - val_accuracy: 0.9056
Epoch 251/350
391/391 - 23s - loss: 0.1057 - accuracy: 0.9797 - val_loss: 0.4928 - val_accuracy: 0.9062
Epoch 252/350
391/391 - 23s - loss: 0.1040 - accuracy: 0.9791 - val_loss: 0.4927 - val_accuracy: 0.9066
Epoch 253/350
391/391 - 23s - loss: 0.1020 - accuracy: 0.9804 - val_loss: 0.4926 - val_accuracy: 0.9074
Epoch 254/350
391/391 - 23s - loss: 0.1021 - accuracy: 0.9802 - val_loss: 0.4944 - val_accuracy: 0.9072
Epoch 255/350
391/391 - 23s - loss: 0.0996 - accuracy: 0.9818 - val_loss: 0.4949 - val_accuracy: 0.9071
Epoch 256/350
391/391 - 23s - loss: 0.1013 - accuracy: 0.9803 - val_loss: 0.4962 - val_accuracy: 0.9070
Epoch 257/350
391/391 - 23s - loss: 0.1023 - accuracy: 0.9799 - val_loss: 0.4933 - val_accuracy: 0.9076
Epoch 258/350
391/391 - 23s - loss: 0.0998 - accuracy: 0.9808 - val_loss: 0.4943 - val_accuracy: 0.9075
Epoch 259/350
391/391 - 23s - loss: 0.1014 - accuracy: 0.9800 - val_loss: 0.4969 - val_accuracy: 0.9070
Epoch 260/350
391/391 - 23s - loss: 0.1010 - accuracy: 0.9806 - val_loss: 0.4941 - val_accuracy: 0.9077
Epoch 261/350
391/391 - 23s - loss: 0.0997 - accuracy: 0.9810 - val_loss: 0.4958 - val_accuracy: 0.9070
Epoch 262/350
391/391 - 23s - loss: 0.1008 - accuracy: 0.9810 - val_loss: 0.4937 - val_accuracy: 0.9073
Epoch 263/350
391/391 - 23s - loss: 0.1005 - accuracy: 0.9809 - val_loss: 0.4964 - val_accuracy: 0.9073
Epoch 264/350
391/391 - 23s - loss: 0.1016 - accuracy: 0.9802 - val_loss: 0.4954 - val_accuracy: 0.9077
Epoch 265/350
391/391 - 23s - loss: 0.1005 - accuracy: 0.9803 - val_loss: 0.4954 - val_accuracy: 0.9072
Epoch 266/350
391/391 - 23s - loss: 0.1027 - accuracy: 0.9798 - val_loss: 0.4970 - val_accuracy: 0.9076
Epoch 267/350
391/391 - 23s - loss: 0.1035 - accuracy: 0.9790 - val_loss: 0.4962 - val_accuracy: 0.9079
Epoch 268/350
391/391 - 23s - loss: 0.1015 - accuracy: 0.9809 - val_loss: 0.4956 - val_accuracy: 0.9082
Epoch 269/350
391/391 - 23s - loss: 0.1030 - accuracy: 0.9801 - val_loss: 0.4933 - val_accuracy: 0.9085
Epoch 270/350
391/391 - 23s - loss: 0.1010 - accuracy: 0.9808 - val_loss: 0.4932 - val_accuracy: 0.9080
Epoch 271/350
391/391 - 23s - loss: 0.1015 - accuracy: 0.9805 - val_loss: 0.4938 - val_accuracy: 0.9081
Epoch 272/350
391/391 - 23s - loss: 0.0994 - accuracy: 0.9812 - val_loss: 0.4962 - val_accuracy: 0.9083
Epoch 273/350
391/391 - 23s - loss: 0.1026 - accuracy: 0.9798 - val_loss: 0.4928 - val_accuracy: 0.9080
Epoch 274/350
391/391 - 23s - loss: 0.1007 - accuracy: 0.9807 - val_loss: 0.4949 - val_accuracy: 0.9072
Epoch 275/350
391/391 - 23s - loss: 0.1020 - accuracy: 0.9805 - val_loss: 0.4920 - val_accuracy: 0.9074
Epoch 276/350
391/391 - 23s - loss: 0.1008 - accuracy: 0.9814 - val_loss: 0.4929 - val_accuracy: 0.9085
Epoch 277/350
391/391 - 23s - loss: 0.0999 - accuracy: 0.9808 - val_loss: 0.4952 - val_accuracy: 0.9073
Epoch 278/350
391/391 - 23s - loss: 0.0979 - accuracy: 0.9821 - val_loss: 0.4958 - val_accuracy: 0.9072
Epoch 279/350
391/391 - 23s - loss: 0.1022 - accuracy: 0.9802 - val_loss: 0.4948 - val_accuracy: 0.9077
Epoch 280/350
391/391 - 23s - loss: 0.1015 - accuracy: 0.9803 - val_loss: 0.4922 - val_accuracy: 0.9082
Epoch 281/350
391/391 - 23s - loss: 0.1016 - accuracy: 0.9807 - val_loss: 0.4922 - val_accuracy: 0.9080
Epoch 282/350
391/391 - 23s - loss: 0.1004 - accuracy: 0.9811 - val_loss: 0.4945 - val_accuracy: 0.9071
Epoch 283/350
391/391 - 23s - loss: 0.1012 - accuracy: 0.9804 - val_loss: 0.4955 - val_accuracy: 0.9077
Epoch 284/350
391/391 - 23s - loss: 0.0997 - accuracy: 0.9802 - val_loss: 0.4920 - val_accuracy: 0.9069
Epoch 285/350
391/391 - 23s - loss: 0.1003 - accuracy: 0.9804 - val_loss: 0.4929 - val_accuracy: 0.9074
Epoch 286/350
391/391 - 23s - loss: 0.0983 - accuracy: 0.9813 - val_loss: 0.4935 - val_accuracy: 0.9078
Epoch 287/350
391/391 - 23s - loss: 0.0998 - accuracy: 0.9810 - val_loss: 0.4948 - val_accuracy: 0.9082
Epoch 288/350
391/391 - 23s - loss: 0.0997 - accuracy: 0.9814 - val_loss: 0.4970 - val_accuracy: 0.9084
Epoch 289/350
391/391 - 23s - loss: 0.0997 - accuracy: 0.9807 - val_loss: 0.4953 - val_accuracy: 0.9079
Epoch 290/350
391/391 - 23s - loss: 0.0989 - accuracy: 0.9813 - val_loss: 0.4969 - val_accuracy: 0.9076
Epoch 291/350
391/391 - 23s - loss: 0.1009 - accuracy: 0.9803 - val_loss: 0.4971 - val_accuracy: 0.9075
Epoch 292/350
391/391 - 23s - loss: 0.1007 - accuracy: 0.9804 - val_loss: 0.4974 - val_accuracy: 0.9074
Epoch 293/350
391/391 - 23s - loss: 0.0988 - accuracy: 0.9815 - val_loss: 0.4942 - val_accuracy: 0.9076
Epoch 294/350
391/391 - 23s - loss: 0.0995 - accuracy: 0.9812 - val_loss: 0.4960 - val_accuracy: 0.9076
Epoch 295/350
391/391 - 23s - loss: 0.0993 - accuracy: 0.9814 - val_loss: 0.4948 - val_accuracy: 0.9072
Epoch 296/350
391/391 - 23s - loss: 0.0998 - accuracy: 0.9807 - val_loss: 0.4966 - val_accuracy: 0.9073
Epoch 297/350
391/391 - 23s - loss: 0.1036 - accuracy: 0.9789 - val_loss: 0.4952 - val_accuracy: 0.9074
Epoch 298/350
391/391 - 23s - loss: 0.1015 - accuracy: 0.9802 - val_loss: 0.4974 - val_accuracy: 0.9077
Epoch 299/350
391/391 - 23s - loss: 0.0991 - accuracy: 0.9816 - val_loss: 0.4968 - val_accuracy: 0.9077
Epoch 300/350


Snapshot weight 4 shuffle 8 at epoch 300
Layer 11
Getting activations...


391/391 - 23s - loss: 0.0982 - accuracy: 0.9820 - val_loss: 0.4993 - val_accuracy: 0.9086
Epoch 301/350
391/391 - 23s - loss: 0.1000 - accuracy: 0.9811 - val_loss: 0.4991 - val_accuracy: 0.9085
Epoch 302/350
391/391 - 23s - loss: 0.0986 - accuracy: 0.9810 - val_loss: 0.4990 - val_accuracy: 0.9083
Epoch 303/350
391/391 - 23s - loss: 0.0984 - accuracy: 0.9819 - val_loss: 0.4987 - val_accuracy: 0.9082
Epoch 304/350
391/391 - 23s - loss: 0.0998 - accuracy: 0.9806 - val_loss: 0.4987 - val_accuracy: 0.9081
Epoch 305/350
391/391 - 23s - loss: 0.0972 - accuracy: 0.9814 - val_loss: 0.4984 - val_accuracy: 0.9080
Epoch 306/350
391/391 - 23s - loss: 0.0994 - accuracy: 0.9814 - val_loss: 0.4984 - val_accuracy: 0.9079
Epoch 307/350
391/391 - 23s - loss: 0.1008 - accuracy: 0.9804 - val_loss: 0.4977 - val_accuracy: 0.9079
Epoch 308/350
391/391 - 23s - loss: 0.0987 - accuracy: 0.9817 - val_loss: 0.4976 - val_accuracy: 0.9080
Epoch 309/350
391/391 - 23s - loss: 0.0981 - accuracy: 0.9811 - val_loss: 0.4977 - val_accuracy: 0.9080
Epoch 310/350
391/391 - 23s - loss: 0.1002 - accuracy: 0.9809 - val_loss: 0.4975 - val_accuracy: 0.9079
Epoch 311/350
391/391 - 23s - loss: 0.0996 - accuracy: 0.9805 - val_loss: 0.4977 - val_accuracy: 0.9080
Epoch 312/350
391/391 - 23s - loss: 0.1000 - accuracy: 0.9816 - val_loss: 0.4981 - val_accuracy: 0.9081
Epoch 313/350
391/391 - 23s - loss: 0.1011 - accuracy: 0.9799 - val_loss: 0.4978 - val_accuracy: 0.9081
Epoch 314/350
391/391 - 23s - loss: 0.0987 - accuracy: 0.9814 - val_loss: 0.4977 - val_accuracy: 0.9084
Epoch 315/350
391/391 - 23s - loss: 0.0996 - accuracy: 0.9801 - val_loss: 0.4979 - val_accuracy: 0.9080
Epoch 316/350
391/391 - 23s - loss: 0.0992 - accuracy: 0.9810 - val_loss: 0.4979 - val_accuracy: 0.9084
Epoch 317/350
391/391 - 23s - loss: 0.0998 - accuracy: 0.9810 - val_loss: 0.4979 - val_accuracy: 0.9084
Epoch 318/350
391/391 - 23s - loss: 0.0971 - accuracy: 0.9822 - val_loss: 0.4980 - val_accuracy: 0.9077
Epoch 319/350
391/391 - 23s - loss: 0.1016 - accuracy: 0.9808 - val_loss: 0.4978 - val_accuracy: 0.9080
Epoch 320/350
391/391 - 23s - loss: 0.0997 - accuracy: 0.9812 - val_loss: 0.4978 - val_accuracy: 0.9083
Epoch 321/350
391/391 - 23s - loss: 0.0986 - accuracy: 0.9803 - val_loss: 0.4980 - val_accuracy: 0.9081
Epoch 322/350
391/391 - 23s - loss: 0.0972 - accuracy: 0.9815 - val_loss: 0.4979 - val_accuracy: 0.9082
Epoch 323/350
391/391 - 23s - loss: 0.0984 - accuracy: 0.9806 - val_loss: 0.4978 - val_accuracy: 0.9083
Epoch 324/350
391/391 - 23s - loss: 0.1026 - accuracy: 0.9797 - val_loss: 0.4977 - val_accuracy: 0.9081
Epoch 325/350
391/391 - 23s - loss: 0.1029 - accuracy: 0.9806 - val_loss: 0.4977 - val_accuracy: 0.9083
Epoch 326/350
391/391 - 23s - loss: 0.1007 - accuracy: 0.9811 - val_loss: 0.4977 - val_accuracy: 0.9082
Epoch 327/350
391/391 - 23s - loss: 0.0987 - accuracy: 0.9809 - val_loss: 0.4975 - val_accuracy: 0.9081
Epoch 328/350
391/391 - 23s - loss: 0.0988 - accuracy: 0.9819 - val_loss: 0.4972 - val_accuracy: 0.9083
Epoch 329/350
391/391 - 23s - loss: 0.0997 - accuracy: 0.9809 - val_loss: 0.4972 - val_accuracy: 0.9081
Epoch 330/350
391/391 - 23s - loss: 0.1010 - accuracy: 0.9802 - val_loss: 0.4971 - val_accuracy: 0.9082
Epoch 331/350
391/391 - 23s - loss: 0.1020 - accuracy: 0.9810 - val_loss: 0.4975 - val_accuracy: 0.9081
Epoch 332/350
391/391 - 23s - loss: 0.1016 - accuracy: 0.9805 - val_loss: 0.4974 - val_accuracy: 0.9081
Epoch 333/350
391/391 - 23s - loss: 0.0996 - accuracy: 0.9813 - val_loss: 0.4974 - val_accuracy: 0.9081
Epoch 334/350
391/391 - 23s - loss: 0.0990 - accuracy: 0.9808 - val_loss: 0.4972 - val_accuracy: 0.9078
Epoch 335/350
391/391 - 23s - loss: 0.0989 - accuracy: 0.9807 - val_loss: 0.4974 - val_accuracy: 0.9081
Epoch 336/350
391/391 - 23s - loss: 0.0985 - accuracy: 0.9816 - val_loss: 0.4972 - val_accuracy: 0.9080
Epoch 337/350
391/391 - 23s - loss: 0.0999 - accuracy: 0.9816 - val_loss: 0.4978 - val_accuracy: 0.9078
Epoch 338/350
391/391 - 23s - loss: 0.1010 - accuracy: 0.9802 - val_loss: 0.4976 - val_accuracy: 0.9080
Epoch 339/350
391/391 - 23s - loss: 0.0997 - accuracy: 0.9809 - val_loss: 0.4978 - val_accuracy: 0.9079
Epoch 340/350
391/391 - 23s - loss: 0.0993 - accuracy: 0.9812 - val_loss: 0.4973 - val_accuracy: 0.9077
Epoch 341/350
391/391 - 23s - loss: 0.1010 - accuracy: 0.9802 - val_loss: 0.4973 - val_accuracy: 0.9080
Epoch 342/350
391/391 - 23s - loss: 0.1010 - accuracy: 0.9806 - val_loss: 0.4977 - val_accuracy: 0.9080
Epoch 343/350
391/391 - 23s - loss: 0.1000 - accuracy: 0.9810 - val_loss: 0.4979 - val_accuracy: 0.9079
Epoch 344/350
391/391 - 23s - loss: 0.1010 - accuracy: 0.9807 - val_loss: 0.4978 - val_accuracy: 0.9079
Epoch 345/350
391/391 - 23s - loss: 0.1030 - accuracy: 0.9799 - val_loss: 0.4978 - val_accuracy: 0.9080
Epoch 346/350
391/391 - 23s - loss: 0.1004 - accuracy: 0.9811 - val_loss: 0.4971 - val_accuracy: 0.9079
Epoch 347/350
391/391 - 23s - loss: 0.0993 - accuracy: 0.9809 - val_loss: 0.4971 - val_accuracy: 0.9078
Epoch 348/350
391/391 - 23s - loss: 0.0999 - accuracy: 0.9808 - val_loss: 0.4970 - val_accuracy: 0.9077
Epoch 349/350
391/391 - 23s - loss: 0.1000 - accuracy: 0.9801 - val_loss: 0.4970 - val_accuracy: 0.9078
Epoch 350/350


Snapshot weight 4 shuffle 8 at epoch 350
Layer 11
Getting activations...


391/391 - 23s - loss: 0.0981 - accuracy: 0.9822 - val_loss: 0.4967 - val_accuracy: 0.9078
/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:493: UserWarning: fill_value is not supported and is always 0 for TensorFlow < 2.4.0.
  return py_builtins.overload_of(f)(*args)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-07-02 19:17:15.138870: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
Saving, final validation acc: 0.907800018787384
