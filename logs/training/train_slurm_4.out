2021-07-01 16:11:51.697454: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 16:13:18.052884: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-07-01 16:13:18.097105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-01 16:13:18.097190: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 16:13:18.137342: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-01 16:13:18.157611: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-01 16:13:18.165957: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-01 16:13:18.208104: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-01 16:13:18.216733: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-01 16:13:18.292554: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-01 16:13:18.297555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-01 16:13:18.301238: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-01 16:13:18.316910: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599940000 Hz
2021-07-01 16:13:18.317019: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x566b720 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-07-01 16:13:18.317062: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-07-01 16:13:18.432865: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5652850 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-07-01 16:13:18.432937: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN X (Pascal), Compute Capability 6.1
2021-07-01 16:13:18.435792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-01 16:13:18.435830: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 16:13:18.435859: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-01 16:13:18.435876: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-01 16:13:18.435892: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-01 16:13:18.435908: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-01 16:13:18.435923: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-01 16:13:18.436792: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-01 16:13:18.438464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-01 16:13:18.440222: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 16:13:20.257392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-01 16:13:20.257471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-07-01 16:13:20.257483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-07-01 16:13:20.268594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11228 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
2021-07-01 16:13:25.978436: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-01 16:13:30.320758: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
Using model index: 4
Making train data...
GCN...
ZCA...
Done!
Making test data...
Done!
Epoch 1/350


Snapshot weight 4 shuffle 0 at epoch 1
Layer 11
Getting activations...


391/391 - 24s - loss: 2.3260 - accuracy: 0.1008 - val_loss: 2.3242 - val_accuracy: 0.0986
Epoch 2/350


Snapshot weight 4 shuffle 0 at epoch 2
Layer 11
Getting activations...


391/391 - 24s - loss: 2.3093 - accuracy: 0.1093 - val_loss: 2.3267 - val_accuracy: 0.1000
Epoch 3/350


Snapshot weight 4 shuffle 0 at epoch 3
Layer 11
Getting activations...


391/391 - 24s - loss: 2.2894 - accuracy: 0.1300 - val_loss: 2.1877 - val_accuracy: 0.1797
Epoch 4/350


Snapshot weight 4 shuffle 0 at epoch 4
Layer 11
Getting activations...


391/391 - 25s - loss: 2.0798 - accuracy: 0.2462 - val_loss: 1.8407 - val_accuracy: 0.3571
Epoch 5/350


Snapshot weight 4 shuffle 0 at epoch 5
Layer 11
Getting activations...


391/391 - 24s - loss: 1.7070 - accuracy: 0.3856 - val_loss: 1.6131 - val_accuracy: 0.4271
Epoch 6/350


Snapshot weight 4 shuffle 0 at epoch 6
Layer 11
Getting activations...


391/391 - 25s - loss: 1.4913 - accuracy: 0.4673 - val_loss: 1.3287 - val_accuracy: 0.5275
Epoch 7/350


Snapshot weight 4 shuffle 0 at epoch 7
Layer 11
Getting activations...


391/391 - 25s - loss: 1.3500 - accuracy: 0.5239 - val_loss: 1.1736 - val_accuracy: 0.5934
Epoch 8/350


Snapshot weight 4 shuffle 0 at epoch 8
Layer 11
Getting activations...


391/391 - 24s - loss: 1.2287 - accuracy: 0.5689 - val_loss: 1.2009 - val_accuracy: 0.5851
Epoch 9/350


Snapshot weight 4 shuffle 0 at epoch 9
Layer 11
Getting activations...


391/391 - 24s - loss: 1.1710 - accuracy: 0.5908 - val_loss: 1.1525 - val_accuracy: 0.6122
Epoch 10/350


Snapshot weight 4 shuffle 0 at epoch 10
Layer 11
Getting activations...


391/391 - 25s - loss: 1.0862 - accuracy: 0.6221 - val_loss: 1.0484 - val_accuracy: 0.6378
Epoch 11/350
391/391 - 24s - loss: 1.0445 - accuracy: 0.6405 - val_loss: 0.9405 - val_accuracy: 0.6830
Epoch 12/350
391/391 - 24s - loss: 0.9946 - accuracy: 0.6556 - val_loss: 0.9542 - val_accuracy: 0.6767
Epoch 13/350
391/391 - 24s - loss: 0.9545 - accuracy: 0.6712 - val_loss: 0.8596 - val_accuracy: 0.7089
Epoch 14/350
391/391 - 24s - loss: 0.9142 - accuracy: 0.6871 - val_loss: 0.8332 - val_accuracy: 0.7164
Epoch 15/350
391/391 - 24s - loss: 0.8707 - accuracy: 0.7014 - val_loss: 0.8553 - val_accuracy: 0.7243
Epoch 16/350
391/391 - 24s - loss: 0.8424 - accuracy: 0.7127 - val_loss: 0.8036 - val_accuracy: 0.7343
Epoch 17/350
391/391 - 24s - loss: 0.8082 - accuracy: 0.7256 - val_loss: 0.7608 - val_accuracy: 0.7508
Epoch 18/350
391/391 - 24s - loss: 0.7816 - accuracy: 0.7365 - val_loss: 0.7441 - val_accuracy: 0.7513
Epoch 19/350
391/391 - 25s - loss: 0.7641 - accuracy: 0.7405 - val_loss: 0.7374 - val_accuracy: 0.7596
Epoch 20/350
391/391 - 24s - loss: 0.7348 - accuracy: 0.7532 - val_loss: 0.6902 - val_accuracy: 0.7733
Epoch 21/350
391/391 - 24s - loss: 0.7092 - accuracy: 0.7610 - val_loss: 0.7125 - val_accuracy: 0.7772
Epoch 22/350
391/391 - 24s - loss: 0.6809 - accuracy: 0.7724 - val_loss: 0.6821 - val_accuracy: 0.7802
Epoch 23/350
391/391 - 24s - loss: 0.6671 - accuracy: 0.7769 - val_loss: 0.6401 - val_accuracy: 0.7887
Epoch 24/350
391/391 - 25s - loss: 0.6528 - accuracy: 0.7799 - val_loss: 0.7020 - val_accuracy: 0.7770
Epoch 25/350
391/391 - 24s - loss: 0.6295 - accuracy: 0.7920 - val_loss: 0.6751 - val_accuracy: 0.7831
Epoch 26/350
391/391 - 24s - loss: 0.6192 - accuracy: 0.7918 - val_loss: 0.5845 - val_accuracy: 0.8122
Epoch 27/350
391/391 - 25s - loss: 0.5969 - accuracy: 0.8018 - val_loss: 0.5700 - val_accuracy: 0.8158
Epoch 28/350
391/391 - 24s - loss: 0.5856 - accuracy: 0.8056 - val_loss: 0.5441 - val_accuracy: 0.8231
Epoch 29/350
391/391 - 24s - loss: 0.5867 - accuracy: 0.8061 - val_loss: 0.5508 - val_accuracy: 0.8273
Epoch 30/350
391/391 - 24s - loss: 0.5707 - accuracy: 0.8108 - val_loss: 0.5789 - val_accuracy: 0.8127
Epoch 31/350
391/391 - 24s - loss: 0.5610 - accuracy: 0.8140 - val_loss: 0.5213 - val_accuracy: 0.8290
Epoch 32/350
391/391 - 24s - loss: 0.5470 - accuracy: 0.8216 - val_loss: 0.5367 - val_accuracy: 0.8258
Epoch 33/350
391/391 - 24s - loss: 0.5411 - accuracy: 0.8194 - val_loss: 0.5900 - val_accuracy: 0.8150
Epoch 34/350
391/391 - 24s - loss: 0.5209 - accuracy: 0.8301 - val_loss: 0.5037 - val_accuracy: 0.8401
Epoch 35/350
391/391 - 24s - loss: 0.5151 - accuracy: 0.8313 - val_loss: 0.5090 - val_accuracy: 0.8421
Epoch 36/350
391/391 - 24s - loss: 0.5050 - accuracy: 0.8349 - val_loss: 0.5189 - val_accuracy: 0.8368
Epoch 37/350
391/391 - 24s - loss: 0.4902 - accuracy: 0.8403 - val_loss: 0.5171 - val_accuracy: 0.8420
Epoch 38/350
391/391 - 25s - loss: 0.4923 - accuracy: 0.8401 - val_loss: 0.5308 - val_accuracy: 0.8316
Epoch 39/350
391/391 - 24s - loss: 0.4829 - accuracy: 0.8424 - val_loss: 0.5059 - val_accuracy: 0.8413
Epoch 40/350
391/391 - 25s - loss: 0.4775 - accuracy: 0.8461 - val_loss: 0.4944 - val_accuracy: 0.8455
Epoch 41/350
391/391 - 24s - loss: 0.4672 - accuracy: 0.8481 - val_loss: 0.4827 - val_accuracy: 0.8516
Epoch 42/350
391/391 - 24s - loss: 0.4654 - accuracy: 0.8482 - val_loss: 0.5007 - val_accuracy: 0.8464
Epoch 43/350
391/391 - 24s - loss: 0.4466 - accuracy: 0.8550 - val_loss: 0.4793 - val_accuracy: 0.8531
Epoch 44/350
391/391 - 24s - loss: 0.4468 - accuracy: 0.8545 - val_loss: 0.4717 - val_accuracy: 0.8544
Epoch 45/350
391/391 - 24s - loss: 0.4423 - accuracy: 0.8567 - val_loss: 0.5340 - val_accuracy: 0.8339
Epoch 46/350
391/391 - 24s - loss: 0.4366 - accuracy: 0.8581 - val_loss: 0.5071 - val_accuracy: 0.8498
Epoch 47/350
391/391 - 24s - loss: 0.4274 - accuracy: 0.8614 - val_loss: 0.4444 - val_accuracy: 0.8627
Epoch 48/350
391/391 - 24s - loss: 0.4220 - accuracy: 0.8627 - val_loss: 0.4664 - val_accuracy: 0.8567
Epoch 49/350
391/391 - 24s - loss: 0.4207 - accuracy: 0.8634 - val_loss: 0.4842 - val_accuracy: 0.8524
Epoch 50/350


Snapshot weight 4 shuffle 0 at epoch 50
Layer 11
Getting activations...


391/391 - 25s - loss: 0.4118 - accuracy: 0.8676 - val_loss: 0.5039 - val_accuracy: 0.8441
Epoch 51/350
391/391 - 24s - loss: 0.4108 - accuracy: 0.8689 - val_loss: 0.4612 - val_accuracy: 0.8592
Epoch 52/350
391/391 - 24s - loss: 0.3993 - accuracy: 0.8714 - val_loss: 0.4726 - val_accuracy: 0.8616
Epoch 53/350
391/391 - 24s - loss: 0.3933 - accuracy: 0.8720 - val_loss: 0.4722 - val_accuracy: 0.8620
Epoch 54/350
391/391 - 24s - loss: 0.3906 - accuracy: 0.8736 - val_loss: 0.4465 - val_accuracy: 0.8601
Epoch 55/350
391/391 - 24s - loss: 0.3870 - accuracy: 0.8759 - val_loss: 0.4709 - val_accuracy: 0.8651
Epoch 56/350
391/391 - 24s - loss: 0.3863 - accuracy: 0.8750 - val_loss: 0.4660 - val_accuracy: 0.8632
Epoch 57/350
391/391 - 24s - loss: 0.3777 - accuracy: 0.8788 - val_loss: 0.4599 - val_accuracy: 0.8621
Epoch 58/350
391/391 - 24s - loss: 0.3764 - accuracy: 0.8801 - val_loss: 0.4609 - val_accuracy: 0.8638
Epoch 59/350
391/391 - 24s - loss: 0.3738 - accuracy: 0.8803 - val_loss: 0.4612 - val_accuracy: 0.8663
Epoch 60/350
391/391 - 24s - loss: 0.3688 - accuracy: 0.8835 - val_loss: 0.4582 - val_accuracy: 0.8700
Epoch 61/350
391/391 - 24s - loss: 0.3613 - accuracy: 0.8859 - val_loss: 0.4672 - val_accuracy: 0.8646
Epoch 62/350
391/391 - 24s - loss: 0.3600 - accuracy: 0.8855 - val_loss: 0.4387 - val_accuracy: 0.8729
Epoch 63/350
391/391 - 24s - loss: 0.3530 - accuracy: 0.8881 - val_loss: 0.4264 - val_accuracy: 0.8684
Epoch 64/350
391/391 - 24s - loss: 0.3465 - accuracy: 0.8890 - val_loss: 0.4406 - val_accuracy: 0.8747
Epoch 65/350
391/391 - 24s - loss: 0.3516 - accuracy: 0.8887 - val_loss: 0.4265 - val_accuracy: 0.8770
Epoch 66/350
391/391 - 24s - loss: 0.3468 - accuracy: 0.8888 - val_loss: 0.4615 - val_accuracy: 0.8658
Epoch 67/350
391/391 - 24s - loss: 0.3392 - accuracy: 0.8928 - val_loss: 0.4177 - val_accuracy: 0.8748
Epoch 68/350
391/391 - 24s - loss: 0.3455 - accuracy: 0.8900 - val_loss: 0.4109 - val_accuracy: 0.8797
Epoch 69/350
391/391 - 24s - loss: 0.3361 - accuracy: 0.8934 - val_loss: 0.4676 - val_accuracy: 0.8688
Epoch 70/350
391/391 - 24s - loss: 0.3312 - accuracy: 0.8970 - val_loss: 0.4119 - val_accuracy: 0.8766
Epoch 71/350
391/391 - 24s - loss: 0.3296 - accuracy: 0.8969 - val_loss: 0.4239 - val_accuracy: 0.8723
Epoch 72/350
391/391 - 24s - loss: 0.3279 - accuracy: 0.8977 - val_loss: 0.4420 - val_accuracy: 0.8754
Epoch 73/350
391/391 - 25s - loss: 0.3189 - accuracy: 0.8996 - val_loss: 0.4409 - val_accuracy: 0.8785
Epoch 74/350
391/391 - 24s - loss: 0.3195 - accuracy: 0.8987 - val_loss: 0.4390 - val_accuracy: 0.8753
Epoch 75/350
391/391 - 24s - loss: 0.3156 - accuracy: 0.9033 - val_loss: 0.4354 - val_accuracy: 0.8714
Epoch 76/350
391/391 - 24s - loss: 0.3129 - accuracy: 0.9009 - val_loss: 0.4304 - val_accuracy: 0.8791
Epoch 77/350
391/391 - 24s - loss: 0.3087 - accuracy: 0.9030 - val_loss: 0.4399 - val_accuracy: 0.8788
Epoch 78/350
391/391 - 24s - loss: 0.3079 - accuracy: 0.9038 - val_loss: 0.4285 - val_accuracy: 0.8777
Epoch 79/350
391/391 - 24s - loss: 0.3028 - accuracy: 0.9047 - val_loss: 0.4392 - val_accuracy: 0.8745
Epoch 80/350
391/391 - 24s - loss: 0.2996 - accuracy: 0.9060 - val_loss: 0.4299 - val_accuracy: 0.8797
Epoch 81/350
391/391 - 24s - loss: 0.2991 - accuracy: 0.9063 - val_loss: 0.4185 - val_accuracy: 0.8801
Epoch 82/350
391/391 - 24s - loss: 0.2944 - accuracy: 0.9084 - val_loss: 0.4239 - val_accuracy: 0.8816
Epoch 83/350
391/391 - 24s - loss: 0.2963 - accuracy: 0.9085 - val_loss: 0.4298 - val_accuracy: 0.8783
Epoch 84/350
391/391 - 24s - loss: 0.2997 - accuracy: 0.9070 - val_loss: 0.4319 - val_accuracy: 0.8791
Epoch 85/350
391/391 - 24s - loss: 0.2883 - accuracy: 0.9119 - val_loss: 0.4216 - val_accuracy: 0.8811
Epoch 86/350
391/391 - 24s - loss: 0.2848 - accuracy: 0.9116 - val_loss: 0.4467 - val_accuracy: 0.8774
Epoch 87/350
391/391 - 24s - loss: 0.2848 - accuracy: 0.9114 - val_loss: 0.4363 - val_accuracy: 0.8750
Epoch 88/350
391/391 - 24s - loss: 0.2900 - accuracy: 0.9100 - val_loss: 0.4383 - val_accuracy: 0.8789
Epoch 89/350
391/391 - 24s - loss: 0.2826 - accuracy: 0.9134 - val_loss: 0.4207 - val_accuracy: 0.8836
Epoch 90/350
391/391 - 24s - loss: 0.2803 - accuracy: 0.9147 - val_loss: 0.4268 - val_accuracy: 0.8822
Epoch 91/350
391/391 - 24s - loss: 0.2775 - accuracy: 0.9139 - val_loss: 0.4332 - val_accuracy: 0.8816
Epoch 92/350
391/391 - 24s - loss: 0.2735 - accuracy: 0.9157 - val_loss: 0.4226 - val_accuracy: 0.8866
Epoch 93/350
391/391 - 24s - loss: 0.2732 - accuracy: 0.9165 - val_loss: 0.4300 - val_accuracy: 0.8838
Epoch 94/350
391/391 - 24s - loss: 0.2671 - accuracy: 0.9183 - val_loss: 0.4529 - val_accuracy: 0.8745
Epoch 95/350
391/391 - 24s - loss: 0.2732 - accuracy: 0.9158 - val_loss: 0.4522 - val_accuracy: 0.8797
Epoch 96/350
391/391 - 25s - loss: 0.2709 - accuracy: 0.9182 - val_loss: 0.4354 - val_accuracy: 0.8862
Epoch 97/350
391/391 - 24s - loss: 0.2703 - accuracy: 0.9175 - val_loss: 0.4303 - val_accuracy: 0.8799
Epoch 98/350
391/391 - 24s - loss: 0.2666 - accuracy: 0.9189 - val_loss: 0.4316 - val_accuracy: 0.8863
Epoch 99/350
391/391 - 24s - loss: 0.2608 - accuracy: 0.9208 - val_loss: 0.4549 - val_accuracy: 0.8804
Epoch 100/350


Snapshot weight 4 shuffle 0 at epoch 100
Layer 11
Getting activations...


391/391 - 25s - loss: 0.2573 - accuracy: 0.9230 - val_loss: 0.4255 - val_accuracy: 0.8838
Epoch 101/350
391/391 - 24s - loss: 0.2538 - accuracy: 0.9234 - val_loss: 0.4225 - val_accuracy: 0.8834
Epoch 102/350
391/391 - 24s - loss: 0.2523 - accuracy: 0.9241 - val_loss: 0.4502 - val_accuracy: 0.8868
Epoch 103/350
391/391 - 24s - loss: 0.2585 - accuracy: 0.9216 - val_loss: 0.4321 - val_accuracy: 0.8861
Epoch 104/350
391/391 - 24s - loss: 0.2545 - accuracy: 0.9234 - val_loss: 0.4242 - val_accuracy: 0.8860
Epoch 105/350
391/391 - 24s - loss: 0.2503 - accuracy: 0.9246 - val_loss: 0.4125 - val_accuracy: 0.8892
Epoch 106/350
391/391 - 24s - loss: 0.2498 - accuracy: 0.9245 - val_loss: 0.4485 - val_accuracy: 0.8847
Epoch 107/350
391/391 - 24s - loss: 0.2477 - accuracy: 0.9261 - val_loss: 0.4206 - val_accuracy: 0.8900
Epoch 108/350
391/391 - 25s - loss: 0.2495 - accuracy: 0.9254 - val_loss: 0.4382 - val_accuracy: 0.8865
Epoch 109/350
391/391 - 25s - loss: 0.2482 - accuracy: 0.9262 - val_loss: 0.4299 - val_accuracy: 0.8855
Epoch 110/350
391/391 - 24s - loss: 0.2426 - accuracy: 0.9275 - val_loss: 0.4824 - val_accuracy: 0.8800
Epoch 111/350
391/391 - 24s - loss: 0.2407 - accuracy: 0.9284 - val_loss: 0.4764 - val_accuracy: 0.8819
Epoch 112/350
391/391 - 24s - loss: 0.2444 - accuracy: 0.9275 - val_loss: 0.4467 - val_accuracy: 0.8800
Epoch 113/350
391/391 - 24s - loss: 0.2412 - accuracy: 0.9283 - val_loss: 0.4567 - val_accuracy: 0.8826
Epoch 114/350
391/391 - 24s - loss: 0.2449 - accuracy: 0.9263 - val_loss: 0.4374 - val_accuracy: 0.8878
Epoch 115/350
391/391 - 24s - loss: 0.2395 - accuracy: 0.9292 - val_loss: 0.4281 - val_accuracy: 0.8865
Epoch 116/350
391/391 - 24s - loss: 0.2356 - accuracy: 0.9316 - val_loss: 0.4174 - val_accuracy: 0.8886
Epoch 117/350
391/391 - 24s - loss: 0.2311 - accuracy: 0.9317 - val_loss: 0.4324 - val_accuracy: 0.8861
Epoch 118/350
391/391 - 24s - loss: 0.2343 - accuracy: 0.9308 - val_loss: 0.4220 - val_accuracy: 0.8885
Epoch 119/350
391/391 - 25s - loss: 0.2302 - accuracy: 0.9318 - val_loss: 0.4370 - val_accuracy: 0.8911
Epoch 120/350
391/391 - 24s - loss: 0.2263 - accuracy: 0.9339 - val_loss: 0.4360 - val_accuracy: 0.8911
Epoch 121/350
391/391 - 25s - loss: 0.2267 - accuracy: 0.9344 - val_loss: 0.4392 - val_accuracy: 0.8880
Epoch 122/350
391/391 - 24s - loss: 0.2309 - accuracy: 0.9317 - val_loss: 0.4460 - val_accuracy: 0.8862
Epoch 123/350
391/391 - 24s - loss: 0.2201 - accuracy: 0.9362 - val_loss: 0.4306 - val_accuracy: 0.8906
Epoch 124/350
391/391 - 24s - loss: 0.2252 - accuracy: 0.9339 - val_loss: 0.4393 - val_accuracy: 0.8894
Epoch 125/350
391/391 - 25s - loss: 0.2239 - accuracy: 0.9351 - val_loss: 0.4429 - val_accuracy: 0.8899
Epoch 126/350
391/391 - 24s - loss: 0.2213 - accuracy: 0.9344 - val_loss: 0.4200 - val_accuracy: 0.8911
Epoch 127/350
391/391 - 24s - loss: 0.2178 - accuracy: 0.9365 - val_loss: 0.4241 - val_accuracy: 0.8939
Epoch 128/350
391/391 - 24s - loss: 0.2195 - accuracy: 0.9362 - val_loss: 0.4481 - val_accuracy: 0.8861
Epoch 129/350
391/391 - 24s - loss: 0.2160 - accuracy: 0.9372 - val_loss: 0.4484 - val_accuracy: 0.8906
Epoch 130/350
391/391 - 24s - loss: 0.2149 - accuracy: 0.9378 - val_loss: 0.4749 - val_accuracy: 0.8858
Epoch 131/350
391/391 - 24s - loss: 0.2197 - accuracy: 0.9366 - val_loss: 0.4301 - val_accuracy: 0.8923
Epoch 132/350
391/391 - 24s - loss: 0.2146 - accuracy: 0.9376 - val_loss: 0.4308 - val_accuracy: 0.8903
Epoch 133/350
391/391 - 25s - loss: 0.2129 - accuracy: 0.9395 - val_loss: 0.4486 - val_accuracy: 0.8857
Epoch 134/350
391/391 - 24s - loss: 0.2164 - accuracy: 0.9374 - val_loss: 0.4404 - val_accuracy: 0.8889
Epoch 135/350
391/391 - 24s - loss: 0.2123 - accuracy: 0.9389 - val_loss: 0.4402 - val_accuracy: 0.8879
Epoch 136/350
391/391 - 24s - loss: 0.2094 - accuracy: 0.9404 - val_loss: 0.4564 - val_accuracy: 0.8918
Epoch 137/350
391/391 - 24s - loss: 0.2087 - accuracy: 0.9400 - val_loss: 0.4373 - val_accuracy: 0.8926
Epoch 138/350
391/391 - 24s - loss: 0.2043 - accuracy: 0.9421 - val_loss: 0.4739 - val_accuracy: 0.8818
Epoch 139/350
391/391 - 24s - loss: 0.2043 - accuracy: 0.9409 - val_loss: 0.4986 - val_accuracy: 0.8847
Epoch 140/350
391/391 - 24s - loss: 0.2091 - accuracy: 0.9401 - val_loss: 0.4436 - val_accuracy: 0.8917
Epoch 141/350
391/391 - 24s - loss: 0.2042 - accuracy: 0.9421 - val_loss: 0.4419 - val_accuracy: 0.8928
Epoch 142/350
391/391 - 24s - loss: 0.2075 - accuracy: 0.9419 - val_loss: 0.4805 - val_accuracy: 0.8863
Epoch 143/350
391/391 - 24s - loss: 0.1994 - accuracy: 0.9443 - val_loss: 0.4909 - val_accuracy: 0.8895
Epoch 144/350
391/391 - 25s - loss: 0.2048 - accuracy: 0.9422 - val_loss: 0.4614 - val_accuracy: 0.8920
Epoch 145/350
391/391 - 24s - loss: 0.2070 - accuracy: 0.9414 - val_loss: 0.4558 - val_accuracy: 0.8913
Epoch 146/350
391/391 - 24s - loss: 0.1986 - accuracy: 0.9447 - val_loss: 0.4400 - val_accuracy: 0.8942
Epoch 147/350
391/391 - 24s - loss: 0.2031 - accuracy: 0.9424 - val_loss: 0.4382 - val_accuracy: 0.8933
Epoch 148/350
391/391 - 24s - loss: 0.1998 - accuracy: 0.9441 - val_loss: 0.4433 - val_accuracy: 0.8910
Epoch 149/350
391/391 - 24s - loss: 0.1990 - accuracy: 0.9446 - val_loss: 0.4530 - val_accuracy: 0.8888
Epoch 150/350


Snapshot weight 4 shuffle 0 at epoch 150
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1987 - accuracy: 0.9437 - val_loss: 0.4417 - val_accuracy: 0.8931
Epoch 151/350
391/391 - 24s - loss: 0.1923 - accuracy: 0.9472 - val_loss: 0.4687 - val_accuracy: 0.8921
Epoch 152/350
391/391 - 24s - loss: 0.1914 - accuracy: 0.9466 - val_loss: 0.4635 - val_accuracy: 0.8940
Epoch 153/350
391/391 - 24s - loss: 0.1960 - accuracy: 0.9463 - val_loss: 0.4531 - val_accuracy: 0.8941
Epoch 154/350
391/391 - 24s - loss: 0.1894 - accuracy: 0.9471 - val_loss: 0.4515 - val_accuracy: 0.8956
Epoch 155/350
391/391 - 24s - loss: 0.1968 - accuracy: 0.9453 - val_loss: 0.4449 - val_accuracy: 0.8961
Epoch 156/350
391/391 - 24s - loss: 0.1909 - accuracy: 0.9467 - val_loss: 0.4842 - val_accuracy: 0.8901
Epoch 157/350
391/391 - 24s - loss: 0.1860 - accuracy: 0.9490 - val_loss: 0.5155 - val_accuracy: 0.8886
Epoch 158/350
391/391 - 24s - loss: 0.1960 - accuracy: 0.9458 - val_loss: 0.4625 - val_accuracy: 0.8940
Epoch 159/350
391/391 - 24s - loss: 0.1895 - accuracy: 0.9472 - val_loss: 0.4401 - val_accuracy: 0.8957
Epoch 160/350
391/391 - 24s - loss: 0.1886 - accuracy: 0.9488 - val_loss: 0.4523 - val_accuracy: 0.8918
Epoch 161/350
391/391 - 24s - loss: 0.1821 - accuracy: 0.9512 - val_loss: 0.4622 - val_accuracy: 0.8953
Epoch 162/350
391/391 - 24s - loss: 0.1875 - accuracy: 0.9496 - val_loss: 0.4542 - val_accuracy: 0.8985
Epoch 163/350
391/391 - 24s - loss: 0.1855 - accuracy: 0.9501 - val_loss: 0.4761 - val_accuracy: 0.8906
Epoch 164/350
391/391 - 24s - loss: 0.1839 - accuracy: 0.9498 - val_loss: 0.4633 - val_accuracy: 0.8928
Epoch 165/350
391/391 - 24s - loss: 0.1855 - accuracy: 0.9498 - val_loss: 0.4695 - val_accuracy: 0.8931
Epoch 166/350
391/391 - 24s - loss: 0.1837 - accuracy: 0.9505 - val_loss: 0.4846 - val_accuracy: 0.8921
Epoch 167/350
391/391 - 25s - loss: 0.1832 - accuracy: 0.9503 - val_loss: 0.4851 - val_accuracy: 0.8929
Epoch 168/350
391/391 - 24s - loss: 0.1869 - accuracy: 0.9490 - val_loss: 0.4724 - val_accuracy: 0.8911
Epoch 169/350
391/391 - 24s - loss: 0.1817 - accuracy: 0.9511 - val_loss: 0.4938 - val_accuracy: 0.8918
Epoch 170/350
391/391 - 24s - loss: 0.1830 - accuracy: 0.9506 - val_loss: 0.4657 - val_accuracy: 0.8938
Epoch 171/350
391/391 - 24s - loss: 0.1812 - accuracy: 0.9505 - val_loss: 0.4677 - val_accuracy: 0.8923
Epoch 172/350
391/391 - 24s - loss: 0.1798 - accuracy: 0.9520 - val_loss: 0.4789 - val_accuracy: 0.8921
Epoch 173/350
391/391 - 24s - loss: 0.1773 - accuracy: 0.9518 - val_loss: 0.4730 - val_accuracy: 0.8978
Epoch 174/350
391/391 - 24s - loss: 0.1800 - accuracy: 0.9520 - val_loss: 0.4747 - val_accuracy: 0.8934
Epoch 175/350
391/391 - 24s - loss: 0.1797 - accuracy: 0.9523 - val_loss: 0.4608 - val_accuracy: 0.8928
Epoch 176/350
391/391 - 24s - loss: 0.1791 - accuracy: 0.9522 - val_loss: 0.4558 - val_accuracy: 0.8975
Epoch 177/350
391/391 - 24s - loss: 0.1789 - accuracy: 0.9515 - val_loss: 0.4444 - val_accuracy: 0.9014
Epoch 178/350
391/391 - 25s - loss: 0.1758 - accuracy: 0.9527 - val_loss: 0.4640 - val_accuracy: 0.8945
Epoch 179/350
391/391 - 25s - loss: 0.1751 - accuracy: 0.9528 - val_loss: 0.5154 - val_accuracy: 0.8940
Epoch 180/350
391/391 - 24s - loss: 0.1821 - accuracy: 0.9514 - val_loss: 0.5022 - val_accuracy: 0.8862
Epoch 181/350
391/391 - 25s - loss: 0.1796 - accuracy: 0.9521 - val_loss: 0.4660 - val_accuracy: 0.8995
Epoch 182/350
391/391 - 24s - loss: 0.1751 - accuracy: 0.9537 - val_loss: 0.4931 - val_accuracy: 0.8919
Epoch 183/350
391/391 - 24s - loss: 0.1710 - accuracy: 0.9557 - val_loss: 0.4959 - val_accuracy: 0.8950
Epoch 184/350
391/391 - 24s - loss: 0.1726 - accuracy: 0.9543 - val_loss: 0.4732 - val_accuracy: 0.8924
Epoch 185/350
391/391 - 24s - loss: 0.1742 - accuracy: 0.9545 - val_loss: 0.5181 - val_accuracy: 0.8939
Epoch 186/350
391/391 - 24s - loss: 0.1691 - accuracy: 0.9549 - val_loss: 0.4805 - val_accuracy: 0.8931
Epoch 187/350
391/391 - 24s - loss: 0.1705 - accuracy: 0.9552 - val_loss: 0.4863 - val_accuracy: 0.8970
Epoch 188/350
391/391 - 24s - loss: 0.1714 - accuracy: 0.9554 - val_loss: 0.4694 - val_accuracy: 0.8918
Epoch 189/350
391/391 - 24s - loss: 0.1722 - accuracy: 0.9541 - val_loss: 0.4811 - val_accuracy: 0.8967
Epoch 190/350
391/391 - 24s - loss: 0.1669 - accuracy: 0.9563 - val_loss: 0.4731 - val_accuracy: 0.8984
Epoch 191/350
391/391 - 24s - loss: 0.1635 - accuracy: 0.9573 - val_loss: 0.4670 - val_accuracy: 0.9015
Epoch 192/350
391/391 - 24s - loss: 0.1702 - accuracy: 0.9560 - val_loss: 0.4508 - val_accuracy: 0.8999
Epoch 193/350
391/391 - 24s - loss: 0.1686 - accuracy: 0.9563 - val_loss: 0.4696 - val_accuracy: 0.8963
Epoch 194/350
391/391 - 24s - loss: 0.1652 - accuracy: 0.9579 - val_loss: 0.5126 - val_accuracy: 0.8966
Epoch 195/350
391/391 - 24s - loss: 0.1691 - accuracy: 0.9561 - val_loss: 0.4659 - val_accuracy: 0.8974
Epoch 196/350
391/391 - 24s - loss: 0.1659 - accuracy: 0.9574 - val_loss: 0.4488 - val_accuracy: 0.8994
Epoch 197/350
391/391 - 25s - loss: 0.1633 - accuracy: 0.9577 - val_loss: 0.4560 - val_accuracy: 0.8989
Epoch 198/350
391/391 - 24s - loss: 0.1664 - accuracy: 0.9569 - val_loss: 0.4959 - val_accuracy: 0.8918
Epoch 199/350
391/391 - 24s - loss: 0.1664 - accuracy: 0.9581 - val_loss: 0.5053 - val_accuracy: 0.8953
Epoch 200/350


Snapshot weight 4 shuffle 0 at epoch 200
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1655 - accuracy: 0.9584 - val_loss: 0.4808 - val_accuracy: 0.8980
Epoch 201/350
391/391 - 24s - loss: 0.1385 - accuracy: 0.9680 - val_loss: 0.4547 - val_accuracy: 0.9049
Epoch 202/350
391/391 - 24s - loss: 0.1266 - accuracy: 0.9716 - val_loss: 0.4524 - val_accuracy: 0.9059
Epoch 203/350
391/391 - 24s - loss: 0.1267 - accuracy: 0.9720 - val_loss: 0.4563 - val_accuracy: 0.9053
Epoch 204/350
391/391 - 24s - loss: 0.1242 - accuracy: 0.9720 - val_loss: 0.4661 - val_accuracy: 0.9048
Epoch 205/350
391/391 - 24s - loss: 0.1189 - accuracy: 0.9751 - val_loss: 0.4736 - val_accuracy: 0.9047
Epoch 206/350
391/391 - 24s - loss: 0.1191 - accuracy: 0.9740 - val_loss: 0.4741 - val_accuracy: 0.9047
Epoch 207/350
391/391 - 24s - loss: 0.1165 - accuracy: 0.9750 - val_loss: 0.4767 - val_accuracy: 0.9051
Epoch 208/350
391/391 - 24s - loss: 0.1177 - accuracy: 0.9741 - val_loss: 0.4737 - val_accuracy: 0.9060
Epoch 209/350
391/391 - 24s - loss: 0.1154 - accuracy: 0.9746 - val_loss: 0.4784 - val_accuracy: 0.9037
Epoch 210/350
391/391 - 24s - loss: 0.1153 - accuracy: 0.9749 - val_loss: 0.4833 - val_accuracy: 0.9055
Epoch 211/350
391/391 - 24s - loss: 0.1152 - accuracy: 0.9756 - val_loss: 0.4852 - val_accuracy: 0.9047
Epoch 212/350
391/391 - 24s - loss: 0.1147 - accuracy: 0.9756 - val_loss: 0.4791 - val_accuracy: 0.9063
Epoch 213/350
391/391 - 24s - loss: 0.1139 - accuracy: 0.9767 - val_loss: 0.4771 - val_accuracy: 0.9066
Epoch 214/350
391/391 - 24s - loss: 0.1172 - accuracy: 0.9747 - val_loss: 0.4835 - val_accuracy: 0.9045
Epoch 215/350
391/391 - 24s - loss: 0.1127 - accuracy: 0.9757 - val_loss: 0.4901 - val_accuracy: 0.9044
Epoch 216/350
391/391 - 24s - loss: 0.1154 - accuracy: 0.9752 - val_loss: 0.4850 - val_accuracy: 0.9041
Epoch 217/350
391/391 - 24s - loss: 0.1126 - accuracy: 0.9768 - val_loss: 0.4946 - val_accuracy: 0.9044
Epoch 218/350
391/391 - 25s - loss: 0.1107 - accuracy: 0.9771 - val_loss: 0.4854 - val_accuracy: 0.9047
Epoch 219/350
391/391 - 24s - loss: 0.1110 - accuracy: 0.9775 - val_loss: 0.4906 - val_accuracy: 0.9064
Epoch 220/350
391/391 - 25s - loss: 0.1109 - accuracy: 0.9767 - val_loss: 0.4967 - val_accuracy: 0.9056
Epoch 221/350
391/391 - 24s - loss: 0.1117 - accuracy: 0.9769 - val_loss: 0.4922 - val_accuracy: 0.9050
Epoch 222/350
391/391 - 24s - loss: 0.1091 - accuracy: 0.9784 - val_loss: 0.4860 - val_accuracy: 0.9048
Epoch 223/350
391/391 - 24s - loss: 0.1105 - accuracy: 0.9769 - val_loss: 0.4910 - val_accuracy: 0.9056
Epoch 224/350
391/391 - 24s - loss: 0.1088 - accuracy: 0.9779 - val_loss: 0.5005 - val_accuracy: 0.9032
Epoch 225/350
391/391 - 24s - loss: 0.1103 - accuracy: 0.9777 - val_loss: 0.4916 - val_accuracy: 0.9038
Epoch 226/350
391/391 - 24s - loss: 0.1097 - accuracy: 0.9776 - val_loss: 0.4955 - val_accuracy: 0.9060
Epoch 227/350
391/391 - 25s - loss: 0.1064 - accuracy: 0.9788 - val_loss: 0.5046 - val_accuracy: 0.9059
Epoch 228/350
391/391 - 25s - loss: 0.1100 - accuracy: 0.9776 - val_loss: 0.5071 - val_accuracy: 0.9051
Epoch 229/350
391/391 - 24s - loss: 0.1066 - accuracy: 0.9785 - val_loss: 0.5097 - val_accuracy: 0.9059
Epoch 230/350
391/391 - 24s - loss: 0.1078 - accuracy: 0.9777 - val_loss: 0.4979 - val_accuracy: 0.9055
Epoch 231/350
391/391 - 24s - loss: 0.1067 - accuracy: 0.9790 - val_loss: 0.5065 - val_accuracy: 0.9039
Epoch 232/350
391/391 - 24s - loss: 0.1086 - accuracy: 0.9782 - val_loss: 0.5032 - val_accuracy: 0.9053
Epoch 233/350
391/391 - 24s - loss: 0.1050 - accuracy: 0.9790 - val_loss: 0.5065 - val_accuracy: 0.9058
Epoch 234/350
391/391 - 24s - loss: 0.1056 - accuracy: 0.9788 - val_loss: 0.5063 - val_accuracy: 0.9049
Epoch 235/350
391/391 - 24s - loss: 0.1051 - accuracy: 0.9793 - val_loss: 0.5097 - val_accuracy: 0.9067
Epoch 236/350
391/391 - 24s - loss: 0.1060 - accuracy: 0.9788 - val_loss: 0.4960 - val_accuracy: 0.9061
Epoch 237/350
391/391 - 24s - loss: 0.1064 - accuracy: 0.9783 - val_loss: 0.5057 - val_accuracy: 0.9047
Epoch 238/350
391/391 - 25s - loss: 0.1066 - accuracy: 0.9781 - val_loss: 0.5050 - val_accuracy: 0.9059
Epoch 239/350
391/391 - 24s - loss: 0.1056 - accuracy: 0.9780 - val_loss: 0.5004 - val_accuracy: 0.9069
Epoch 240/350
391/391 - 24s - loss: 0.1049 - accuracy: 0.9785 - val_loss: 0.5008 - val_accuracy: 0.9061
Epoch 241/350
391/391 - 24s - loss: 0.1066 - accuracy: 0.9789 - val_loss: 0.5009 - val_accuracy: 0.9065
Epoch 242/350
391/391 - 24s - loss: 0.1034 - accuracy: 0.9801 - val_loss: 0.5064 - val_accuracy: 0.9054
Epoch 243/350
391/391 - 24s - loss: 0.1052 - accuracy: 0.9784 - val_loss: 0.4993 - val_accuracy: 0.9074
Epoch 244/350
391/391 - 24s - loss: 0.1045 - accuracy: 0.9794 - val_loss: 0.5025 - val_accuracy: 0.9087
Epoch 245/350
391/391 - 24s - loss: 0.1042 - accuracy: 0.9791 - val_loss: 0.5001 - val_accuracy: 0.9076
Epoch 246/350
391/391 - 24s - loss: 0.1059 - accuracy: 0.9787 - val_loss: 0.5072 - val_accuracy: 0.9054
Epoch 247/350
391/391 - 24s - loss: 0.1022 - accuracy: 0.9802 - val_loss: 0.5093 - val_accuracy: 0.9054
Epoch 248/350
391/391 - 24s - loss: 0.1062 - accuracy: 0.9789 - val_loss: 0.4999 - val_accuracy: 0.9061
Epoch 249/350
391/391 - 25s - loss: 0.1032 - accuracy: 0.9799 - val_loss: 0.5107 - val_accuracy: 0.9056
Epoch 250/350


Snapshot weight 4 shuffle 0 at epoch 250
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1022 - accuracy: 0.9797 - val_loss: 0.5213 - val_accuracy: 0.9049
Epoch 251/350
391/391 - 24s - loss: 0.1008 - accuracy: 0.9804 - val_loss: 0.5132 - val_accuracy: 0.9064
Epoch 252/350
391/391 - 25s - loss: 0.1024 - accuracy: 0.9796 - val_loss: 0.5101 - val_accuracy: 0.9066
Epoch 253/350
391/391 - 24s - loss: 0.0995 - accuracy: 0.9811 - val_loss: 0.5097 - val_accuracy: 0.9065
Epoch 254/350
391/391 - 24s - loss: 0.1018 - accuracy: 0.9803 - val_loss: 0.5078 - val_accuracy: 0.9076
Epoch 255/350
391/391 - 24s - loss: 0.0983 - accuracy: 0.9816 - val_loss: 0.5101 - val_accuracy: 0.9063
Epoch 256/350
391/391 - 25s - loss: 0.0971 - accuracy: 0.9816 - val_loss: 0.5097 - val_accuracy: 0.9070
Epoch 257/350
391/391 - 24s - loss: 0.1009 - accuracy: 0.9806 - val_loss: 0.5097 - val_accuracy: 0.9073
Epoch 258/350
391/391 - 24s - loss: 0.1020 - accuracy: 0.9794 - val_loss: 0.5100 - val_accuracy: 0.9073
Epoch 259/350
391/391 - 24s - loss: 0.0996 - accuracy: 0.9805 - val_loss: 0.5095 - val_accuracy: 0.9071
Epoch 260/350
391/391 - 24s - loss: 0.1007 - accuracy: 0.9805 - val_loss: 0.5103 - val_accuracy: 0.9065
Epoch 261/350
391/391 - 25s - loss: 0.0981 - accuracy: 0.9822 - val_loss: 0.5113 - val_accuracy: 0.9066
Epoch 262/350
391/391 - 25s - loss: 0.0990 - accuracy: 0.9812 - val_loss: 0.5080 - val_accuracy: 0.9077
Epoch 263/350
391/391 - 25s - loss: 0.0991 - accuracy: 0.9813 - val_loss: 0.5107 - val_accuracy: 0.9079
Epoch 264/350
391/391 - 25s - loss: 0.1005 - accuracy: 0.9806 - val_loss: 0.5083 - val_accuracy: 0.9064
Epoch 265/350
391/391 - 24s - loss: 0.1005 - accuracy: 0.9806 - val_loss: 0.5083 - val_accuracy: 0.9065
Epoch 266/350
391/391 - 24s - loss: 0.1007 - accuracy: 0.9801 - val_loss: 0.5057 - val_accuracy: 0.9071
Epoch 267/350
391/391 - 25s - loss: 0.0984 - accuracy: 0.9814 - val_loss: 0.5052 - val_accuracy: 0.9072
Epoch 268/350
391/391 - 24s - loss: 0.1008 - accuracy: 0.9809 - val_loss: 0.5063 - val_accuracy: 0.9065
Epoch 269/350
391/391 - 24s - loss: 0.1007 - accuracy: 0.9808 - val_loss: 0.5076 - val_accuracy: 0.9065
Epoch 270/350
391/391 - 24s - loss: 0.0988 - accuracy: 0.9813 - val_loss: 0.5100 - val_accuracy: 0.9062
Epoch 271/350
391/391 - 24s - loss: 0.0996 - accuracy: 0.9810 - val_loss: 0.5097 - val_accuracy: 0.9063
Epoch 272/350
391/391 - 24s - loss: 0.0984 - accuracy: 0.9813 - val_loss: 0.5098 - val_accuracy: 0.9066
Epoch 273/350
391/391 - 25s - loss: 0.1018 - accuracy: 0.9804 - val_loss: 0.5071 - val_accuracy: 0.9059
Epoch 274/350
391/391 - 24s - loss: 0.1010 - accuracy: 0.9806 - val_loss: 0.5075 - val_accuracy: 0.9070
Epoch 275/350
391/391 - 25s - loss: 0.0976 - accuracy: 0.9819 - val_loss: 0.5065 - val_accuracy: 0.9065
Epoch 276/350
391/391 - 24s - loss: 0.0980 - accuracy: 0.9816 - val_loss: 0.5083 - val_accuracy: 0.9073
Epoch 277/350
391/391 - 24s - loss: 0.0979 - accuracy: 0.9819 - val_loss: 0.5098 - val_accuracy: 0.9077
Epoch 278/350
391/391 - 24s - loss: 0.1017 - accuracy: 0.9800 - val_loss: 0.5095 - val_accuracy: 0.9072
Epoch 279/350
391/391 - 25s - loss: 0.0999 - accuracy: 0.9809 - val_loss: 0.5097 - val_accuracy: 0.9075
Epoch 280/350
391/391 - 24s - loss: 0.1004 - accuracy: 0.9803 - val_loss: 0.5099 - val_accuracy: 0.9076
Epoch 281/350
391/391 - 24s - loss: 0.0987 - accuracy: 0.9813 - val_loss: 0.5102 - val_accuracy: 0.9068
Epoch 282/350
391/391 - 24s - loss: 0.1011 - accuracy: 0.9806 - val_loss: 0.5125 - val_accuracy: 0.9077
Epoch 283/350
391/391 - 24s - loss: 0.0995 - accuracy: 0.9806 - val_loss: 0.5095 - val_accuracy: 0.9078
Epoch 284/350
391/391 - 24s - loss: 0.0998 - accuracy: 0.9805 - val_loss: 0.5114 - val_accuracy: 0.9083
Epoch 285/350
391/391 - 25s - loss: 0.1003 - accuracy: 0.9799 - val_loss: 0.5091 - val_accuracy: 0.9079
Epoch 286/350
391/391 - 24s - loss: 0.1001 - accuracy: 0.9806 - val_loss: 0.5079 - val_accuracy: 0.9069
Epoch 287/350
391/391 - 24s - loss: 0.1008 - accuracy: 0.9808 - val_loss: 0.5107 - val_accuracy: 0.9073
Epoch 288/350
391/391 - 24s - loss: 0.1000 - accuracy: 0.9809 - val_loss: 0.5075 - val_accuracy: 0.9074
Epoch 289/350
391/391 - 24s - loss: 0.1006 - accuracy: 0.9810 - val_loss: 0.5041 - val_accuracy: 0.9075
Epoch 290/350
391/391 - 25s - loss: 0.0979 - accuracy: 0.9813 - val_loss: 0.5065 - val_accuracy: 0.9076
Epoch 291/350
391/391 - 24s - loss: 0.0967 - accuracy: 0.9820 - val_loss: 0.5098 - val_accuracy: 0.9076
Epoch 292/350
391/391 - 24s - loss: 0.1000 - accuracy: 0.9809 - val_loss: 0.5096 - val_accuracy: 0.9081
Epoch 293/350
391/391 - 24s - loss: 0.1001 - accuracy: 0.9806 - val_loss: 0.5118 - val_accuracy: 0.9077
Epoch 294/350
391/391 - 24s - loss: 0.0997 - accuracy: 0.9810 - val_loss: 0.5066 - val_accuracy: 0.9077
Epoch 295/350
391/391 - 24s - loss: 0.0999 - accuracy: 0.9803 - val_loss: 0.5081 - val_accuracy: 0.9074
Epoch 296/350
391/391 - 25s - loss: 0.1004 - accuracy: 0.9802 - val_loss: 0.5080 - val_accuracy: 0.9075
Epoch 297/350
391/391 - 24s - loss: 0.0989 - accuracy: 0.9809 - val_loss: 0.5066 - val_accuracy: 0.9077
Epoch 298/350
391/391 - 24s - loss: 0.0980 - accuracy: 0.9817 - val_loss: 0.5112 - val_accuracy: 0.9077
Epoch 299/350
391/391 - 24s - loss: 0.0997 - accuracy: 0.9811 - val_loss: 0.5085 - val_accuracy: 0.9078
Epoch 300/350


Snapshot weight 4 shuffle 0 at epoch 300
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1002 - accuracy: 0.9807 - val_loss: 0.5102 - val_accuracy: 0.9075
Epoch 301/350
391/391 - 24s - loss: 0.0990 - accuracy: 0.9812 - val_loss: 0.5096 - val_accuracy: 0.9078
Epoch 302/350
391/391 - 24s - loss: 0.1017 - accuracy: 0.9796 - val_loss: 0.5094 - val_accuracy: 0.9076
Epoch 303/350
391/391 - 24s - loss: 0.0993 - accuracy: 0.9812 - val_loss: 0.5094 - val_accuracy: 0.9076
Epoch 304/350
391/391 - 24s - loss: 0.1006 - accuracy: 0.9815 - val_loss: 0.5094 - val_accuracy: 0.9077
Epoch 305/350
391/391 - 24s - loss: 0.0983 - accuracy: 0.9807 - val_loss: 0.5094 - val_accuracy: 0.9078
Epoch 306/350
391/391 - 24s - loss: 0.1013 - accuracy: 0.9803 - val_loss: 0.5096 - val_accuracy: 0.9079
Epoch 307/350
391/391 - 24s - loss: 0.0987 - accuracy: 0.9817 - val_loss: 0.5096 - val_accuracy: 0.9079
Epoch 308/350
391/391 - 24s - loss: 0.1017 - accuracy: 0.9798 - val_loss: 0.5091 - val_accuracy: 0.9078
Epoch 309/350
391/391 - 24s - loss: 0.0976 - accuracy: 0.9816 - val_loss: 0.5091 - val_accuracy: 0.9073
Epoch 310/350
391/391 - 24s - loss: 0.0980 - accuracy: 0.9811 - val_loss: 0.5089 - val_accuracy: 0.9074
Epoch 311/350
391/391 - 24s - loss: 0.0977 - accuracy: 0.9812 - val_loss: 0.5088 - val_accuracy: 0.9077
Epoch 312/350
391/391 - 24s - loss: 0.0975 - accuracy: 0.9822 - val_loss: 0.5093 - val_accuracy: 0.9079
Epoch 313/350
391/391 - 24s - loss: 0.0985 - accuracy: 0.9815 - val_loss: 0.5096 - val_accuracy: 0.9077
Epoch 314/350
391/391 - 24s - loss: 0.0996 - accuracy: 0.9808 - val_loss: 0.5095 - val_accuracy: 0.9077
Epoch 315/350
391/391 - 24s - loss: 0.0987 - accuracy: 0.9817 - val_loss: 0.5095 - val_accuracy: 0.9077
Epoch 316/350
391/391 - 24s - loss: 0.1000 - accuracy: 0.9812 - val_loss: 0.5094 - val_accuracy: 0.9077
Epoch 317/350
391/391 - 24s - loss: 0.0998 - accuracy: 0.9809 - val_loss: 0.5088 - val_accuracy: 0.9075
Epoch 318/350
391/391 - 24s - loss: 0.0978 - accuracy: 0.9818 - val_loss: 0.5090 - val_accuracy: 0.9076
Epoch 319/350
391/391 - 25s - loss: 0.0991 - accuracy: 0.9811 - val_loss: 0.5088 - val_accuracy: 0.9075
Epoch 320/350
391/391 - 24s - loss: 0.0986 - accuracy: 0.9807 - val_loss: 0.5090 - val_accuracy: 0.9075
Epoch 321/350
391/391 - 24s - loss: 0.0981 - accuracy: 0.9825 - val_loss: 0.5087 - val_accuracy: 0.9075
Epoch 322/350
391/391 - 24s - loss: 0.0998 - accuracy: 0.9804 - val_loss: 0.5084 - val_accuracy: 0.9075
Epoch 323/350
391/391 - 24s - loss: 0.1017 - accuracy: 0.9804 - val_loss: 0.5080 - val_accuracy: 0.9077
Epoch 324/350
391/391 - 24s - loss: 0.1009 - accuracy: 0.9803 - val_loss: 0.5085 - val_accuracy: 0.9075
Epoch 325/350
391/391 - 24s - loss: 0.0979 - accuracy: 0.9816 - val_loss: 0.5087 - val_accuracy: 0.9076
Epoch 326/350
391/391 - 24s - loss: 0.1006 - accuracy: 0.9808 - val_loss: 0.5085 - val_accuracy: 0.9075
Epoch 327/350
391/391 - 24s - loss: 0.0988 - accuracy: 0.9815 - val_loss: 0.5084 - val_accuracy: 0.9076
Epoch 328/350
391/391 - 24s - loss: 0.0991 - accuracy: 0.9813 - val_loss: 0.5084 - val_accuracy: 0.9075
Epoch 329/350
391/391 - 24s - loss: 0.0994 - accuracy: 0.9811 - val_loss: 0.5085 - val_accuracy: 0.9080
Epoch 330/350
391/391 - 24s - loss: 0.0993 - accuracy: 0.9816 - val_loss: 0.5090 - val_accuracy: 0.9077
Epoch 331/350
391/391 - 24s - loss: 0.0994 - accuracy: 0.9806 - val_loss: 0.5091 - val_accuracy: 0.9075
Epoch 332/350
391/391 - 24s - loss: 0.0978 - accuracy: 0.9814 - val_loss: 0.5092 - val_accuracy: 0.9080
Epoch 333/350
391/391 - 24s - loss: 0.0993 - accuracy: 0.9807 - val_loss: 0.5095 - val_accuracy: 0.9080
Epoch 334/350
391/391 - 24s - loss: 0.0987 - accuracy: 0.9812 - val_loss: 0.5092 - val_accuracy: 0.9080
Epoch 335/350
391/391 - 24s - loss: 0.0996 - accuracy: 0.9811 - val_loss: 0.5089 - val_accuracy: 0.9073
Epoch 336/350
391/391 - 24s - loss: 0.0982 - accuracy: 0.9820 - val_loss: 0.5086 - val_accuracy: 0.9074
Epoch 337/350
391/391 - 24s - loss: 0.0968 - accuracy: 0.9823 - val_loss: 0.5085 - val_accuracy: 0.9073
Epoch 338/350
391/391 - 24s - loss: 0.1014 - accuracy: 0.9804 - val_loss: 0.5086 - val_accuracy: 0.9073
Epoch 339/350
391/391 - 24s - loss: 0.0966 - accuracy: 0.9817 - val_loss: 0.5087 - val_accuracy: 0.9074
Epoch 340/350
391/391 - 24s - loss: 0.0992 - accuracy: 0.9807 - val_loss: 0.5089 - val_accuracy: 0.9076
Epoch 341/350
391/391 - 24s - loss: 0.0985 - accuracy: 0.9807 - val_loss: 0.5090 - val_accuracy: 0.9077
Epoch 342/350
391/391 - 24s - loss: 0.0995 - accuracy: 0.9809 - val_loss: 0.5091 - val_accuracy: 0.9075
Epoch 343/350
391/391 - 24s - loss: 0.0978 - accuracy: 0.9813 - val_loss: 0.5088 - val_accuracy: 0.9073
Epoch 344/350
391/391 - 25s - loss: 0.0978 - accuracy: 0.9822 - val_loss: 0.5084 - val_accuracy: 0.9074
Epoch 345/350
391/391 - 24s - loss: 0.0998 - accuracy: 0.9809 - val_loss: 0.5084 - val_accuracy: 0.9078
Epoch 346/350
391/391 - 24s - loss: 0.0972 - accuracy: 0.9817 - val_loss: 0.5083 - val_accuracy: 0.9076
Epoch 347/350
391/391 - 24s - loss: 0.0978 - accuracy: 0.9817 - val_loss: 0.5083 - val_accuracy: 0.9077
Epoch 348/350
391/391 - 24s - loss: 0.0994 - accuracy: 0.9806 - val_loss: 0.5080 - val_accuracy: 0.9078
Epoch 349/350
391/391 - 24s - loss: 0.0984 - accuracy: 0.9816 - val_loss: 0.5082 - val_accuracy: 0.9081
Epoch 350/350


Snapshot weight 4 shuffle 0 at epoch 350
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1011 - accuracy: 0.9804 - val_loss: 0.5079 - val_accuracy: 0.9075
/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:493: UserWarning: fill_value is not supported and is always 0 for TensorFlow < 2.4.0.
  return py_builtins.overload_of(f)(*args)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-07-01 18:42:32.000428: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
Saving, final validation acc: 0.9075000286102295
