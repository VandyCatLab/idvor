2021-07-02 07:01:10.752883: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 07:02:38.040694: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-07-02 07:02:38.085428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-02 07:02:38.085505: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 07:02:38.128327: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-02 07:02:38.150249: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-02 07:02:38.158973: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-02 07:02:38.203815: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-02 07:02:38.212675: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-02 07:02:38.292550: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 07:02:38.294967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-02 07:02:38.298745: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-02 07:02:38.315172: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599865000 Hz
2021-07-02 07:02:38.315345: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5b0cce0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-07-02 07:02:38.315368: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-07-02 07:02:38.467545: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5aede10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-07-02 07:02:38.467613: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN X (Pascal), Compute Capability 6.1
2021-07-02 07:02:38.470252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-07-02 07:02:38.470317: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 07:02:38.470350: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-02 07:02:38.470369: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-02 07:02:38.470386: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-02 07:02:38.470403: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-02 07:02:38.470420: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-02 07:02:38.471063: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 07:02:38.472745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-07-02 07:02:38.474559: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-07-02 07:02:40.310058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-02 07:02:40.310161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2021-07-02 07:02:40.310175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2021-07-02 07:02:40.320037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11228 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
2021-07-02 07:02:46.309261: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2021-07-02 07:02:48.897346: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
Using model index: 50
Making train data...
GCN...
ZCA...
Done!
Making test data...
Done!
Epoch 1/350


Snapshot weight 0 shuffle 5 at epoch 1
Layer 11
Getting activations...


391/391 - 25s - loss: 2.3228 - accuracy: 0.1118 - val_loss: 2.3097 - val_accuracy: 0.1035
Epoch 2/350


Snapshot weight 0 shuffle 5 at epoch 2
Layer 11
Getting activations...


391/391 - 25s - loss: 2.3181 - accuracy: 0.1155 - val_loss: 2.3177 - val_accuracy: 0.1105
Epoch 3/350


Snapshot weight 0 shuffle 5 at epoch 3
Layer 11
Getting activations...


391/391 - 25s - loss: 2.2900 - accuracy: 0.1517 - val_loss: 2.2471 - val_accuracy: 0.1867
Epoch 4/350


Snapshot weight 0 shuffle 5 at epoch 4
Layer 11
Getting activations...


391/391 - 26s - loss: 2.1929 - accuracy: 0.2036 - val_loss: 2.1215 - val_accuracy: 0.2472
Epoch 5/350


Snapshot weight 0 shuffle 5 at epoch 5
Layer 11
Getting activations...


391/391 - 25s - loss: 2.1146 - accuracy: 0.2483 - val_loss: 2.0205 - val_accuracy: 0.2931
Epoch 6/350


Snapshot weight 0 shuffle 5 at epoch 6
Layer 11
Getting activations...


391/391 - 25s - loss: 2.0384 - accuracy: 0.2906 - val_loss: 2.1056 - val_accuracy: 0.2891
Epoch 7/350


Snapshot weight 0 shuffle 5 at epoch 7
Layer 11
Getting activations...


391/391 - 25s - loss: 1.9850 - accuracy: 0.3117 - val_loss: 1.9108 - val_accuracy: 0.3397
Epoch 8/350


Snapshot weight 0 shuffle 5 at epoch 8
Layer 11
Getting activations...


391/391 - 25s - loss: 1.9328 - accuracy: 0.3329 - val_loss: 1.8709 - val_accuracy: 0.3536
Epoch 9/350


Snapshot weight 0 shuffle 5 at epoch 9
Layer 11
Getting activations...


391/391 - 25s - loss: 1.8860 - accuracy: 0.3480 - val_loss: 1.8506 - val_accuracy: 0.3665
Epoch 10/350


Snapshot weight 0 shuffle 5 at epoch 10
Layer 11
Getting activations...


391/391 - 25s - loss: 1.8627 - accuracy: 0.3659 - val_loss: 1.8599 - val_accuracy: 0.3774
Epoch 11/350
391/391 - 25s - loss: 1.7591 - accuracy: 0.4159 - val_loss: 1.4548 - val_accuracy: 0.5176
Epoch 12/350
391/391 - 25s - loss: 1.4280 - accuracy: 0.5190 - val_loss: 1.1861 - val_accuracy: 0.5875
Epoch 13/350
391/391 - 25s - loss: 1.2159 - accuracy: 0.5795 - val_loss: 1.2536 - val_accuracy: 0.5831
Epoch 14/350
391/391 - 25s - loss: 1.1179 - accuracy: 0.6123 - val_loss: 1.0317 - val_accuracy: 0.6450
Epoch 15/350
391/391 - 25s - loss: 1.0641 - accuracy: 0.6326 - val_loss: 1.1306 - val_accuracy: 0.6215
Epoch 16/350
391/391 - 25s - loss: 1.0171 - accuracy: 0.6485 - val_loss: 0.9941 - val_accuracy: 0.6643
Epoch 17/350
391/391 - 25s - loss: 0.9661 - accuracy: 0.6684 - val_loss: 1.0085 - val_accuracy: 0.6710
Epoch 18/350
391/391 - 25s - loss: 0.9111 - accuracy: 0.6869 - val_loss: 0.8826 - val_accuracy: 0.7036
Epoch 19/350
391/391 - 25s - loss: 0.8789 - accuracy: 0.7006 - val_loss: 0.8982 - val_accuracy: 0.7082
Epoch 20/350
391/391 - 25s - loss: 0.8375 - accuracy: 0.7163 - val_loss: 0.7696 - val_accuracy: 0.7400
Epoch 21/350
391/391 - 25s - loss: 0.8139 - accuracy: 0.7258 - val_loss: 0.7668 - val_accuracy: 0.7474
Epoch 22/350
391/391 - 25s - loss: 0.7856 - accuracy: 0.7342 - val_loss: 0.7566 - val_accuracy: 0.7542
Epoch 23/350
391/391 - 25s - loss: 0.7497 - accuracy: 0.7488 - val_loss: 0.7561 - val_accuracy: 0.7604
Epoch 24/350
391/391 - 25s - loss: 0.7268 - accuracy: 0.7583 - val_loss: 0.7004 - val_accuracy: 0.7720
Epoch 25/350
391/391 - 25s - loss: 0.7120 - accuracy: 0.7623 - val_loss: 0.6541 - val_accuracy: 0.7910
Epoch 26/350
391/391 - 25s - loss: 0.6928 - accuracy: 0.7688 - val_loss: 0.6549 - val_accuracy: 0.7812
Epoch 27/350
391/391 - 25s - loss: 0.6660 - accuracy: 0.7786 - val_loss: 0.6595 - val_accuracy: 0.7922
Epoch 28/350
391/391 - 25s - loss: 0.6517 - accuracy: 0.7844 - val_loss: 0.6002 - val_accuracy: 0.8062
Epoch 29/350
391/391 - 25s - loss: 0.6282 - accuracy: 0.7913 - val_loss: 0.5809 - val_accuracy: 0.8139
Epoch 30/350
391/391 - 25s - loss: 0.6199 - accuracy: 0.7934 - val_loss: 0.5758 - val_accuracy: 0.8134
Epoch 31/350
391/391 - 25s - loss: 0.6048 - accuracy: 0.7993 - val_loss: 0.5717 - val_accuracy: 0.8156
Epoch 32/350
391/391 - 25s - loss: 0.5976 - accuracy: 0.8053 - val_loss: 0.5654 - val_accuracy: 0.8220
Epoch 33/350
391/391 - 25s - loss: 0.5801 - accuracy: 0.8090 - val_loss: 0.5940 - val_accuracy: 0.8204
Epoch 34/350
391/391 - 25s - loss: 0.5643 - accuracy: 0.8146 - val_loss: 0.5668 - val_accuracy: 0.8203
Epoch 35/350
391/391 - 25s - loss: 0.5608 - accuracy: 0.8165 - val_loss: 0.5737 - val_accuracy: 0.8119
Epoch 36/350
391/391 - 25s - loss: 0.5409 - accuracy: 0.8204 - val_loss: 0.5256 - val_accuracy: 0.8367
Epoch 37/350
391/391 - 25s - loss: 0.5341 - accuracy: 0.8253 - val_loss: 0.5167 - val_accuracy: 0.8372
Epoch 38/350
391/391 - 25s - loss: 0.5233 - accuracy: 0.8284 - val_loss: 0.5475 - val_accuracy: 0.8269
Epoch 39/350
391/391 - 25s - loss: 0.5167 - accuracy: 0.8315 - val_loss: 0.5092 - val_accuracy: 0.8376
Epoch 40/350
391/391 - 25s - loss: 0.5024 - accuracy: 0.8362 - val_loss: 0.5210 - val_accuracy: 0.8374
Epoch 41/350
391/391 - 25s - loss: 0.4927 - accuracy: 0.8383 - val_loss: 0.4878 - val_accuracy: 0.8485
Epoch 42/350
391/391 - 25s - loss: 0.4882 - accuracy: 0.8414 - val_loss: 0.4770 - val_accuracy: 0.8452
Epoch 43/350
391/391 - 25s - loss: 0.4853 - accuracy: 0.8418 - val_loss: 0.4870 - val_accuracy: 0.8497
Epoch 44/350
391/391 - 25s - loss: 0.4762 - accuracy: 0.8459 - val_loss: 0.5529 - val_accuracy: 0.8270
Epoch 45/350
391/391 - 25s - loss: 0.4701 - accuracy: 0.8474 - val_loss: 0.4871 - val_accuracy: 0.8497
Epoch 46/350
391/391 - 25s - loss: 0.4603 - accuracy: 0.8506 - val_loss: 0.4728 - val_accuracy: 0.8553
Epoch 47/350
391/391 - 25s - loss: 0.4546 - accuracy: 0.8521 - val_loss: 0.4972 - val_accuracy: 0.8490
Epoch 48/350
391/391 - 25s - loss: 0.4439 - accuracy: 0.8554 - val_loss: 0.5008 - val_accuracy: 0.8519
Epoch 49/350
391/391 - 25s - loss: 0.4399 - accuracy: 0.8573 - val_loss: 0.4700 - val_accuracy: 0.8539
Epoch 50/350


Snapshot weight 0 shuffle 5 at epoch 50
Layer 11
Getting activations...


391/391 - 25s - loss: 0.4376 - accuracy: 0.8582 - val_loss: 0.4747 - val_accuracy: 0.8571
Epoch 51/350
391/391 - 25s - loss: 0.4248 - accuracy: 0.8616 - val_loss: 0.4959 - val_accuracy: 0.8502
Epoch 52/350
391/391 - 25s - loss: 0.4203 - accuracy: 0.8657 - val_loss: 0.4886 - val_accuracy: 0.8515
Epoch 53/350
391/391 - 25s - loss: 0.4197 - accuracy: 0.8634 - val_loss: 0.4613 - val_accuracy: 0.8549
Epoch 54/350
391/391 - 25s - loss: 0.4123 - accuracy: 0.8682 - val_loss: 0.4532 - val_accuracy: 0.8618
Epoch 55/350
391/391 - 25s - loss: 0.4054 - accuracy: 0.8709 - val_loss: 0.4866 - val_accuracy: 0.8582
Epoch 56/350
391/391 - 25s - loss: 0.4015 - accuracy: 0.8722 - val_loss: 0.4708 - val_accuracy: 0.8610
Epoch 57/350
391/391 - 25s - loss: 0.4071 - accuracy: 0.8687 - val_loss: 0.4442 - val_accuracy: 0.8677
Epoch 58/350
391/391 - 25s - loss: 0.3915 - accuracy: 0.8753 - val_loss: 0.4297 - val_accuracy: 0.8707
Epoch 59/350
391/391 - 25s - loss: 0.3890 - accuracy: 0.8752 - val_loss: 0.4781 - val_accuracy: 0.8564
Epoch 60/350
391/391 - 25s - loss: 0.3860 - accuracy: 0.8772 - val_loss: 0.4792 - val_accuracy: 0.8568
Epoch 61/350
391/391 - 25s - loss: 0.3792 - accuracy: 0.8780 - val_loss: 0.4746 - val_accuracy: 0.8624
Epoch 62/350
391/391 - 25s - loss: 0.3771 - accuracy: 0.8804 - val_loss: 0.4252 - val_accuracy: 0.8727
Epoch 63/350
391/391 - 25s - loss: 0.3710 - accuracy: 0.8824 - val_loss: 0.4193 - val_accuracy: 0.8728
Epoch 64/350
391/391 - 25s - loss: 0.3688 - accuracy: 0.8830 - val_loss: 0.4246 - val_accuracy: 0.8716
Epoch 65/350
391/391 - 25s - loss: 0.3652 - accuracy: 0.8851 - val_loss: 0.4240 - val_accuracy: 0.8709
Epoch 66/350
391/391 - 25s - loss: 0.3599 - accuracy: 0.8861 - val_loss: 0.4237 - val_accuracy: 0.8764
Epoch 67/350
391/391 - 25s - loss: 0.3527 - accuracy: 0.8861 - val_loss: 0.4611 - val_accuracy: 0.8649
Epoch 68/350
391/391 - 25s - loss: 0.3557 - accuracy: 0.8880 - val_loss: 0.4358 - val_accuracy: 0.8745
Epoch 69/350
391/391 - 25s - loss: 0.3473 - accuracy: 0.8908 - val_loss: 0.4569 - val_accuracy: 0.8668
Epoch 70/350
391/391 - 25s - loss: 0.3433 - accuracy: 0.8915 - val_loss: 0.4358 - val_accuracy: 0.8778
Epoch 71/350
391/391 - 25s - loss: 0.3404 - accuracy: 0.8922 - val_loss: 0.3986 - val_accuracy: 0.8838
Epoch 72/350
391/391 - 25s - loss: 0.3352 - accuracy: 0.8942 - val_loss: 0.4329 - val_accuracy: 0.8752
Epoch 73/350
391/391 - 25s - loss: 0.3380 - accuracy: 0.8925 - val_loss: 0.4880 - val_accuracy: 0.8655
Epoch 74/350
391/391 - 25s - loss: 0.3320 - accuracy: 0.8952 - val_loss: 0.4446 - val_accuracy: 0.8786
Epoch 75/350
391/391 - 25s - loss: 0.3272 - accuracy: 0.8976 - val_loss: 0.4528 - val_accuracy: 0.8736
Epoch 76/350
391/391 - 25s - loss: 0.3235 - accuracy: 0.8969 - val_loss: 0.4126 - val_accuracy: 0.8776
Epoch 77/350
391/391 - 25s - loss: 0.3250 - accuracy: 0.8970 - val_loss: 0.4264 - val_accuracy: 0.8811
Epoch 78/350
391/391 - 25s - loss: 0.3180 - accuracy: 0.9011 - val_loss: 0.4197 - val_accuracy: 0.8842
Epoch 79/350
391/391 - 25s - loss: 0.3151 - accuracy: 0.9008 - val_loss: 0.4382 - val_accuracy: 0.8787
Epoch 80/350
391/391 - 25s - loss: 0.3092 - accuracy: 0.9046 - val_loss: 0.4374 - val_accuracy: 0.8751
Epoch 81/350
391/391 - 25s - loss: 0.3113 - accuracy: 0.9033 - val_loss: 0.4415 - val_accuracy: 0.8778
Epoch 82/350
391/391 - 25s - loss: 0.3078 - accuracy: 0.9034 - val_loss: 0.4438 - val_accuracy: 0.8771
Epoch 83/350
391/391 - 25s - loss: 0.3045 - accuracy: 0.9046 - val_loss: 0.4188 - val_accuracy: 0.8808
Epoch 84/350
391/391 - 25s - loss: 0.3028 - accuracy: 0.9057 - val_loss: 0.4153 - val_accuracy: 0.8806
Epoch 85/350
391/391 - 25s - loss: 0.2971 - accuracy: 0.9077 - val_loss: 0.4458 - val_accuracy: 0.8755
Epoch 86/350
391/391 - 25s - loss: 0.2960 - accuracy: 0.9070 - val_loss: 0.4207 - val_accuracy: 0.8842
Epoch 87/350
391/391 - 25s - loss: 0.2905 - accuracy: 0.9107 - val_loss: 0.4538 - val_accuracy: 0.8721
Epoch 88/350
391/391 - 25s - loss: 0.2884 - accuracy: 0.9107 - val_loss: 0.4832 - val_accuracy: 0.8678
Epoch 89/350
391/391 - 25s - loss: 0.2966 - accuracy: 0.9086 - val_loss: 0.4208 - val_accuracy: 0.8800
Epoch 90/350
391/391 - 25s - loss: 0.2852 - accuracy: 0.9127 - val_loss: 0.4205 - val_accuracy: 0.8841
Epoch 91/350
391/391 - 25s - loss: 0.2862 - accuracy: 0.9115 - val_loss: 0.4167 - val_accuracy: 0.8854
Epoch 92/350
391/391 - 25s - loss: 0.2814 - accuracy: 0.9145 - val_loss: 0.4038 - val_accuracy: 0.8838
Epoch 93/350
391/391 - 25s - loss: 0.2820 - accuracy: 0.9141 - val_loss: 0.4000 - val_accuracy: 0.8876
Epoch 94/350
391/391 - 25s - loss: 0.2749 - accuracy: 0.9163 - val_loss: 0.4386 - val_accuracy: 0.8786
Epoch 95/350
391/391 - 25s - loss: 0.2756 - accuracy: 0.9148 - val_loss: 0.4341 - val_accuracy: 0.8834
Epoch 96/350
391/391 - 25s - loss: 0.2717 - accuracy: 0.9163 - val_loss: 0.4173 - val_accuracy: 0.8842
Epoch 97/350
391/391 - 25s - loss: 0.2710 - accuracy: 0.9167 - val_loss: 0.4064 - val_accuracy: 0.8858
Epoch 98/350
391/391 - 25s - loss: 0.2695 - accuracy: 0.9165 - val_loss: 0.4111 - val_accuracy: 0.8871
Epoch 99/350
391/391 - 25s - loss: 0.2732 - accuracy: 0.9158 - val_loss: 0.3900 - val_accuracy: 0.8920
Epoch 100/350


Snapshot weight 0 shuffle 5 at epoch 100
Layer 11
Getting activations...


391/391 - 25s - loss: 0.2731 - accuracy: 0.9162 - val_loss: 0.4337 - val_accuracy: 0.8834
Epoch 101/350
391/391 - 25s - loss: 0.2631 - accuracy: 0.9205 - val_loss: 0.4090 - val_accuracy: 0.8862
Epoch 102/350
391/391 - 25s - loss: 0.2654 - accuracy: 0.9193 - val_loss: 0.4090 - val_accuracy: 0.8925
Epoch 103/350
391/391 - 25s - loss: 0.2596 - accuracy: 0.9210 - val_loss: 0.4314 - val_accuracy: 0.8860
Epoch 104/350
391/391 - 25s - loss: 0.2624 - accuracy: 0.9199 - val_loss: 0.4351 - val_accuracy: 0.8831
Epoch 105/350
391/391 - 25s - loss: 0.2625 - accuracy: 0.9199 - val_loss: 0.4235 - val_accuracy: 0.8856
Epoch 106/350
391/391 - 25s - loss: 0.2590 - accuracy: 0.9211 - val_loss: 0.4125 - val_accuracy: 0.8888
Epoch 107/350
391/391 - 25s - loss: 0.2548 - accuracy: 0.9236 - val_loss: 0.4009 - val_accuracy: 0.8875
Epoch 108/350
391/391 - 25s - loss: 0.2548 - accuracy: 0.9230 - val_loss: 0.4075 - val_accuracy: 0.8873
Epoch 109/350
391/391 - 25s - loss: 0.2502 - accuracy: 0.9236 - val_loss: 0.4432 - val_accuracy: 0.8811
Epoch 110/350
391/391 - 25s - loss: 0.2523 - accuracy: 0.9238 - val_loss: 0.4157 - val_accuracy: 0.8876
Epoch 111/350
391/391 - 25s - loss: 0.2473 - accuracy: 0.9262 - val_loss: 0.4098 - val_accuracy: 0.8900
Epoch 112/350
391/391 - 25s - loss: 0.2451 - accuracy: 0.9252 - val_loss: 0.4314 - val_accuracy: 0.8882
Epoch 113/350
391/391 - 25s - loss: 0.2486 - accuracy: 0.9254 - val_loss: 0.4155 - val_accuracy: 0.8881
Epoch 114/350
391/391 - 25s - loss: 0.2429 - accuracy: 0.9266 - val_loss: 0.4288 - val_accuracy: 0.8900
Epoch 115/350
391/391 - 25s - loss: 0.2432 - accuracy: 0.9287 - val_loss: 0.4308 - val_accuracy: 0.8881
Epoch 116/350
391/391 - 25s - loss: 0.2400 - accuracy: 0.9282 - val_loss: 0.4488 - val_accuracy: 0.8851
Epoch 117/350
391/391 - 25s - loss: 0.2361 - accuracy: 0.9303 - val_loss: 0.4488 - val_accuracy: 0.8855
Epoch 118/350
391/391 - 25s - loss: 0.2401 - accuracy: 0.9271 - val_loss: 0.4103 - val_accuracy: 0.8904
Epoch 119/350
391/391 - 25s - loss: 0.2324 - accuracy: 0.9315 - val_loss: 0.4286 - val_accuracy: 0.8912
Epoch 120/350
391/391 - 25s - loss: 0.2289 - accuracy: 0.9313 - val_loss: 0.4272 - val_accuracy: 0.8913
Epoch 121/350
391/391 - 25s - loss: 0.2376 - accuracy: 0.9308 - val_loss: 0.4589 - val_accuracy: 0.8833
Epoch 122/350
391/391 - 25s - loss: 0.2283 - accuracy: 0.9339 - val_loss: 0.4233 - val_accuracy: 0.8906
Epoch 123/350
391/391 - 25s - loss: 0.2284 - accuracy: 0.9332 - val_loss: 0.4406 - val_accuracy: 0.8811
Epoch 124/350
391/391 - 25s - loss: 0.2301 - accuracy: 0.9323 - val_loss: 0.4329 - val_accuracy: 0.8931
Epoch 125/350
391/391 - 25s - loss: 0.2242 - accuracy: 0.9335 - val_loss: 0.4310 - val_accuracy: 0.8883
Epoch 126/350
391/391 - 25s - loss: 0.2214 - accuracy: 0.9352 - val_loss: 0.4485 - val_accuracy: 0.8868
Epoch 127/350
391/391 - 25s - loss: 0.2254 - accuracy: 0.9337 - val_loss: 0.4034 - val_accuracy: 0.8922
Epoch 128/350
391/391 - 25s - loss: 0.2220 - accuracy: 0.9353 - val_loss: 0.4292 - val_accuracy: 0.8941
Epoch 129/350
391/391 - 25s - loss: 0.2199 - accuracy: 0.9364 - val_loss: 0.4550 - val_accuracy: 0.8917
Epoch 130/350
391/391 - 25s - loss: 0.2249 - accuracy: 0.9342 - val_loss: 0.4502 - val_accuracy: 0.8892
Epoch 131/350
391/391 - 25s - loss: 0.2211 - accuracy: 0.9351 - val_loss: 0.4175 - val_accuracy: 0.8946
Epoch 132/350
391/391 - 25s - loss: 0.2190 - accuracy: 0.9354 - val_loss: 0.4345 - val_accuracy: 0.8926
Epoch 133/350
391/391 - 25s - loss: 0.2137 - accuracy: 0.9381 - val_loss: 0.4397 - val_accuracy: 0.8903
Epoch 134/350
391/391 - 25s - loss: 0.2166 - accuracy: 0.9382 - val_loss: 0.4616 - val_accuracy: 0.8833
Epoch 135/350
391/391 - 25s - loss: 0.2161 - accuracy: 0.9370 - val_loss: 0.4313 - val_accuracy: 0.8922
Epoch 136/350
391/391 - 25s - loss: 0.2147 - accuracy: 0.9380 - val_loss: 0.4284 - val_accuracy: 0.8959
Epoch 137/350
391/391 - 25s - loss: 0.2128 - accuracy: 0.9393 - val_loss: 0.4477 - val_accuracy: 0.8905
Epoch 138/350
391/391 - 25s - loss: 0.2083 - accuracy: 0.9406 - val_loss: 0.4593 - val_accuracy: 0.8884
Epoch 139/350
391/391 - 25s - loss: 0.2080 - accuracy: 0.9408 - val_loss: 0.4406 - val_accuracy: 0.8937
Epoch 140/350
391/391 - 25s - loss: 0.2116 - accuracy: 0.9398 - val_loss: 0.4303 - val_accuracy: 0.8953
Epoch 141/350
391/391 - 25s - loss: 0.2083 - accuracy: 0.9409 - val_loss: 0.4553 - val_accuracy: 0.8913
Epoch 142/350
391/391 - 25s - loss: 0.2096 - accuracy: 0.9399 - val_loss: 0.4274 - val_accuracy: 0.8957
Epoch 143/350
391/391 - 25s - loss: 0.2070 - accuracy: 0.9428 - val_loss: 0.4268 - val_accuracy: 0.8962
Epoch 144/350
391/391 - 25s - loss: 0.2117 - accuracy: 0.9402 - val_loss: 0.4381 - val_accuracy: 0.8969
Epoch 145/350
391/391 - 25s - loss: 0.2025 - accuracy: 0.9428 - val_loss: 0.4315 - val_accuracy: 0.8965
Epoch 146/350
391/391 - 25s - loss: 0.2102 - accuracy: 0.9395 - val_loss: 0.4355 - val_accuracy: 0.8976
Epoch 147/350
391/391 - 25s - loss: 0.2081 - accuracy: 0.9405 - val_loss: 0.4231 - val_accuracy: 0.8965
Epoch 148/350
391/391 - 25s - loss: 0.2013 - accuracy: 0.9437 - val_loss: 0.4194 - val_accuracy: 0.8968
Epoch 149/350
391/391 - 25s - loss: 0.1975 - accuracy: 0.9443 - val_loss: 0.4690 - val_accuracy: 0.8916
Epoch 150/350


Snapshot weight 0 shuffle 5 at epoch 150
Layer 11
Getting activations...


391/391 - 25s - loss: 0.2000 - accuracy: 0.9438 - val_loss: 0.4293 - val_accuracy: 0.8959
Epoch 151/350
391/391 - 25s - loss: 0.1982 - accuracy: 0.9452 - val_loss: 0.4345 - val_accuracy: 0.8978
Epoch 152/350
391/391 - 25s - loss: 0.1979 - accuracy: 0.9432 - val_loss: 0.4918 - val_accuracy: 0.8835
Epoch 153/350
391/391 - 25s - loss: 0.1996 - accuracy: 0.9451 - val_loss: 0.4514 - val_accuracy: 0.8965
Epoch 154/350
391/391 - 25s - loss: 0.1943 - accuracy: 0.9454 - val_loss: 0.4381 - val_accuracy: 0.8952
Epoch 155/350
391/391 - 25s - loss: 0.1975 - accuracy: 0.9453 - val_loss: 0.4756 - val_accuracy: 0.8906
Epoch 156/350
391/391 - 25s - loss: 0.1959 - accuracy: 0.9444 - val_loss: 0.4473 - val_accuracy: 0.8963
Epoch 157/350
391/391 - 25s - loss: 0.1943 - accuracy: 0.9471 - val_loss: 0.4389 - val_accuracy: 0.9021
Epoch 158/350
391/391 - 25s - loss: 0.1907 - accuracy: 0.9477 - val_loss: 0.4395 - val_accuracy: 0.8927
Epoch 159/350
391/391 - 25s - loss: 0.1988 - accuracy: 0.9443 - val_loss: 0.4425 - val_accuracy: 0.8981
Epoch 160/350
391/391 - 25s - loss: 0.1885 - accuracy: 0.9488 - val_loss: 0.4471 - val_accuracy: 0.8962
Epoch 161/350
391/391 - 25s - loss: 0.1921 - accuracy: 0.9464 - val_loss: 0.4289 - val_accuracy: 0.8997
Epoch 162/350
391/391 - 25s - loss: 0.1923 - accuracy: 0.9469 - val_loss: 0.4250 - val_accuracy: 0.8990
Epoch 163/350
391/391 - 25s - loss: 0.1900 - accuracy: 0.9487 - val_loss: 0.4467 - val_accuracy: 0.8963
Epoch 164/350
391/391 - 25s - loss: 0.1880 - accuracy: 0.9482 - val_loss: 0.4225 - val_accuracy: 0.9012
Epoch 165/350
391/391 - 25s - loss: 0.1888 - accuracy: 0.9478 - val_loss: 0.4488 - val_accuracy: 0.8958
Epoch 166/350
391/391 - 25s - loss: 0.1862 - accuracy: 0.9493 - val_loss: 0.4617 - val_accuracy: 0.8957
Epoch 167/350
391/391 - 25s - loss: 0.1865 - accuracy: 0.9487 - val_loss: 0.4697 - val_accuracy: 0.8964
Epoch 168/350
391/391 - 25s - loss: 0.1810 - accuracy: 0.9509 - val_loss: 0.4499 - val_accuracy: 0.8984
Epoch 169/350
391/391 - 25s - loss: 0.1828 - accuracy: 0.9501 - val_loss: 0.4552 - val_accuracy: 0.8996
Epoch 170/350
391/391 - 25s - loss: 0.1856 - accuracy: 0.9496 - val_loss: 0.4781 - val_accuracy: 0.8934
Epoch 171/350
391/391 - 25s - loss: 0.1847 - accuracy: 0.9502 - val_loss: 0.4720 - val_accuracy: 0.8959
Epoch 172/350
391/391 - 25s - loss: 0.1854 - accuracy: 0.9488 - val_loss: 0.4616 - val_accuracy: 0.8957
Epoch 173/350
391/391 - 25s - loss: 0.1807 - accuracy: 0.9519 - val_loss: 0.4847 - val_accuracy: 0.8931
Epoch 174/350
391/391 - 25s - loss: 0.1838 - accuracy: 0.9501 - val_loss: 0.4256 - val_accuracy: 0.9019
Epoch 175/350
391/391 - 25s - loss: 0.1795 - accuracy: 0.9519 - val_loss: 0.4584 - val_accuracy: 0.8964
Epoch 176/350
391/391 - 25s - loss: 0.1831 - accuracy: 0.9512 - val_loss: 0.4487 - val_accuracy: 0.8986
Epoch 177/350
391/391 - 25s - loss: 0.1780 - accuracy: 0.9529 - val_loss: 0.4794 - val_accuracy: 0.8951
Epoch 178/350
391/391 - 25s - loss: 0.1789 - accuracy: 0.9524 - val_loss: 0.4407 - val_accuracy: 0.8999
Epoch 179/350
391/391 - 25s - loss: 0.1774 - accuracy: 0.9534 - val_loss: 0.4504 - val_accuracy: 0.8971
Epoch 180/350
391/391 - 25s - loss: 0.1768 - accuracy: 0.9533 - val_loss: 0.4332 - val_accuracy: 0.8997
Epoch 181/350
391/391 - 25s - loss: 0.1781 - accuracy: 0.9528 - val_loss: 0.4411 - val_accuracy: 0.8987
Epoch 182/350
391/391 - 25s - loss: 0.1749 - accuracy: 0.9536 - val_loss: 0.4457 - val_accuracy: 0.8970
Epoch 183/350
391/391 - 25s - loss: 0.1731 - accuracy: 0.9546 - val_loss: 0.4381 - val_accuracy: 0.9005
Epoch 184/350
391/391 - 25s - loss: 0.1740 - accuracy: 0.9550 - val_loss: 0.4621 - val_accuracy: 0.9008
Epoch 185/350
391/391 - 25s - loss: 0.1725 - accuracy: 0.9546 - val_loss: 0.4636 - val_accuracy: 0.9023
Epoch 186/350
391/391 - 25s - loss: 0.1752 - accuracy: 0.9542 - val_loss: 0.4902 - val_accuracy: 0.8924
Epoch 187/350
391/391 - 25s - loss: 0.1710 - accuracy: 0.9553 - val_loss: 0.4901 - val_accuracy: 0.8939
Epoch 188/350
391/391 - 25s - loss: 0.1718 - accuracy: 0.9540 - val_loss: 0.4792 - val_accuracy: 0.8957
Epoch 189/350
391/391 - 25s - loss: 0.1729 - accuracy: 0.9548 - val_loss: 0.5006 - val_accuracy: 0.8946
Epoch 190/350
391/391 - 25s - loss: 0.1650 - accuracy: 0.9576 - val_loss: 0.4562 - val_accuracy: 0.8984
Epoch 191/350
391/391 - 25s - loss: 0.1711 - accuracy: 0.9555 - val_loss: 0.4485 - val_accuracy: 0.8960
Epoch 192/350
391/391 - 25s - loss: 0.1768 - accuracy: 0.9533 - val_loss: 0.4510 - val_accuracy: 0.8978
Epoch 193/350
391/391 - 25s - loss: 0.1712 - accuracy: 0.9557 - val_loss: 0.4516 - val_accuracy: 0.9000
Epoch 194/350
391/391 - 25s - loss: 0.1699 - accuracy: 0.9560 - val_loss: 0.5146 - val_accuracy: 0.8932
Epoch 195/350
391/391 - 25s - loss: 0.1677 - accuracy: 0.9569 - val_loss: 0.4598 - val_accuracy: 0.8991
Epoch 196/350
391/391 - 25s - loss: 0.1670 - accuracy: 0.9564 - val_loss: 0.4701 - val_accuracy: 0.8965
Epoch 197/350
391/391 - 25s - loss: 0.1649 - accuracy: 0.9576 - val_loss: 0.4655 - val_accuracy: 0.9011
Epoch 198/350
391/391 - 25s - loss: 0.1648 - accuracy: 0.9569 - val_loss: 0.4545 - val_accuracy: 0.9006
Epoch 199/350
391/391 - 25s - loss: 0.1691 - accuracy: 0.9567 - val_loss: 0.4545 - val_accuracy: 0.8993
Epoch 200/350


Snapshot weight 0 shuffle 5 at epoch 200
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1661 - accuracy: 0.9583 - val_loss: 0.4802 - val_accuracy: 0.8934
Epoch 201/350
391/391 - 25s - loss: 0.1398 - accuracy: 0.9668 - val_loss: 0.4390 - val_accuracy: 0.9059
Epoch 202/350
391/391 - 25s - loss: 0.1282 - accuracy: 0.9705 - val_loss: 0.4455 - val_accuracy: 0.9063
Epoch 203/350
391/391 - 25s - loss: 0.1226 - accuracy: 0.9730 - val_loss: 0.4485 - val_accuracy: 0.9064
Epoch 204/350
391/391 - 25s - loss: 0.1234 - accuracy: 0.9726 - val_loss: 0.4627 - val_accuracy: 0.9069
Epoch 205/350
391/391 - 25s - loss: 0.1203 - accuracy: 0.9738 - val_loss: 0.4568 - val_accuracy: 0.9085
Epoch 206/350
391/391 - 25s - loss: 0.1193 - accuracy: 0.9741 - val_loss: 0.4605 - val_accuracy: 0.9073
Epoch 207/350
391/391 - 25s - loss: 0.1174 - accuracy: 0.9749 - val_loss: 0.4735 - val_accuracy: 0.9074
Epoch 208/350
391/391 - 25s - loss: 0.1179 - accuracy: 0.9748 - val_loss: 0.4771 - val_accuracy: 0.9078
Epoch 209/350
391/391 - 25s - loss: 0.1177 - accuracy: 0.9740 - val_loss: 0.4686 - val_accuracy: 0.9074
Epoch 210/350
391/391 - 25s - loss: 0.1168 - accuracy: 0.9747 - val_loss: 0.4680 - val_accuracy: 0.9058
Epoch 211/350
391/391 - 25s - loss: 0.1143 - accuracy: 0.9761 - val_loss: 0.4665 - val_accuracy: 0.9084
Epoch 212/350
391/391 - 25s - loss: 0.1142 - accuracy: 0.9748 - val_loss: 0.4716 - val_accuracy: 0.9096
Epoch 213/350
391/391 - 25s - loss: 0.1178 - accuracy: 0.9749 - val_loss: 0.4701 - val_accuracy: 0.9083
Epoch 214/350
391/391 - 25s - loss: 0.1138 - accuracy: 0.9761 - val_loss: 0.4677 - val_accuracy: 0.9090
Epoch 215/350
391/391 - 25s - loss: 0.1133 - accuracy: 0.9760 - val_loss: 0.4731 - val_accuracy: 0.9086
Epoch 216/350
391/391 - 25s - loss: 0.1138 - accuracy: 0.9762 - val_loss: 0.4855 - val_accuracy: 0.9070
Epoch 217/350
391/391 - 25s - loss: 0.1142 - accuracy: 0.9759 - val_loss: 0.4718 - val_accuracy: 0.9091
Epoch 218/350
391/391 - 25s - loss: 0.1123 - accuracy: 0.9764 - val_loss: 0.4753 - val_accuracy: 0.9087
Epoch 219/350
391/391 - 25s - loss: 0.1137 - accuracy: 0.9761 - val_loss: 0.4852 - val_accuracy: 0.9088
Epoch 220/350
391/391 - 25s - loss: 0.1119 - accuracy: 0.9774 - val_loss: 0.4805 - val_accuracy: 0.9069
Epoch 221/350
391/391 - 25s - loss: 0.1110 - accuracy: 0.9769 - val_loss: 0.4766 - val_accuracy: 0.9096
Epoch 222/350
391/391 - 25s - loss: 0.1095 - accuracy: 0.9772 - val_loss: 0.4861 - val_accuracy: 0.9082
Epoch 223/350
391/391 - 25s - loss: 0.1105 - accuracy: 0.9770 - val_loss: 0.4878 - val_accuracy: 0.9076
Epoch 224/350
391/391 - 25s - loss: 0.1094 - accuracy: 0.9770 - val_loss: 0.4896 - val_accuracy: 0.9092
Epoch 225/350
391/391 - 25s - loss: 0.1115 - accuracy: 0.9768 - val_loss: 0.4831 - val_accuracy: 0.9075
Epoch 226/350
391/391 - 25s - loss: 0.1094 - accuracy: 0.9776 - val_loss: 0.4938 - val_accuracy: 0.9077
Epoch 227/350
391/391 - 25s - loss: 0.1084 - accuracy: 0.9782 - val_loss: 0.4948 - val_accuracy: 0.9075
Epoch 228/350
391/391 - 25s - loss: 0.1069 - accuracy: 0.9774 - val_loss: 0.4892 - val_accuracy: 0.9078
Epoch 229/350
391/391 - 25s - loss: 0.1081 - accuracy: 0.9783 - val_loss: 0.4944 - val_accuracy: 0.9069
Epoch 230/350
391/391 - 25s - loss: 0.1080 - accuracy: 0.9775 - val_loss: 0.4894 - val_accuracy: 0.9093
Epoch 231/350
391/391 - 25s - loss: 0.1070 - accuracy: 0.9784 - val_loss: 0.4854 - val_accuracy: 0.9089
Epoch 232/350
391/391 - 25s - loss: 0.1093 - accuracy: 0.9771 - val_loss: 0.4940 - val_accuracy: 0.9093
Epoch 233/350
391/391 - 25s - loss: 0.1053 - accuracy: 0.9787 - val_loss: 0.4985 - val_accuracy: 0.9077
Epoch 234/350
391/391 - 25s - loss: 0.1075 - accuracy: 0.9781 - val_loss: 0.4998 - val_accuracy: 0.9081
Epoch 235/350
391/391 - 25s - loss: 0.1089 - accuracy: 0.9778 - val_loss: 0.4927 - val_accuracy: 0.9082
Epoch 236/350
391/391 - 25s - loss: 0.1067 - accuracy: 0.9785 - val_loss: 0.5012 - val_accuracy: 0.9080
Epoch 237/350
391/391 - 25s - loss: 0.1044 - accuracy: 0.9792 - val_loss: 0.4956 - val_accuracy: 0.9089
Epoch 238/350
391/391 - 25s - loss: 0.1062 - accuracy: 0.9781 - val_loss: 0.4960 - val_accuracy: 0.9086
Epoch 239/350
391/391 - 25s - loss: 0.1056 - accuracy: 0.9787 - val_loss: 0.5096 - val_accuracy: 0.9084
Epoch 240/350
391/391 - 25s - loss: 0.1071 - accuracy: 0.9779 - val_loss: 0.4964 - val_accuracy: 0.9104
Epoch 241/350
391/391 - 25s - loss: 0.1080 - accuracy: 0.9782 - val_loss: 0.4994 - val_accuracy: 0.9077
Epoch 242/350
391/391 - 25s - loss: 0.1051 - accuracy: 0.9789 - val_loss: 0.5003 - val_accuracy: 0.9076
Epoch 243/350
391/391 - 25s - loss: 0.1062 - accuracy: 0.9792 - val_loss: 0.4941 - val_accuracy: 0.9090
Epoch 244/350
391/391 - 25s - loss: 0.1043 - accuracy: 0.9790 - val_loss: 0.4916 - val_accuracy: 0.9059
Epoch 245/350
391/391 - 25s - loss: 0.1070 - accuracy: 0.9779 - val_loss: 0.4950 - val_accuracy: 0.9106
Epoch 246/350
391/391 - 25s - loss: 0.1060 - accuracy: 0.9786 - val_loss: 0.5084 - val_accuracy: 0.9077
Epoch 247/350
391/391 - 25s - loss: 0.1012 - accuracy: 0.9805 - val_loss: 0.5060 - val_accuracy: 0.9079
Epoch 248/350
391/391 - 25s - loss: 0.1011 - accuracy: 0.9807 - val_loss: 0.4980 - val_accuracy: 0.9093
Epoch 249/350
391/391 - 25s - loss: 0.1043 - accuracy: 0.9797 - val_loss: 0.5046 - val_accuracy: 0.9088
Epoch 250/350


Snapshot weight 0 shuffle 5 at epoch 250
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1048 - accuracy: 0.9792 - val_loss: 0.5034 - val_accuracy: 0.9096
Epoch 251/350
391/391 - 25s - loss: 0.1028 - accuracy: 0.9803 - val_loss: 0.4985 - val_accuracy: 0.9105
Epoch 252/350
391/391 - 25s - loss: 0.1026 - accuracy: 0.9796 - val_loss: 0.4990 - val_accuracy: 0.9100
Epoch 253/350
391/391 - 25s - loss: 0.0985 - accuracy: 0.9807 - val_loss: 0.4999 - val_accuracy: 0.9100
Epoch 254/350
391/391 - 25s - loss: 0.1023 - accuracy: 0.9795 - val_loss: 0.5006 - val_accuracy: 0.9099
Epoch 255/350
391/391 - 25s - loss: 0.1008 - accuracy: 0.9802 - val_loss: 0.5014 - val_accuracy: 0.9097
Epoch 256/350
391/391 - 25s - loss: 0.1024 - accuracy: 0.9803 - val_loss: 0.5013 - val_accuracy: 0.9097
Epoch 257/350
391/391 - 25s - loss: 0.1019 - accuracy: 0.9799 - val_loss: 0.4982 - val_accuracy: 0.9100
Epoch 258/350
391/391 - 25s - loss: 0.1027 - accuracy: 0.9798 - val_loss: 0.5003 - val_accuracy: 0.9098
Epoch 259/350
391/391 - 25s - loss: 0.1015 - accuracy: 0.9805 - val_loss: 0.5008 - val_accuracy: 0.9094
Epoch 260/350
391/391 - 25s - loss: 0.1018 - accuracy: 0.9799 - val_loss: 0.5011 - val_accuracy: 0.9094
Epoch 261/350
391/391 - 25s - loss: 0.1006 - accuracy: 0.9795 - val_loss: 0.5009 - val_accuracy: 0.9088
Epoch 262/350
391/391 - 25s - loss: 0.1025 - accuracy: 0.9799 - val_loss: 0.5004 - val_accuracy: 0.9092
Epoch 263/350
391/391 - 25s - loss: 0.1012 - accuracy: 0.9803 - val_loss: 0.5028 - val_accuracy: 0.9086
Epoch 264/350
391/391 - 25s - loss: 0.1002 - accuracy: 0.9814 - val_loss: 0.5042 - val_accuracy: 0.9079
Epoch 265/350
391/391 - 25s - loss: 0.1001 - accuracy: 0.9804 - val_loss: 0.5016 - val_accuracy: 0.9090
Epoch 266/350
391/391 - 25s - loss: 0.1007 - accuracy: 0.9807 - val_loss: 0.5013 - val_accuracy: 0.9093
Epoch 267/350
391/391 - 25s - loss: 0.1009 - accuracy: 0.9802 - val_loss: 0.5035 - val_accuracy: 0.9084
Epoch 268/350
391/391 - 25s - loss: 0.0999 - accuracy: 0.9808 - val_loss: 0.5004 - val_accuracy: 0.9091
Epoch 269/350
391/391 - 25s - loss: 0.1013 - accuracy: 0.9798 - val_loss: 0.5025 - val_accuracy: 0.9091
Epoch 270/350
391/391 - 25s - loss: 0.1023 - accuracy: 0.9801 - val_loss: 0.5014 - val_accuracy: 0.9093
Epoch 271/350
391/391 - 25s - loss: 0.0991 - accuracy: 0.9814 - val_loss: 0.5042 - val_accuracy: 0.9090
Epoch 272/350
391/391 - 25s - loss: 0.1003 - accuracy: 0.9806 - val_loss: 0.5014 - val_accuracy: 0.9088
Epoch 273/350
391/391 - 25s - loss: 0.0989 - accuracy: 0.9811 - val_loss: 0.5012 - val_accuracy: 0.9095
Epoch 274/350
391/391 - 25s - loss: 0.1010 - accuracy: 0.9803 - val_loss: 0.5008 - val_accuracy: 0.9091
Epoch 275/350
391/391 - 25s - loss: 0.1018 - accuracy: 0.9807 - val_loss: 0.4997 - val_accuracy: 0.9094
Epoch 276/350
391/391 - 25s - loss: 0.0998 - accuracy: 0.9803 - val_loss: 0.5032 - val_accuracy: 0.9085
Epoch 277/350
391/391 - 25s - loss: 0.1006 - accuracy: 0.9808 - val_loss: 0.5040 - val_accuracy: 0.9089
Epoch 278/350
391/391 - 25s - loss: 0.0991 - accuracy: 0.9809 - val_loss: 0.5044 - val_accuracy: 0.9092
Epoch 279/350
391/391 - 25s - loss: 0.1015 - accuracy: 0.9808 - val_loss: 0.5026 - val_accuracy: 0.9098
Epoch 280/350
391/391 - 25s - loss: 0.0961 - accuracy: 0.9814 - val_loss: 0.5043 - val_accuracy: 0.9081
Epoch 281/350
391/391 - 25s - loss: 0.1000 - accuracy: 0.9808 - val_loss: 0.5043 - val_accuracy: 0.9079
Epoch 282/350
391/391 - 25s - loss: 0.1004 - accuracy: 0.9810 - val_loss: 0.5047 - val_accuracy: 0.9090
Epoch 283/350
391/391 - 25s - loss: 0.1011 - accuracy: 0.9810 - val_loss: 0.5062 - val_accuracy: 0.9088
Epoch 284/350
391/391 - 25s - loss: 0.1013 - accuracy: 0.9804 - val_loss: 0.5007 - val_accuracy: 0.9088
Epoch 285/350
391/391 - 25s - loss: 0.1003 - accuracy: 0.9807 - val_loss: 0.5021 - val_accuracy: 0.9085
Epoch 286/350
391/391 - 25s - loss: 0.0993 - accuracy: 0.9812 - val_loss: 0.5034 - val_accuracy: 0.9087
Epoch 287/350
391/391 - 25s - loss: 0.1005 - accuracy: 0.9807 - val_loss: 0.5033 - val_accuracy: 0.9090
Epoch 288/350
391/391 - 25s - loss: 0.1001 - accuracy: 0.9803 - val_loss: 0.5023 - val_accuracy: 0.9092
Epoch 289/350
391/391 - 25s - loss: 0.1034 - accuracy: 0.9799 - val_loss: 0.5028 - val_accuracy: 0.9085
Epoch 290/350
391/391 - 25s - loss: 0.1000 - accuracy: 0.9808 - val_loss: 0.5017 - val_accuracy: 0.9088
Epoch 291/350
391/391 - 25s - loss: 0.1000 - accuracy: 0.9806 - val_loss: 0.5040 - val_accuracy: 0.9090
Epoch 292/350
391/391 - 25s - loss: 0.0998 - accuracy: 0.9808 - val_loss: 0.5023 - val_accuracy: 0.9090
Epoch 293/350
391/391 - 25s - loss: 0.0995 - accuracy: 0.9809 - val_loss: 0.5025 - val_accuracy: 0.9092
Epoch 294/350
391/391 - 25s - loss: 0.0965 - accuracy: 0.9817 - val_loss: 0.5045 - val_accuracy: 0.9093
Epoch 295/350
391/391 - 25s - loss: 0.0991 - accuracy: 0.9810 - val_loss: 0.5035 - val_accuracy: 0.9091
Epoch 296/350
391/391 - 25s - loss: 0.1011 - accuracy: 0.9800 - val_loss: 0.5022 - val_accuracy: 0.9095
Epoch 297/350
391/391 - 25s - loss: 0.1001 - accuracy: 0.9802 - val_loss: 0.5024 - val_accuracy: 0.9092
Epoch 298/350
391/391 - 25s - loss: 0.1002 - accuracy: 0.9807 - val_loss: 0.5036 - val_accuracy: 0.9089
Epoch 299/350
391/391 - 25s - loss: 0.0981 - accuracy: 0.9811 - val_loss: 0.5019 - val_accuracy: 0.9088
Epoch 300/350


Snapshot weight 0 shuffle 5 at epoch 300
Layer 11
Getting activations...


391/391 - 25s - loss: 0.1023 - accuracy: 0.9798 - val_loss: 0.5018 - val_accuracy: 0.9093
Epoch 301/350
391/391 - 25s - loss: 0.1008 - accuracy: 0.9807 - val_loss: 0.5027 - val_accuracy: 0.9093
Epoch 302/350
391/391 - 25s - loss: 0.0992 - accuracy: 0.9819 - val_loss: 0.5029 - val_accuracy: 0.9097
Epoch 303/350
391/391 - 25s - loss: 0.0994 - accuracy: 0.9812 - val_loss: 0.5033 - val_accuracy: 0.9095
Epoch 304/350
391/391 - 25s - loss: 0.1016 - accuracy: 0.9800 - val_loss: 0.5030 - val_accuracy: 0.9095
Epoch 305/350
391/391 - 25s - loss: 0.0989 - accuracy: 0.9806 - val_loss: 0.5033 - val_accuracy: 0.9094
Epoch 306/350
391/391 - 25s - loss: 0.0998 - accuracy: 0.9810 - val_loss: 0.5033 - val_accuracy: 0.9093
Epoch 307/350
391/391 - 25s - loss: 0.0996 - accuracy: 0.9808 - val_loss: 0.5036 - val_accuracy: 0.9090
Epoch 308/350
391/391 - 25s - loss: 0.1004 - accuracy: 0.9813 - val_loss: 0.5038 - val_accuracy: 0.9089
Epoch 309/350
391/391 - 25s - loss: 0.1005 - accuracy: 0.9811 - val_loss: 0.5040 - val_accuracy: 0.9089
Epoch 310/350
391/391 - 25s - loss: 0.0991 - accuracy: 0.9811 - val_loss: 0.5040 - val_accuracy: 0.9089
Epoch 311/350
391/391 - 25s - loss: 0.1003 - accuracy: 0.9804 - val_loss: 0.5040 - val_accuracy: 0.9092
Epoch 312/350
391/391 - 25s - loss: 0.1007 - accuracy: 0.9805 - val_loss: 0.5039 - val_accuracy: 0.9089
Epoch 313/350
391/391 - 25s - loss: 0.0994 - accuracy: 0.9809 - val_loss: 0.5040 - val_accuracy: 0.9087
Epoch 314/350
391/391 - 25s - loss: 0.0991 - accuracy: 0.9811 - val_loss: 0.5039 - val_accuracy: 0.9092
Epoch 315/350
391/391 - 25s - loss: 0.1004 - accuracy: 0.9804 - val_loss: 0.5036 - val_accuracy: 0.9091
Epoch 316/350
391/391 - 25s - loss: 0.0991 - accuracy: 0.9809 - val_loss: 0.5037 - val_accuracy: 0.9092
Epoch 317/350
391/391 - 25s - loss: 0.0997 - accuracy: 0.9803 - val_loss: 0.5038 - val_accuracy: 0.9092
Epoch 318/350
391/391 - 25s - loss: 0.0993 - accuracy: 0.9814 - val_loss: 0.5042 - val_accuracy: 0.9091
Epoch 319/350
391/391 - 25s - loss: 0.0986 - accuracy: 0.9811 - val_loss: 0.5043 - val_accuracy: 0.9091
Epoch 320/350
391/391 - 25s - loss: 0.0983 - accuracy: 0.9810 - val_loss: 0.5044 - val_accuracy: 0.9090
Epoch 321/350
391/391 - 25s - loss: 0.0990 - accuracy: 0.9810 - val_loss: 0.5042 - val_accuracy: 0.9089
Epoch 322/350
391/391 - 25s - loss: 0.0994 - accuracy: 0.9806 - val_loss: 0.5041 - val_accuracy: 0.9092
Epoch 323/350
391/391 - 25s - loss: 0.0990 - accuracy: 0.9811 - val_loss: 0.5045 - val_accuracy: 0.9090
Epoch 324/350
391/391 - 25s - loss: 0.0991 - accuracy: 0.9816 - val_loss: 0.5048 - val_accuracy: 0.9090
Epoch 325/350
391/391 - 25s - loss: 0.0983 - accuracy: 0.9810 - val_loss: 0.5047 - val_accuracy: 0.9091
Epoch 326/350
391/391 - 25s - loss: 0.0987 - accuracy: 0.9812 - val_loss: 0.5045 - val_accuracy: 0.9090
Epoch 327/350
391/391 - 25s - loss: 0.0990 - accuracy: 0.9820 - val_loss: 0.5046 - val_accuracy: 0.9090
Epoch 328/350
391/391 - 25s - loss: 0.0976 - accuracy: 0.9816 - val_loss: 0.5046 - val_accuracy: 0.9090
Epoch 329/350
391/391 - 25s - loss: 0.0986 - accuracy: 0.9810 - val_loss: 0.5046 - val_accuracy: 0.9091
Epoch 330/350
391/391 - 25s - loss: 0.0984 - accuracy: 0.9816 - val_loss: 0.5038 - val_accuracy: 0.9093
Epoch 331/350
391/391 - 25s - loss: 0.1005 - accuracy: 0.9813 - val_loss: 0.5037 - val_accuracy: 0.9092
Epoch 332/350
391/391 - 25s - loss: 0.1015 - accuracy: 0.9800 - val_loss: 0.5038 - val_accuracy: 0.9091
Epoch 333/350
391/391 - 25s - loss: 0.0995 - accuracy: 0.9800 - val_loss: 0.5040 - val_accuracy: 0.9086
Epoch 334/350
391/391 - 25s - loss: 0.0974 - accuracy: 0.9815 - val_loss: 0.5046 - val_accuracy: 0.9088
Epoch 335/350
391/391 - 25s - loss: 0.0996 - accuracy: 0.9800 - val_loss: 0.5046 - val_accuracy: 0.9087
Epoch 336/350
391/391 - 25s - loss: 0.1008 - accuracy: 0.9800 - val_loss: 0.5046 - val_accuracy: 0.9089
Epoch 337/350
391/391 - 25s - loss: 0.0990 - accuracy: 0.9807 - val_loss: 0.5046 - val_accuracy: 0.9088
Epoch 338/350
391/391 - 25s - loss: 0.0975 - accuracy: 0.9819 - val_loss: 0.5045 - val_accuracy: 0.9090
Epoch 339/350
391/391 - 25s - loss: 0.0986 - accuracy: 0.9808 - val_loss: 0.5045 - val_accuracy: 0.9087
Epoch 340/350
391/391 - 25s - loss: 0.1006 - accuracy: 0.9801 - val_loss: 0.5047 - val_accuracy: 0.9086
Epoch 341/350
391/391 - 25s - loss: 0.0996 - accuracy: 0.9806 - val_loss: 0.5046 - val_accuracy: 0.9089
Epoch 342/350
391/391 - 25s - loss: 0.0982 - accuracy: 0.9814 - val_loss: 0.5044 - val_accuracy: 0.9085
Epoch 343/350
391/391 - 25s - loss: 0.1001 - accuracy: 0.9802 - val_loss: 0.5040 - val_accuracy: 0.9089
Epoch 344/350
391/391 - 25s - loss: 0.0968 - accuracy: 0.9820 - val_loss: 0.5042 - val_accuracy: 0.9085
Epoch 345/350
391/391 - 25s - loss: 0.0996 - accuracy: 0.9807 - val_loss: 0.5039 - val_accuracy: 0.9087
Epoch 346/350
391/391 - 25s - loss: 0.0974 - accuracy: 0.9819 - val_loss: 0.5040 - val_accuracy: 0.9089
Epoch 347/350
391/391 - 25s - loss: 0.0997 - accuracy: 0.9804 - val_loss: 0.5038 - val_accuracy: 0.9090
Epoch 348/350
391/391 - 25s - loss: 0.0993 - accuracy: 0.9819 - val_loss: 0.5041 - val_accuracy: 0.9088
Epoch 349/350
391/391 - 25s - loss: 0.0990 - accuracy: 0.9808 - val_loss: 0.5041 - val_accuracy: 0.9089
Epoch 350/350


Snapshot weight 0 shuffle 5 at epoch 350
Layer 11
Getting activations...


391/391 - 25s - loss: 0.0982 - accuracy: 0.9815 - val_loss: 0.5041 - val_accuracy: 0.9086
/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:493: UserWarning: fill_value is not supported and is always 0 for TensorFlow < 2.4.0.
  return py_builtins.overload_of(f)(*args)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2021-07-02 09:34:43.635972: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
Saving, final validation acc: 0.9085999727249146
